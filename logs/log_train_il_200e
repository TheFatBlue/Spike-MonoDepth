/root/miniconda3/envs/scv/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Trainable parameters: 20545951
S2DepthTransformerUNetConv(
  (encoder): LongSpikeStreamEncoderConv(
    (swin3d): SwinTransformer3D(
      (patch_embed): PatchEmbedLocalGlobal(
        (head): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (global_head): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (global_residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (global_proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=384, out_features=192, bias=False)
            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=768, out_features=384, bias=False)
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
    (conv_layers): ModuleList(
      (0): ModuleList(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ModuleList(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ModuleList(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (resblocks): ModuleList(
    (0): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (decoders): ModuleList(
    (0): UpsampleConvLayer(
      (conv2d): Conv2d(384, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (1): UpsampleConvLayer(
      (conv2d): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (2): UpsampleConvLayer(
      (conv2d): Conv2d(96, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (pred): ConvLayer(
    (conv2d): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)
Setting up Multi Scale Gradient loss...
Done
---- Single Training ----
Use GPU: 0 for training
Found 26 samples in /root/autodl-tmp/Spike-Stero/train
Found 8 samples in /root/autodl-tmp/Spike-Stero/validation
-----  [3, 6, 12]
---- new version 4 ----
Model Initialized
Using scale_invariant_loss with config {'weight': 1.0, 'n_lambda': 1.0}
Will not use phased architecture
Using Multi Scale Gradient loss with weight=0.25
Will not use MSE loss
Train Epoch: 1 [0/816 (0%)] loss: 0.0224 L_si: 0.0003 L_grad: 0.0221 
Train Epoch: 1 [36/816 (4%)] loss: 0.0179 L_si: 0.0005 L_grad: 0.0174 
Train Epoch: 1 [72/816 (9%)] loss: 0.0053 L_si: 0.0000 L_grad: 0.0053 
Train Epoch: 1 [108/816 (13%)] loss: 0.0024 L_si: 0.0000 L_grad: 0.0024 
Train Epoch: 1 [144/816 (18%)] loss: 0.0017 L_si: 0.0000 L_grad: 0.0016 
Train Epoch: 1 [180/816 (22%)] loss: 0.0011 L_si: 0.0000 L_grad: 0.0011 
Train Epoch: 1 [216/816 (26%)] loss: 0.0009 L_si: 0.0000 L_grad: 0.0009 
Train Epoch: 1 [252/816 (31%)] loss: 0.0007 L_si: 0.0000 L_grad: 0.0007 
Train Epoch: 1 [288/816 (35%)] loss: 0.0005 L_si: 0.0000 L_grad: 0.0005 
Train Epoch: 1 [324/816 (40%)] loss: 0.0005 L_si: 0.0000 L_grad: 0.0005 
Train Epoch: 1 [360/816 (44%)] loss: 0.0004 L_si: 0.0000 L_grad: 0.0004 
Train Epoch: 1 [396/816 (49%)] loss: 0.0004 L_si: 0.0000 L_grad: 0.0004 
Train Epoch: 1 [432/816 (53%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [468/816 (57%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [504/816 (62%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [540/816 (66%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [576/816 (71%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [612/816 (75%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [648/816 (79%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [684/816 (84%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [720/816 (88%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [756/816 (93%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [792/816 (97%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.00030027638422325253, 0.00029466941487044096, 0.0003245527623221278, 0.0003462712047621608, 0.00022219715174287558, 0.0002810550795402378, 0.0002885853755287826, 0.0002552115765865892, 0.00021772530453745276, 0.000289185147266835, 0.0003404382732696831, 0.00022811806411482394, 0.0003220113576389849, 0.00026199885178357363, 0.0002448511077091098, 0.0003132034617010504, 0.0002612163661979139, 0.000297316670184955, 8.470275497529656e-05], 'L_si': [1.7881393432617188e-07, 2.086162567138672e-07, 2.384185791015625e-07, 3.5762786865234375e-07, 1.1920928955078125e-07, 2.682209014892578e-07, 1.7881393432617188e-07, 1.1920928955078125e-07, 8.940696716308594e-08, 2.086162567138672e-07, 2.086162567138672e-07, 8.940696716308594e-08, 2.384185791015625e-07, 1.4901161193847656e-07, 2.086162567138672e-07, 2.682209014892578e-07, 2.086162567138672e-07, 2.086162567138672e-07, 3.2782554626464844e-07], 'L_grad': [0.00030009757028892636, 0.0002944607986137271, 0.00032431434374302626, 0.00034591357689350843, 0.0002220779424533248, 0.0002807868586387485, 0.00028840656159445643, 0.00025509236729703844, 0.00021763589757028967, 0.0002889765310101211, 0.00034022965701296926, 0.00022802865714766085, 0.00032177293905988336, 0.00026184984017163515, 0.0002446424914523959, 0.00031293524079956114, 0.0002610077499412, 0.00029710805392824113, 8.437492942903191e-05]}
Train Epoch: 2 [0/816 (0%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 2 [36/816 (4%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [72/816 (9%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [108/816 (13%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [144/816 (18%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [180/816 (22%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [216/816 (26%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [252/816 (31%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [288/816 (35%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [324/816 (40%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [360/816 (44%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [396/816 (49%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [432/816 (53%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.00015935338160488755, 0.00016036626766435802, 0.00016400983440689743, 0.00016207044245675206, 0.00015471098595298827, 0.00016688948380760849, 0.0001725288457237184, 0.00016346907068509609, 0.0001513013121439144, 0.00016336928820237517, 0.00015431109932251275, 0.00014800700591877103, 0.00015595457807648927, 0.0001715939142741263, 0.00015976963913999498, 0.00015418449766002595, 0.00015474145766347647, 0.00015301196253858507, 3.866126644425094e-05], 'L_si': [0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 8.940696716308594e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0], 'L_grad': [0.00015935338160488755, 0.00016033646534197032, 0.00016395022976212204, 0.00016201083781197667, 0.00015471098595298827, 0.0001668596814852208, 0.0001724990434013307, 0.0001634094660403207, 0.0001513311144663021, 0.00016330968355759978, 0.00015425149467773736, 0.00014794740127399564, 0.00015586517110932618, 0.0001715641119517386, 0.00015976963913999498, 0.00015415469533763826, 0.00015474145766347647, 0.00015295235789380968, 3.866126644425094e-05]}
Train Epoch: 3 [0/816 (0%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [36/816 (4%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [216/816 (26%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [360/816 (44%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [396/816 (49%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [432/816 (53%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [648/816 (79%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [792/816 (97%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [7.341626042034477e-05, 7.214338984340429e-05, 8.531869389116764e-05, 8.445086132269353e-05, 8.090455230558291e-05, 7.81148046371527e-05, 7.56787194404751e-05, 8.036392682697624e-05, 7.761170127196237e-05, 7.885711966082454e-05, 7.409344834741205e-05, 8.163102756952867e-05, 7.031670975266024e-05, 7.30062965885736e-05, 8.048038580454886e-05, 7.40149334887974e-05, 6.98422227287665e-05, 7.228229515021667e-05, 2.0676532585639507e-05], 'L_si': [0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [7.341626042034477e-05, 7.217319216579199e-05, 8.537829853594303e-05, 8.442105900030583e-05, 8.09343546279706e-05, 7.8085002314765e-05, 7.56787194404751e-05, 8.033412450458854e-05, 7.767130591673777e-05, 7.882731733843684e-05, 7.409344834741205e-05, 8.163102756952867e-05, 7.028690743027255e-05, 7.30360989109613e-05, 8.039097883738577e-05, 7.40149334887974e-05, 6.98124204063788e-05, 7.225249282782897e-05, 2.0616927940864116e-05]}
Train Epoch: 4 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [180/816 (22%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [216/816 (26%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [288/816 (35%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [360/816 (44%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [396/816 (49%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [504/816 (62%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [612/816 (75%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch004-loss-0.0001.pth.tar ...
all losses in batch in validation:  {'loss': [9.943173063220456e-05, 0.0001057522022165358, 0.000107659085188061, 0.0001028448241413571, 9.813968790695071e-05, 9.937529102899134e-05, 0.00010026436939369887, 0.00010228052269667387, 0.00010133702744496986, 0.00010427356028230861, 0.0001066201293724589, 9.684246469987556e-05, 0.00010558216308709234, 0.00011333278962410986, 0.00010410440154373646, 0.00010098162601934746, 0.00011093715875176713, 0.00010337838466512039, 2.5059563995455392e-05], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08], 'L_grad': [9.946153295459226e-05, 0.0001057820045389235, 0.0001076292828656733, 0.00010290442878613248, 9.810988558456302e-05, 9.934548870660365e-05, 0.00010023456707131118, 0.00010228052269667387, 0.00010130722512258217, 0.00010424375795992091, 0.00010656052472768351, 9.681266237748787e-05, 0.00010555236076470464, 0.00011333278962410986, 0.00010404479689896107, 0.00010095182369695976, 0.00011093715875176713, 0.00010337838466512039, 2.5029761673067696e-05]}
Train Epoch: 5 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [216/816 (26%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 5 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 5 [576/816 (71%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 5 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 5 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.35933315102011e-05, 8.244927448686212e-05, 8.439023804385215e-05, 7.509986608056352e-05, 7.910898420959711e-05, 7.692094368394464e-05, 8.262120536528528e-05, 8.327531395480037e-05, 7.532729068771005e-05, 8.191457891371101e-05, 8.557754335924983e-05, 7.813177217030898e-05, 8.125911699607968e-05, 7.559695950476453e-05, 8.085730951279402e-05, 8.411975431954488e-05, 8.47309420350939e-05, 7.785202615195885e-05, 2.16310490941396e-05], 'L_si': [0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 8.940696716308594e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [8.35933315102011e-05, 8.244927448686212e-05, 8.436043572146446e-05, 7.509986608056352e-05, 7.910898420959711e-05, 7.692094368394464e-05, 8.262120536528528e-05, 8.324551163241267e-05, 7.529748836532235e-05, 8.188477659132332e-05, 8.551793871447444e-05, 7.804236520314589e-05, 8.125911699607968e-05, 7.559695950476453e-05, 8.085730951279402e-05, 8.414955664193258e-05, 8.470113971270621e-05, 7.788182847434655e-05, 2.1571444449364208e-05]}
Train Epoch: 6 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [360/816 (44%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 6 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 6 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 6 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 6 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 6 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.2308398658642545e-05, 3.226811531931162e-05, 3.4902106563095e-05, 3.304872734588571e-05, 3.80177516490221e-05, 3.183606895618141e-05, 3.694564657052979e-05, 4.000114495283924e-05, 3.598730472731404e-05, 3.57087301381398e-05, 3.154457954224199e-05, 3.591650602174923e-05, 3.46372471540235e-05, 3.252576425438747e-05, 3.576152084860951e-05, 3.823027145699598e-05, 3.513562842272222e-05, 3.469401417532936e-05, 8.120802704070229e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 0.0, 8.940696716308594e-08, -2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [3.227859633625485e-05, 3.2297917641699314e-05, 3.49319088854827e-05, 3.3018925023498014e-05, 3.798794932663441e-05, 3.180626663379371e-05, 3.694564657052979e-05, 3.9911737985676154e-05, 3.598730472731404e-05, 3.564912549336441e-05, 3.1514777219854295e-05, 3.5946308344136924e-05, 3.4667049476411194e-05, 3.243635728722438e-05, 3.576152084860951e-05, 3.823027145699598e-05, 3.5046221455559134e-05, 3.472381649771705e-05, 8.18040734884562e-06]}
Train Epoch: 7 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.21878724207636e-05, 3.4894736018031836e-05, 3.42712810379453e-05, 3.079644375247881e-05, 3.3584281482035294e-05, 3.086162905674428e-05, 3.0449988116743043e-05, 3.610335988923907e-05, 3.585351805668324e-05, 3.305319478386082e-05, 3.396505780983716e-05, 3.537567681632936e-05, 3.074173946515657e-05, 3.107036172877997e-05, 3.242088496335782e-05, 3.440716682234779e-05, 3.6037461541127414e-05, 3.355554144945927e-05, 6.841747563157696e-06], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [3.21878724207636e-05, 3.492453834041953e-05, 3.42712810379453e-05, 3.079644375247881e-05, 3.35544791596476e-05, 3.086162905674428e-05, 3.047979043913074e-05, 3.613316221162677e-05, 3.582371573429555e-05, 3.305319478386082e-05, 3.402466245461255e-05, 3.5345874493941665e-05, 3.0711937142768875e-05, 3.112996637355536e-05, 3.242088496335782e-05, 3.4377364499960095e-05, 3.600765921873972e-05, 3.361514609423466e-05, 6.871549885545392e-06]}
Train Epoch: 8 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch008-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.7145007556537166e-05, 4.7153316700132564e-05, 4.377654113341123e-05, 4.1168175812345e-05, 4.934325261274353e-05, 5.097313260193914e-05, 4.613128839991987e-05, 4.4624783186009154e-05, 4.6137294702930376e-05, 4.671717033488676e-05, 4.8429170419694856e-05, 4.5874694478698075e-05, 4.5532437070505694e-05, 4.584439375321381e-05, 4.645644730771892e-05, 5.105911259306595e-05, 4.6614288294222206e-05, 4.245217132847756e-05, 1.188565329357516e-05], 'L_si': [0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [4.7145007556537166e-05, 4.712351437774487e-05, 4.371693648863584e-05, 4.110857116756961e-05, 4.934325261274353e-05, 5.0883725634776056e-05, 4.610148607753217e-05, 4.459498086362146e-05, 4.6137294702930376e-05, 4.671717033488676e-05, 4.839936809730716e-05, 4.5874694478698075e-05, 4.5502634748118e-05, 4.581459143082611e-05, 4.642664498533122e-05, 5.102931027067825e-05, 4.658448597183451e-05, 4.2422369006089866e-05, 1.1855850971187465e-05]}
Train Epoch: 9 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [2.8047768864780664e-05, 3.2353593269363046e-05, 2.3294151105801575e-05, 2.5840943635557778e-05, 3.0587245419155806e-05, 3.2578416721662506e-05, 2.2071371859055944e-05, 2.3939468519529328e-05, 2.461539042997174e-05, 2.3351720301434398e-05, 3.215811011614278e-05, 2.6579524273984134e-05, 3.169546471326612e-05, 2.458376548020169e-05, 3.152310455334373e-05, 2.9659891879418865e-05, 2.7794481866294518e-05, 2.6193960366072133e-05, 6.239270078367554e-06], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0], 'L_grad': [2.7988164220005274e-05, 3.232379094697535e-05, 2.3353755750576966e-05, 2.5811141313170083e-05, 3.06170477415435e-05, 3.254861439927481e-05, 2.2071371859055944e-05, 2.3939468519529328e-05, 2.4585588107584044e-05, 2.3381522623822093e-05, 3.2187912438530475e-05, 2.6639128918759525e-05, 3.163586006849073e-05, 2.4643370124977082e-05, 3.152310455334373e-05, 2.963008955703117e-05, 2.7794481866294518e-05, 2.6193960366072133e-05, 6.239270078367554e-06]}
Train Epoch: 10 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.843002792156767e-05, 1.5089949556568172e-05, 1.795061325537972e-05, 1.9409068045206368e-05, 1.8521805031923577e-05, 1.4613760868087411e-05, 1.7390388165949844e-05, 1.605483703315258e-05, 1.6061252608778886e-05, 1.9863797206198797e-05, 1.5068550055730157e-05, 1.565416641824413e-05, 1.3286999092088081e-05, 1.819748467823956e-05, 1.8982751498697326e-05, 1.8324444681638852e-05, 1.7402653611497954e-05, 1.329101542069111e-05, 2.89173567580292e-06], 'L_si': [0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [1.843002792156767e-05, 1.5030344911792781e-05, 1.7920810932992026e-05, 1.9438870367594063e-05, 1.8521805031923577e-05, 1.4643563190475106e-05, 1.7330783521174453e-05, 1.605483703315258e-05, 1.6001647964003496e-05, 1.9893599528586492e-05, 1.5068550055730157e-05, 1.565416641824413e-05, 1.3316801414475776e-05, 1.8227287000627257e-05, 1.8982751498697326e-05, 1.8384049326414242e-05, 1.743245593388565e-05, 1.3320817743078806e-05, 2.89173567580292e-06]}
Train Epoch: 11 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.736140256980434e-05, 1.8262668163515627e-05, 1.7131118511315435e-05, 1.627259553060867e-05, 1.7335945813101716e-05, 1.8090184312313795e-05, 1.815660289139487e-05, 1.5191313650575466e-05, 1.9136259652441368e-05, 1.796926517272368e-05, 1.975829218281433e-05, 1.768003130564466e-05, 1.8291819287696853e-05, 1.7825408576754853e-05, 1.8396152881905437e-05, 1.7115648006438278e-05, 1.7553033103467897e-05, 1.703281668596901e-05, 3.75884792447323e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.7391204892192036e-05, 1.8232865841127932e-05, 1.716092083370313e-05, 1.627259553060867e-05, 1.7335945813101716e-05, 1.811998663470149e-05, 1.8126800569007173e-05, 1.5221115972963162e-05, 1.9136259652441368e-05, 1.7939462850335985e-05, 1.975829218281433e-05, 1.7709833628032357e-05, 1.8291819287696853e-05, 1.785521089914255e-05, 1.8396152881905437e-05, 1.7175252651213668e-05, 1.75232307810802e-05, 1.7003014363581315e-05, 3.7290456020855345e-06]}
Train Epoch: 12 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch012-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [9.786489499674644e-06, 9.00394661584869e-06, 1.0471240784681868e-05, 9.33623050514143e-06, 9.827174835663754e-06, 8.794599125394598e-06, 1.0048036529042292e-05, 9.933117325999774e-06, 9.263688298233319e-06, 9.112630323215853e-06, 9.663971468398813e-06, 9.605047125660349e-06, 8.288481694762595e-06, 1.0111550182045903e-05, 9.847761248238385e-06, 9.673147360445e-06, 8.750323104322888e-06, 9.250624316337053e-06, 2.3392890398099553e-06], 'L_si': [0.0, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [9.786489499674644e-06, 9.00394661584869e-06, 1.0471240784681868e-05, 9.366032827529125e-06, 9.79737251327606e-06, 8.824401447782293e-06, 1.0048036529042292e-05, 9.96291964838747e-06, 9.293490620621014e-06, 9.112630323215853e-06, 9.663971468398813e-06, 9.605047125660349e-06, 8.228877049987204e-06, 1.0051945537270512e-05, 9.788156603462994e-06, 9.673147360445e-06, 8.750323104322888e-06, 9.280426638724748e-06, 2.2796843950345647e-06]}
Train Epoch: 13 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [8.432611139141954e-06, 7.228658432723023e-06, 7.975389962666668e-06, 8.0638455983717e-06, 5.995569608785445e-06, 7.809067028574646e-06, 7.080469003994949e-06, 9.682138625066727e-06, 9.977386980608571e-06, 8.630626325611956e-06, 7.134961379051674e-06, 6.8765048126806505e-06, 7.757891580695286e-06, 7.479869054805022e-06, 6.48849436402088e-06, 8.252407496911474e-06, 8.61402259033639e-06, 8.682942279847339e-06, 1.8084379007632378e-06], 'L_si': [0.0, 2.9802322387695312e-08, 8.940696716308594e-08, 5.960464477539063e-08, -5.960464477539063e-08, 0.0, -8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [8.432611139141954e-06, 7.198856110335328e-06, 7.885982995503582e-06, 8.004240953596309e-06, 6.0551742535608355e-06, 7.809067028574646e-06, 7.169875971158035e-06, 9.652336302679032e-06, 1.0007189302996267e-05, 8.660428647999652e-06, 7.105159056663979e-06, 6.8765048126806505e-06, 7.757891580695286e-06, 7.539473699580412e-06, 6.48849436402088e-06, 8.252407496911474e-06, 8.584220267948695e-06, 8.682942279847339e-06, 1.7786355783755425e-06]}
Train Epoch: 14 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0041959285445046e-05, 1.106575109588448e-05, 1.0173011105507612e-05, 1.3396796020970214e-05, 1.0275010936311446e-05, 9.604428669263143e-06, 1.1416835150157567e-05, 1.008650451694848e-05, 1.0798454241012223e-05, 1.3918250260758214e-05, 1.1477000953163952e-05, 9.841404789767694e-06, 8.475717550027184e-06, 1.2850848179368768e-05, 1.173992313852068e-05, 1.1633393114607316e-05, 9.352684173791204e-06, 1.137614617618965e-05, 3.85227394872345e-06], 'L_si': [-2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.0071761607832741e-05, 1.106575109588448e-05, 1.0202813427895308e-05, 1.3396796020970214e-05, 1.0275010936311446e-05, 9.634230991650838e-06, 1.1446637472545262e-05, 1.008650451694848e-05, 1.0798454241012223e-05, 1.3888447938370518e-05, 1.1506803275551647e-05, 9.871207112155389e-06, 8.475717550027184e-06, 1.2910452824144159e-05, 1.1799527783296071e-05, 1.1633393114607316e-05, 9.322881851403508e-06, 1.1405948498577345e-05, 3.882076271111146e-06]}
Train Epoch: 15 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [5.952388164587319e-06, 7.784550689393654e-06, 5.836862328578718e-06, 6.264699550229125e-06, 6.3028019212652e-06, 6.7664104790310375e-06, 7.290435860340949e-06, 7.134520274121314e-06, 6.707495685986942e-06, 6.374001259246143e-06, 6.652712727373e-06, 6.876050974824466e-06, 5.961426268186187e-06, 5.776847501692828e-06, 6.026179107720964e-06, 7.361391453741817e-06, 6.203773409652058e-06, 6.969613878027303e-06, 1.6790020254120464e-06], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08], 'L_grad': [5.892783519811928e-06, 7.75474836700596e-06, 5.866664650966413e-06, 6.234897227841429e-06, 6.332604243652895e-06, 6.7664104790310375e-06, 7.2308312155655585e-06, 7.104717951733619e-06, 6.737298008374637e-06, 6.403803581633838e-06, 6.622910404985305e-06, 6.8462486524367705e-06, 5.991228590573883e-06, 5.7470451793051325e-06, 6.026179107720964e-06, 7.361391453741817e-06, 6.233575732039753e-06, 6.969613878027303e-06, 1.6193973806366557e-06]}
Train Epoch: 16 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch016-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.1403905773477163e-05, 1.0667592505342327e-05, 1.0201782060903497e-05, 1.0270097845932469e-05, 1.0393507182016037e-05, 1.073398016160354e-05, 1.0536021363805048e-05, 9.684839824330993e-06, 9.01348812476499e-06, 9.536254765407648e-06, 1.024301218421897e-05, 9.585192856320646e-06, 9.843309271673206e-06, 1.0474031114426907e-05, 1.0020388799603097e-05, 9.844481610343792e-06, 9.692606909084134e-06, 1.0253048458253033e-05, 2.420289547444554e-06], 'L_si': [2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [1.1374103451089468e-05, 1.0667592505342327e-05, 1.0171979738515802e-05, 1.0299900168320164e-05, 1.0423309504403733e-05, 1.0644573194440454e-05, 1.0565823686192743e-05, 9.744444469106384e-06, 8.983685802377295e-06, 9.536254765407648e-06, 1.0272814506606665e-05, 9.674599823483732e-06, 9.813506949285511e-06, 1.0503833436814602e-05, 1.0050191121990792e-05, 9.814679287956096e-06, 9.722409231471829e-06, 1.0282850780640729e-05, 2.420289547444554e-06]}
Train Epoch: 17 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [5.92903234064579e-06, 5.882249752175994e-06, 5.485596375365276e-06, 5.985672032693401e-06, 5.816752491227817e-06, 6.162040790513856e-06, 5.419767148850951e-06, 5.655334462062456e-06, 6.044657311576884e-06, 6.514490905829007e-06, 6.253438641579123e-06, 5.417874490376562e-06, 6.209454113559332e-06, 5.725946721213404e-06, 5.868199878023006e-06, 5.898993549635634e-06, 6.297208528849296e-06, 5.918687293160474e-06, 1.8210826056019869e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [5.899230018258095e-06, 5.852447429788299e-06, 5.515398697752971e-06, 5.955869710305706e-06, 5.7869501688401215e-06, 6.191843112901552e-06, 5.389964826463256e-06, 5.62553213967476e-06, 6.044657311576884e-06, 6.514490905829007e-06, 6.2832409639668185e-06, 5.447676812764257e-06, 6.209454113559332e-06, 5.696144398825709e-06, 5.868199878023006e-06, 5.839388904860243e-06, 6.237603884073906e-06, 5.888884970772779e-06, 1.7912802832142916e-06]}
Train Epoch: 18 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [6.773645964130992e-06, 7.073140295688063e-06, 7.852439011912793e-06, 7.766428097966127e-06, 7.133715371310245e-06, 6.6906377469422296e-06, 6.218574526428711e-06, 6.872960511827841e-06, 6.282505637500435e-06, 6.88857016939437e-06, 6.944344931980595e-06, 7.302381163754035e-06, 7.627446393598802e-06, 7.601008746860316e-06, 8.038134183152579e-06, 7.733561687928159e-06, 7.276671112776967e-06, 7.350228770519607e-06, 1.952966840690351e-06], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [6.773645964130992e-06, 7.102942618075758e-06, 7.852439011912793e-06, 7.826032742741518e-06, 7.133715371310245e-06, 6.6906377469422296e-06, 6.218574526428711e-06, 6.902762834215537e-06, 6.342110282275826e-06, 6.858767847006675e-06, 6.944344931980595e-06, 7.2725788413663395e-06, 7.627446393598802e-06, 7.541404102084925e-06, 8.09773882792797e-06, 7.733561687928159e-06, 7.276671112776967e-06, 7.380031092907302e-06, 2.0125714854657417e-06]}
Train Epoch: 19 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.2836251193657517e-06, 3.952492079406511e-06, 3.5292637221573386e-06, 3.1935342121869326e-06, 3.4924985357065452e-06, 3.50539244209358e-06, 3.326841124362545e-06, 3.5419220694166142e-06, 3.3531232475070283e-06, 3.4602248888404574e-06, 3.6114415706833825e-06, 3.551071131369099e-06, 3.5977893730887445e-06, 3.1349277378467377e-06, 3.355603439558763e-06, 3.900887804775266e-06, 3.012491561094066e-06, 3.3382236779289087e-06, 8.523045949004882e-07], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [3.2836251193657517e-06, 3.982294401794206e-06, 3.5292637221573386e-06, 3.1935342121869326e-06, 3.4924985357065452e-06, 3.50539244209358e-06, 3.2970388019748498e-06, 3.5419220694166142e-06, 3.3531232475070283e-06, 3.4602248888404574e-06, 3.6114415706833825e-06, 3.551071131369099e-06, 3.5977893730887445e-06, 3.1349277378467377e-06, 3.355603439558763e-06, 3.900887804775266e-06, 3.012491561094066e-06, 3.3382236779289087e-06, 8.523045949004882e-07]}
Train Epoch: 20 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch020-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.8831857384357136e-06, 5.08091579831671e-06, 5.030377906223293e-06, 5.085617885924876e-06, 4.96237407787703e-06, 4.582288056553807e-06, 5.845859050168656e-06, 4.564624305203324e-06, 4.5810088522557635e-06, 5.006951141695026e-06, 5.008902917325031e-06, 4.48036371381022e-06, 4.457604518393055e-06, 4.509190148382913e-06, 5.4709062169422396e-06, 5.023587164032506e-06, 4.766584879689617e-06, 5.162673915037885e-06, 1.5859309314691927e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [4.853383416048018e-06, 5.051113475929014e-06, 5.030377906223293e-06, 5.026013241149485e-06, 4.96237407787703e-06, 4.552485734166112e-06, 5.8160567277809605e-06, 4.564624305203324e-06, 4.5810088522557635e-06, 4.977148819307331e-06, 4.979100594937336e-06, 4.450561391422525e-06, 4.427802196005359e-06, 4.538992470770609e-06, 5.4709062169422396e-06, 4.9937848416448105e-06, 4.736782557301922e-06, 5.103069270262495e-06, 1.526326286693802e-06]}
Train Epoch: 21 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.3546500617376296e-06, 2.7189835236640647e-06, 3.0130170216580154e-06, 2.8141937491454883e-06, 3.1836964353715302e-06, 2.736729129537707e-06, 2.9400082439678954e-06, 2.653563569765538e-06, 2.843462198143243e-06, 3.1391100492328405e-06, 2.465949137331336e-06, 2.975302322738571e-06, 2.7295607196720084e-06, 3.1055292311066296e-06, 2.7712346764019458e-06, 2.9995555905770743e-06, 3.238715635234257e-06, 3.195689032509108e-06, 6.795219178457046e-07], 'L_si': [8.940696716308594e-08, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [3.2652430945745436e-06, 2.659378878888674e-06, 3.0130170216580154e-06, 2.8141937491454883e-06, 3.1240917905961396e-06, 2.736729129537707e-06, 2.8804035991925048e-06, 2.6237612473778427e-06, 2.843462198143243e-06, 3.0497030820697546e-06, 2.495751459719031e-06, 2.9455000003508758e-06, 2.7593630420597037e-06, 3.0757269087189343e-06, 2.7712346764019458e-06, 2.9995555905770743e-06, 3.1791109904588666e-06, 3.1658867101214128e-06, 7.093242402333999e-07]}
Train Epoch: 22 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [2.0609677449101582e-06, 1.717654640742694e-06, 1.911025265144417e-06, 1.8841700466509792e-06, 1.951241074493737e-06, 1.6880929933904554e-06, 1.6685256696291617e-06, 1.6399801552324789e-06, 1.7982475810640608e-06, 1.7956512010641745e-06, 1.9383207927603507e-06, 1.7338360294161248e-06, 1.7303813137914403e-06, 1.7495036672698916e-06, 1.6741300896683242e-06, 1.9815381619991967e-06, 1.7216864307556534e-06, 2.017284032262978e-06, 5.208261200095876e-07], 'L_si': [0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [2.0609677449101582e-06, 1.717654640742694e-06, 1.911025265144417e-06, 1.8841700466509792e-06, 1.8916364297183463e-06, 1.65829067100276e-06, 1.698327992016857e-06, 1.6399801552324789e-06, 1.7982475810640608e-06, 1.7956512010641745e-06, 1.9383207927603507e-06, 1.7636383518038201e-06, 1.7303813137914403e-06, 1.7495036672698916e-06, 1.6741300896683242e-06, 1.9815381619991967e-06, 1.6918841083679581e-06, 2.017284032262978e-06, 5.208261200095876e-07]}
Train Epoch: 23 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.3605048227182124e-06, 2.51621668212465e-06, 2.4155724531738088e-06, 2.5360266135976417e-06, 2.413907395748538e-06, 2.3370832877844805e-06, 2.2934261778573273e-06, 2.3848863293096656e-06, 2.316568043170264e-06, 2.315651272510877e-06, 2.4527118966943817e-06, 2.2132653612061404e-06, 2.497512014087988e-06, 2.2442973204306327e-06, 2.4967048375401646e-06, 2.440687012494891e-06, 2.2896358586876886e-06, 2.5204167286574375e-06, 5.736580988013884e-07], 'L_si': [0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0], 'L_grad': [2.3605048227182124e-06, 2.486414359736955e-06, 2.3857701307861134e-06, 2.476421968822251e-06, 2.3841050733608427e-06, 2.3370832877844805e-06, 2.2934261778573273e-06, 2.3550840069219703e-06, 2.316568043170264e-06, 2.315651272510877e-06, 2.4527118966943817e-06, 2.1536607164307497e-06, 2.497512014087988e-06, 2.2442973204306327e-06, 2.437100192764774e-06, 2.440687012494891e-06, 2.2896358586876886e-06, 2.490614406269742e-06, 5.736580988013884e-07]}
Train Epoch: 24 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch024-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.642194320083945e-06, 1.6890644474187866e-06, 1.630489350645803e-06, 1.7515741319584777e-06, 1.718125076877186e-06, 1.6331076722053695e-06, 1.5919097222649725e-06, 1.5735198530819616e-06, 1.6744583035688265e-06, 1.7202803519467125e-06, 1.4503325473924633e-06, 1.7516024399810703e-06, 1.605928446224425e-06, 1.5930065728753107e-06, 1.7496928421678604e-06, 1.743630946293706e-06, 1.6739420516387327e-06, 1.68014400969696e-06, 3.9899228454487456e-07], 'L_si': [0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 8.940696716308594e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [1.642194320083945e-06, 1.629459802643396e-06, 1.6006870282581076e-06, 1.7515741319584777e-06, 1.6287181097141001e-06, 1.6629099945930648e-06, 1.5025027551018866e-06, 1.5735198530819616e-06, 1.6446559811811312e-06, 1.6904780295590172e-06, 1.4503325473924633e-06, 1.7814047623687657e-06, 1.5463238014490344e-06, 1.5632042504876154e-06, 1.719890519780165e-06, 1.7138286239060108e-06, 1.6441397292510374e-06, 1.6503416873092647e-06, 4.585969293202652e-07]}
Train Epoch: 25 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.5913199149508728e-06, 1.4882931509418995e-06, 1.4270397059590323e-06, 1.5079087916092249e-06, 1.6569866829740931e-06, 1.7955344446818344e-06, 1.8232253751193639e-06, 1.8647682509254082e-06, 1.4932687690816238e-06, 1.5875078815952293e-06, 1.5181948356257635e-06, 1.4626173197029857e-06, 1.4198169537849026e-06, 1.545346322018304e-06, 1.7128659237641841e-06, 1.7293675682594767e-06, 1.282414814340882e-06, 1.4707595710206078e-06, 4.421959260980657e-07], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.5615175925631775e-06, 1.5180954733295948e-06, 1.4568420283467276e-06, 1.5079087916092249e-06, 1.6867890053617884e-06, 1.7359297999064438e-06, 1.7934230527316686e-06, 1.834965928537713e-06, 1.523071091469319e-06, 1.5279032368198386e-06, 1.5479971580134588e-06, 1.4328149973152904e-06, 1.4496192761725979e-06, 1.5751486444059992e-06, 1.6830636013764888e-06, 1.759169890647172e-06, 1.3122171367285773e-06, 1.4409572486329125e-06, 4.1239360371037037e-07]}
Train Epoch: 26 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.077485308087489e-06, 9.984933058149181e-07, 1.1260234487053822e-06, 1.1013726179953665e-06, 9.797762459129444e-07, 1.022549099616299e-06, 1.2775033155776327e-06, 1.312224640059867e-06, 1.048345666276873e-06, 1.1064078080380568e-06, 1.1789336440415354e-06, 1.0115377335750964e-06, 1.2041500667692162e-06, 1.1316882364553749e-06, 1.065274318534648e-06, 1.0240538586003822e-06, 1.1349113719916204e-06, 8.961833373177797e-07, 2.2384095643701585e-07], 'L_si': [-2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 8.940696716308594e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.1072876304751844e-06, 9.984933058149181e-07, 1.1558257710930775e-06, 1.1013726179953665e-06, 9.797762459129444e-07, 1.022549099616299e-06, 1.2477009931899374e-06, 1.222817672896781e-06, 1.0185433438891778e-06, 1.0468031632626662e-06, 1.1491313216538401e-06, 1.0115377335750964e-06, 1.174347744381521e-06, 1.1316882364553749e-06, 1.0354719961469527e-06, 1.0240538586003822e-06, 1.0753067272162298e-06, 8.663810149300843e-07, 1.9403863404932054e-07]}
Train Epoch: 27 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [8.366303063667146e-07, 7.926244052214315e-07, 8.891859124560142e-07, 9.369410918225185e-07, 8.712744943295547e-07, 9.175391824101098e-07, 9.353016139357351e-07, 9.562049854139332e-07, 1.0570029189693742e-06, 8.875797448126832e-07, 9.408033179170161e-07, 9.570929933033767e-07, 8.754897180551779e-07, 8.35569608170772e-07, 8.28190138690843e-07, 9.205054425365233e-07, 9.438564916308678e-07, 8.359776302313549e-07, 2.084281049974379e-07], 'L_si': [0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [8.366303063667146e-07, 7.926244052214315e-07, 9.189882348437095e-07, 9.369410918225185e-07, 8.712744943295547e-07, 8.877368600224145e-07, 9.054992915480398e-07, 9.860073078016285e-07, 1.0272005965816788e-06, 8.875797448126832e-07, 9.110009955293208e-07, 9.272906709156814e-07, 8.754897180551779e-07, 8.35569608170772e-07, 8.28190138690843e-07, 8.90703120148828e-07, 9.140541692431725e-07, 8.359776302313549e-07, 2.084281049974379e-07]}
Train Epoch: 28 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch028-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.816596745309653e-06, 3.508268719087937e-06, 4.167361566942418e-06, 3.960822141380049e-06, 4.108360371901654e-06, 4.169596650172025e-06, 4.258621174813015e-06, 3.8795906220912e-06, 3.928173100575805e-06, 3.4618080917425686e-06, 4.084756255906541e-06, 4.044172783324029e-06, 4.028535840916447e-06, 4.443449142854661e-06, 3.9627557271160185e-06, 3.934022515750257e-06, 3.934380856662756e-06, 4.016502771264641e-06, 7.226619800348999e-07], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, -8.940696716308594e-08], 'L_grad': [3.816596745309653e-06, 3.508268719087937e-06, 4.167361566942418e-06, 3.960822141380049e-06, 4.108360371901654e-06, 4.080189683008939e-06, 4.288423497200711e-06, 3.849788299703505e-06, 3.898370778188109e-06, 3.4320057693548733e-06, 4.114558578294236e-06, 4.044172783324029e-06, 3.968931196141057e-06, 4.4136468204669654e-06, 3.903151082340628e-06, 3.934022515750257e-06, 3.9045785342750605e-06, 4.076107416040031e-06, 8.120689471979858e-07]}
Train Epoch: 29 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.546193172747735e-06, 2.1887444745516405e-06, 2.7403500553191407e-06, 2.807376404234674e-06, 2.5155873117910232e-06, 2.599677145553869e-06, 2.5705066946102306e-06, 2.814384515659185e-06, 2.8177832973597106e-06, 2.66671759163728e-06, 2.4596618004579796e-06, 2.607162514323136e-06, 2.630401468195487e-06, 2.8709182515740395e-06, 2.5648730570537737e-06, 2.6216341666440712e-06, 2.5520507733745035e-06, 2.405339955657837e-06, 7.072223411341838e-07], 'L_si': [0.0, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [2.546193172747735e-06, 2.158942152163945e-06, 2.7999547000945313e-06, 2.7775740818469785e-06, 2.485784989403328e-06, 2.599677145553869e-06, 2.600309016997926e-06, 2.78458219327149e-06, 2.7879809749720152e-06, 2.66671759163728e-06, 2.4596618004579796e-06, 2.636964836710831e-06, 2.630401468195487e-06, 2.7815112844109535e-06, 2.5350707346660784e-06, 2.591831844256376e-06, 2.581853095762199e-06, 2.4351422780455323e-06, 7.072223411341838e-07]}
Train Epoch: 30 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
New Learning Rate: 0.000150
all losses in batch in validation:  {'loss': [1.3162378991182777e-06, 1.1822532997030066e-06, 1.1817979839179316e-06, 1.0962694432237186e-06, 1.173810687760124e-06, 1.3969340670882957e-06, 1.0617750376695767e-06, 1.0990173677782877e-06, 1.0582205050013727e-06, 1.1384511253709206e-06, 1.2262863720025052e-06, 1.2458071978471708e-06, 1.1771186336773098e-06, 1.193060597870499e-06, 1.1943182016693754e-06, 1.2655144701056997e-06, 1.1231176131332177e-06, 1.1094631418018253e-06, 2.901507798469538e-07], 'L_si': [0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0], 'L_grad': [1.3162378991182777e-06, 1.1822532997030066e-06, 1.1519956615302362e-06, 1.0962694432237186e-06, 1.1440083653724287e-06, 1.337329422312905e-06, 1.0617750376695767e-06, 1.0990173677782877e-06, 1.0582205050013727e-06, 1.1384511253709206e-06, 1.2262863720025052e-06, 1.2160048754594754e-06, 1.1771186336773098e-06, 1.1632582754828036e-06, 1.16451587928168e-06, 1.205909825330309e-06, 1.1231176131332177e-06, 1.1094631418018253e-06, 2.901507798469538e-07]}
Train Epoch: 31 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [7.350025725827436e-07, 7.024759156593063e-07, 5.992241085550631e-07, 7.099032472979161e-07, 7.257589231812744e-07, 7.11849224899197e-07, 7.097772254383017e-07, 6.925423576831236e-07, 6.601782160942093e-07, 6.838488388893893e-07, 6.332597877189983e-07, 6.150316949060652e-07, 7.586955916849547e-07, 6.953355864425248e-07, 6.388523274836189e-07, 7.150755436668987e-07, 6.95839844411239e-07, 6.85235022501729e-07, 2.0474701045714028e-07], 'L_si': [2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08], 'L_grad': [7.052002501950483e-07, 7.024759156593063e-07, 6.290264309427585e-07, 6.801009249102208e-07, 6.959566007935791e-07, 6.522445801238064e-07, 6.799749030506064e-07, 6.329377129077329e-07, 6.601782160942093e-07, 6.838488388893893e-07, 6.630621101066936e-07, 6.150316949060652e-07, 7.288932692972594e-07, 6.953355864425248e-07, 6.388523274836189e-07, 6.852732212792034e-07, 6.95839844411239e-07, 6.85235022501729e-07, 1.7494468806944496e-07]}
Train Epoch: 32 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch032-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.4664892584478366e-07, 3.953711598114751e-07, 3.933471646178077e-07, 5.037236974203552e-07, 4.0058154127109447e-07, 5.541602945413615e-07, 4.235643018546398e-07, 4.841615464101778e-07, 4.846933734370396e-07, 4.5447694674294326e-07, 5.341402129488415e-07, 5.033711545365804e-07, 4.426233317644801e-07, 4.6335202341651893e-07, 4.142391105688148e-07, 4.4721952008330845e-07, 4.0552239966018533e-07, 4.1621029822636046e-07, 6.432503596442984e-08], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [4.1684660345708835e-07, 4.251734821991704e-07, 4.2314948700550303e-07, 4.7392137503265985e-07, 4.303838636587898e-07, 5.243579721536662e-07, 3.9376197946694447e-07, 4.841615464101778e-07, 4.846933734370396e-07, 4.842792691306386e-07, 4.7453553975174145e-07, 4.735688321488851e-07, 4.724256541521754e-07, 4.931543458042142e-07, 4.440414329565101e-07, 4.1741719769561314e-07, 4.3532472204788064e-07, 4.758149430017511e-07, 1.2392968073982047e-07]}
Train Epoch: 33 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.177390676180949e-07, 5.418501700660272e-07, 4.873168109043036e-07, 4.960239721185644e-07, 5.200108716962859e-07, 4.679788787598227e-07, 5.328080305844196e-07, 5.317013460626185e-07, 5.486091367856716e-07, 5.180304469831754e-07, 5.573128305513819e-07, 5.364796606954769e-07, 4.975350975655601e-07, 4.900924750472768e-07, 4.795865038431657e-07, 4.865685809818387e-07, 5.447261059998709e-07, 4.871106966675143e-07, 1.4775514500797726e-07], 'L_si': [2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [4.879367452303995e-07, 4.822455252906366e-07, 4.575145169383177e-07, 4.662216497308691e-07, 4.902085493085906e-07, 4.381765563721274e-07, 4.7320335738731956e-07, 4.720967012872279e-07, 4.89004492010281e-07, 4.8822812459548e-07, 4.977081857759913e-07, 4.768750159200863e-07, 4.677327751778648e-07, 4.602901526595815e-07, 4.497841814554704e-07, 4.5676625859414344e-07, 4.851214612244803e-07, 4.573084027015284e-07, 1.1795282262028195e-07]}
Train Epoch: 34 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [4.914317628390563e-07, 4.411875522691844e-07, 4.09264117706698e-07, 4.553792507522303e-07, 4.913728162136977e-07, 4.4505685536933015e-07, 4.590452817865298e-07, 4.056115585626685e-07, 4.5753438371320954e-07, 4.2555183199510793e-07, 4.06317440138082e-07, 4.3186747689105687e-07, 4.1165162656398024e-07, 5.186082034924766e-07, 4.415728085405135e-07, 4.1671665940157254e-07, 4.208121708870749e-07, 4.2086156781806494e-07, 1.2193302723062516e-07], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [4.61629440451361e-07, 4.411875522691844e-07, 4.09264117706698e-07, 4.553792507522303e-07, 4.6157049382600235e-07, 4.4505685536933015e-07, 4.888476041742251e-07, 4.056115585626685e-07, 4.5753438371320954e-07, 4.2555183199510793e-07, 4.06317440138082e-07, 4.616697992787522e-07, 4.1165162656398024e-07, 4.888058811047813e-07, 4.415728085405135e-07, 4.1671665940157254e-07, 4.208121708870749e-07, 4.2086156781806494e-07, 1.2193302723062516e-07]}
Train Epoch: 35 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.415821652197337e-07, 3.0963516906012956e-07, 3.629835987339902e-07, 3.0623016300523886e-07, 4.067486258918507e-07, 3.718753305292921e-07, 3.2507733749298495e-07, 3.4127154435736884e-07, 3.3946730582101736e-07, 3.7125363405721146e-07, 3.393818133190507e-07, 3.5956168176198844e-07, 3.74915970269285e-07, 3.4308703789065476e-07, 3.819712901531602e-07, 3.2555644224885327e-07, 3.1652800203119114e-07, 3.260343248712161e-07, 7.126416790015355e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [3.7138448760742904e-07, 3.3943749144782487e-07, 3.9278592112168553e-07, 3.360324853929342e-07, 4.067486258918507e-07, 4.0167765291698743e-07, 3.5487965988068026e-07, 3.7107386674506415e-07, 3.692696282087127e-07, 4.0105595644490677e-07, 3.69184135706746e-07, 3.8936400414968375e-07, 3.74915970269285e-07, 3.7288936027835007e-07, 3.819712901531602e-07, 3.553587646365486e-07, 3.4633032441888645e-07, 3.558366472589114e-07, 1.0106649028784886e-07]}
Train Epoch: 36 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch036-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.275956371202483e-07, 4.438753933300177e-07, 4.13703844515112e-07, 5.078641152067576e-07, 3.2299169561156305e-07, 4.122753693991399e-07, 3.104625818650675e-07, 5.016420345782535e-07, 3.049615600048128e-07, 4.1329789723931754e-07, 4.134411710765562e-07, 5.044574891144293e-07, 4.673277089750627e-07, 3.176420761974441e-07, 4.098189094747795e-07, 4.183640953669965e-07, 4.677972640365624e-07, 5.053753397987748e-07, 4.7725535523568396e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -8.940696716308594e-08, -2.9802322387695312e-08, -8.940696716308594e-08, 2.9802322387695312e-08, -8.940696716308594e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -8.940696716308594e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [4.573979595079436e-07, 4.73677715717713e-07, 4.435061669028073e-07, 4.780617928190622e-07, 4.12398662774649e-07, 4.420776917868352e-07, 3.998695490281534e-07, 4.7183974061226763e-07, 3.943685271678987e-07, 4.4310021962701285e-07, 4.432434934642515e-07, 4.74655166726734e-07, 4.673277089750627e-07, 4.0704904336053005e-07, 4.396212318624748e-07, 4.481664177546918e-07, 4.677972640365624e-07, 4.755730174110795e-07, 1.0733018029895902e-07]}
Train Epoch: 37 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.7444141298692557e-07, 3.760299591704097e-07, 3.603015272801713e-07, 3.5048577728957753e-07, 3.654031388578005e-07, 3.48040799735827e-07, 3.820463234660565e-07, 3.5622875316221325e-07, 3.700554316310445e-07, 3.630476896887558e-07, 3.9615542846149765e-07, 3.75571033828237e-07, 3.878206200624845e-07, 3.8617241671090596e-07, 3.523375937675155e-07, 3.740430258858396e-07, 2.715439961775701e-07, 3.6567837469192455e-07, 9.779610365967528e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08, 0.0, 0.0], 'L_grad': [3.7444141298692557e-07, 3.760299591704097e-07, 3.603015272801713e-07, 3.5048577728957753e-07, 3.654031388578005e-07, 3.48040799735827e-07, 3.820463234660565e-07, 3.5622875316221325e-07, 3.700554316310445e-07, 3.630476896887558e-07, 3.9615542846149765e-07, 3.75571033828237e-07, 3.878206200624845e-07, 3.8617241671090596e-07, 3.523375937675155e-07, 3.740430258858396e-07, 3.311486409529607e-07, 3.6567837469192455e-07, 9.779610365967528e-08]}
Train Epoch: 38 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [2.2468536542419315e-07, 2.1704168773339916e-07, 2.2340533689657605e-07, 1.6300775484978658e-07, 1.771764601699033e-07, 1.6015899007015832e-07, 2.900503943692456e-07, 1.5987755830337846e-07, 1.7246551919924968e-07, 1.4746649412700208e-07, 2.3496464507388737e-07, 2.2636098151451733e-07, 1.5843517076064018e-07, 2.815254447341431e-07, 1.6747362963087653e-07, 2.1417343987195636e-07, 1.6263265933957882e-07, 2.0468810646434576e-07, 1.2979545260805025e-07], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 8.940696716308594e-08], 'L_grad': [1.9488304303649784e-07, 1.8723936534570385e-07, 1.9360301450888073e-07, 1.928100772374819e-07, 2.069787825575986e-07, 1.8996131245785364e-07, 2.0064342720615969e-07, 1.8967988069107378e-07, 2.02267841586945e-07, 1.772688165146974e-07, 1.7536000029849674e-07, 1.9655865912682202e-07, 1.882374931483355e-07, 1.9211847757105716e-07, 1.9727595201857184e-07, 1.8437111748426105e-07, 1.9243498172727413e-07, 2.0468810646434576e-07, 4.038848544496432e-08]}
Train Epoch: 39 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.871766978136293e-07, 3.860732533667033e-07, 3.872384013448027e-07, 3.353372051151382e-07, 4.075327524333261e-07, 3.945988567011227e-07, 3.413218792047701e-07, 3.7719556189586e-07, 4.248041705068317e-07, 3.8337068986038503e-07, 3.9461076539737405e-07, 3.67167956483172e-07, 3.8558067672056495e-07, 3.7821931186954316e-07, 3.9035575127854827e-07, 3.7602063684971654e-07, 3.8988358141978097e-07, 3.8720571637895773e-07, 1.1204139127585222e-07], 'L_si': [-2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [4.169790202013246e-07, 3.860732533667033e-07, 3.872384013448027e-07, 3.651395275028335e-07, 4.075327524333261e-07, 4.24401179088818e-07, 3.711242015924654e-07, 4.069978842835553e-07, 3.950018481191364e-07, 4.1317301224808034e-07, 3.9461076539737405e-07, 3.9697027887086733e-07, 3.8558067672056495e-07, 4.080216342572385e-07, 3.9035575127854827e-07, 3.7602063684971654e-07, 4.196859038074763e-07, 3.8720571637895773e-07, 8.223906888815691e-08]}
Train Epoch: 40 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch040-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.1278320850324235e-07, 4.152286123826343e-07, 4.169292822098214e-07, 4.203594698992674e-07, 4.1576157627787325e-07, 4.019974255697889e-07, 4.5525945324698114e-07, 4.211470354675839e-07, 3.9931376250024186e-07, 4.045547825626272e-07, 4.4739823579220683e-07, 3.999219018169242e-07, 4.3207666067246464e-07, 4.6042003987167845e-07, 4.194313589778176e-07, 3.999404043497634e-07, 4.481426003621891e-07, 4.152325061568263e-07, 1.5526956076428178e-07], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08], 'L_grad': [4.1278320850324235e-07, 4.152286123826343e-07, 4.169292822098214e-07, 4.203594698992674e-07, 4.1576157627787325e-07, 4.019974255697889e-07, 3.956548084715905e-07, 4.211470354675839e-07, 3.9931376250024186e-07, 4.045547825626272e-07, 3.877935910168162e-07, 3.999219018169242e-07, 4.3207666067246464e-07, 4.0081539509628783e-07, 4.194313589778176e-07, 3.999404043497634e-07, 3.885379555867985e-07, 4.152325061568263e-07, 9.566491598889115e-08]}
Train Epoch: 41 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.464625481479743e-07, 2.053163257187407e-07, 1.9525799643815844e-07, 2.164936461213074e-07, 2.0267920319838595e-07, 2.0402752909376431e-07, 2.0425422064818122e-07, 2.0396802824507176e-07, 2.0370197262309375e-07, 1.9304764009575592e-07, 2.1239895886537852e-07, 2.0752885632191465e-07, 1.881659841274086e-07, 2.0298337233271013e-07, 2.0259150801393844e-07, 2.1207100076026109e-07, 1.6586619722147589e-07, 1.9679609408740362e-07, 8.306079024578139e-08], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [2.16660225760279e-07, 2.053163257187407e-07, 1.9525799643815844e-07, 2.164936461213074e-07, 2.0267920319838595e-07, 2.0402752909376431e-07, 2.0425422064818122e-07, 2.0396802824507176e-07, 2.0370197262309375e-07, 1.9304764009575592e-07, 2.1239895886537852e-07, 2.0752885632191465e-07, 1.881659841274086e-07, 2.0298337233271013e-07, 2.0259150801393844e-07, 2.1207100076026109e-07, 2.254708419968665e-07, 1.9679609408740362e-07, 5.325846785808608e-08]}
Train Epoch: 42 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.9429432402139355e-07, 2.652045623108279e-07, 2.7903311661248154e-07, 2.504495739685808e-07, 2.6405976427668065e-07, 2.985217406603624e-07, 2.962080145607615e-07, 2.8971743404326844e-07, 2.6945224362862064e-07, 2.841422599431098e-07, 2.8362205739540514e-07, 2.562977954312373e-07, 2.630868891628779e-07, 2.3954345351739903e-07, 2.449191640607751e-07, 3.306838607386453e-07, 2.2061692561692325e-07, 2.464729220719164e-07, 4.260753883045254e-08], 'L_si': [0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [2.9429432402139355e-07, 2.950068846985232e-07, 3.0883543900017685e-07, 3.1005421874397143e-07, 2.9386208666437597e-07, 3.283240630480577e-07, 3.260103369484568e-07, 3.1951975643096375e-07, 3.2905688840401126e-07, 3.1394458233080513e-07, 2.8362205739540514e-07, 2.8610011781893263e-07, 2.9288921155057324e-07, 2.9914809829278965e-07, 3.045238088361657e-07, 2.710792159632547e-07, 2.802215703923139e-07, 3.06077566847307e-07, 7.240986121814785e-08]}
Train Epoch: 43 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.5586843460368982e-07, 1.8266490542373504e-07, 2.089490465095878e-07, 1.3286867783790512e-07, 1.7842720012595237e-07, 1.568240577398683e-07, 1.7394427231920417e-07, 1.837778427216108e-07, 1.8918098021458718e-07, 1.1152151557780599e-07, 1.6753290310589364e-07, 1.6080997511380701e-07, 1.83313630941484e-07, 1.6597002172602515e-07, 1.2457297771106823e-07, 2.181584477511933e-07, 1.8503791920920776e-07, 1.5731487224002194e-07, 2.2798804621970703e-08], 'L_si': [0.0, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08], 'L_grad': [1.5586843460368982e-07, 1.8266490542373504e-07, 1.7914672412189248e-07, 1.9247332261329575e-07, 1.7842720012595237e-07, 1.568240577398683e-07, 1.7394427231920417e-07, 1.837778427216108e-07, 1.8918098021458718e-07, 1.413238379655013e-07, 1.9733522549358895e-07, 1.6080997511380701e-07, 1.83313630941484e-07, 1.9577234411372046e-07, 1.8417762248645886e-07, 1.88356125363498e-07, 1.8503791920920776e-07, 1.5731487224002194e-07, 5.2601127009666016e-08]}
Train Epoch: 44 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch044-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.4293324568370736e-07, 1.414340573546724e-07, 1.544214285331691e-07, 1.356632424176496e-07, 1.3472634918798576e-07, 1.4486303712146764e-07, 1.3488654815319023e-07, 1.413940537986491e-07, 1.3800509179873188e-07, 1.3530565468045097e-07, 1.1610143246798543e-07, 1.3396322628977941e-07, 1.3533140474919492e-07, 1.1814030642653961e-07, 1.4012572080446262e-07, 1.2969084650649165e-07, 1.28023287970791e-07, 1.257781008234815e-07, 2.970533330426406e-08], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [1.4293324568370736e-07, 1.7123637974236772e-07, 1.544214285331691e-07, 1.654655648053449e-07, 1.6452867157568107e-07, 1.7466535950916295e-07, 1.6468887054088555e-07, 1.7119637618634442e-07, 1.678074141864272e-07, 1.6510797706814628e-07, 1.4590375485568075e-07, 1.6376554867747473e-07, 1.6513372713689023e-07, 1.4794262881423492e-07, 1.4012572080446262e-07, 1.5949316889418697e-07, 1.578256103584863e-07, 1.257781008234815e-07, 2.970533330426406e-08]}
Train Epoch: 45 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.3510371843494795e-07, 1.4413275550850813e-07, 1.4727227437560941e-07, 1.34938403562046e-07, 1.4387165947482572e-07, 1.6663719293319446e-07, 1.6895953081075277e-07, 1.4325502206702367e-07, 1.1172726033237268e-07, 1.6565564919801545e-07, 1.418022606003433e-07, 1.6866044916241663e-07, 1.3665761855463643e-07, 1.4931083569535986e-07, 1.3994059600008768e-07, 1.3970993961720524e-07, 1.294248477279325e-07, 1.3948057642210188e-07, 9.785886589952497e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.3510371843494795e-07, 1.4413275550850813e-07, 1.4727227437560941e-07, 1.34938403562046e-07, 1.4387165947482572e-07, 1.3683487054549914e-07, 1.3915720842305745e-07, 1.4325502206702367e-07, 1.1172726033237268e-07, 1.6565564919801545e-07, 1.418022606003433e-07, 1.3885812677472131e-07, 1.3665761855463643e-07, 1.4931083569535986e-07, 1.3994059600008768e-07, 1.3970993961720524e-07, 1.294248477279325e-07, 1.3948057642210188e-07, 3.8254221124134347e-08]}
Train Epoch: 46 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.1721355264171507e-07, 1.1955637546634534e-07, 1.0750010659421605e-07, 1.1517424525209208e-07, 1.1048847170513909e-07, 5.769567223978811e-08, 1.7044659728071565e-07, 1.1708003455623839e-07, 1.1183190196106807e-07, 1.223221204327274e-07, 6.183222467370797e-08, 1.1477937533754812e-07, 1.2239462421348435e-07, 6.756991410838964e-08, 1.1701857260959514e-07, 1.1528337040545011e-07, 5.682518633420841e-08, 6.152173170903552e-08, 2.8966960385901075e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0, -5.960464477539063e-08, 0.0, 0.0, -5.960464477539063e-08, 0.0, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, 0.0], 'L_grad': [1.1721355264171507e-07, 1.1955637546634534e-07, 1.0750010659421605e-07, 1.1517424525209208e-07, 1.1048847170513909e-07, 1.1730031701517873e-07, 1.1084195250532503e-07, 1.1708003455623839e-07, 1.1183190196106807e-07, 1.223221204327274e-07, 1.214368694490986e-07, 1.1477937533754812e-07, 1.2239462421348435e-07, 1.2717455888378026e-07, 1.1701857260959514e-07, 1.1528337040545011e-07, 1.1642983110959904e-07, 1.2112637648442615e-07, 2.8966960385901075e-08]}
Train Epoch: 47 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.5457672475349682e-07, 1.411365104786455e-07, 1.3699974488190492e-07, 1.4569381789897307e-07, 1.4681788229609083e-07, 1.6717280004741042e-07, 1.4861048214243056e-07, 1.3863783010492625e-07, 1.452797278034268e-07, 1.5708563694261102e-07, 1.5997315472304763e-07, 1.4187234853579866e-07, 1.6594853491369577e-07, 1.566218656989804e-07, 1.5065421621329733e-07, 1.397237525679884e-07, 1.749885711888055e-07, 1.5305712963709084e-07, 3.5480262283726915e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.5457672475349682e-07, 1.411365104786455e-07, 1.3699974488190492e-07, 1.4569381789897307e-07, 1.4681788229609083e-07, 1.6717280004741042e-07, 1.4861048214243056e-07, 1.3863783010492625e-07, 1.452797278034268e-07, 1.5708563694261102e-07, 1.5997315472304763e-07, 1.4187234853579866e-07, 1.6594853491369577e-07, 1.566218656989804e-07, 1.5065421621329733e-07, 1.397237525679884e-07, 1.749885711888055e-07, 1.5305712963709084e-07, 3.5480262283726915e-08]}
Train Epoch: 48 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch048-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.0004281136843929e-07, 1.0481052470368013e-07, 9.16498947844957e-08, 9.658037924964447e-08, 9.633205877435103e-08, 9.37530160172173e-08, 9.434653236439772e-08, 9.882528217985964e-08, 9.709315662576046e-08, 9.697214409243315e-08, 8.918779315081338e-08, 8.938395268387467e-08, 1.0610217060502691e-07, 1.0271277517404087e-07, 9.491350994039749e-08, 9.083137086918214e-08, 9.173237458526273e-08, 1.0675370276658214e-07, 2.15767599343053e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.0004281136843929e-07, 1.0481052470368013e-07, 9.16498947844957e-08, 9.658037924964447e-08, 9.633205877435103e-08, 9.37530160172173e-08, 9.434653236439772e-08, 9.882528217985964e-08, 9.709315662576046e-08, 9.697214409243315e-08, 8.918779315081338e-08, 8.938395268387467e-08, 1.0610217060502691e-07, 1.0271277517404087e-07, 9.491350994039749e-08, 9.083137086918214e-08, 9.173237458526273e-08, 1.0675370276658214e-07, 2.15767599343053e-08]}
Train Epoch: 49 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.206210811233177e-07, 1.2395895510053379e-07, 1.3899396833494393e-07, 1.2815367256280297e-07, 1.301909975381932e-07, 1.3723948200095037e-07, 1.3801115983369527e-07, 1.2692558470916993e-07, 1.3071995397240244e-07, 1.1902373842076486e-07, 1.3397300335782347e-07, 1.0814036244255476e-07, 1.374516074292842e-07, 1.1226617857573729e-07, 1.0645074155490875e-07, 1.290246700591524e-07, 9.827869007494883e-08, 1.31138421011201e-07, 5.431580163417493e-08], 'L_si': [0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.206210811233177e-07, 9.415663271283847e-08, 1.0919164594724862e-07, 9.835135017510765e-08, 1.0038867515049787e-07, 1.0743716671868242e-07, 1.0820883744599996e-07, 9.712325521604726e-08, 1.0091763158470712e-07, 8.922141603306954e-08, 1.0417068097012816e-07, 1.0814036244255476e-07, 1.0764928504158888e-07, 1.1226617857573729e-07, 1.0645074155490875e-07, 9.922235477688446e-08, 9.827869007494883e-08, 1.0133610572893303e-07, 2.451347924647962e-08]}
Train Epoch: 50 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.3479821348028054e-07, 4.844066836540151e-08, 5.828184157508076e-08, 1.3869160397916858e-07, 4.6205144599298364e-08, 1.0824692964206406e-07, 5.607714115285489e-08, 1.1067105987194736e-07, 1.9462176226170413e-07, 1.3091741379867017e-07, 1.9029832287742465e-07, 1.935129603225505e-07, 1.9643115933831723e-07, 5.799203961487365e-08, 6.458267876041646e-08, 1.0799840310937725e-07, 1.8754653297037294e-07, 1.7449045230932825e-07, 2.0301413883316854e-08], 'L_si': [0.0, -5.960464477539063e-08, -5.960464477539063e-08, 0.0, -5.960464477539063e-08, 0.0, -5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0], 'L_grad': [1.3479821348028054e-07, 1.0804531314079213e-07, 1.1788648635047139e-07, 1.3869160397916858e-07, 1.0580978937468899e-07, 1.0824692964206406e-07, 1.1568178592824552e-07, 1.1067105987194736e-07, 1.350171174863135e-07, 1.3091741379867017e-07, 1.3069367810203403e-07, 1.3390831554715987e-07, 1.368265145629266e-07, 1.1759668439026427e-07, 1.2418732353580708e-07, 1.0799840310937725e-07, 1.279418881949823e-07, 1.1488581463936498e-07, 2.0301413883316854e-08]}
Train Epoch: 51 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [6.175987721235288e-08, 5.9283109976604464e-08, 6.03643783847474e-08, 6.433852206555457e-08, 5.883943288154114e-08, 6.004241726031978e-08, 6.068083990840023e-08, 5.8414343584445305e-08, 6.19457907191645e-08, 6.130112240043673e-08, 5.893086552077875e-08, 6.417521092316747e-08, 6.24954026307023e-08, 6.040599487278087e-08, 6.092983539929264e-08, 6.128915686076652e-08, 6.748364000941365e-08, 6.142330022385067e-08, -5.514618095503465e-09], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [9.156219960004819e-08, 8.908543236429978e-08, 9.016670077244271e-08, 9.414084445324988e-08, 8.864175526923646e-08, 8.984473964801509e-08, 9.048316229609554e-08, 8.821666597214062e-08, 9.174811310685982e-08, 9.110344478813204e-08, 8.873318790847406e-08, 9.397753331086278e-08, 9.229772501839761e-08, 9.020831726047618e-08, 9.073215778698795e-08, 9.109147924846184e-08, 9.728596239710896e-08, 9.122562261154599e-08, 2.4287704292191847e-08]}
Train Epoch: 52 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch052-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.5565626060597424e-08, 2.827002276717394e-08, 3.0422015129261126e-08, 2.894434203426499e-08, 2.8292433285059815e-08, 2.1485639933871425e-08, 2.5206773557329143e-08, 6.091076443226484e-08, 2.9534213297210954e-08, 2.7849274886193598e-08, 2.765503381851886e-08, 2.7686610337696038e-08, 2.9223400588307413e-08, 2.8291715636896697e-08, 2.504506824152486e-08, 2.538143917263369e-08, 2.72812457069449e-08, 2.9320695205115044e-08, -3.8717367090157495e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [8.517027083598805e-08, 8.787466754256457e-08, 9.002665990465175e-08, 8.854898680965562e-08, 8.789707806045044e-08, 8.109028470926205e-08, 8.481141833271977e-08, 9.071308681996015e-08, 8.913885807260158e-08, 8.745391966158422e-08, 8.725967859390948e-08, 8.729125511308666e-08, 8.882804536369804e-08, 8.789636041228732e-08, 8.464971301691548e-08, 8.498608394802432e-08, 8.688589048233553e-08, 8.892533998050567e-08, 2.088727946158997e-08]}
Train Epoch: 53 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [8.111271654343e-09, 8.04788768959952e-09, 8.685503871674882e-09, 6.1255214234279265e-09, 9.205560758118736e-09, 6.5571015284149325e-09, 1.0991968224516313e-08, 6.9295964522098075e-09, 9.780521281754773e-09, 1.0568392383447645e-08, 6.791836426600639e-09, 8.916526184066242e-09, 5.563613569847803e-09, 7.413152758317665e-09, 7.642594113121959e-09, 1.0366353109247939e-08, 5.874063901956106e-09, 7.67904850818013e-09, 6.865856505555712e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [3.791359404203831e-08, 3.785021007729483e-08, 3.8487826259370195e-08, 3.592784381112324e-08, 3.900788314581405e-08, 3.6359423916110245e-08, 4.0794290612211626e-08, 3.673191883990512e-08, 3.9582843669450085e-08, 4.037071477114296e-08, 3.659415881429595e-08, 3.8718848571761555e-08, 3.5365935957543115e-08, 3.721547514601298e-08, 3.744491650081727e-08, 4.016867549694325e-08, 3.567638628965142e-08, 3.748137089587544e-08, 9.053917615631235e-09]}
Train Epoch: 54 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [-3.7238052641441755e-09, -3.841780227276104e-09, -3.770503909095169e-09, -3.9573038179696596e-09, -3.7933283181246225e-09, -3.819012661665511e-09, -3.8367957699847466e-09, -3.793640956928357e-09, -3.8387923950722325e-09, -3.91169052704754e-09, -3.770161072225164e-09, -3.7870044877763576e-09, -3.7747369674434594e-09, -3.7564742427775855e-09, -3.5393536990113716e-09, -3.869018883051467e-09, -3.6271963210765534e-09, -3.760593614288155e-09, -2.3289523198855022e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [2.6078517123551137e-08, 2.596054216041921e-08, 2.6031818478600144e-08, 2.5845018569725653e-08, 2.600899406957069e-08, 2.5983309726029802e-08, 2.5965526617710566e-08, 2.6008681430766956e-08, 2.596352999262308e-08, 2.5890631860647773e-08, 2.6032161315470148e-08, 2.6015317899918955e-08, 2.6027585420251853e-08, 2.6045848144917727e-08, 2.626296868868394e-08, 2.5933303504643845e-08, 2.617512606661876e-08, 2.6041728773407158e-08, 6.5127987447510804e-09]}
Train Epoch: 55 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [-1.4561994277073609e-08, -1.4671392989384913e-08, -1.4550568749882586e-08, -1.472773547561701e-08, -1.4734863995613523e-08, -1.4742287390845377e-08, -1.4723699592877892e-08, -1.459466147935018e-08, -1.4666873937585478e-08, -1.4594206731999293e-08, -1.4753181787341418e-08, -1.4817366889019468e-08, -1.4587161700774232e-08, -1.473591026979193e-08, -1.4605518572352594e-08, -1.4871240239244798e-08, -1.4506142065329186e-08, -1.477770084079566e-08, -2.601053594730729e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.5240328110621704e-08, 1.51309293983104e-08, 1.5251753637812726e-08, 1.5074586912078303e-08, 1.506745839208179e-08, 1.5060034996849936e-08, 1.507862279481742e-08, 1.5207660908345133e-08, 1.5135448450109834e-08, 1.520811565569602e-08, 1.5049140600353894e-08, 1.4984955498675845e-08, 1.521516068692108e-08, 1.5066412117903383e-08, 1.519680381534272e-08, 1.4931082148450514e-08, 1.5296180322366126e-08, 1.5024621546899652e-08, 3.791785552209603e-09]}
Train Epoch: 56 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch056-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.220920146735807e-08, 4.2340104755567154e-08, 4.207976900261201e-08, 4.259393904249009e-08, 4.264447284185735e-08, 4.256148500303425e-08, 4.22279491374411e-08, 4.2064055350010676e-08, 4.2212835893451484e-08, 4.2370906783162354e-08, 4.2716013837207356e-08, 4.259346653157081e-08, 4.213995197233089e-08, 4.2325527971343035e-08, 4.246130913543311e-08, 4.218554749968462e-08, 4.2086988116807333e-08, 4.259275954154873e-08, 1.0501879366131561e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [4.220920146735807e-08, 4.2340104755567154e-08, 4.207976900261201e-08, 4.259393904249009e-08, 4.264447284185735e-08, 4.256148500303425e-08, 4.22279491374411e-08, 4.2064055350010676e-08, 4.2212835893451484e-08, 4.2370906783162354e-08, 4.2716013837207356e-08, 4.259346653157081e-08, 4.213995197233089e-08, 4.2325527971343035e-08, 4.246130913543311e-08, 4.218554749968462e-08, 4.2086988116807333e-08, 4.259275954154873e-08, 1.0501879366131561e-08]}
Train Epoch: 57 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.993116510197069e-08, 2.988452862950908e-08, 2.968947931947241e-08, 2.9834183123966795e-08, 2.98370146367688e-08, 2.995145109707664e-08, 2.9930653511200944e-08, 2.997387227310355e-08, 2.984682367923597e-08, 2.982982039156923e-08, 2.989693825838913e-08, 2.964937806382295e-08, 2.9883974406175184e-08, 2.9790767186455014e-08, 2.99383025037514e-08, 2.992010195157491e-08, 2.9727976524895894e-08, 2.987587066627384e-08, -5.2243343873215053e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08], 'L_grad': [2.993116510197069e-08, 2.988452862950908e-08, 2.968947931947241e-08, 2.9834183123966795e-08, 2.98370146367688e-08, 2.995145109707664e-08, 2.9930653511200944e-08, 2.997387227310355e-08, 2.984682367923597e-08, 2.982982039156923e-08, 2.989693825838913e-08, 2.964937806382295e-08, 2.9883974406175184e-08, 2.9790767186455014e-08, 2.99383025037514e-08, 2.992010195157491e-08, 2.9727976524895894e-08, 2.987587066627384e-08, 7.361301790353991e-09]}
Train Epoch: 58 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [-3.216428012819961e-08, -3.105565227201623e-08, -3.257365221998043e-08, -3.280535310068444e-08, -3.070077170264085e-08, -3.14347339269716e-08, -3.120570113424037e-08, -3.267705039888824e-08, -3.150544358732077e-08, -3.0784846671849664e-08, -3.056858233208004e-08, -3.27451132875467e-08, -3.285765615146374e-08, -3.2293037577346695e-08, -3.208572962876133e-08, -3.1782626308540785e-08, -3.12219015086157e-08, -3.206019982826547e-08, -5.2922697335588964e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [2.7440364647191018e-08, 2.8548992503374393e-08, 2.7030992555410194e-08, 2.6799293451063022e-08, 2.8903873072749775e-08, 2.8169910848419022e-08, 2.8398945417507093e-08, 2.6927594376502384e-08, 2.8099201188069856e-08, 2.88197998798978e-08, 2.9036062443310584e-08, 2.6859531487843924e-08, 2.6746988623926882e-08, 2.731160719804393e-08, 2.7518915146629297e-08, 2.782201846684984e-08, 2.8382741490418084e-08, 2.7544444947125157e-08, 6.681946551623241e-09]}
Train Epoch: 59 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.361052142101471e-07, 1.3636132223382447e-07, 1.3623802885831537e-07, 1.361116659381878e-07, 1.362539450155964e-07, 1.3628483941374725e-07, 1.3615702698643872e-07, 1.3627646922032e-07, 1.3618819139082916e-07, 1.36207759737772e-07, 1.361038073355303e-07, 1.3644662999467982e-07, 1.36039403741961e-07, 1.361623276352475e-07, 1.3640610063703207e-07, 1.3623811412344367e-07, 1.3626318207116128e-07, 1.3635923323818133e-07, 6.385866413438634e-08], 'L_si': [1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 5.960464477539063e-08], 'L_grad': [1.6895924659365846e-08, 1.7152038012113735e-08, 1.7028737531177285e-08, 1.690237461104971e-08, 1.704465368845831e-08, 1.707554808660916e-08, 1.6947735659300633e-08, 1.7067186774966103e-08, 1.697890184004791e-08, 1.6998475516061262e-08, 1.6894512455678523e-08, 1.7237338667541735e-08, 1.6830114191179746e-08, 1.69530451898936e-08, 1.7196818191678176e-08, 1.7028821019948737e-08, 1.705389784945055e-08, 1.7149943687400082e-08, 4.254022023530979e-09]}
Train Epoch: 60 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch060-loss-0.0000.pth.tar ...
New Learning Rate: 0.000075
all losses in batch in validation:  {'loss': [6.082914172367282e-09, 5.886500176188747e-09, 6.025810517229502e-09, 6.021328768923695e-09, 6.086672499350243e-09, 6.023017196099545e-09, 5.912987433021044e-09, 5.9874172286811245e-09, 5.825889104471571e-09, 6.0171152505006376e-09, 6.144620812165158e-09, 6.174392108704296e-09, 6.093633153625433e-09, 5.946072523244084e-09, 6.052084611241071e-09, 6.055647538971698e-09, 6.173557220989778e-09, 6.0709792748525615e-09, 1.5106985662427519e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [6.082914172367282e-09, 5.886500176188747e-09, 6.025810517229502e-09, 6.021328768923695e-09, 6.086672499350243e-09, 6.023017196099545e-09, 5.912987433021044e-09, 5.9874172286811245e-09, 5.825889104471571e-09, 6.0171152505006376e-09, 6.144620812165158e-09, 6.174392108704296e-09, 6.093633153625433e-09, 5.946072523244084e-09, 6.052084611241071e-09, 6.055647538971698e-09, 6.173557220989778e-09, 6.0709792748525615e-09, 1.5106985662427519e-09]}
Train Epoch: 61 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.474033481003062e-08, 7.469952834071591e-08, 7.464540630053307e-08, 7.472102225847266e-08, 7.467433960073322e-08, 7.463505369287304e-08, 7.46595958389662e-08, 7.472093699334437e-08, 7.468849361202956e-08, 7.470275420473627e-08, 7.473434493476816e-08, 7.461082418558362e-08, 7.468345586403302e-08, 7.477989782955774e-08, 7.46832427012123e-08, 7.462607243269304e-08, 7.466566387392959e-08, 7.463792428552551e-08, -2.605241178343931e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [1.5135690034639993e-08, 1.509488356532529e-08, 1.5040759748785604e-08, 1.5116377483082033e-08, 1.5069694825342594e-08, 1.5030412470196097e-08, 1.5054951063575572e-08, 1.511629399431058e-08, 1.5083848836638936e-08, 1.509811298205932e-08, 1.5129703712091214e-08, 1.5006179410193e-08, 1.5078809312285557e-08, 1.5175253054167115e-08, 1.507859792582167e-08, 1.502142765730241e-08, 1.5061019098538964e-08, 1.503327951013489e-08, 3.749911492434421e-09]}
Train Epoch: 62 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-6.022951026807277e-09, -6.008121999911964e-09, -6.027352839055311e-09, -6.013976872054627e-09, -6.00748251144978e-09, -6.022133902661153e-09, -6.025652865560005e-09, -6.014143849597531e-09, -5.987647710981037e-09, -6.0105627142093e-09, -6.023110898922823e-09, -6.013895159640015e-09, -6.021977583259286e-09, -6.023118004350181e-09, -6.026283472237992e-09, -6.0232849818930845e-09, -6.02030603147341e-09, -6.001689811796496e-09, -2.3846988383979806e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [2.3779371360888035e-08, 2.379420038778335e-08, 2.377496954864e-08, 2.3788345515640685e-08, 2.3794839876245533e-08, 2.378018848503416e-08, 2.3776669522135307e-08, 2.3788178538097782e-08, 2.3814674676714276e-08, 2.3791759673486013e-08, 2.377921148877249e-08, 2.3788427228055298e-08, 2.3780344804436027e-08, 2.377920438334513e-08, 2.377603891545732e-08, 2.3779037405802228e-08, 2.3782016356221902e-08, 2.3800632575898817e-08, 5.955334003715507e-09]}
Train Epoch: 63 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-1.5707634304362728e-08, -1.5702834588182668e-08, -1.5706248746027995e-08, -1.570507990322767e-08, -1.5702816824614274e-08, -1.571799046473643e-08, -1.5706696387951524e-08, -1.5716086210204594e-08, -1.571124386146039e-08, -1.570288965524469e-08, -1.5711204781609922e-08, -1.570149876783944e-08, -1.5703966127489366e-08, -1.5717024126615797e-08, -1.5698102373562506e-08, -1.5706696387951524e-08, -1.5711854928213143e-08, -1.5711613343682984e-08, -2.6274662445757713e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.4094688971511005e-08, 1.4099488687691064e-08, 1.4096072753488897e-08, 1.4097241596289223e-08, 1.4099506451259458e-08, 1.4084332811137301e-08, 1.4095626887922208e-08, 1.4086235289312299e-08, 1.4091079414413343e-08, 1.4099432732450623e-08, 1.409111671790697e-08, 1.4100824508034293e-08, 1.4098356260205946e-08, 1.4085297372901096e-08, 1.4104220902311226e-08, 1.4095626887922208e-08, 1.409046745948217e-08, 1.4090709044012328e-08, 3.5276608301160195e-09]}
Train Epoch: 64 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch064-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.3772496032515846e-08, 1.3772162077430039e-08, 1.3772273987910921e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772496032515846e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772496032515846e-08, 1.3772496032515846e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 3.443012763781894e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.3772496032515846e-08, 1.3772162077430039e-08, 1.3772273987910921e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772496032515846e-08, 1.3772385010213384e-08, 1.3772385010213384e-08, 1.3772496032515846e-08, 1.3772496032515846e-08, 1.3772385010213384e-08, 1.3772273987910921e-08, 1.3772385010213384e-08, 3.443012763781894e-09]}
Train Epoch: 65 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.5326461877407382e-08, 1.5338191161617942e-08, 1.5322434876452462e-08, 1.535552840437049e-08, 1.5343612602691792e-08, 1.5315436030505225e-08, 1.5335789527171073e-08, 1.5328652125390363e-08, 1.5327195512782055e-08, 1.5341644399313736e-08, 1.5344761905566884e-08, 1.5306850897900404e-08, 1.5304959077866442e-08, 1.5338777359374944e-08, 1.5324197022437147e-08, 1.531553728284507e-08, 1.5337272785131972e-08, 1.534243310175043e-08, 3.8233580745838935e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.5326461877407382e-08, 1.5338191161617942e-08, 1.5322434876452462e-08, 1.535552840437049e-08, 1.5343612602691792e-08, 1.5315436030505225e-08, 1.5335789527171073e-08, 1.5328652125390363e-08, 1.5327195512782055e-08, 1.5341644399313736e-08, 1.5344761905566884e-08, 1.5306850897900404e-08, 1.5304959077866442e-08, 1.5338777359374944e-08, 1.5324197022437147e-08, 1.531553728284507e-08, 1.5337272785131972e-08, 1.534243310175043e-08, 3.8233580745838935e-09]}
Train Epoch: 66 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [-4.0782001775596655e-08, -4.078102833204866e-08, -4.078162874066038e-08, -4.0782001775596655e-08, -4.0781884536045254e-08, -4.0782001775596655e-08, -4.078140136698494e-08, -4.0782001775596655e-08, -4.078162874066038e-08, -4.0781614529805665e-08, -4.0782001775596655e-08, -4.0781884536045254e-08, -4.0780960830488766e-08, -4.0782001775596655e-08, -4.0781884536045254e-08, -4.0781884536045254e-08, -4.0782001775596655e-08, -4.0782001775596655e-08, -5.489898313726371e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [1.882264299979397e-08, 1.8823616443341962e-08, 1.8823014258373405e-08, 1.882264299979397e-08, 1.882276201570221e-08, 1.882264299979397e-08, 1.8823245184762527e-08, 1.882264299979397e-08, 1.8823014258373405e-08, 1.88230320219418e-08, 1.882264299979397e-08, 1.882276201570221e-08, 1.882368216854502e-08, 1.882264299979397e-08, 1.882276201570221e-08, 1.882276201570221e-08, 1.882264299979397e-08, 1.882264299979397e-08, 4.705660749948493e-09]}
Train Epoch: 67 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.088793386676116e-08, 5.0896325376470486e-08, 5.090055665846194e-08, 5.08882962435564e-08, 5.089904675514845e-08, 5.0909093829432095e-08, 5.089068366714855e-08, 5.0898403713972584e-08, 5.0907193127613937e-08, 5.088793386676116e-08, 5.0897753567369364e-08, 5.0894637837473056e-08, 5.089641064159878e-08, 5.0898840697755077e-08, 5.088801913188945e-08, 5.091319721373111e-08, 5.089095367338814e-08, 5.089698618121474e-08, 3.507628676402419e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [2.1085613255422686e-08, 2.1094002988775173e-08, 2.1098234270766625e-08, 2.1085975632217924e-08, 2.1096724367453135e-08, 2.1106773218093622e-08, 2.1088361279453238e-08, 2.1096081326277272e-08, 2.1104870739918624e-08, 2.1085613255422686e-08, 2.109543117967405e-08, 2.1092315449777743e-08, 2.1094086477546625e-08, 2.1096518310059764e-08, 2.1085696744194138e-08, 2.1110874826035797e-08, 2.1088631285692827e-08, 2.109466201716259e-08, 5.273964376328877e-09]}
Train Epoch: 68 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch068-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [-1.873545230068885e-08, -1.874527910672441e-08, -1.867751286965813e-08, -1.874527910672441e-08, -1.8739850560223204e-08, -1.8733233630996438e-08, -1.8739850560223204e-08, -1.8739498841569002e-08, -1.8728657735778143e-08, -1.8728481876451042e-08, -1.8730773376773868e-08, -1.8691387992930686e-08, -1.874154875736167e-08, -1.8741632246133122e-08, -1.872566990357427e-08, -1.8736880491587726e-08, -1.874527910672441e-08, -1.874527910672441e-08, -2.7032465155230057e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.1066870087006464e-08, 1.1057043280970902e-08, 1.1124809518037182e-08, 1.1057043280970902e-08, 1.1062471827472109e-08, 1.1069088756698875e-08, 1.1062471827472109e-08, 1.106282354612631e-08, 1.107366465191717e-08, 1.107384051124427e-08, 1.1071548122743025e-08, 1.1110934394764627e-08, 1.1060773630333642e-08, 1.106069014156219e-08, 1.1076652484121041e-08, 1.1065441896107586e-08, 1.1057043280970902e-08, 1.1057043280970902e-08, 2.769856788376046e-09]}
Train Epoch: 69 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 5.981394046727928e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 2.3925576186911712e-08, 5.981394046727928e-09]}
Train Epoch: 70 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.3654179443232124e-09, 3.3656313291885454e-09, 3.3656686326821728e-09, 3.3656313291885454e-09, 3.3653901887475968e-09, 3.3653528852539694e-09, 3.365789424947252e-09, 3.3654643516456417e-09, 3.3654923292658623e-09, 3.365520084841478e-09, 3.3657707732004383e-09, 3.365297374102738e-09, 3.3653344555517606e-09, 3.3655294107148848e-09, 3.3655480624616985e-09, 3.365520084841478e-09, 3.365297374102738e-09, 3.3654830033924554e-09, 8.413382213134923e-10], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [3.3654179443232124e-09, 3.3656313291885454e-09, 3.3656686326821728e-09, 3.3656313291885454e-09, 3.3653901887475968e-09, 3.3653528852539694e-09, 3.365789424947252e-09, 3.3654643516456417e-09, 3.3654923292658623e-09, 3.365520084841478e-09, 3.3657707732004383e-09, 3.365297374102738e-09, 3.3653344555517606e-09, 3.3655294107148848e-09, 3.3655480624616985e-09, 3.365520084841478e-09, 3.365297374102738e-09, 3.3654830033924554e-09, 8.413382213134923e-10]}
Train Epoch: 71 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-7.626985265574149e-09, -7.64809726661042e-09, -7.621880016017712e-09, -7.6491648570709e-09, -7.608907282019572e-09, -3.7458466550788216e-08, -3.743692644775365e-08, -7.626159259643828e-09, -3.743884846585388e-08, -7.624970876918269e-09, -3.744380450143581e-08, -7.641620669573967e-09, -3.7453816048582667e-08, -3.74248685375278e-08, -7.634159970848486e-09, -3.744589349707894e-08, -3.7433565580613504e-08, -3.745318721826152e-08, -2.42671749361989e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [2.2175337122121164e-08, 2.2154225121084892e-08, 2.21804423716776e-08, 2.2153157530624412e-08, 2.219341510567574e-08, 2.214617822460241e-08, 2.2167718327636976e-08, 2.2176163128051485e-08, 2.2165796309536745e-08, 2.2177351510777044e-08, 2.2160842050311658e-08, 2.2160701718121345e-08, 2.215082695045112e-08, 2.2179774461505986e-08, 2.2168162416846826e-08, 2.2158753054668523e-08, 2.2171077418420282e-08, 2.2151457557129106e-08, 5.535147895585624e-09]}
Train Epoch: 72 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch072-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 8.72825012265821e-08, 3.672178650049318e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 2.7677852898477795e-08, 6.919463224619449e-09]}
Train Epoch: 73 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 3.9792156236728715e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 1.5916862494691486e-08, 3.9792156236728715e-09]}
Train Epoch: 74 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -3.955908312036627e-08, -5.4593254361634536e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 2.0045561655024358e-08, 5.011390413756089e-09]}
Train Epoch: 75 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 1.0575937903212207e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 4.230375161284883e-09, 1.0575937903212207e-09]}
Train Epoch: 76 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch076-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 8.211630841969964e-08, 6.523256246282472e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 2.251166364430901e-08, 5.6279159110772525e-09]}
Train Epoch: 77 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 1.0782513015783479e-07, 9.401150435905947e-08], 'L_si': [8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08], 'L_grad': [1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 1.8418159442035176e-08, 4.604539860508794e-09]}
Train Epoch: 78 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 9.064781636425323e-08, 8.971717591066408e-08], 'L_si': [8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08, 8.940696716308594e-08], 'L_grad': [1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 1.2408477578773613e-09, 3.1021193946934034e-10]}
Train Epoch: 79 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, -8.908145332497952e-09, 3.502586665149465e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 2.089417705519736e-08, 5.22354426379934e-09]}
Train Epoch: 80 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch080-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 5.759633125990149e-08, 3.6750826382103696e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 2.7794008872206177e-08, 6.948502218051544e-09]}
Train Epoch: 81 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 6.202132851740316e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 9.666740297120668e-09, 2.416685074280167e-09]}
Train Epoch: 82 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, -5.41780522667068e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08], 'L_grad': [2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 2.170637181109214e-08, 5.426592952773035e-09]}
Train Epoch: 83 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 4.708932976882352e-08, 3.4124074232977364e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 1.7287007381128205e-08, 4.321751845282051e-09]}
Train Epoch: 84 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch084-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 7.837984128400421e-08, 4.693800015331817e-09], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0], 'L_grad': [1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 1.877520006132727e-08, 4.693800015331817e-09]}
Train Epoch: 85 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, -2.682137001386309e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08], 'L_grad': [1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 1.1923809495328896e-08, 2.980952373832224e-09]}
Train Epoch: 86 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 7.700279525124643e-08, 6.395418239435458e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 1.73981504758558e-08, 4.34953761896395e-09]}
Train Epoch: 87 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -3.41756170030294e-08, -2.3445064556426587e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 2.5429027772361223e-08, 6.357256943090306e-09]}
Train Epoch: 88 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch088-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 7.176777927497824e-08, 3.040784291030718e-09], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0], 'L_grad': [1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 1.2163137164122872e-08, 3.040784291030718e-09]}
Train Epoch: 89 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 1.375831288896734e-07, 6.419810461011366e-08], 'L_si': [1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 5.960464477539063e-08], 'L_grad': [1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 1.837383578617846e-08, 4.593458946544615e-09]}
Train Epoch: 90 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
New Learning Rate: 0.000037
all losses in batch in validation:  {'loss': [1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, -2.4922373498270645e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08], 'L_grad': [1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 1.951979733405551e-08, 4.879949333513878e-09]}
Train Epoch: 91 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 7.915774347111437e-08, 6.449291589660788e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 1.955309514301007e-08, 4.888273785752517e-09]}
Train Epoch: 92 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch092-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 3.425306616122725e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08], 'L_grad': [1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 1.780296976505724e-08, 4.45074244126431e-09]}
Train Epoch: 93 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, -5.48312470982637e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.960464477539063e-08], 'L_grad': [1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 1.9093597813935048e-08, 4.773399453483762e-09]}
Train Epoch: 94 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.7354542570255944e-08, 3.169037654515705e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 7.552221070739051e-09, 1.888055267684763e-09]}
Train Epoch: 95 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 4.81633506410617e-08, 3.439257767468007e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 1.8361028253366385e-08, 4.590257063341596e-09]}
Train Epoch: 96 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch096-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [-3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -3.8892110865162977e-08, -5.442651129783371e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 2.071253391022765e-08, 5.178133477556912e-09]}
Train Epoch: 97 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09]}
Train Epoch: 98 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 1.3969838619232178e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 1.3969838619232178e-09]}
Train Epoch: 99 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, -2.307120894329273e-08, 1.6827785831452502e-09], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 6.731114332581001e-09, 1.6827785831452502e-09]}
Train Epoch: 100 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch100-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 6.459658585811212e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 2.583863434324485e-08, 6.459658585811212e-09]}
Train Epoch: 101 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 101 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 101 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 6.251114825772675e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 1.162601570570132e-08, 2.90650392642533e-09]}
Train Epoch: 102 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 102 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 102 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 7.974274751632038e-08, 6.463917401333674e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 2.0138106293643432e-08, 5.034526573410858e-09]}
Train Epoch: 103 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 103 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 103 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 1.9931856165555928e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 7.972742466222371e-09, 1.9931856165555928e-09]}
Train Epoch: 104 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 104 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 104 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch104-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 4.740449810469727e-08, 3.42028663169458e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 1.7602175717001955e-08, 4.400543929250489e-09]}
Train Epoch: 105 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 105 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 105 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 1.3489012129497269e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 5.3956048517989075e-09, 1.3489012129497269e-09]}
Train Epoch: 106 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 106 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 106 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 106 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 106 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 106 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 2.8435258592196533e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 1.1374103436878613e-08, 2.8435258592196533e-09]}
Train Epoch: 107 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 107 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 107 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 1.3969838619232178e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 5.587935447692871e-09, 1.3969838619232178e-09]}
Train Epoch: 108 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 108 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 108 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 108 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 108 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 108 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch108-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 3.0546029705647015e-08, 2.998825010536166e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 7.437068183513418e-10, 1.8592670458783545e-10]}
Train Epoch: 109 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 109 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 109 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 7.636845111846924e-08, 6.379559636116028e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 4.190951585769653e-09]}
Train Epoch: 110 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 110 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 110 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 110 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 110 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 110 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 4.9280469482937406e-08, 6.447417888466589e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 1.9478147095242093e-08, 4.869536773810523e-09]}
Train Epoch: 111 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 111 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 111 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 111 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 111 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 8.01339865574846e-08, 6.473698022091412e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 2.05293382293803e-08, 5.132334557345075e-09]}
Train Epoch: 112 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 112 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 112 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch112-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 6.406568786587741e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 1.784417591466081e-08, 4.461043978665202e-09]}
Train Epoch: 113 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 113 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 113 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 113 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 113 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 113 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 113 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9796865419484675e-08, -2.9800958145642653e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 5.4569682106375694e-12, 1.3642420526593924e-12]}
Train Epoch: 114 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 114 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 114 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [-4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -4.841240297537297e-08, -5.680658432538621e-08], 'L_si': [-5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 1.1192241800017655e-08, 2.7980604500044137e-09]}
Train Epoch: 115 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 115 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 115 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 115 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 115 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 7.639673782477985e-08, 6.380266626138109e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 1.6792093049389223e-08, 4.198023262347306e-09]}
Train Epoch: 116 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 116 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 116 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch116-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 1.3976521051617397e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 5.590608420646959e-09, 1.3976521051617397e-09]}
Train Epoch: 117 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 117 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [468/816 (57%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 117 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 117 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 117 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 117 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 6.239861249923706e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09]}
Train Epoch: 118 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [504/816 (62%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 118 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 118 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, 2.7939677238464355e-09], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09]}
Train Epoch: 119 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 119 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 119 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 7.695123116491231e-08, 6.394129314912789e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 1.734658816587853e-08, 4.336647041469632e-09]}
Train Epoch: 120 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 120 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 120 [288/816 (35%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 120 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 120 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 120 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 120 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch120-loss-0.0000.pth.tar ...
New Learning Rate: 0.000019
all losses in batch in validation:  {'loss': [4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, 4.375367268494301e-08, -2.6314484813383388e-08], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 1.395135118542612e-08, 3.48783779635653e-09]}
Train Epoch: 121 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [144/816 (18%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 121 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 121 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 121 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.4212827298697448e-08, -2.8404949503624266e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 5.589494644908655e-09, 1.3973736612271637e-09]}
Train Epoch: 122 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 122 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 122 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 122 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 122 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 122 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -1.30385160446167e-08, -2.561137080192566e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 4.190951585769653e-09]}
Train Epoch: 123 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 123 [72/816 (9%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 123 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 123 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [396/816 (49%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 123 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 123 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 123 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 6.379559636116028e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 4.190951585769653e-09]}
Train Epoch: 124 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 124 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 124 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 124 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch124-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 5.587935447692871e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 2.2351741790771484e-08, 5.587935447692871e-09]}
Train Epoch: 125 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 125 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 125 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 125 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 125 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 125 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 4.190951585769653e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 1.6763806343078613e-08, 4.190951585769653e-09]}
Train Epoch: 126 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 126 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 126 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 126 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 126 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 9.167707148982629e-10], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 3.6670828595930516e-09, 9.167707148982629e-10]}
Train Epoch: 127 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 127 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 127 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 127 [792/816 (97%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 2.906921592327194e-09], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'L_grad': [1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 1.1627686369308776e-08, 2.906921592327194e-09]}
Train Epoch: 128 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [216/816 (26%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 128 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 128 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [540/816 (66%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 128 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [720/816 (88%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 128 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 128 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_200e/train_s2d_SpikeTransformer/checkpoint-epoch128-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 6.239916672257095e-08], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 1.117809844686235e-08, 2.7945246117155875e-09]}
Train Epoch: 129 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [36/816 (4%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 129 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [108/816 (13%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 129 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [252/816 (31%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 129 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [360/816 (44%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 129 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [612/816 (75%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 129 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 129 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 7.078051567077637e-08, 6.239861249923706e-08], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09]}
Train Epoch: 130 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [180/816 (22%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [324/816 (40%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [432/816 (53%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [576/816 (71%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [648/816 (79%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [684/816 (84%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 130 [756/816 (93%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 130 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [-1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -1.862645149230957e-08, -2.7008354663848877e-08], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 1.1175870895385742e-08, 2.7939677238464355e-09]}
Train Epoch: 131 [0/816 (0%)] loss: -0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 131 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 131 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
