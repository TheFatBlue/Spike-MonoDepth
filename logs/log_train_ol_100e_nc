/root/miniconda3/envs/scv/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Trainable parameters: 20545951
S2DepthTransformerUNetConv(
  (encoder): LongSpikeStreamEncoderConv(
    (swin3d): SwinTransformer3D(
      (patch_embed): PatchEmbedLocalGlobal(
        (head): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (global_head): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (global_residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (global_proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=384, out_features=192, bias=False)
            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=768, out_features=384, bias=False)
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
    (conv_layers): ModuleList(
      (0): ModuleList(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ModuleList(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ModuleList(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (resblocks): ModuleList(
    (0): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (decoders): ModuleList(
    (0): UpsampleConvLayer(
      (conv2d): Conv2d(384, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (1): UpsampleConvLayer(
      (conv2d): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (2): UpsampleConvLayer(
      (conv2d): Conv2d(96, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (pred): ConvLayer(
    (conv2d): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)
Setting up Multi Scale Gradient loss...
Done
---- Single Training ----
Use GPU: 0 for training
Found 26 samples in /root/autodl-tmp/Spike-Stero/train
Found 8 samples in /root/autodl-tmp/Spike-Stero/validation
-----  [3, 6, 12]
---- new version 4 ----
Model Initialized
Using scale_invariant_loss with config {'weight': 1.0, 'n_lambda': 1.0}
Will not use phased architecture
Using Multi Scale Gradient loss with weight=0.25
Will not use MSE loss
Train Epoch: 1 [0/684 (0%)] loss: 0.0878 L_si: 0.0275 L_grad: 0.0603 
Train Epoch: 1 [36/684 (5%)] loss: 0.0717 L_si: 0.0262 L_grad: 0.0455 
Train Epoch: 1 [72/684 (11%)] loss: 0.0366 L_si: 0.0111 L_grad: 0.0255 
Train Epoch: 1 [108/684 (16%)] loss: 0.0542 L_si: 0.0184 L_grad: 0.0358 
Train Epoch: 1 [144/684 (21%)] loss: 0.0320 L_si: 0.0081 L_grad: 0.0239 
Train Epoch: 1 [180/684 (26%)] loss: 0.0460 L_si: 0.0186 L_grad: 0.0274 
Train Epoch: 1 [216/684 (32%)] loss: 0.0301 L_si: 0.0097 L_grad: 0.0204 
Train Epoch: 1 [252/684 (37%)] loss: 0.0317 L_si: 0.0099 L_grad: 0.0218 
Train Epoch: 1 [288/684 (42%)] loss: 0.0419 L_si: 0.0137 L_grad: 0.0282 
Train Epoch: 1 [324/684 (47%)] loss: 0.0268 L_si: 0.0060 L_grad: 0.0208 
Train Epoch: 1 [360/684 (53%)] loss: 0.0792 L_si: 0.0298 L_grad: 0.0495 
Train Epoch: 1 [396/684 (58%)] loss: 0.0412 L_si: 0.0122 L_grad: 0.0290 
Train Epoch: 1 [432/684 (63%)] loss: 0.0470 L_si: 0.0154 L_grad: 0.0316 
Train Epoch: 1 [468/684 (68%)] loss: 0.0231 L_si: 0.0057 L_grad: 0.0175 
Train Epoch: 1 [504/684 (74%)] loss: 0.0569 L_si: 0.0219 L_grad: 0.0350 
Train Epoch: 1 [540/684 (79%)] loss: 0.0149 L_si: 0.0030 L_grad: 0.0118 
Train Epoch: 1 [576/684 (84%)] loss: 0.0435 L_si: 0.0163 L_grad: 0.0273 
Train Epoch: 1 [612/684 (89%)] loss: 0.0357 L_si: 0.0091 L_grad: 0.0267 
Train Epoch: 1 [648/684 (95%)] loss: 0.0502 L_si: 0.0237 L_grad: 0.0265 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.026786930859088898, 0.010221155360341072, 0.008849726058542728, 0.03139171376824379, 0.008933022618293762, 0.0163356214761734, 0.008640909567475319, 0.02460608258843422, 0.01987835392355919, 0.009459164924919605, 0.011150877922773361, 0.023191701620817184, 0.01163681223988533, 0.018082287162542343, 0.009768473915755749], 'L_si': [0.008899729698896408, 0.0010163038969039917, 0.0006510131061077118, 0.011652175337076187, 0.0009162463247776031, 0.0039047934114933014, 0.0008203387260437012, 0.008933160454034805, 0.006358258426189423, 0.0011397004127502441, 0.001612599939107895, 0.008784934878349304, 0.001738566905260086, 0.005887895822525024, 0.0011093765497207642], 'L_grad': [0.01788720116019249, 0.00920485146343708, 0.008198712952435017, 0.019739538431167603, 0.008016776293516159, 0.0124308280646801, 0.007820570841431618, 0.015672922134399414, 0.013520094566047192, 0.008319464512169361, 0.009538277983665466, 0.014406765811145306, 0.009898245334625244, 0.012194390408694744, 0.008659097366034985]}
Train Epoch: 2 [0/684 (0%)] loss: 0.0801 L_si: 0.0369 L_grad: 0.0432 
Train Epoch: 2 [36/684 (5%)] loss: 0.0466 L_si: 0.0141 L_grad: 0.0325 
Train Epoch: 2 [72/684 (11%)] loss: 0.0429 L_si: 0.0162 L_grad: 0.0267 
Train Epoch: 2 [108/684 (16%)] loss: 0.0509 L_si: 0.0154 L_grad: 0.0355 
Train Epoch: 2 [144/684 (21%)] loss: 0.0637 L_si: 0.0273 L_grad: 0.0364 
Train Epoch: 2 [180/684 (26%)] loss: 0.0380 L_si: 0.0176 L_grad: 0.0203 
Train Epoch: 2 [216/684 (32%)] loss: 0.0341 L_si: 0.0088 L_grad: 0.0253 
Train Epoch: 2 [252/684 (37%)] loss: 0.0367 L_si: 0.0125 L_grad: 0.0242 
Train Epoch: 2 [288/684 (42%)] loss: 0.0308 L_si: 0.0092 L_grad: 0.0216 
Train Epoch: 2 [324/684 (47%)] loss: 0.0535 L_si: 0.0153 L_grad: 0.0383 
Train Epoch: 2 [360/684 (53%)] loss: 0.0543 L_si: 0.0193 L_grad: 0.0350 
Train Epoch: 2 [396/684 (58%)] loss: 0.0531 L_si: 0.0203 L_grad: 0.0328 
Train Epoch: 2 [432/684 (63%)] loss: 0.0318 L_si: 0.0082 L_grad: 0.0236 
Train Epoch: 2 [468/684 (68%)] loss: 0.0626 L_si: 0.0237 L_grad: 0.0389 
Train Epoch: 2 [504/684 (74%)] loss: 0.0329 L_si: 0.0099 L_grad: 0.0230 
Train Epoch: 2 [540/684 (79%)] loss: 0.0309 L_si: 0.0067 L_grad: 0.0242 
Train Epoch: 2 [576/684 (84%)] loss: 0.0553 L_si: 0.0183 L_grad: 0.0371 
Train Epoch: 2 [612/684 (89%)] loss: 0.0430 L_si: 0.0160 L_grad: 0.0270 
Train Epoch: 2 [648/684 (95%)] loss: 0.0546 L_si: 0.0248 L_grad: 0.0298 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.012398343533277512, 0.031141038984060287, 0.02306879311800003, 0.009465282782912254, 0.009174397215247154, 0.015062440186738968, 0.033389441668987274, 0.009797058068215847, 0.008930828422307968, 0.008725585415959358, 0.013041116297245026, 0.01052764430642128, 0.018814757466316223, 0.01803000643849373, 0.015951629728078842], 'L_si': [0.002258390188217163, 0.011562354862689972, 0.00880962610244751, 0.0012672990560531616, 0.001046895980834961, 0.003312986344099045, 0.013701964169740677, 0.0009841956198215485, 0.0007404796779155731, 0.0010417550802230835, 0.0020581036806106567, 0.0010893642902374268, 0.006121072918176651, 0.005979325622320175, 0.0031961798667907715], 'L_grad': [0.010139953345060349, 0.019578684121370316, 0.014259166084229946, 0.008197983726859093, 0.008127501234412193, 0.011749453842639923, 0.019687477499246597, 0.008812862448394299, 0.008190348744392395, 0.007683830335736275, 0.010983012616634369, 0.009438280016183853, 0.012693684548139572, 0.012050680816173553, 0.012755448929965496]}
Train Epoch: 3 [0/684 (0%)] loss: 0.0172 L_si: 0.0035 L_grad: 0.0136 
Train Epoch: 3 [36/684 (5%)] loss: 0.0311 L_si: 0.0080 L_grad: 0.0232 
Train Epoch: 3 [72/684 (11%)] loss: 0.0192 L_si: 0.0022 L_grad: 0.0170 
Train Epoch: 3 [108/684 (16%)] loss: 0.0527 L_si: 0.0180 L_grad: 0.0347 
Train Epoch: 3 [144/684 (21%)] loss: 0.0280 L_si: 0.0051 L_grad: 0.0229 
Train Epoch: 3 [180/684 (26%)] loss: 0.0441 L_si: 0.0155 L_grad: 0.0285 
Train Epoch: 3 [216/684 (32%)] loss: 0.0243 L_si: 0.0064 L_grad: 0.0179 
Train Epoch: 3 [252/684 (37%)] loss: 0.0208 L_si: 0.0066 L_grad: 0.0142 
Train Epoch: 3 [288/684 (42%)] loss: 0.0778 L_si: 0.0351 L_grad: 0.0427 
Train Epoch: 3 [324/684 (47%)] loss: 0.0661 L_si: 0.0302 L_grad: 0.0359 
Train Epoch: 3 [360/684 (53%)] loss: 0.0748 L_si: 0.0401 L_grad: 0.0347 
Train Epoch: 3 [396/684 (58%)] loss: 0.0707 L_si: 0.0247 L_grad: 0.0461 
Train Epoch: 3 [432/684 (63%)] loss: 0.0361 L_si: 0.0110 L_grad: 0.0251 
Train Epoch: 3 [468/684 (68%)] loss: 0.0388 L_si: 0.0102 L_grad: 0.0286 
Train Epoch: 3 [504/684 (74%)] loss: 0.0443 L_si: 0.0112 L_grad: 0.0331 
Train Epoch: 3 [540/684 (79%)] loss: 0.0348 L_si: 0.0084 L_grad: 0.0263 
Train Epoch: 3 [576/684 (84%)] loss: 0.0604 L_si: 0.0243 L_grad: 0.0361 
Train Epoch: 3 [612/684 (89%)] loss: 0.0516 L_si: 0.0181 L_grad: 0.0335 
Train Epoch: 3 [648/684 (95%)] loss: 0.0580 L_si: 0.0257 L_grad: 0.0323 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.022533517330884933, 0.0193953774869442, 0.01661752723157406, 0.011311476118862629, 0.008604606613516808, 0.010462800972163677, 0.010557443834841251, 0.009211482480168343, 0.02951175346970558, 0.020949488505721092, 0.015381521545350552, 0.022430751472711563, 0.012697119265794754, 0.018885497003793716, 0.008859983645379543], 'L_si': [0.008702374994754791, 0.006244082003831863, 0.003191255033016205, 0.0013813599944114685, 0.000769786536693573, 0.0013487599790096283, 0.0013508275151252747, 0.0009338892996311188, 0.01127384603023529, 0.006569072604179382, 0.0033349692821502686, 0.008429944515228271, 0.002020176500082016, 0.00614558532834053, 0.001084350049495697], 'L_grad': [0.013831142336130142, 0.01315129641443491, 0.013426272198557854, 0.00993011612445116, 0.007834820076823235, 0.009114040993154049, 0.009206616319715977, 0.008277593180537224, 0.01823790743947029, 0.01438041590154171, 0.012046552263200283, 0.014000807888805866, 0.010676942765712738, 0.012739911675453186, 0.007775633595883846]}
Train Epoch: 4 [0/684 (0%)] loss: 0.0321 L_si: 0.0108 L_grad: 0.0213 
Train Epoch: 4 [36/684 (5%)] loss: 0.0528 L_si: 0.0174 L_grad: 0.0353 
Train Epoch: 4 [72/684 (11%)] loss: 0.0454 L_si: 0.0128 L_grad: 0.0326 
Train Epoch: 4 [108/684 (16%)] loss: 0.0373 L_si: 0.0174 L_grad: 0.0198 
Train Epoch: 4 [144/684 (21%)] loss: 0.0327 L_si: 0.0081 L_grad: 0.0246 
Train Epoch: 4 [180/684 (26%)] loss: 0.0798 L_si: 0.0337 L_grad: 0.0461 
Train Epoch: 4 [216/684 (32%)] loss: 0.0277 L_si: 0.0090 L_grad: 0.0187 
Train Epoch: 4 [252/684 (37%)] loss: 0.0283 L_si: 0.0090 L_grad: 0.0193 
Train Epoch: 4 [288/684 (42%)] loss: 0.0514 L_si: 0.0194 L_grad: 0.0320 
Train Epoch: 4 [324/684 (47%)] loss: 0.0297 L_si: 0.0091 L_grad: 0.0207 
Train Epoch: 4 [360/684 (53%)] loss: 0.0584 L_si: 0.0199 L_grad: 0.0385 
Train Epoch: 4 [396/684 (58%)] loss: 0.0731 L_si: 0.0333 L_grad: 0.0399 
Train Epoch: 4 [432/684 (63%)] loss: 0.0528 L_si: 0.0161 L_grad: 0.0366 
Train Epoch: 4 [468/684 (68%)] loss: 0.0455 L_si: 0.0195 L_grad: 0.0260 
Train Epoch: 4 [504/684 (74%)] loss: 0.0446 L_si: 0.0143 L_grad: 0.0303 
Train Epoch: 4 [540/684 (79%)] loss: 0.0676 L_si: 0.0274 L_grad: 0.0402 
Train Epoch: 4 [576/684 (84%)] loss: 0.0608 L_si: 0.0288 L_grad: 0.0320 
Train Epoch: 4 [612/684 (89%)] loss: 0.0282 L_si: 0.0093 L_grad: 0.0189 
Train Epoch: 4 [648/684 (95%)] loss: 0.0454 L_si: 0.0179 L_grad: 0.0275 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008990148082375526, 0.025679724290966988, 0.014726473949849606, 0.015765391290187836, 0.023487141355872154, 0.01357860118150711, 0.00880129262804985, 0.009566221386194229, 0.01661846973001957, 0.019408516585826874, 0.019290953874588013, 0.03507252410054207, 0.008041121065616608, 0.009928707033395767, 0.008661286905407906], 'L_si': [0.0010584183037281036, 0.009316951036453247, 0.003262333571910858, 0.003590371459722519, 0.008978310972452164, 0.001997612416744232, 0.0008018463850021362, 0.0009495653212070465, 0.00330464169383049, 0.006242256611585617, 0.006213180720806122, 0.01452961191534996, 0.0008709020912647247, 0.001048840582370758, 0.0011529810726642609], 'L_grad': [0.007931729778647423, 0.01636277325451374, 0.011464140377938747, 0.012175018899142742, 0.01450883038341999, 0.011580988764762878, 0.007999446243047714, 0.008616656064987183, 0.01331382803618908, 0.013166259974241257, 0.013077773153781891, 0.020542912185192108, 0.007170218508690596, 0.00887986645102501, 0.007508306298404932]}
Train Epoch: 5 [0/684 (0%)] loss: 0.0452 L_si: 0.0167 L_grad: 0.0284 
Train Epoch: 5 [36/684 (5%)] loss: 0.0353 L_si: 0.0093 L_grad: 0.0260 
Train Epoch: 5 [72/684 (11%)] loss: 0.0518 L_si: 0.0204 L_grad: 0.0315 
Train Epoch: 5 [108/684 (16%)] loss: 0.0364 L_si: 0.0128 L_grad: 0.0236 
Train Epoch: 5 [144/684 (21%)] loss: 0.0255 L_si: 0.0056 L_grad: 0.0200 
Train Epoch: 5 [180/684 (26%)] loss: 0.0469 L_si: 0.0128 L_grad: 0.0341 
Train Epoch: 5 [216/684 (32%)] loss: 0.0277 L_si: 0.0057 L_grad: 0.0219 
Train Epoch: 5 [252/684 (37%)] loss: 0.0536 L_si: 0.0199 L_grad: 0.0337 
Train Epoch: 5 [288/684 (42%)] loss: 0.0333 L_si: 0.0075 L_grad: 0.0258 
Train Epoch: 5 [324/684 (47%)] loss: 0.0433 L_si: 0.0131 L_grad: 0.0302 
Train Epoch: 5 [360/684 (53%)] loss: 0.0242 L_si: 0.0057 L_grad: 0.0185 
Train Epoch: 5 [396/684 (58%)] loss: 0.0291 L_si: 0.0070 L_grad: 0.0220 
Train Epoch: 5 [432/684 (63%)] loss: 0.0738 L_si: 0.0353 L_grad: 0.0386 
Train Epoch: 5 [468/684 (68%)] loss: 0.0763 L_si: 0.0341 L_grad: 0.0422 
Train Epoch: 5 [504/684 (74%)] loss: 0.0545 L_si: 0.0204 L_grad: 0.0341 
Train Epoch: 5 [540/684 (79%)] loss: 0.0436 L_si: 0.0164 L_grad: 0.0272 
Train Epoch: 5 [576/684 (84%)] loss: 0.0735 L_si: 0.0325 L_grad: 0.0410 
Train Epoch: 5 [612/684 (89%)] loss: 0.0444 L_si: 0.0156 L_grad: 0.0288 
Train Epoch: 5 [648/684 (95%)] loss: 0.0451 L_si: 0.0167 L_grad: 0.0284 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.025146443396806717, 0.009967230260372162, 0.01776881329715252, 0.012408814392983913, 0.015300987288355827, 0.018445000052452087, 0.010084424167871475, 0.025093667209148407, 0.009668754413723946, 0.02926810458302498, 0.010307504795491695, 0.010230282321572304, 0.023811321705579758, 0.008989443071186543, 0.011312907561659813], 'L_si': [0.009045638144016266, 0.0010851547122001648, 0.006062760949134827, 0.0020544305443763733, 0.003297746181488037, 0.005857881158590317, 0.0013889260590076447, 0.008213784545660019, 0.0010432638227939606, 0.011226203292608261, 0.0014809034764766693, 0.001376871019601822, 0.008749168366193771, 0.0012404248118400574, 0.0015692710876464844], 'L_grad': [0.01610080525279045, 0.008882075548171997, 0.011706052348017693, 0.01035438384860754, 0.01200324110686779, 0.012587117962539196, 0.00869549810886383, 0.016879882663488388, 0.008625490590929985, 0.018041901290416718, 0.008826601319015026, 0.008853411301970482, 0.015062153339385986, 0.007749018259346485, 0.009743636474013329]}
Train Epoch: 6 [0/684 (0%)] loss: 0.0486 L_si: 0.0230 L_grad: 0.0255 
Train Epoch: 6 [36/684 (5%)] loss: 0.0371 L_si: 0.0133 L_grad: 0.0238 
Train Epoch: 6 [72/684 (11%)] loss: 0.0841 L_si: 0.0372 L_grad: 0.0469 
Train Epoch: 6 [108/684 (16%)] loss: 0.0525 L_si: 0.0171 L_grad: 0.0354 
Train Epoch: 6 [144/684 (21%)] loss: 0.0287 L_si: 0.0073 L_grad: 0.0214 
Train Epoch: 6 [180/684 (26%)] loss: 0.0387 L_si: 0.0140 L_grad: 0.0247 
Train Epoch: 6 [216/684 (32%)] loss: 0.0373 L_si: 0.0099 L_grad: 0.0273 
Train Epoch: 6 [252/684 (37%)] loss: 0.0260 L_si: 0.0045 L_grad: 0.0215 
Train Epoch: 6 [288/684 (42%)] loss: 0.0666 L_si: 0.0265 L_grad: 0.0401 
Train Epoch: 6 [324/684 (47%)] loss: 0.0522 L_si: 0.0195 L_grad: 0.0327 
Train Epoch: 6 [360/684 (53%)] loss: 0.0264 L_si: 0.0054 L_grad: 0.0210 
Train Epoch: 6 [396/684 (58%)] loss: 0.0245 L_si: 0.0046 L_grad: 0.0199 
Train Epoch: 6 [432/684 (63%)] loss: 0.0438 L_si: 0.0129 L_grad: 0.0309 
Train Epoch: 6 [468/684 (68%)] loss: 0.0591 L_si: 0.0209 L_grad: 0.0382 
Train Epoch: 6 [504/684 (74%)] loss: 0.0628 L_si: 0.0305 L_grad: 0.0323 
Train Epoch: 6 [540/684 (79%)] loss: 0.0407 L_si: 0.0115 L_grad: 0.0292 
Train Epoch: 6 [576/684 (84%)] loss: 0.0511 L_si: 0.0218 L_grad: 0.0293 
Train Epoch: 6 [612/684 (89%)] loss: 0.0525 L_si: 0.0177 L_grad: 0.0349 
Train Epoch: 6 [648/684 (95%)] loss: 0.0225 L_si: 0.0040 L_grad: 0.0185 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.027959415689110756, 0.008776177652180195, 0.030249040573835373, 0.024175520986318588, 0.01001741923391819, 0.029595378786325455, 0.018435006961226463, 0.010814188979566097, 0.00874156691133976, 0.013080082833766937, 0.015648480504751205, 0.010592118836939335, 0.009776878170669079, 0.008811237290501595, 0.011761832982301712], 'L_si': [0.010843783617019653, 0.0008868016302585602, 0.011454887688159943, 0.008968781679868698, 0.0009723789989948273, 0.0113026462495327, 0.0061340294778347015, 0.001475844532251358, 0.0008156076073646545, 0.0020368844270706177, 0.003373868763446808, 0.001434970647096634, 0.0009772330522537231, 0.0010689273476600647, 0.0012793540954589844], 'L_grad': [0.017115632072091103, 0.007889376021921635, 0.01879415288567543, 0.015206738375127316, 0.009045040234923363, 0.018292732536792755, 0.012300977483391762, 0.00933834444731474, 0.007925959303975105, 0.01104319840669632, 0.012274611741304398, 0.009157148189842701, 0.008799645118415356, 0.00774230994284153, 0.010482478886842728]}
Train Epoch: 7 [0/684 (0%)] loss: 0.0394 L_si: 0.0123 L_grad: 0.0271 
Train Epoch: 7 [36/684 (5%)] loss: 0.0200 L_si: 0.0038 L_grad: 0.0162 
Train Epoch: 7 [72/684 (11%)] loss: 0.0563 L_si: 0.0197 L_grad: 0.0366 
Train Epoch: 7 [108/684 (16%)] loss: 0.0282 L_si: 0.0061 L_grad: 0.0221 
Train Epoch: 7 [144/684 (21%)] loss: 0.0336 L_si: 0.0098 L_grad: 0.0238 
Train Epoch: 7 [180/684 (26%)] loss: 0.0514 L_si: 0.0225 L_grad: 0.0288 
Train Epoch: 7 [216/684 (32%)] loss: 0.0592 L_si: 0.0233 L_grad: 0.0359 
Train Epoch: 7 [252/684 (37%)] loss: 0.0391 L_si: 0.0113 L_grad: 0.0278 
Train Epoch: 7 [288/684 (42%)] loss: 0.0254 L_si: 0.0052 L_grad: 0.0202 
Train Epoch: 7 [324/684 (47%)] loss: 0.0546 L_si: 0.0252 L_grad: 0.0294 
Train Epoch: 7 [360/684 (53%)] loss: 0.0318 L_si: 0.0074 L_grad: 0.0244 
Train Epoch: 7 [396/684 (58%)] loss: 0.0680 L_si: 0.0277 L_grad: 0.0403 
Train Epoch: 7 [432/684 (63%)] loss: 0.0302 L_si: 0.0065 L_grad: 0.0236 
Train Epoch: 7 [468/684 (68%)] loss: 0.0808 L_si: 0.0376 L_grad: 0.0432 
Train Epoch: 7 [504/684 (74%)] loss: 0.0360 L_si: 0.0087 L_grad: 0.0273 
Train Epoch: 7 [540/684 (79%)] loss: 0.0456 L_si: 0.0167 L_grad: 0.0290 
Train Epoch: 7 [576/684 (84%)] loss: 0.0811 L_si: 0.0325 L_grad: 0.0487 
Train Epoch: 7 [612/684 (89%)] loss: 0.0458 L_si: 0.0185 L_grad: 0.0273 
Train Epoch: 7 [648/684 (95%)] loss: 0.0513 L_si: 0.0177 L_grad: 0.0336 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.00851591769605875, 0.019939113408327103, 0.03068627044558525, 0.01798234134912491, 0.00921257771551609, 0.009431233629584312, 0.024824894964694977, 0.01732015237212181, 0.008857954293489456, 0.0193037036806345, 0.009963243268430233, 0.010176308453083038, 0.019011834636330605, 0.023489268496632576, 0.010139267891645432], 'L_si': [0.0007550567388534546, 0.006528910249471664, 0.011318642646074295, 0.0042456164956092834, 0.001126844435930252, 0.0011323541402816772, 0.00933043658733368, 0.00380127876996994, 0.000998660922050476, 0.006177365779876709, 0.0009155720472335815, 0.0012391768395900726, 0.005975686013698578, 0.008870236575603485, 0.0010227486491203308], 'L_grad': [0.0077608609572052956, 0.013410203158855438, 0.019367627799510956, 0.013736724853515625, 0.008085733279585838, 0.008298879489302635, 0.015494458377361298, 0.01351887360215187, 0.00785929337143898, 0.01312633790075779, 0.009047671221196651, 0.008937131613492966, 0.013036148622632027, 0.014619031921029091, 0.0091165192425251]}
Train Epoch: 8 [0/684 (0%)] loss: 0.0250 L_si: 0.0042 L_grad: 0.0208 
Train Epoch: 8 [36/684 (5%)] loss: 0.0507 L_si: 0.0175 L_grad: 0.0331 
Train Epoch: 8 [72/684 (11%)] loss: 0.0441 L_si: 0.0157 L_grad: 0.0284 
Train Epoch: 8 [108/684 (16%)] loss: 0.0302 L_si: 0.0091 L_grad: 0.0210 
Train Epoch: 8 [144/684 (21%)] loss: 0.0297 L_si: 0.0061 L_grad: 0.0236 
Train Epoch: 8 [180/684 (26%)] loss: 0.0283 L_si: 0.0062 L_grad: 0.0220 
Train Epoch: 8 [216/684 (32%)] loss: 0.0314 L_si: 0.0080 L_grad: 0.0234 
Train Epoch: 8 [252/684 (37%)] loss: 0.0261 L_si: 0.0055 L_grad: 0.0206 
Train Epoch: 8 [288/684 (42%)] loss: 0.0646 L_si: 0.0276 L_grad: 0.0371 
Train Epoch: 8 [324/684 (47%)] loss: 0.0573 L_si: 0.0161 L_grad: 0.0412 
Train Epoch: 8 [360/684 (53%)] loss: 0.0496 L_si: 0.0161 L_grad: 0.0335 
Train Epoch: 8 [396/684 (58%)] loss: 0.0690 L_si: 0.0297 L_grad: 0.0393 
Train Epoch: 8 [432/684 (63%)] loss: 0.0431 L_si: 0.0173 L_grad: 0.0257 
Train Epoch: 8 [468/684 (68%)] loss: 0.0821 L_si: 0.0352 L_grad: 0.0469 
Train Epoch: 8 [504/684 (74%)] loss: 0.0414 L_si: 0.0125 L_grad: 0.0289 
Train Epoch: 8 [540/684 (79%)] loss: 0.0804 L_si: 0.0280 L_grad: 0.0525 
Train Epoch: 8 [576/684 (84%)] loss: 0.0371 L_si: 0.0100 L_grad: 0.0270 
Train Epoch: 8 [612/684 (89%)] loss: 0.0384 L_si: 0.0112 L_grad: 0.0272 
Train Epoch: 8 [648/684 (95%)] loss: 0.0614 L_si: 0.0246 L_grad: 0.0368 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010749515146017075, 0.009217998944222927, 0.023405078798532486, 0.01079484075307846, 0.016838382929563522, 0.008803103119134903, 0.01933497190475464, 0.020465385168790817, 0.026531100273132324, 0.02285921946167946, 0.009174076840281487, 0.010385474190115929, 0.00981823354959488, 0.02868949994444847, 0.01193266548216343], 'L_si': [0.0014581717550754547, 0.0007480084896087646, 0.008768849074840546, 0.0016087926924228668, 0.00403551384806633, 0.0007358454167842865, 0.006258752197027206, 0.0064053013920784, 0.00859975814819336, 0.008781716227531433, 0.0009385310113430023, 0.0012829117476940155, 0.0010189004242420197, 0.011116333305835724, 0.0019122958183288574], 'L_grad': [0.00929134339094162, 0.008469990454614162, 0.01463622972369194, 0.009186048060655594, 0.012802870012819767, 0.008067257702350616, 0.013076219707727432, 0.014060084708034992, 0.017931342124938965, 0.014077502302825451, 0.008235545828938484, 0.009102562442421913, 0.00879933312535286, 0.017573166638612747, 0.010020369663834572]}
Train Epoch: 9 [0/684 (0%)] loss: 0.1033 L_si: 0.0485 L_grad: 0.0548 
Train Epoch: 9 [36/684 (5%)] loss: 0.0250 L_si: 0.0064 L_grad: 0.0186 
Train Epoch: 9 [72/684 (11%)] loss: 0.0554 L_si: 0.0257 L_grad: 0.0297 
Train Epoch: 9 [108/684 (16%)] loss: 0.0242 L_si: 0.0050 L_grad: 0.0193 
Train Epoch: 9 [144/684 (21%)] loss: 0.0279 L_si: 0.0055 L_grad: 0.0225 
Train Epoch: 9 [180/684 (26%)] loss: 0.0449 L_si: 0.0156 L_grad: 0.0293 
Train Epoch: 9 [216/684 (32%)] loss: 0.0237 L_si: 0.0052 L_grad: 0.0185 
Train Epoch: 9 [252/684 (37%)] loss: 0.0263 L_si: 0.0068 L_grad: 0.0194 
Train Epoch: 9 [288/684 (42%)] loss: 0.0527 L_si: 0.0179 L_grad: 0.0348 
Train Epoch: 9 [324/684 (47%)] loss: 0.0557 L_si: 0.0193 L_grad: 0.0365 
Train Epoch: 9 [360/684 (53%)] loss: 0.0590 L_si: 0.0225 L_grad: 0.0364 
Train Epoch: 9 [396/684 (58%)] loss: 0.0393 L_si: 0.0127 L_grad: 0.0266 
Train Epoch: 9 [432/684 (63%)] loss: 0.0348 L_si: 0.0144 L_grad: 0.0203 
Train Epoch: 9 [468/684 (68%)] loss: 0.0495 L_si: 0.0207 L_grad: 0.0289 
Train Epoch: 9 [504/684 (74%)] loss: 0.0628 L_si: 0.0282 L_grad: 0.0346 
Train Epoch: 9 [540/684 (79%)] loss: 0.0566 L_si: 0.0259 L_grad: 0.0307 
Train Epoch: 9 [576/684 (84%)] loss: 0.0359 L_si: 0.0119 L_grad: 0.0240 
Train Epoch: 9 [612/684 (89%)] loss: 0.0314 L_si: 0.0067 L_grad: 0.0248 
Train Epoch: 9 [648/684 (95%)] loss: 0.0457 L_si: 0.0148 L_grad: 0.0309 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009967704303562641, 0.01277073472738266, 0.023614995181560516, 0.019113676622509956, 0.023386307060718536, 0.01062129158526659, 0.016476696357131004, 0.015154142864048481, 0.009302876889705658, 0.010934094898402691, 0.0254066102206707, 0.010910693556070328, 0.015259544365108013, 0.019094277173280716, 0.019608523696660995], 'L_si': [0.001171022653579712, 0.00170927494764328, 0.008808158338069916, 0.0063252560794353485, 0.008717060089111328, 0.0015150420367717743, 0.00338011234998703, 0.003117389976978302, 0.0010233521461486816, 0.001627545803785324, 0.008876629173755646, 0.001487787812948227, 0.003369338810443878, 0.005983233451843262, 0.006406314671039581], 'L_grad': [0.00879668164998293, 0.01106145977973938, 0.0148068368434906, 0.012788420543074608, 0.014669246971607208, 0.009106249548494816, 0.013096584007143974, 0.012036752887070179, 0.008279524743556976, 0.009306549094617367, 0.016529981046915054, 0.0094229057431221, 0.011890205554664135, 0.013111044652760029, 0.013202209025621414]}
Train Epoch: 10 [0/684 (0%)] loss: 0.0260 L_si: 0.0053 L_grad: 0.0207 
Train Epoch: 10 [36/684 (5%)] loss: 0.0406 L_si: 0.0164 L_grad: 0.0242 
Train Epoch: 10 [72/684 (11%)] loss: 0.0678 L_si: 0.0244 L_grad: 0.0435 
Train Epoch: 10 [108/684 (16%)] loss: 0.0284 L_si: 0.0067 L_grad: 0.0218 
Train Epoch: 10 [144/684 (21%)] loss: 0.0406 L_si: 0.0152 L_grad: 0.0253 
Train Epoch: 10 [180/684 (26%)] loss: 0.0210 L_si: 0.0065 L_grad: 0.0145 
Train Epoch: 10 [216/684 (32%)] loss: 0.0665 L_si: 0.0240 L_grad: 0.0424 
Train Epoch: 10 [252/684 (37%)] loss: 0.0585 L_si: 0.0216 L_grad: 0.0370 
Train Epoch: 10 [288/684 (42%)] loss: 0.0424 L_si: 0.0109 L_grad: 0.0315 
Train Epoch: 10 [324/684 (47%)] loss: 0.0941 L_si: 0.0453 L_grad: 0.0489 
Train Epoch: 10 [360/684 (53%)] loss: 0.0551 L_si: 0.0179 L_grad: 0.0372 
Train Epoch: 10 [396/684 (58%)] loss: 0.0498 L_si: 0.0184 L_grad: 0.0314 
Train Epoch: 10 [432/684 (63%)] loss: 0.0381 L_si: 0.0098 L_grad: 0.0283 
Train Epoch: 10 [468/684 (68%)] loss: 0.0624 L_si: 0.0281 L_grad: 0.0342 
Train Epoch: 10 [504/684 (74%)] loss: 0.0572 L_si: 0.0270 L_grad: 0.0302 
Train Epoch: 10 [540/684 (79%)] loss: 0.0389 L_si: 0.0159 L_grad: 0.0230 
Train Epoch: 10 [576/684 (84%)] loss: 0.0421 L_si: 0.0151 L_grad: 0.0271 
Train Epoch: 10 [612/684 (89%)] loss: 0.0460 L_si: 0.0164 L_grad: 0.0295 
Train Epoch: 10 [648/684 (95%)] loss: 0.0362 L_si: 0.0140 L_grad: 0.0223 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch010-loss-0.0450.pth.tar ...
all losses in batch in validation:  {'loss': [0.010247865691781044, 0.010522760450839996, 0.009426400065422058, 0.03160577267408371, 0.009429387748241425, 0.024678703397512436, 0.008623456582427025, 0.01079745776951313, 0.008726084604859352, 0.008646171540021896, 0.01551119890064001, 0.043191276490688324, 0.01294480636715889, 0.022977927699685097, 0.011141020804643631], 'L_si': [0.0012716390192508698, 0.0012916848063468933, 0.0010184049606323242, 0.011732783168554306, 0.00115898996591568, 0.008263062685728073, 0.000776488333940506, 0.001421567052602768, 0.0012070946395397186, 0.0008329190313816071, 0.0033713392913341522, 0.01903408393263817, 0.0018711313605308533, 0.00881173089146614, 0.001381807029247284], 'L_grad': [0.008976226672530174, 0.009231075644493103, 0.008407995104789734, 0.019872987642884254, 0.008270397782325745, 0.016415640711784363, 0.007846968248486519, 0.009375890716910362, 0.0075189899653196335, 0.00781325250864029, 0.012139859609305859, 0.024157190695405006, 0.011073675006628036, 0.014166196808218956, 0.009759213775396347]}
Train Epoch: 11 [0/684 (0%)] loss: 0.0271 L_si: 0.0058 L_grad: 0.0214 
Train Epoch: 11 [36/684 (5%)] loss: 0.0543 L_si: 0.0246 L_grad: 0.0297 
Train Epoch: 11 [72/684 (11%)] loss: 0.0740 L_si: 0.0293 L_grad: 0.0447 
Train Epoch: 11 [108/684 (16%)] loss: 0.0352 L_si: 0.0088 L_grad: 0.0264 
Train Epoch: 11 [144/684 (21%)] loss: 0.0440 L_si: 0.0165 L_grad: 0.0275 
Train Epoch: 11 [180/684 (26%)] loss: 0.0277 L_si: 0.0059 L_grad: 0.0218 
Train Epoch: 11 [216/684 (32%)] loss: 0.0353 L_si: 0.0105 L_grad: 0.0247 
Train Epoch: 11 [252/684 (37%)] loss: 0.0709 L_si: 0.0249 L_grad: 0.0461 
Train Epoch: 11 [288/684 (42%)] loss: 0.0346 L_si: 0.0082 L_grad: 0.0263 
Train Epoch: 11 [324/684 (47%)] loss: 0.0571 L_si: 0.0204 L_grad: 0.0367 
Train Epoch: 11 [360/684 (53%)] loss: 0.0280 L_si: 0.0068 L_grad: 0.0212 
Train Epoch: 11 [396/684 (58%)] loss: 0.0550 L_si: 0.0192 L_grad: 0.0358 
Train Epoch: 11 [432/684 (63%)] loss: 0.0418 L_si: 0.0127 L_grad: 0.0290 
Train Epoch: 11 [468/684 (68%)] loss: 0.0423 L_si: 0.0152 L_grad: 0.0271 
Train Epoch: 11 [504/684 (74%)] loss: 0.0491 L_si: 0.0154 L_grad: 0.0337 
Train Epoch: 11 [540/684 (79%)] loss: 0.0219 L_si: 0.0047 L_grad: 0.0172 
Train Epoch: 11 [576/684 (84%)] loss: 0.0332 L_si: 0.0104 L_grad: 0.0229 
Train Epoch: 11 [612/684 (89%)] loss: 0.0553 L_si: 0.0229 L_grad: 0.0325 
Train Epoch: 11 [648/684 (95%)] loss: 0.0561 L_si: 0.0214 L_grad: 0.0347 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.011055662296712399, 0.009085237979888916, 0.009945657104253769, 0.011109675280749798, 0.010115018114447594, 0.0638962835073471, 0.008610866963863373, 0.015325073152780533, 0.00871105957776308, 0.018684735521674156, 0.00932049285620451, 0.01293081883341074, 0.008381837047636509, 0.015180451795458794, 0.0253358893096447], 'L_si': [0.001479916274547577, 0.001043558120727539, 0.0010155513882637024, 0.001383855938911438, 0.00154055655002594, 0.029113788157701492, 0.0009260661900043488, 0.0033590011298656464, 0.0009203255176544189, 0.006032928824424744, 0.0012277290225028992, 0.001611180603504181, 0.0007859580218791962, 0.003588855266571045, 0.009522482752799988], 'L_grad': [0.009575746022164822, 0.008041679859161377, 0.008930105715990067, 0.00972581934183836, 0.008574461564421654, 0.034782495349645615, 0.007684800773859024, 0.011966072022914886, 0.007790734060108662, 0.012651806697249413, 0.00809276383370161, 0.011319638229906559, 0.007595879025757313, 0.011591596528887749, 0.01581340655684471]}
Train Epoch: 12 [0/684 (0%)] loss: 0.0411 L_si: 0.0167 L_grad: 0.0244 
Train Epoch: 12 [36/684 (5%)] loss: 0.0542 L_si: 0.0236 L_grad: 0.0306 
Train Epoch: 12 [72/684 (11%)] loss: 0.0208 L_si: 0.0038 L_grad: 0.0170 
Train Epoch: 12 [108/684 (16%)] loss: 0.0468 L_si: 0.0169 L_grad: 0.0299 
Train Epoch: 12 [144/684 (21%)] loss: 0.0394 L_si: 0.0121 L_grad: 0.0273 
Train Epoch: 12 [180/684 (26%)] loss: 0.0548 L_si: 0.0170 L_grad: 0.0378 
Train Epoch: 12 [216/684 (32%)] loss: 0.0597 L_si: 0.0213 L_grad: 0.0384 
Train Epoch: 12 [252/684 (37%)] loss: 0.0523 L_si: 0.0212 L_grad: 0.0311 
Train Epoch: 12 [288/684 (42%)] loss: 0.0420 L_si: 0.0136 L_grad: 0.0283 
Train Epoch: 12 [324/684 (47%)] loss: 0.0439 L_si: 0.0138 L_grad: 0.0301 
Train Epoch: 12 [360/684 (53%)] loss: 0.0453 L_si: 0.0147 L_grad: 0.0306 
Train Epoch: 12 [396/684 (58%)] loss: 0.0571 L_si: 0.0248 L_grad: 0.0322 
Train Epoch: 12 [432/684 (63%)] loss: 0.0735 L_si: 0.0286 L_grad: 0.0448 
Train Epoch: 12 [468/684 (68%)] loss: 0.0647 L_si: 0.0197 L_grad: 0.0451 
Train Epoch: 12 [504/684 (74%)] loss: 0.0557 L_si: 0.0239 L_grad: 0.0318 
Train Epoch: 12 [540/684 (79%)] loss: 0.0433 L_si: 0.0133 L_grad: 0.0300 
Train Epoch: 12 [576/684 (84%)] loss: 0.0467 L_si: 0.0164 L_grad: 0.0302 
Train Epoch: 12 [612/684 (89%)] loss: 0.0299 L_si: 0.0085 L_grad: 0.0215 
Train Epoch: 12 [648/684 (95%)] loss: 0.0438 L_si: 0.0136 L_grad: 0.0302 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.023106111213564873, 0.024001464247703552, 0.024140190333127975, 0.026755601167678833, 0.008259229362010956, 0.008432839065790176, 0.008590581826865673, 0.010511744767427444, 0.013151420280337334, 0.008467214182019234, 0.009167322888970375, 0.028709828853607178, 0.019884033128619194, 0.015733614563941956, 0.010214412584900856], 'L_si': [0.005937166512012482, 0.008907672017812729, 0.008862219750881195, 0.009828291833400726, 0.0008738934993743896, 0.0007303133606910706, 0.0009118691086769104, 0.0011611878871917725, 0.002111278474330902, 0.0006003156304359436, 0.0009585767984390259, 0.011124402284622192, 0.00657876580953598, 0.00347711518406868, 0.0011425726115703583], 'L_grad': [0.01716894470155239, 0.015093791298568249, 0.01527797058224678, 0.016927309334278107, 0.007385335862636566, 0.0077025252394378185, 0.007678712718188763, 0.009350556880235672, 0.011040141806006432, 0.00786689855158329, 0.00820874609053135, 0.017585426568984985, 0.013305267319083214, 0.012256499379873276, 0.009071839973330498]}
Train Epoch: 13 [0/684 (0%)] loss: 0.0447 L_si: 0.0176 L_grad: 0.0271 
Train Epoch: 13 [36/684 (5%)] loss: 0.0600 L_si: 0.0183 L_grad: 0.0416 
Train Epoch: 13 [72/684 (11%)] loss: 0.0363 L_si: 0.0086 L_grad: 0.0277 
Train Epoch: 13 [108/684 (16%)] loss: 0.0617 L_si: 0.0287 L_grad: 0.0330 
Train Epoch: 13 [144/684 (21%)] loss: 0.0201 L_si: 0.0029 L_grad: 0.0172 
Train Epoch: 13 [180/684 (26%)] loss: 0.0226 L_si: 0.0038 L_grad: 0.0188 
Train Epoch: 13 [216/684 (32%)] loss: 0.0475 L_si: 0.0148 L_grad: 0.0327 
Train Epoch: 13 [252/684 (37%)] loss: 0.0565 L_si: 0.0266 L_grad: 0.0299 
Train Epoch: 13 [288/684 (42%)] loss: 0.0339 L_si: 0.0121 L_grad: 0.0218 
Train Epoch: 13 [324/684 (47%)] loss: 0.0648 L_si: 0.0242 L_grad: 0.0406 
Train Epoch: 13 [360/684 (53%)] loss: 0.0325 L_si: 0.0080 L_grad: 0.0246 
Train Epoch: 13 [396/684 (58%)] loss: 0.0400 L_si: 0.0105 L_grad: 0.0295 
Train Epoch: 13 [432/684 (63%)] loss: 0.0665 L_si: 0.0290 L_grad: 0.0375 
Train Epoch: 13 [468/684 (68%)] loss: 0.0352 L_si: 0.0167 L_grad: 0.0185 
Train Epoch: 13 [504/684 (74%)] loss: 0.0362 L_si: 0.0078 L_grad: 0.0284 
Train Epoch: 13 [540/684 (79%)] loss: 0.0572 L_si: 0.0225 L_grad: 0.0347 
Train Epoch: 13 [576/684 (84%)] loss: 0.0617 L_si: 0.0291 L_grad: 0.0326 
Train Epoch: 13 [612/684 (89%)] loss: 0.0361 L_si: 0.0082 L_grad: 0.0279 
Train Epoch: 13 [648/684 (95%)] loss: 0.0905 L_si: 0.0429 L_grad: 0.0476 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.017783571034669876, 0.009278420358896255, 0.0215260349214077, 0.016779422760009766, 0.02340015023946762, 0.011106014251708984, 0.01115511730313301, 0.010202517732977867, 0.009615110233426094, 0.028739575296640396, 0.009686949662864208, 0.008789410814642906, 0.01131619792431593, 0.03785967081785202, 0.010680552572011948], 'L_si': [0.005778118968009949, 0.0013650953769683838, 0.005507864058017731, 0.0036250874400138855, 0.008718825876712799, 0.0014681331813335419, 0.0017481222748756409, 0.0013331174850463867, 0.0008893385529518127, 0.011129569262266159, 0.0011047683656215668, 0.0009511113166809082, 0.001807820051908493, 0.01659567281603813, 0.0013471916317939758], 'L_grad': [0.012005452066659927, 0.007913324981927872, 0.01601817086338997, 0.013154336251318455, 0.014681323431432247, 0.009637881070375443, 0.00940699502825737, 0.00886940024793148, 0.008725771680474281, 0.017610006034374237, 0.008582181297242641, 0.007838299497961998, 0.009508377872407436, 0.021263999864459038, 0.009333360940217972]}
Train Epoch: 14 [0/684 (0%)] loss: 0.0382 L_si: 0.0148 L_grad: 0.0234 
Train Epoch: 14 [36/684 (5%)] loss: 0.0554 L_si: 0.0227 L_grad: 0.0327 
Train Epoch: 14 [72/684 (11%)] loss: 0.0543 L_si: 0.0247 L_grad: 0.0296 
Train Epoch: 14 [108/684 (16%)] loss: 0.0644 L_si: 0.0294 L_grad: 0.0350 
Train Epoch: 14 [144/684 (21%)] loss: 0.0394 L_si: 0.0126 L_grad: 0.0268 
Train Epoch: 14 [180/684 (26%)] loss: 0.0331 L_si: 0.0093 L_grad: 0.0238 
Train Epoch: 14 [216/684 (32%)] loss: 0.0408 L_si: 0.0176 L_grad: 0.0232 
Train Epoch: 14 [252/684 (37%)] loss: 0.0409 L_si: 0.0163 L_grad: 0.0246 
Train Epoch: 14 [288/684 (42%)] loss: 0.0231 L_si: 0.0049 L_grad: 0.0182 
Train Epoch: 14 [324/684 (47%)] loss: 0.0401 L_si: 0.0142 L_grad: 0.0259 
Train Epoch: 14 [360/684 (53%)] loss: 0.0506 L_si: 0.0156 L_grad: 0.0349 
Train Epoch: 14 [396/684 (58%)] loss: 0.0723 L_si: 0.0297 L_grad: 0.0426 
Train Epoch: 14 [432/684 (63%)] loss: 0.0687 L_si: 0.0284 L_grad: 0.0403 
Train Epoch: 14 [468/684 (68%)] loss: 0.0294 L_si: 0.0081 L_grad: 0.0213 
Train Epoch: 14 [504/684 (74%)] loss: 0.0358 L_si: 0.0102 L_grad: 0.0257 
Train Epoch: 14 [540/684 (79%)] loss: 0.0480 L_si: 0.0166 L_grad: 0.0314 
Train Epoch: 14 [576/684 (84%)] loss: 0.0429 L_si: 0.0154 L_grad: 0.0275 
Train Epoch: 14 [612/684 (89%)] loss: 0.0425 L_si: 0.0108 L_grad: 0.0317 
Train Epoch: 14 [648/684 (95%)] loss: 0.0625 L_si: 0.0227 L_grad: 0.0397 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.032457754015922546, 0.02593272551894188, 0.023652857169508934, 0.010221738368272781, 0.009771342389285564, 0.010705051943659782, 0.008524361997842789, 0.01994413137435913, 0.023880787193775177, 0.011500982567667961, 0.01912078633904457, 0.014963015913963318, 0.008800884708762169, 0.008857574313879013, 0.011210711672902107], 'L_si': [0.011865869164466858, 0.008640021085739136, 0.008722200989723206, 0.001510433852672577, 0.0012095347046852112, 0.0010902881622314453, 0.0008722767233848572, 0.006220363080501556, 0.009019225835800171, 0.001485973596572876, 0.0060196854174137115, 0.0035282745957374573, 0.0008853375911712646, 0.0009739995002746582, 0.001503974199295044], 'L_grad': [0.02059188485145569, 0.017292704433202744, 0.014930656179785728, 0.008711304515600204, 0.008561807684600353, 0.009614763781428337, 0.007652084808796644, 0.013723768293857574, 0.014861561357975006, 0.010015008971095085, 0.01310110092163086, 0.01143474131822586, 0.007915547117590904, 0.007883574813604355, 0.009706737473607063]}
Train Epoch: 15 [0/684 (0%)] loss: 0.0532 L_si: 0.0174 L_grad: 0.0358 
Train Epoch: 15 [36/684 (5%)] loss: 0.0214 L_si: 0.0035 L_grad: 0.0180 
Train Epoch: 15 [72/684 (11%)] loss: 0.0425 L_si: 0.0105 L_grad: 0.0321 
Train Epoch: 15 [108/684 (16%)] loss: 0.0639 L_si: 0.0253 L_grad: 0.0387 
Train Epoch: 15 [144/684 (21%)] loss: 0.0392 L_si: 0.0086 L_grad: 0.0306 
Train Epoch: 15 [180/684 (26%)] loss: 0.0473 L_si: 0.0162 L_grad: 0.0311 
Train Epoch: 15 [216/684 (32%)] loss: 0.0363 L_si: 0.0138 L_grad: 0.0225 
Train Epoch: 15 [252/684 (37%)] loss: 0.0249 L_si: 0.0076 L_grad: 0.0173 
Train Epoch: 15 [288/684 (42%)] loss: 0.0470 L_si: 0.0206 L_grad: 0.0264 
Train Epoch: 15 [324/684 (47%)] loss: 0.0327 L_si: 0.0075 L_grad: 0.0252 
Train Epoch: 15 [360/684 (53%)] loss: 0.0444 L_si: 0.0190 L_grad: 0.0255 
Train Epoch: 15 [396/684 (58%)] loss: 0.0360 L_si: 0.0128 L_grad: 0.0232 
Train Epoch: 15 [432/684 (63%)] loss: 0.0404 L_si: 0.0152 L_grad: 0.0252 
Train Epoch: 15 [468/684 (68%)] loss: 0.0508 L_si: 0.0176 L_grad: 0.0332 
Train Epoch: 15 [504/684 (74%)] loss: 0.0548 L_si: 0.0210 L_grad: 0.0337 
Train Epoch: 15 [540/684 (79%)] loss: 0.0382 L_si: 0.0093 L_grad: 0.0289 
Train Epoch: 15 [576/684 (84%)] loss: 0.0427 L_si: 0.0187 L_grad: 0.0239 
Train Epoch: 15 [612/684 (89%)] loss: 0.0594 L_si: 0.0226 L_grad: 0.0368 
Train Epoch: 15 [648/684 (95%)] loss: 0.0197 L_si: 0.0032 L_grad: 0.0164 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.025303680449724197, 0.00848606787621975, 0.024635443463921547, 0.008640616200864315, 0.014955191873013973, 0.008689096197485924, 0.015358461067080498, 0.02126842737197876, 0.01068062148988247, 0.015082821249961853, 0.01932748407125473, 0.009571320377290249, 0.011700760573148727, 0.009620163589715958, 0.035475198179483414], 'L_si': [0.009195804595947266, 0.0009901784360408783, 0.00941215455532074, 0.0007499828934669495, 0.003422323614358902, 0.0009822063148021698, 0.0032968223094940186, 0.006909552961587906, 0.0014259517192840576, 0.0032296553254127502, 0.006140664219856262, 0.0010081678628921509, 0.0013557374477386475, 0.0008690059185028076, 0.014562845230102539], 'L_grad': [0.016107875853776932, 0.0074958899058401585, 0.015223288908600807, 0.007890633307397366, 0.011532868258655071, 0.007706889882683754, 0.01206163875758648, 0.01435887347906828, 0.009254669770598412, 0.011853165924549103, 0.013186819851398468, 0.008563152514398098, 0.01034502312541008, 0.00875115767121315, 0.020912352949380875]}
Train Epoch: 16 [0/684 (0%)] loss: 0.0276 L_si: 0.0069 L_grad: 0.0208 
Train Epoch: 16 [36/684 (5%)] loss: 0.0415 L_si: 0.0097 L_grad: 0.0318 
Train Epoch: 16 [72/684 (11%)] loss: 0.0596 L_si: 0.0224 L_grad: 0.0372 
Train Epoch: 16 [108/684 (16%)] loss: 0.0365 L_si: 0.0126 L_grad: 0.0239 
Train Epoch: 16 [144/684 (21%)] loss: 0.0205 L_si: 0.0041 L_grad: 0.0164 
Train Epoch: 16 [180/684 (26%)] loss: 0.1013 L_si: 0.0445 L_grad: 0.0569 
Train Epoch: 16 [216/684 (32%)] loss: 0.0345 L_si: 0.0074 L_grad: 0.0271 
Train Epoch: 16 [252/684 (37%)] loss: 0.0241 L_si: 0.0038 L_grad: 0.0202 
Train Epoch: 16 [288/684 (42%)] loss: 0.0233 L_si: 0.0048 L_grad: 0.0185 
Train Epoch: 16 [324/684 (47%)] loss: 0.0336 L_si: 0.0069 L_grad: 0.0267 
Train Epoch: 16 [360/684 (53%)] loss: 0.0558 L_si: 0.0235 L_grad: 0.0323 
Train Epoch: 16 [396/684 (58%)] loss: 0.0369 L_si: 0.0086 L_grad: 0.0283 
Train Epoch: 16 [432/684 (63%)] loss: 0.0623 L_si: 0.0279 L_grad: 0.0344 
Train Epoch: 16 [468/684 (68%)] loss: 0.0357 L_si: 0.0108 L_grad: 0.0249 
Train Epoch: 16 [504/684 (74%)] loss: 0.0234 L_si: 0.0048 L_grad: 0.0186 
Train Epoch: 16 [540/684 (79%)] loss: 0.0611 L_si: 0.0230 L_grad: 0.0381 
Train Epoch: 16 [576/684 (84%)] loss: 0.0479 L_si: 0.0165 L_grad: 0.0314 
Train Epoch: 16 [612/684 (89%)] loss: 0.0522 L_si: 0.0245 L_grad: 0.0277 
Train Epoch: 16 [648/684 (95%)] loss: 0.0762 L_si: 0.0312 L_grad: 0.0450 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.018299371004104614, 0.009040456265211105, 0.010152358561754227, 0.03162809833884239, 0.02672642096877098, 0.009648658335208893, 0.014897990971803665, 0.011259756982326508, 0.008367067202925682, 0.010584676638245583, 0.0244889035820961, 0.008829673752188683, 0.03360806778073311, 0.010014516301453114, 0.009614653885364532], 'L_si': [0.005878463387489319, 0.0010100528597831726, 0.0010974854230880737, 0.011077851057052612, 0.009657170623540878, 0.0011342540383338928, 0.0034334659576416016, 0.0017891228199005127, 0.0009191781282424927, 0.0014462880790233612, 0.009319707751274109, 0.0008650608360767365, 0.01388169452548027, 0.0009962022304534912, 0.0010616853833198547], 'L_grad': [0.01242090854793787, 0.008030403405427933, 0.009054873138666153, 0.02055024728178978, 0.017069250345230103, 0.008514404296875, 0.011464525014162064, 0.009470634162425995, 0.007447889074683189, 0.009138388559222221, 0.015169195830821991, 0.007964612916111946, 0.019726373255252838, 0.009018314070999622, 0.008552968502044678]}
Train Epoch: 17 [0/684 (0%)] loss: 0.0548 L_si: 0.0251 L_grad: 0.0297 
Train Epoch: 17 [36/684 (5%)] loss: 0.0268 L_si: 0.0063 L_grad: 0.0204 
Train Epoch: 17 [72/684 (11%)] loss: 0.0691 L_si: 0.0307 L_grad: 0.0384 
Train Epoch: 17 [108/684 (16%)] loss: 0.0229 L_si: 0.0046 L_grad: 0.0183 
Train Epoch: 17 [144/684 (21%)] loss: 0.0478 L_si: 0.0194 L_grad: 0.0284 
Train Epoch: 17 [180/684 (26%)] loss: 0.0717 L_si: 0.0359 L_grad: 0.0358 
Train Epoch: 17 [216/684 (32%)] loss: 0.0438 L_si: 0.0144 L_grad: 0.0294 
Train Epoch: 17 [252/684 (37%)] loss: 0.0256 L_si: 0.0054 L_grad: 0.0202 
Train Epoch: 17 [288/684 (42%)] loss: 0.0717 L_si: 0.0304 L_grad: 0.0413 
Train Epoch: 17 [324/684 (47%)] loss: 0.0366 L_si: 0.0090 L_grad: 0.0276 
Train Epoch: 17 [360/684 (53%)] loss: 0.0169 L_si: 0.0030 L_grad: 0.0139 
Train Epoch: 17 [396/684 (58%)] loss: 0.0568 L_si: 0.0215 L_grad: 0.0353 
Train Epoch: 17 [432/684 (63%)] loss: 0.0474 L_si: 0.0143 L_grad: 0.0332 
Train Epoch: 17 [468/684 (68%)] loss: 0.0289 L_si: 0.0055 L_grad: 0.0234 
Train Epoch: 17 [504/684 (74%)] loss: 0.0385 L_si: 0.0134 L_grad: 0.0251 
Train Epoch: 17 [540/684 (79%)] loss: 0.0398 L_si: 0.0125 L_grad: 0.0273 
Train Epoch: 17 [576/684 (84%)] loss: 0.0370 L_si: 0.0119 L_grad: 0.0251 
Train Epoch: 17 [612/684 (89%)] loss: 0.0589 L_si: 0.0195 L_grad: 0.0394 
Train Epoch: 17 [648/684 (95%)] loss: 0.0295 L_si: 0.0067 L_grad: 0.0228 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.025328421965241432, 0.023529214784502983, 0.02463054656982422, 0.011382614262402058, 0.009051046334207058, 0.023631583899259567, 0.013413854874670506, 0.009177367202937603, 0.007976759225130081, 0.009400226175785065, 0.030605483800172806, 0.02372729405760765, 0.008073974400758743, 0.009991630911827087, 0.009225415997207165], 'L_si': [0.009311534464359283, 0.005952112376689911, 0.00832875445485115, 0.0015884935855865479, 0.0009435266256332397, 0.008713744580745697, 0.00228133425116539, 0.0010008513927459717, 0.0007931068539619446, 0.0010271668434143066, 0.011469848453998566, 0.008805274963378906, 0.000984039157629013, 0.0008594021201133728, 0.0009966865181922913], 'L_grad': [0.01601688750088215, 0.017577102407813072, 0.016301792114973068, 0.00979412067681551, 0.008107519708573818, 0.01491783931851387, 0.011132520623505116, 0.008176515810191631, 0.007183652371168137, 0.008373059332370758, 0.01913563534617424, 0.014922020025551319, 0.00708993524312973, 0.009132228791713715, 0.008228729479014874]}
Train Epoch: 18 [0/684 (0%)] loss: 0.0481 L_si: 0.0153 L_grad: 0.0328 
Train Epoch: 18 [36/684 (5%)] loss: 0.0747 L_si: 0.0266 L_grad: 0.0481 
Train Epoch: 18 [72/684 (11%)] loss: 0.0724 L_si: 0.0368 L_grad: 0.0356 
Train Epoch: 18 [108/684 (16%)] loss: 0.0893 L_si: 0.0448 L_grad: 0.0444 
Train Epoch: 18 [144/684 (21%)] loss: 0.0536 L_si: 0.0176 L_grad: 0.0360 
Train Epoch: 18 [180/684 (26%)] loss: 0.0377 L_si: 0.0116 L_grad: 0.0262 
Train Epoch: 18 [216/684 (32%)] loss: 0.0332 L_si: 0.0070 L_grad: 0.0262 
Train Epoch: 18 [252/684 (37%)] loss: 0.0304 L_si: 0.0053 L_grad: 0.0251 
Train Epoch: 18 [288/684 (42%)] loss: 0.0552 L_si: 0.0186 L_grad: 0.0366 
Train Epoch: 18 [324/684 (47%)] loss: 0.0267 L_si: 0.0062 L_grad: 0.0205 
Train Epoch: 18 [360/684 (53%)] loss: 0.0269 L_si: 0.0061 L_grad: 0.0208 
Train Epoch: 18 [396/684 (58%)] loss: 0.0605 L_si: 0.0285 L_grad: 0.0320 
Train Epoch: 18 [432/684 (63%)] loss: 0.0553 L_si: 0.0243 L_grad: 0.0311 
Train Epoch: 18 [468/684 (68%)] loss: 0.0604 L_si: 0.0250 L_grad: 0.0354 
Train Epoch: 18 [504/684 (74%)] loss: 0.0341 L_si: 0.0104 L_grad: 0.0237 
Train Epoch: 18 [540/684 (79%)] loss: 0.0260 L_si: 0.0063 L_grad: 0.0197 
Train Epoch: 18 [576/684 (84%)] loss: 0.0538 L_si: 0.0190 L_grad: 0.0348 
Train Epoch: 18 [612/684 (89%)] loss: 0.0515 L_si: 0.0159 L_grad: 0.0356 
Train Epoch: 18 [648/684 (95%)] loss: 0.0700 L_si: 0.0278 L_grad: 0.0421 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.01885443925857544, 0.027957040816545486, 0.039178796112537384, 0.008373602293431759, 0.013579938560724258, 0.009671524167060852, 0.008911572396755219, 0.02389335073530674, 0.009748142212629318, 0.010856117121875286, 0.00867072120308876, 0.020661374554038048, 0.015194876119494438, 0.015050019137561321, 0.008894143626093864], 'L_si': [0.005995839834213257, 0.010291598737239838, 0.01618628203868866, 0.0008690208196640015, 0.0020270943641662598, 0.0008369386196136475, 0.0009883195161819458, 0.009011134505271912, 0.0012083053588867188, 0.0013294517993927002, 0.0011855587363243103, 0.006549261510372162, 0.003013625741004944, 0.00325041264295578, 0.0008557550609111786], 'L_grad': [0.012858599424362183, 0.01766544207930565, 0.022992515936493874, 0.007504581473767757, 0.011552844196557999, 0.008834585547447205, 0.007923252880573273, 0.014882216230034828, 0.0085398368537426, 0.009526665322482586, 0.00748516246676445, 0.014112113043665886, 0.012181250378489494, 0.011799606494605541, 0.008038388565182686]}
Train Epoch: 19 [0/684 (0%)] loss: 0.0375 L_si: 0.0103 L_grad: 0.0272 
Train Epoch: 19 [36/684 (5%)] loss: 0.0409 L_si: 0.0157 L_grad: 0.0252 
Train Epoch: 19 [72/684 (11%)] loss: 0.0546 L_si: 0.0206 L_grad: 0.0340 
Train Epoch: 19 [108/684 (16%)] loss: 0.0464 L_si: 0.0166 L_grad: 0.0298 
Train Epoch: 19 [144/684 (21%)] loss: 0.0381 L_si: 0.0123 L_grad: 0.0258 
Train Epoch: 19 [180/684 (26%)] loss: 0.0434 L_si: 0.0166 L_grad: 0.0268 
Train Epoch: 19 [216/684 (32%)] loss: 0.0464 L_si: 0.0158 L_grad: 0.0306 
Train Epoch: 19 [252/684 (37%)] loss: 0.0196 L_si: 0.0035 L_grad: 0.0161 
Train Epoch: 19 [288/684 (42%)] loss: 0.0272 L_si: 0.0070 L_grad: 0.0201 
Train Epoch: 19 [324/684 (47%)] loss: 0.0417 L_si: 0.0150 L_grad: 0.0267 
Train Epoch: 19 [360/684 (53%)] loss: 0.0557 L_si: 0.0229 L_grad: 0.0329 
Train Epoch: 19 [396/684 (58%)] loss: 0.0644 L_si: 0.0316 L_grad: 0.0328 
Train Epoch: 19 [432/684 (63%)] loss: 0.0465 L_si: 0.0180 L_grad: 0.0285 
Train Epoch: 19 [468/684 (68%)] loss: 0.0531 L_si: 0.0225 L_grad: 0.0306 
Train Epoch: 19 [504/684 (74%)] loss: 0.0427 L_si: 0.0120 L_grad: 0.0308 
Train Epoch: 19 [540/684 (79%)] loss: 0.0494 L_si: 0.0183 L_grad: 0.0311 
Train Epoch: 19 [576/684 (84%)] loss: 0.0745 L_si: 0.0273 L_grad: 0.0473 
Train Epoch: 19 [612/684 (89%)] loss: 0.0533 L_si: 0.0229 L_grad: 0.0304 
Train Epoch: 19 [648/684 (95%)] loss: 0.0498 L_si: 0.0200 L_grad: 0.0298 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.013849352486431599, 0.008055752143263817, 0.008741667494177818, 0.02602142095565796, 0.010124903172254562, 0.009291752241551876, 0.02066333219408989, 0.008735885843634605, 0.011193550191819668, 0.008098925463855267, 0.024169616401195526, 0.01096353679895401, 0.053713828325271606, 0.008354485966265202, 0.015827661380171776], 'L_si': [0.0022447705268859863, 0.0009426325559616089, 0.0009378194808959961, 0.008490525186061859, 0.0013176128268241882, 0.0009612664580345154, 0.006408482789993286, 0.0011689960956573486, 0.0013459622859954834, 0.000784650444984436, 0.009023517370223999, 0.0016510263085365295, 0.02408847212791443, 0.0006841868162155151, 0.003418534994125366], 'L_grad': [0.011604581959545612, 0.007113119121640921, 0.007803848013281822, 0.0175308957695961, 0.008807290345430374, 0.00833048578351736, 0.014254849404096603, 0.007566889747977257, 0.009847587905824184, 0.0073142750188708305, 0.015146099030971527, 0.00931251049041748, 0.02962535433471203, 0.007670299150049686, 0.01240912638604641]}
Train Epoch: 20 [0/684 (0%)] loss: 0.0470 L_si: 0.0155 L_grad: 0.0316 
Train Epoch: 20 [36/684 (5%)] loss: 0.0401 L_si: 0.0103 L_grad: 0.0298 
Train Epoch: 20 [72/684 (11%)] loss: 0.0558 L_si: 0.0194 L_grad: 0.0364 
Train Epoch: 20 [108/684 (16%)] loss: 0.0450 L_si: 0.0154 L_grad: 0.0296 
Train Epoch: 20 [144/684 (21%)] loss: 0.0613 L_si: 0.0214 L_grad: 0.0398 
Train Epoch: 20 [180/684 (26%)] loss: 0.0771 L_si: 0.0375 L_grad: 0.0396 
Train Epoch: 20 [216/684 (32%)] loss: 0.0420 L_si: 0.0148 L_grad: 0.0272 
Train Epoch: 20 [252/684 (37%)] loss: 0.0414 L_si: 0.0115 L_grad: 0.0299 
Train Epoch: 20 [288/684 (42%)] loss: 0.0363 L_si: 0.0095 L_grad: 0.0268 
Train Epoch: 20 [324/684 (47%)] loss: 0.0209 L_si: 0.0040 L_grad: 0.0169 
Train Epoch: 20 [360/684 (53%)] loss: 0.0684 L_si: 0.0270 L_grad: 0.0413 
Train Epoch: 20 [396/684 (58%)] loss: 0.0253 L_si: 0.0053 L_grad: 0.0200 
Train Epoch: 20 [432/684 (63%)] loss: 0.0398 L_si: 0.0118 L_grad: 0.0280 
Train Epoch: 20 [468/684 (68%)] loss: 0.0343 L_si: 0.0108 L_grad: 0.0235 
Train Epoch: 20 [504/684 (74%)] loss: 0.0457 L_si: 0.0157 L_grad: 0.0300 
Train Epoch: 20 [540/684 (79%)] loss: 0.0446 L_si: 0.0164 L_grad: 0.0282 
Train Epoch: 20 [576/684 (84%)] loss: 0.0263 L_si: 0.0053 L_grad: 0.0211 
Train Epoch: 20 [612/684 (89%)] loss: 0.0731 L_si: 0.0315 L_grad: 0.0416 
Train Epoch: 20 [648/684 (95%)] loss: 0.0520 L_si: 0.0191 L_grad: 0.0329 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch020-loss-0.0449.pth.tar ...
all losses in batch in validation:  {'loss': [0.010338434018194675, 0.04519866779446602, 0.008290935307741165, 0.020594969391822815, 0.008406739681959152, 0.009970513172447681, 0.02680642530322075, 0.02325299009680748, 0.011814101599156857, 0.018434317782521248, 0.009116467088460922, 0.009208964183926582, 0.009006595239043236, 0.010749908164143562, 0.017399810254573822], 'L_si': [0.001532241702079773, 0.019251585006713867, 0.0007179751992225647, 0.0064098164439201355, 0.0006429702043533325, 0.0009163320064544678, 0.008888304233551025, 0.008830755949020386, 0.0015170648694038391, 0.005966268479824066, 0.0010534077882766724, 0.0009652748703956604, 0.0009850859642028809, 0.0014742761850357056, 0.003925792872905731], 'L_grad': [0.008806192316114902, 0.02594708278775215, 0.0075729601085186005, 0.014185152016580105, 0.007763769011944532, 0.009054181165993214, 0.017918121069669724, 0.014422234147787094, 0.010297036729753017, 0.012468049302697182, 0.00806305930018425, 0.008243689313530922, 0.008021509274840355, 0.009275631979107857, 0.013474018312990665]}
Train Epoch: 21 [0/684 (0%)] loss: 0.0301 L_si: 0.0061 L_grad: 0.0240 
Train Epoch: 21 [36/684 (5%)] loss: 0.0654 L_si: 0.0245 L_grad: 0.0409 
Train Epoch: 21 [72/684 (11%)] loss: 0.0390 L_si: 0.0119 L_grad: 0.0271 
Train Epoch: 21 [108/684 (16%)] loss: 0.0300 L_si: 0.0082 L_grad: 0.0218 
Train Epoch: 21 [144/684 (21%)] loss: 0.0497 L_si: 0.0171 L_grad: 0.0326 
Train Epoch: 21 [180/684 (26%)] loss: 0.0242 L_si: 0.0049 L_grad: 0.0193 
Train Epoch: 21 [216/684 (32%)] loss: 0.0496 L_si: 0.0175 L_grad: 0.0321 
Train Epoch: 21 [252/684 (37%)] loss: 0.0364 L_si: 0.0095 L_grad: 0.0269 
Train Epoch: 21 [288/684 (42%)] loss: 0.0623 L_si: 0.0244 L_grad: 0.0379 
Train Epoch: 21 [324/684 (47%)] loss: 0.0407 L_si: 0.0134 L_grad: 0.0273 
Train Epoch: 21 [360/684 (53%)] loss: 0.0445 L_si: 0.0164 L_grad: 0.0281 
Train Epoch: 21 [396/684 (58%)] loss: 0.0243 L_si: 0.0059 L_grad: 0.0183 
Train Epoch: 21 [432/684 (63%)] loss: 0.0384 L_si: 0.0141 L_grad: 0.0243 
Train Epoch: 21 [468/684 (68%)] loss: 0.0427 L_si: 0.0152 L_grad: 0.0275 
Train Epoch: 21 [504/684 (74%)] loss: 0.0403 L_si: 0.0160 L_grad: 0.0243 
Train Epoch: 21 [540/684 (79%)] loss: 0.0504 L_si: 0.0230 L_grad: 0.0274 
Train Epoch: 21 [576/684 (84%)] loss: 0.0459 L_si: 0.0147 L_grad: 0.0312 
Train Epoch: 21 [612/684 (89%)] loss: 0.0383 L_si: 0.0175 L_grad: 0.0209 
Train Epoch: 21 [648/684 (95%)] loss: 0.0602 L_si: 0.0238 L_grad: 0.0364 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009002587758004665, 0.018880337476730347, 0.009261094033718109, 0.01628006063401699, 0.009208784438669682, 0.009716125205159187, 0.010562626644968987, 0.023714806884527206, 0.03144378587603569, 0.012563498690724373, 0.023437945172190666, 0.008711465634405613, 0.025364093482494354, 0.02102847956120968, 0.008529111742973328], 'L_si': [0.0011916160583496094, 0.006220772862434387, 0.0012410208582878113, 0.003935195505619049, 0.000876113772392273, 0.0012605488300323486, 0.0015257671475410461, 0.0087117999792099, 0.01074250042438507, 0.0019960105419158936, 0.009012755006551743, 0.000758044421672821, 0.009227976202964783, 0.006527215242385864, 0.0008392333984375], 'L_grad': [0.007810971699655056, 0.01265956461429596, 0.008020073175430298, 0.012344865128397942, 0.008332670666277409, 0.008455576375126839, 0.00903685949742794, 0.015003005973994732, 0.02070128545165062, 0.01056748814880848, 0.014425190165638924, 0.007953421212732792, 0.01613611727952957, 0.014501264318823814, 0.007689878344535828]}
Train Epoch: 22 [0/684 (0%)] loss: 0.0771 L_si: 0.0379 L_grad: 0.0392 
Train Epoch: 22 [36/684 (5%)] loss: 0.0861 L_si: 0.0420 L_grad: 0.0441 
Train Epoch: 22 [72/684 (11%)] loss: 0.0686 L_si: 0.0274 L_grad: 0.0412 
Train Epoch: 22 [108/684 (16%)] loss: 0.0553 L_si: 0.0230 L_grad: 0.0323 
Train Epoch: 22 [144/684 (21%)] loss: 0.0198 L_si: 0.0031 L_grad: 0.0166 
Train Epoch: 22 [180/684 (26%)] loss: 0.0571 L_si: 0.0254 L_grad: 0.0317 
Train Epoch: 22 [216/684 (32%)] loss: 0.0406 L_si: 0.0158 L_grad: 0.0248 
Train Epoch: 22 [252/684 (37%)] loss: 0.0463 L_si: 0.0167 L_grad: 0.0296 
Train Epoch: 22 [288/684 (42%)] loss: 0.0438 L_si: 0.0206 L_grad: 0.0232 
Train Epoch: 22 [324/684 (47%)] loss: 0.0357 L_si: 0.0151 L_grad: 0.0206 
Train Epoch: 22 [360/684 (53%)] loss: 0.0487 L_si: 0.0186 L_grad: 0.0300 
Train Epoch: 22 [396/684 (58%)] loss: 0.0211 L_si: 0.0032 L_grad: 0.0179 
Train Epoch: 22 [432/684 (63%)] loss: 0.0239 L_si: 0.0045 L_grad: 0.0194 
Train Epoch: 22 [468/684 (68%)] loss: 0.0203 L_si: 0.0038 L_grad: 0.0165 
Train Epoch: 22 [504/684 (74%)] loss: 0.0566 L_si: 0.0196 L_grad: 0.0369 
Train Epoch: 22 [540/684 (79%)] loss: 0.0430 L_si: 0.0156 L_grad: 0.0274 
Train Epoch: 22 [576/684 (84%)] loss: 0.0724 L_si: 0.0315 L_grad: 0.0409 
Train Epoch: 22 [612/684 (89%)] loss: 0.0444 L_si: 0.0136 L_grad: 0.0309 
Train Epoch: 22 [648/684 (95%)] loss: 0.0274 L_si: 0.0050 L_grad: 0.0225 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009331049397587776, 0.016921188682317734, 0.009153862483799458, 0.008879879489541054, 0.028179869055747986, 0.026300646364688873, 0.009568301029503345, 0.01576223410665989, 0.01870114356279373, 0.010219551622867584, 0.034320730715990067, 0.01893039047718048, 0.00874016061425209, 0.008620209991931915, 0.0154513418674469], 'L_si': [0.0008401423692703247, 0.004070192575454712, 0.0008221417665481567, 0.0008501410484313965, 0.0104055255651474, 0.009481437504291534, 0.0011463239789009094, 0.0033455193042755127, 0.006032712757587433, 0.001028895378112793, 0.014450624585151672, 0.006392739713191986, 0.0009835213422775269, 0.0010292455554008484, 0.0033230260014533997], 'L_grad': [0.008490907028317451, 0.012850995175540447, 0.0083317207172513, 0.008029738441109657, 0.017774343490600586, 0.01681920886039734, 0.008421977050602436, 0.012416714802384377, 0.012668430805206299, 0.009190656244754791, 0.019870106130838394, 0.01253764983266592, 0.007756639271974564, 0.007590964436531067, 0.0121283158659935]}
Train Epoch: 23 [0/684 (0%)] loss: 0.0644 L_si: 0.0231 L_grad: 0.0413 
Train Epoch: 23 [36/684 (5%)] loss: 0.0655 L_si: 0.0285 L_grad: 0.0370 
Train Epoch: 23 [72/684 (11%)] loss: 0.0439 L_si: 0.0126 L_grad: 0.0313 
Train Epoch: 23 [108/684 (16%)] loss: 0.0430 L_si: 0.0117 L_grad: 0.0313 
Train Epoch: 23 [144/684 (21%)] loss: 0.0627 L_si: 0.0304 L_grad: 0.0323 
Train Epoch: 23 [180/684 (26%)] loss: 0.0333 L_si: 0.0107 L_grad: 0.0225 
Train Epoch: 23 [216/684 (32%)] loss: 0.0580 L_si: 0.0193 L_grad: 0.0387 
Train Epoch: 23 [252/684 (37%)] loss: 0.0627 L_si: 0.0260 L_grad: 0.0368 
Train Epoch: 23 [288/684 (42%)] loss: 0.0473 L_si: 0.0176 L_grad: 0.0297 
Train Epoch: 23 [324/684 (47%)] loss: 0.0330 L_si: 0.0085 L_grad: 0.0244 
Train Epoch: 23 [360/684 (53%)] loss: 0.0232 L_si: 0.0041 L_grad: 0.0190 
Train Epoch: 23 [396/684 (58%)] loss: 0.0264 L_si: 0.0053 L_grad: 0.0211 
Train Epoch: 23 [432/684 (63%)] loss: 0.0770 L_si: 0.0360 L_grad: 0.0411 
Train Epoch: 23 [468/684 (68%)] loss: 0.0342 L_si: 0.0096 L_grad: 0.0247 
Train Epoch: 23 [504/684 (74%)] loss: 0.0443 L_si: 0.0155 L_grad: 0.0288 
Train Epoch: 23 [540/684 (79%)] loss: 0.0789 L_si: 0.0396 L_grad: 0.0393 
Train Epoch: 23 [576/684 (84%)] loss: 0.0390 L_si: 0.0097 L_grad: 0.0293 
Train Epoch: 23 [612/684 (89%)] loss: 0.0299 L_si: 0.0077 L_grad: 0.0222 
Train Epoch: 23 [648/684 (95%)] loss: 0.0328 L_si: 0.0076 L_grad: 0.0252 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.021363886073231697, 0.02645505778491497, 0.01097913272678852, 0.024460524320602417, 0.008846832439303398, 0.011970601044595242, 0.009047245606780052, 0.02600739523768425, 0.017840169370174408, 0.01670796424150467, 0.009487065486609936, 0.010932022705674171, 0.009895715862512589, 0.019814137369394302, 0.02329760044813156], 'L_si': [0.006544359028339386, 0.009153798222541809, 0.001211024820804596, 0.008734501898288727, 0.0009967312216758728, 0.0015712454915046692, 0.000881880521774292, 0.008528731763362885, 0.0034223124384880066, 0.0035629048943519592, 0.0009138584136962891, 0.0013243108987808228, 0.0010874271392822266, 0.006379440426826477, 0.008754737675189972], 'L_grad': [0.014819527044892311, 0.01730125956237316, 0.009768107905983925, 0.01572602242231369, 0.007850101217627525, 0.010399355553090572, 0.00816536508500576, 0.017478663474321365, 0.014417856931686401, 0.01314505934715271, 0.008573207072913647, 0.009607711806893349, 0.008808288723230362, 0.013434696942567825, 0.01454286277294159]}
Train Epoch: 24 [0/684 (0%)] loss: 0.0391 L_si: 0.0096 L_grad: 0.0295 
Train Epoch: 24 [36/684 (5%)] loss: 0.0436 L_si: 0.0181 L_grad: 0.0255 
Train Epoch: 24 [72/684 (11%)] loss: 0.0304 L_si: 0.0087 L_grad: 0.0217 
Train Epoch: 24 [108/684 (16%)] loss: 0.0750 L_si: 0.0313 L_grad: 0.0436 
Train Epoch: 24 [144/684 (21%)] loss: 0.0708 L_si: 0.0281 L_grad: 0.0427 
Train Epoch: 24 [180/684 (26%)] loss: 0.0568 L_si: 0.0249 L_grad: 0.0319 
Train Epoch: 24 [216/684 (32%)] loss: 0.0467 L_si: 0.0159 L_grad: 0.0309 
Train Epoch: 24 [252/684 (37%)] loss: 0.0419 L_si: 0.0151 L_grad: 0.0268 
Train Epoch: 24 [288/684 (42%)] loss: 0.0493 L_si: 0.0192 L_grad: 0.0301 
Train Epoch: 24 [324/684 (47%)] loss: 0.0341 L_si: 0.0078 L_grad: 0.0263 
Train Epoch: 24 [360/684 (53%)] loss: 0.0468 L_si: 0.0152 L_grad: 0.0316 
Train Epoch: 24 [396/684 (58%)] loss: 0.0392 L_si: 0.0142 L_grad: 0.0250 
Train Epoch: 24 [432/684 (63%)] loss: 0.0338 L_si: 0.0085 L_grad: 0.0253 
Train Epoch: 24 [468/684 (68%)] loss: 0.0227 L_si: 0.0053 L_grad: 0.0173 
Train Epoch: 24 [504/684 (74%)] loss: 0.0538 L_si: 0.0235 L_grad: 0.0303 
Train Epoch: 24 [540/684 (79%)] loss: 0.0565 L_si: 0.0212 L_grad: 0.0353 
Train Epoch: 24 [576/684 (84%)] loss: 0.0376 L_si: 0.0105 L_grad: 0.0271 
Train Epoch: 24 [612/684 (89%)] loss: 0.0445 L_si: 0.0120 L_grad: 0.0326 
Train Epoch: 24 [648/684 (95%)] loss: 0.0323 L_si: 0.0064 L_grad: 0.0259 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.023073989897966385, 0.009083702228963375, 0.03936154022812843, 0.009237155318260193, 0.009177673608064651, 0.02124660834670067, 0.008652755059301853, 0.009271767921745777, 0.008661932311952114, 0.008415084332227707, 0.03693215176463127, 0.01585017889738083, 0.018126551061868668, 0.009308550506830215, 0.012251334264874458], 'L_si': [0.005884133279323578, 0.0009971708059310913, 0.017218150198459625, 0.0007143318653106689, 0.0008039772510528564, 0.006691187620162964, 0.0009019374847412109, 0.0011753737926483154, 0.0007321983575820923, 0.0007537156343460083, 0.014764167368412018, 0.0036468207836151123, 0.006125584244728088, 0.0010125264525413513, 0.002079494297504425], 'L_grad': [0.017189856618642807, 0.008086531423032284, 0.022143390029668808, 0.008522823452949524, 0.008373696357011795, 0.01455541979521513, 0.007750817574560642, 0.008096394129097462, 0.007929733954370022, 0.007661368232220411, 0.022167984396219254, 0.012203359045088291, 0.012000967748463154, 0.008296024054288864, 0.010171839967370033]}
Train Epoch: 25 [0/684 (0%)] loss: 0.0400 L_si: 0.0134 L_grad: 0.0266 
Train Epoch: 25 [36/684 (5%)] loss: 0.0984 L_si: 0.0467 L_grad: 0.0516 
Train Epoch: 25 [72/684 (11%)] loss: 0.0545 L_si: 0.0179 L_grad: 0.0366 
Train Epoch: 25 [108/684 (16%)] loss: 0.0351 L_si: 0.0100 L_grad: 0.0252 
Train Epoch: 25 [144/684 (21%)] loss: 0.0362 L_si: 0.0119 L_grad: 0.0242 
Train Epoch: 25 [180/684 (26%)] loss: 0.0431 L_si: 0.0147 L_grad: 0.0284 
Train Epoch: 25 [216/684 (32%)] loss: 0.0171 L_si: 0.0031 L_grad: 0.0141 
Train Epoch: 25 [252/684 (37%)] loss: 0.0319 L_si: 0.0062 L_grad: 0.0257 
Train Epoch: 25 [288/684 (42%)] loss: 0.0573 L_si: 0.0230 L_grad: 0.0343 
Train Epoch: 25 [324/684 (47%)] loss: 0.0498 L_si: 0.0188 L_grad: 0.0311 
Train Epoch: 25 [360/684 (53%)] loss: 0.0242 L_si: 0.0048 L_grad: 0.0193 
Train Epoch: 25 [396/684 (58%)] loss: 0.0274 L_si: 0.0076 L_grad: 0.0198 
Train Epoch: 25 [432/684 (63%)] loss: 0.0478 L_si: 0.0152 L_grad: 0.0326 
Train Epoch: 25 [468/684 (68%)] loss: 0.0537 L_si: 0.0177 L_grad: 0.0360 
Train Epoch: 25 [504/684 (74%)] loss: 0.0348 L_si: 0.0123 L_grad: 0.0226 
Train Epoch: 25 [540/684 (79%)] loss: 0.0404 L_si: 0.0120 L_grad: 0.0285 
Train Epoch: 25 [576/684 (84%)] loss: 0.0539 L_si: 0.0227 L_grad: 0.0312 
Train Epoch: 25 [612/684 (89%)] loss: 0.0374 L_si: 0.0121 L_grad: 0.0253 
Train Epoch: 25 [648/684 (95%)] loss: 0.0459 L_si: 0.0185 L_grad: 0.0274 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.024624377489089966, 0.010182417929172516, 0.03095346689224243, 0.019221089780330658, 0.011437034234404564, 0.008694194257259369, 0.009524724446237087, 0.02558903768658638, 0.008927649818360806, 0.01006266288459301, 0.010347957722842693, 0.009264614433050156, 0.007812026422470808, 0.034084707498550415, 0.017286378890275955], 'L_si': [0.00914047658443451, 0.001027613878250122, 0.010512806475162506, 0.006037943065166473, 0.001691184937953949, 0.000839918851852417, 0.0010134503245353699, 0.009225957095623016, 0.0010431110858917236, 0.0013602301478385925, 0.001601003110408783, 0.0010658130049705505, 0.00105242058634758, 0.014299891889095306, 0.003831341862678528], 'L_grad': [0.015483901835978031, 0.009154804050922394, 0.020440660417079926, 0.013183146715164185, 0.009745849296450615, 0.007854275405406952, 0.008511274121701717, 0.016363080590963364, 0.007884538732469082, 0.008702432736754417, 0.00874695461243391, 0.008198801428079605, 0.006759605836123228, 0.01978481374680996, 0.013455036096274853]}
Train Epoch: 26 [0/684 (0%)] loss: 0.0494 L_si: 0.0257 L_grad: 0.0237 
Train Epoch: 26 [36/684 (5%)] loss: 0.0419 L_si: 0.0170 L_grad: 0.0249 
Train Epoch: 26 [72/684 (11%)] loss: 0.0356 L_si: 0.0087 L_grad: 0.0269 
Train Epoch: 26 [108/684 (16%)] loss: 0.0859 L_si: 0.0422 L_grad: 0.0437 
Train Epoch: 26 [144/684 (21%)] loss: 0.0683 L_si: 0.0266 L_grad: 0.0417 
Train Epoch: 26 [180/684 (26%)] loss: 0.0506 L_si: 0.0215 L_grad: 0.0291 
Train Epoch: 26 [216/684 (32%)] loss: 0.0899 L_si: 0.0429 L_grad: 0.0470 
Train Epoch: 26 [252/684 (37%)] loss: 0.0558 L_si: 0.0242 L_grad: 0.0316 
Train Epoch: 26 [288/684 (42%)] loss: 0.0596 L_si: 0.0219 L_grad: 0.0377 
Train Epoch: 26 [324/684 (47%)] loss: 0.0562 L_si: 0.0230 L_grad: 0.0331 
Train Epoch: 26 [360/684 (53%)] loss: 0.0463 L_si: 0.0190 L_grad: 0.0273 
Train Epoch: 26 [396/684 (58%)] loss: 0.0239 L_si: 0.0058 L_grad: 0.0181 
Train Epoch: 26 [432/684 (63%)] loss: 0.0648 L_si: 0.0276 L_grad: 0.0372 
Train Epoch: 26 [468/684 (68%)] loss: 0.0675 L_si: 0.0360 L_grad: 0.0315 
Train Epoch: 26 [504/684 (74%)] loss: 0.0195 L_si: 0.0051 L_grad: 0.0144 
Train Epoch: 26 [540/684 (79%)] loss: 0.0435 L_si: 0.0155 L_grad: 0.0280 
Train Epoch: 26 [576/684 (84%)] loss: 0.0541 L_si: 0.0202 L_grad: 0.0339 
Train Epoch: 26 [612/684 (89%)] loss: 0.0562 L_si: 0.0222 L_grad: 0.0340 
Train Epoch: 26 [648/684 (95%)] loss: 0.0511 L_si: 0.0161 L_grad: 0.0350 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010501401498913765, 0.017123792320489883, 0.009381097741425037, 0.018697604537010193, 0.01868494227528572, 0.025236384943127632, 0.024074561893939972, 0.009578746743500233, 0.012243261560797691, 0.0293912161141634, 0.015874985605478287, 0.009590363129973412, 0.010548156686127186, 0.018770217895507812, 0.011099252849817276], 'L_si': [0.001392081379890442, 0.0037159547209739685, 0.0012051016092300415, 0.006097018718719482, 0.005820531398057938, 0.009204298257827759, 0.008970476686954498, 0.0010281801223754883, 0.0016653016209602356, 0.011277362704277039, 0.0035247430205345154, 0.000967852771282196, 0.001498594880104065, 0.006012529134750366, 0.0011555477976799011], 'L_grad': [0.009109320119023323, 0.013407837599515915, 0.008175996132194996, 0.01260058581829071, 0.012864411808550358, 0.016032086685299873, 0.015104085206985474, 0.008550566621124744, 0.010577959939837456, 0.01811385340988636, 0.012350241653621197, 0.008622510358691216, 0.009049561806023121, 0.012757689692080021, 0.009943705052137375]}
Train Epoch: 27 [0/684 (0%)] loss: 0.0341 L_si: 0.0092 L_grad: 0.0249 
Train Epoch: 27 [36/684 (5%)] loss: 0.0390 L_si: 0.0097 L_grad: 0.0293 
Train Epoch: 27 [72/684 (11%)] loss: 0.0499 L_si: 0.0157 L_grad: 0.0341 
Train Epoch: 27 [108/684 (16%)] loss: 0.0563 L_si: 0.0241 L_grad: 0.0323 
Train Epoch: 27 [144/684 (21%)] loss: 0.0422 L_si: 0.0178 L_grad: 0.0244 
Train Epoch: 27 [180/684 (26%)] loss: 0.0655 L_si: 0.0216 L_grad: 0.0440 
Train Epoch: 27 [216/684 (32%)] loss: 0.0443 L_si: 0.0188 L_grad: 0.0255 
Train Epoch: 27 [252/684 (37%)] loss: 0.0338 L_si: 0.0084 L_grad: 0.0254 
Train Epoch: 27 [288/684 (42%)] loss: 0.0393 L_si: 0.0126 L_grad: 0.0267 
Train Epoch: 27 [324/684 (47%)] loss: 0.0419 L_si: 0.0124 L_grad: 0.0295 
Train Epoch: 27 [360/684 (53%)] loss: 0.0676 L_si: 0.0291 L_grad: 0.0386 
Train Epoch: 27 [396/684 (58%)] loss: 0.0403 L_si: 0.0154 L_grad: 0.0249 
Train Epoch: 27 [432/684 (63%)] loss: 0.0545 L_si: 0.0202 L_grad: 0.0342 
Train Epoch: 27 [468/684 (68%)] loss: 0.0524 L_si: 0.0208 L_grad: 0.0316 
Train Epoch: 27 [504/684 (74%)] loss: 0.0408 L_si: 0.0167 L_grad: 0.0241 
Train Epoch: 27 [540/684 (79%)] loss: 0.0375 L_si: 0.0151 L_grad: 0.0223 
Train Epoch: 27 [576/684 (84%)] loss: 0.0320 L_si: 0.0098 L_grad: 0.0222 
Train Epoch: 27 [612/684 (89%)] loss: 0.0398 L_si: 0.0120 L_grad: 0.0278 
Train Epoch: 27 [648/684 (95%)] loss: 0.0469 L_si: 0.0168 L_grad: 0.0301 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008587987162172794, 0.02888946235179901, 0.03442976623773575, 0.010291345417499542, 0.03068305179476738, 0.008663294836878777, 0.009127847850322723, 0.00911892019212246, 0.00837605819106102, 0.01147271879017353, 0.024191604927182198, 0.009127398952841759, 0.01033069659024477, 0.00875803641974926, 0.025701895356178284], 'L_si': [0.0008677095174789429, 0.011121086776256561, 0.01180964708328247, 0.0010667964816093445, 0.011669851839542389, 0.0008895695209503174, 0.001050405204296112, 0.0007838830351829529, 0.0009229555726051331, 0.0017246529459953308, 0.009017542004585266, 0.000818498432636261, 0.001132473349571228, 0.0010229870676994324, 0.00960443913936615], 'L_grad': [0.0077202776446938515, 0.01776837557554245, 0.022620119154453278, 0.009224548935890198, 0.01901319995522499, 0.007773725315928459, 0.008077442646026611, 0.008335037156939507, 0.007453102618455887, 0.0097480658441782, 0.015174062922596931, 0.008308900520205498, 0.009198223240673542, 0.007735049352049828, 0.016097456216812134]}
Train Epoch: 28 [0/684 (0%)] loss: 0.0249 L_si: 0.0057 L_grad: 0.0192 
Train Epoch: 28 [36/684 (5%)] loss: 0.0506 L_si: 0.0161 L_grad: 0.0344 
Train Epoch: 28 [72/684 (11%)] loss: 0.0705 L_si: 0.0301 L_grad: 0.0405 
Train Epoch: 28 [108/684 (16%)] loss: 0.0470 L_si: 0.0192 L_grad: 0.0279 
Train Epoch: 28 [144/684 (21%)] loss: 0.0341 L_si: 0.0092 L_grad: 0.0249 
Train Epoch: 28 [180/684 (26%)] loss: 0.0486 L_si: 0.0215 L_grad: 0.0271 
Train Epoch: 28 [216/684 (32%)] loss: 0.0239 L_si: 0.0044 L_grad: 0.0195 
Train Epoch: 28 [252/684 (37%)] loss: 0.0698 L_si: 0.0293 L_grad: 0.0405 
Train Epoch: 28 [288/684 (42%)] loss: 0.0594 L_si: 0.0211 L_grad: 0.0383 
Train Epoch: 28 [324/684 (47%)] loss: 0.0526 L_si: 0.0207 L_grad: 0.0318 
Train Epoch: 28 [360/684 (53%)] loss: 0.0250 L_si: 0.0050 L_grad: 0.0200 
Train Epoch: 28 [396/684 (58%)] loss: 0.0393 L_si: 0.0120 L_grad: 0.0273 
Train Epoch: 28 [432/684 (63%)] loss: 0.0650 L_si: 0.0269 L_grad: 0.0380 
Train Epoch: 28 [468/684 (68%)] loss: 0.0304 L_si: 0.0075 L_grad: 0.0229 
Train Epoch: 28 [504/684 (74%)] loss: 0.0419 L_si: 0.0136 L_grad: 0.0283 
Train Epoch: 28 [540/684 (79%)] loss: 0.0351 L_si: 0.0072 L_grad: 0.0279 
Train Epoch: 28 [576/684 (84%)] loss: 0.0465 L_si: 0.0185 L_grad: 0.0279 
Train Epoch: 28 [612/684 (89%)] loss: 0.0337 L_si: 0.0105 L_grad: 0.0232 
Train Epoch: 28 [648/684 (95%)] loss: 0.0437 L_si: 0.0147 L_grad: 0.0291 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009479687549173832, 0.008535953238606453, 0.016419272869825363, 0.008374551311135292, 0.024447761476039886, 0.030151862651109695, 0.01915327087044716, 0.023790277540683746, 0.021160392090678215, 0.01011306419968605, 0.008609598502516747, 0.010745730251073837, 0.009212184697389603, 0.019810983911156654, 0.020909864455461502], 'L_si': [0.0010186731815338135, 0.000696033239364624, 0.0037966445088386536, 0.00083894282579422, 0.009123407304286957, 0.011292263865470886, 0.004527553915977478, 0.009129524230957031, 0.00655558705329895, 0.000974312424659729, 0.0009267628192901611, 0.001233413815498352, 0.0007627904415130615, 0.0059227123856544495, 0.007059209048748016], 'L_grad': [0.008461014367640018, 0.007839919999241829, 0.01262262836098671, 0.007535608485341072, 0.015324353240430355, 0.01885959878563881, 0.01462571695446968, 0.014660753309726715, 0.014604805037379265, 0.009138751775026321, 0.007682835217565298, 0.009512316435575485, 0.008449394255876541, 0.013888271525502205, 0.013850654475390911]}
Train Epoch: 29 [0/684 (0%)] loss: 0.0390 L_si: 0.0097 L_grad: 0.0293 
Train Epoch: 29 [36/684 (5%)] loss: 0.0490 L_si: 0.0139 L_grad: 0.0351 
Train Epoch: 29 [72/684 (11%)] loss: 0.0375 L_si: 0.0107 L_grad: 0.0267 
Train Epoch: 29 [108/684 (16%)] loss: 0.0253 L_si: 0.0051 L_grad: 0.0202 
Train Epoch: 29 [144/684 (21%)] loss: 0.0477 L_si: 0.0178 L_grad: 0.0299 
Train Epoch: 29 [180/684 (26%)] loss: 0.0803 L_si: 0.0312 L_grad: 0.0491 
Train Epoch: 29 [216/684 (32%)] loss: 0.0618 L_si: 0.0324 L_grad: 0.0294 
Train Epoch: 29 [252/684 (37%)] loss: 0.0388 L_si: 0.0135 L_grad: 0.0253 
Train Epoch: 29 [288/684 (42%)] loss: 0.0388 L_si: 0.0107 L_grad: 0.0281 
Train Epoch: 29 [324/684 (47%)] loss: 0.0313 L_si: 0.0083 L_grad: 0.0231 
Train Epoch: 29 [360/684 (53%)] loss: 0.0644 L_si: 0.0271 L_grad: 0.0373 
Train Epoch: 29 [396/684 (58%)] loss: 0.0442 L_si: 0.0161 L_grad: 0.0281 
Train Epoch: 29 [432/684 (63%)] loss: 0.0317 L_si: 0.0078 L_grad: 0.0239 
Train Epoch: 29 [468/684 (68%)] loss: 0.0665 L_si: 0.0315 L_grad: 0.0350 
Train Epoch: 29 [504/684 (74%)] loss: 0.0329 L_si: 0.0090 L_grad: 0.0240 
Train Epoch: 29 [540/684 (79%)] loss: 0.0673 L_si: 0.0258 L_grad: 0.0415 
Train Epoch: 29 [576/684 (84%)] loss: 0.0787 L_si: 0.0326 L_grad: 0.0460 
Train Epoch: 29 [612/684 (89%)] loss: 0.0303 L_si: 0.0065 L_grad: 0.0238 
Train Epoch: 29 [648/684 (95%)] loss: 0.0444 L_si: 0.0161 L_grad: 0.0283 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.019617432728409767, 0.015489271841943264, 0.02086234837770462, 0.012170709669589996, 0.023819709196686745, 0.009212568402290344, 0.017546262592077255, 0.018918352201581, 0.014738164842128754, 0.0248713456094265, 0.010638219304382801, 0.009567972272634506, 0.023199614137411118, 0.009510891512036324, 0.00954363401979208], 'L_si': [0.006039418280124664, 0.003223791718482971, 0.006422251462936401, 0.0019139721989631653, 0.008949488401412964, 0.0009756311774253845, 0.00380522757768631, 0.006208114326000214, 0.003215596079826355, 0.009009510278701782, 0.0014618784189224243, 0.0012664943933486938, 0.009038545191287994, 0.001192629337310791, 0.0011545568704605103], 'L_grad': [0.013578014448285103, 0.012265480123460293, 0.014440097846090794, 0.010256737470626831, 0.01487022079527378, 0.00823693722486496, 0.013741035014390945, 0.012710237875580788, 0.011522568762302399, 0.015861835330724716, 0.009176340885460377, 0.008301477879285812, 0.014161068946123123, 0.008318262174725533, 0.00838907714933157]}
Train Epoch: 30 [0/684 (0%)] loss: 0.0773 L_si: 0.0358 L_grad: 0.0414 
Train Epoch: 30 [36/684 (5%)] loss: 0.0503 L_si: 0.0154 L_grad: 0.0349 
Train Epoch: 30 [72/684 (11%)] loss: 0.0320 L_si: 0.0082 L_grad: 0.0238 
Train Epoch: 30 [108/684 (16%)] loss: 0.0697 L_si: 0.0321 L_grad: 0.0376 
Train Epoch: 30 [144/684 (21%)] loss: 0.0504 L_si: 0.0186 L_grad: 0.0318 
Train Epoch: 30 [180/684 (26%)] loss: 0.0376 L_si: 0.0093 L_grad: 0.0283 
Train Epoch: 30 [216/684 (32%)] loss: 0.0804 L_si: 0.0368 L_grad: 0.0436 
Train Epoch: 30 [252/684 (37%)] loss: 0.0509 L_si: 0.0175 L_grad: 0.0334 
Train Epoch: 30 [288/684 (42%)] loss: 0.0375 L_si: 0.0138 L_grad: 0.0237 
Train Epoch: 30 [324/684 (47%)] loss: 0.0327 L_si: 0.0109 L_grad: 0.0219 
Train Epoch: 30 [360/684 (53%)] loss: 0.0262 L_si: 0.0076 L_grad: 0.0186 
Train Epoch: 30 [396/684 (58%)] loss: 0.0401 L_si: 0.0119 L_grad: 0.0282 
Train Epoch: 30 [432/684 (63%)] loss: 0.0696 L_si: 0.0298 L_grad: 0.0398 
Train Epoch: 30 [468/684 (68%)] loss: 0.0218 L_si: 0.0045 L_grad: 0.0173 
Train Epoch: 30 [504/684 (74%)] loss: 0.0539 L_si: 0.0207 L_grad: 0.0332 
Train Epoch: 30 [540/684 (79%)] loss: 0.0584 L_si: 0.0273 L_grad: 0.0310 
Train Epoch: 30 [576/684 (84%)] loss: 0.0354 L_si: 0.0130 L_grad: 0.0224 
Train Epoch: 30 [612/684 (89%)] loss: 0.0521 L_si: 0.0174 L_grad: 0.0347 
Train Epoch: 30 [648/684 (95%)] loss: 0.0535 L_si: 0.0228 L_grad: 0.0307 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch030-loss-0.0467.pth.tar ...
New Learning Rate: 0.000150
all losses in batch in validation:  {'loss': [0.01949542574584484, 0.011739030480384827, 0.01256057620048523, 0.010356152430176735, 0.008757511153817177, 0.023930111899971962, 0.015054427087306976, 0.01597410812973976, 0.008733303286135197, 0.03283509239554405, 0.02610786072909832, 0.024673378095030785, 0.009589671157300472, 0.00939132459461689, 0.0127828698605299], 'L_si': [0.006369359791278839, 0.0014309436082839966, 0.002216033637523651, 0.0011454969644546509, 0.000990942120552063, 0.008940555155277252, 0.0031762495636940002, 0.0035469383001327515, 0.0008274242281913757, 0.013795711100101471, 0.00863388180732727, 0.008851185441017151, 0.0010892301797866821, 0.0007539466023445129, 0.0021155253052711487], 'L_grad': [0.013126065954566002, 0.01030808687210083, 0.010344542562961578, 0.009210655465722084, 0.007766569033265114, 0.01498955674469471, 0.011878177523612976, 0.01242716982960701, 0.007905879057943821, 0.01903938129544258, 0.01747397892177105, 0.015822192654013634, 0.00850044097751379, 0.008637377992272377, 0.010667344555258751]}
Train Epoch: 31 [0/684 (0%)] loss: 0.0567 L_si: 0.0249 L_grad: 0.0318 
Train Epoch: 31 [36/684 (5%)] loss: 0.0494 L_si: 0.0165 L_grad: 0.0330 
Train Epoch: 31 [72/684 (11%)] loss: 0.0340 L_si: 0.0107 L_grad: 0.0233 
Train Epoch: 31 [108/684 (16%)] loss: 0.0410 L_si: 0.0107 L_grad: 0.0304 
Train Epoch: 31 [144/684 (21%)] loss: 0.0399 L_si: 0.0095 L_grad: 0.0304 
Train Epoch: 31 [180/684 (26%)] loss: 0.0481 L_si: 0.0138 L_grad: 0.0343 
Train Epoch: 31 [216/684 (32%)] loss: 0.0320 L_si: 0.0076 L_grad: 0.0244 
Train Epoch: 31 [252/684 (37%)] loss: 0.0572 L_si: 0.0218 L_grad: 0.0354 
Train Epoch: 31 [288/684 (42%)] loss: 0.0312 L_si: 0.0107 L_grad: 0.0205 
Train Epoch: 31 [324/684 (47%)] loss: 0.0640 L_si: 0.0281 L_grad: 0.0358 
Train Epoch: 31 [360/684 (53%)] loss: 0.0348 L_si: 0.0136 L_grad: 0.0212 
Train Epoch: 31 [396/684 (58%)] loss: 0.0463 L_si: 0.0163 L_grad: 0.0300 
Train Epoch: 31 [432/684 (63%)] loss: 0.0333 L_si: 0.0085 L_grad: 0.0248 
Train Epoch: 31 [468/684 (68%)] loss: 0.0228 L_si: 0.0049 L_grad: 0.0180 
Train Epoch: 31 [504/684 (74%)] loss: 0.0561 L_si: 0.0255 L_grad: 0.0306 
Train Epoch: 31 [540/684 (79%)] loss: 0.0638 L_si: 0.0266 L_grad: 0.0371 
Train Epoch: 31 [576/684 (84%)] loss: 0.0269 L_si: 0.0060 L_grad: 0.0209 
Train Epoch: 31 [612/684 (89%)] loss: 0.0657 L_si: 0.0285 L_grad: 0.0372 
Train Epoch: 31 [648/684 (95%)] loss: 0.0252 L_si: 0.0047 L_grad: 0.0205 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.018069788813591003, 0.011708797886967659, 0.038687847554683685, 0.025051474571228027, 0.030121251940727234, 0.009500563144683838, 0.018659045919775963, 0.009495178237557411, 0.010424153879284859, 0.010001779533922672, 0.009210234507918358, 0.023233868181705475, 0.009087775833904743, 0.008215900510549545, 0.008476104587316513], 'L_si': [0.004016898572444916, 0.0015426725149154663, 0.017083562910556793, 0.008989714086055756, 0.011579640209674835, 0.0009750500321388245, 0.005919590592384338, 0.0013661012053489685, 0.0014405101537704468, 0.0011293068528175354, 0.0007359683513641357, 0.006271064281463623, 0.0009609609842300415, 0.0008688047528266907, 0.0009341835975646973], 'L_grad': [0.014052890241146088, 0.010166125372052193, 0.021604282781481743, 0.01606176048517227, 0.0185416117310524, 0.008525513112545013, 0.012739455327391624, 0.008129077032208443, 0.008983643725514412, 0.008872472681105137, 0.008474266156554222, 0.016962803900241852, 0.008126814849674702, 0.007347095757722855, 0.007541920989751816]}
Train Epoch: 32 [0/684 (0%)] loss: 0.0551 L_si: 0.0233 L_grad: 0.0318 
Train Epoch: 32 [36/684 (5%)] loss: 0.0366 L_si: 0.0110 L_grad: 0.0255 
Train Epoch: 32 [72/684 (11%)] loss: 0.0380 L_si: 0.0138 L_grad: 0.0242 
Train Epoch: 32 [108/684 (16%)] loss: 0.0258 L_si: 0.0054 L_grad: 0.0204 
Train Epoch: 32 [144/684 (21%)] loss: 0.0603 L_si: 0.0247 L_grad: 0.0356 
Train Epoch: 32 [180/684 (26%)] loss: 0.0572 L_si: 0.0256 L_grad: 0.0316 
Train Epoch: 32 [216/684 (32%)] loss: 0.0329 L_si: 0.0078 L_grad: 0.0251 
Train Epoch: 32 [252/684 (37%)] loss: 0.0457 L_si: 0.0134 L_grad: 0.0323 
Train Epoch: 32 [288/684 (42%)] loss: 0.0557 L_si: 0.0196 L_grad: 0.0361 
Train Epoch: 32 [324/684 (47%)] loss: 0.0397 L_si: 0.0097 L_grad: 0.0300 
Train Epoch: 32 [360/684 (53%)] loss: 0.0312 L_si: 0.0076 L_grad: 0.0236 
Train Epoch: 32 [396/684 (58%)] loss: 0.0270 L_si: 0.0065 L_grad: 0.0205 
Train Epoch: 32 [432/684 (63%)] loss: 0.0385 L_si: 0.0105 L_grad: 0.0280 
Train Epoch: 32 [468/684 (68%)] loss: 0.0730 L_si: 0.0313 L_grad: 0.0416 
Train Epoch: 32 [504/684 (74%)] loss: 0.0766 L_si: 0.0287 L_grad: 0.0479 
Train Epoch: 32 [540/684 (79%)] loss: 0.0512 L_si: 0.0240 L_grad: 0.0272 
Train Epoch: 32 [576/684 (84%)] loss: 0.0595 L_si: 0.0278 L_grad: 0.0317 
Train Epoch: 32 [612/684 (89%)] loss: 0.0540 L_si: 0.0236 L_grad: 0.0304 
Train Epoch: 32 [648/684 (95%)] loss: 0.0252 L_si: 0.0045 L_grad: 0.0207 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010024402290582657, 0.03302180767059326, 0.0086732292547822, 0.009119361639022827, 0.021851617842912674, 0.009297845885157585, 0.030294351279735565, 0.016345029696822166, 0.022623034194111824, 0.026920277625322342, 0.008918190374970436, 0.00878260936588049, 0.010775662958621979, 0.015337372198700905, 0.007859425619244576], 'L_si': [0.0011788830161094666, 0.01400187611579895, 0.0009149834513664246, 0.0009106248617172241, 0.006914667785167694, 0.0014278292655944824, 0.011478908360004425, 0.0033208057284355164, 0.00711648166179657, 0.00989360362291336, 0.0009143128991127014, 0.0009452179074287415, 0.0012159943580627441, 0.0030472129583358765, 0.0006432458758354187], 'L_grad': [0.00884551927447319, 0.01901993155479431, 0.007758245803415775, 0.008208736777305603, 0.01493695005774498, 0.007870016619563103, 0.01881544291973114, 0.01302422396838665, 0.015506552532315254, 0.01702667400240898, 0.008003877475857735, 0.007837391458451748, 0.009559668600559235, 0.012290159240365028, 0.007216179743409157]}
Train Epoch: 33 [0/684 (0%)] loss: 0.0953 L_si: 0.0482 L_grad: 0.0471 
Train Epoch: 33 [36/684 (5%)] loss: 0.0434 L_si: 0.0167 L_grad: 0.0268 
Train Epoch: 33 [72/684 (11%)] loss: 0.0391 L_si: 0.0104 L_grad: 0.0287 
Train Epoch: 33 [108/684 (16%)] loss: 0.0345 L_si: 0.0113 L_grad: 0.0232 
Train Epoch: 33 [144/684 (21%)] loss: 0.0343 L_si: 0.0076 L_grad: 0.0266 
Train Epoch: 33 [180/684 (26%)] loss: 0.0433 L_si: 0.0110 L_grad: 0.0323 
Train Epoch: 33 [216/684 (32%)] loss: 0.0434 L_si: 0.0172 L_grad: 0.0262 
Train Epoch: 33 [252/684 (37%)] loss: 0.0522 L_si: 0.0192 L_grad: 0.0330 
Train Epoch: 33 [288/684 (42%)] loss: 0.0369 L_si: 0.0098 L_grad: 0.0271 
Train Epoch: 33 [324/684 (47%)] loss: 0.0168 L_si: 0.0033 L_grad: 0.0135 
Train Epoch: 33 [360/684 (53%)] loss: 0.0601 L_si: 0.0205 L_grad: 0.0397 
Train Epoch: 33 [396/684 (58%)] loss: 0.0560 L_si: 0.0236 L_grad: 0.0323 
Train Epoch: 33 [432/684 (63%)] loss: 0.0560 L_si: 0.0215 L_grad: 0.0345 
Train Epoch: 33 [468/684 (68%)] loss: 0.0859 L_si: 0.0401 L_grad: 0.0458 
Train Epoch: 33 [504/684 (74%)] loss: 0.0343 L_si: 0.0094 L_grad: 0.0249 
Train Epoch: 33 [540/684 (79%)] loss: 0.0576 L_si: 0.0228 L_grad: 0.0348 
Train Epoch: 33 [576/684 (84%)] loss: 0.0524 L_si: 0.0206 L_grad: 0.0318 
Train Epoch: 33 [612/684 (89%)] loss: 0.0487 L_si: 0.0189 L_grad: 0.0298 
Train Epoch: 33 [648/684 (95%)] loss: 0.0195 L_si: 0.0038 L_grad: 0.0157 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.019489381462335587, 0.01052592322230339, 0.01175601128488779, 0.0334048718214035, 0.010803807526826859, 0.016739381477236748, 0.02524230256676674, 0.019071362912654877, 0.009394383057951927, 0.01416915375739336, 0.013105452060699463, 0.023934803903102875, 0.009353714063763618, 0.014986377209424973, 0.008388781920075417], 'L_si': [0.006194785237312317, 0.0012430846691131592, 0.0016298666596412659, 0.014085136353969574, 0.0014686957001686096, 0.00379006564617157, 0.009372524917125702, 0.006081022322177887, 0.000879921019077301, 0.003160715103149414, 0.0016851425170898438, 0.00895373523235321, 0.0011669695377349854, 0.0034389421343803406, 0.0008204281330108643], 'L_grad': [0.013294595293700695, 0.009282838553190231, 0.010126144625246525, 0.01931973360478878, 0.009335111826658249, 0.012949315831065178, 0.015869777649641037, 0.01299034059047699, 0.008514462038874626, 0.011008438654243946, 0.01142030954360962, 0.014981068670749664, 0.008186744526028633, 0.011547435075044632, 0.007568353321403265]}
Train Epoch: 34 [0/684 (0%)] loss: 0.0496 L_si: 0.0204 L_grad: 0.0292 
Train Epoch: 34 [36/684 (5%)] loss: 0.0481 L_si: 0.0203 L_grad: 0.0278 
Train Epoch: 34 [72/684 (11%)] loss: 0.0623 L_si: 0.0215 L_grad: 0.0408 
Train Epoch: 34 [108/684 (16%)] loss: 0.0403 L_si: 0.0108 L_grad: 0.0295 
Train Epoch: 34 [144/684 (21%)] loss: 0.0481 L_si: 0.0186 L_grad: 0.0295 
Train Epoch: 34 [180/684 (26%)] loss: 0.0401 L_si: 0.0144 L_grad: 0.0258 
Train Epoch: 34 [216/684 (32%)] loss: 0.0517 L_si: 0.0199 L_grad: 0.0319 
Train Epoch: 34 [252/684 (37%)] loss: 0.0358 L_si: 0.0138 L_grad: 0.0220 
Train Epoch: 34 [288/684 (42%)] loss: 0.0666 L_si: 0.0229 L_grad: 0.0437 
Train Epoch: 34 [324/684 (47%)] loss: 0.0732 L_si: 0.0290 L_grad: 0.0442 
Train Epoch: 34 [360/684 (53%)] loss: 0.0703 L_si: 0.0306 L_grad: 0.0397 
Train Epoch: 34 [396/684 (58%)] loss: 0.0464 L_si: 0.0164 L_grad: 0.0300 
Train Epoch: 34 [432/684 (63%)] loss: 0.0435 L_si: 0.0151 L_grad: 0.0284 
Train Epoch: 34 [468/684 (68%)] loss: 0.0185 L_si: 0.0037 L_grad: 0.0148 
Train Epoch: 34 [504/684 (74%)] loss: 0.0445 L_si: 0.0124 L_grad: 0.0321 
Train Epoch: 34 [540/684 (79%)] loss: 0.0381 L_si: 0.0115 L_grad: 0.0266 
Train Epoch: 34 [576/684 (84%)] loss: 0.0309 L_si: 0.0075 L_grad: 0.0235 
Train Epoch: 34 [612/684 (89%)] loss: 0.0426 L_si: 0.0136 L_grad: 0.0291 
Train Epoch: 34 [648/684 (95%)] loss: 0.0258 L_si: 0.0042 L_grad: 0.0216 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009504903107881546, 0.02709060162305832, 0.008998002856969833, 0.010479601100087166, 0.011696910485625267, 0.034052059054374695, 0.016288619488477707, 0.00839732214808464, 0.015790807083249092, 0.0087303901091218, 0.015540262684226036, 0.009754480794072151, 0.03320031613111496, 0.010022591799497604, 0.02037452906370163], 'L_si': [0.0011774972081184387, 0.009758681058883667, 0.0011493712663650513, 0.0016809254884719849, 0.001739703118801117, 0.014117538928985596, 0.003598526120185852, 0.0008925870060920715, 0.0031946152448654175, 0.0007197856903076172, 0.0036329329013824463, 0.0011946484446525574, 0.014066129922866821, 0.0009812265634536743, 0.006410591304302216], 'L_grad': [0.008327405899763107, 0.017331920564174652, 0.007848631590604782, 0.008798675611615181, 0.00995720736682415, 0.0199345201253891, 0.01269009429961443, 0.007504735141992569, 0.012596191838383675, 0.008010604418814182, 0.01190732978284359, 0.008559832349419594, 0.01913418620824814, 0.00904136523604393, 0.013963938690721989]}
Train Epoch: 35 [0/684 (0%)] loss: 0.0449 L_si: 0.0128 L_grad: 0.0321 
Train Epoch: 35 [36/684 (5%)] loss: 0.0322 L_si: 0.0065 L_grad: 0.0257 
Train Epoch: 35 [72/684 (11%)] loss: 0.0376 L_si: 0.0107 L_grad: 0.0269 
Train Epoch: 35 [108/684 (16%)] loss: 0.0353 L_si: 0.0082 L_grad: 0.0271 
Train Epoch: 35 [144/684 (21%)] loss: 0.0208 L_si: 0.0031 L_grad: 0.0178 
Train Epoch: 35 [180/684 (26%)] loss: 0.0624 L_si: 0.0230 L_grad: 0.0394 
Train Epoch: 35 [216/684 (32%)] loss: 0.0380 L_si: 0.0106 L_grad: 0.0274 
Train Epoch: 35 [252/684 (37%)] loss: 0.0667 L_si: 0.0279 L_grad: 0.0388 
Train Epoch: 35 [288/684 (42%)] loss: 0.0670 L_si: 0.0292 L_grad: 0.0378 
Train Epoch: 35 [324/684 (47%)] loss: 0.0602 L_si: 0.0275 L_grad: 0.0327 
Train Epoch: 35 [360/684 (53%)] loss: 0.0453 L_si: 0.0141 L_grad: 0.0312 
Train Epoch: 35 [396/684 (58%)] loss: 0.0404 L_si: 0.0147 L_grad: 0.0257 
Train Epoch: 35 [432/684 (63%)] loss: 0.0502 L_si: 0.0198 L_grad: 0.0304 
Train Epoch: 35 [468/684 (68%)] loss: 0.0494 L_si: 0.0177 L_grad: 0.0317 
Train Epoch: 35 [504/684 (74%)] loss: 0.0211 L_si: 0.0048 L_grad: 0.0163 
Train Epoch: 35 [540/684 (79%)] loss: 0.0359 L_si: 0.0118 L_grad: 0.0241 
Train Epoch: 35 [576/684 (84%)] loss: 0.0361 L_si: 0.0106 L_grad: 0.0255 
Train Epoch: 35 [612/684 (89%)] loss: 0.0587 L_si: 0.0200 L_grad: 0.0386 
Train Epoch: 35 [648/684 (95%)] loss: 0.0381 L_si: 0.0151 L_grad: 0.0231 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.011695362627506256, 0.011898206546902657, 0.00910102017223835, 0.023461375385522842, 0.010104521177709103, 0.03457554057240486, 0.02510560303926468, 0.016896232962608337, 0.015658998861908913, 0.017099713906645775, 0.00964541919529438, 0.011669518426060677, 0.01851561665534973, 0.01871059276163578, 0.009871073067188263], 'L_si': [0.0016845911741256714, 0.0015885233879089355, 0.0009388923645019531, 0.008920684456825256, 0.0008174777030944824, 0.014401882886886597, 0.009263984858989716, 0.003876917064189911, 0.0034396573901176453, 0.004040345549583435, 0.0012967213988304138, 0.0015687420964241028, 0.005998857319355011, 0.005964435636997223, 0.0010738298296928406], 'L_grad': [0.010010771453380585, 0.010309683158993721, 0.008162127807736397, 0.014540689997375011, 0.00928704347461462, 0.020173657685518265, 0.015841618180274963, 0.013019316829741001, 0.012219341471791267, 0.01305936835706234, 0.008348697796463966, 0.010100776329636574, 0.012516760267317295, 0.012746157124638557, 0.008797243237495422]}
Train Epoch: 36 [0/684 (0%)] loss: 0.0144 L_si: 0.0027 L_grad: 0.0117 
Train Epoch: 36 [36/684 (5%)] loss: 0.0275 L_si: 0.0045 L_grad: 0.0230 
Train Epoch: 36 [72/684 (11%)] loss: 0.0716 L_si: 0.0265 L_grad: 0.0451 
Train Epoch: 36 [108/684 (16%)] loss: 0.0836 L_si: 0.0370 L_grad: 0.0466 
Train Epoch: 36 [144/684 (21%)] loss: 0.0563 L_si: 0.0244 L_grad: 0.0320 
Train Epoch: 36 [180/684 (26%)] loss: 0.0546 L_si: 0.0174 L_grad: 0.0373 
Train Epoch: 36 [216/684 (32%)] loss: 0.0455 L_si: 0.0177 L_grad: 0.0278 
Train Epoch: 36 [252/684 (37%)] loss: 0.0474 L_si: 0.0132 L_grad: 0.0343 
Train Epoch: 36 [288/684 (42%)] loss: 0.0461 L_si: 0.0159 L_grad: 0.0302 
Train Epoch: 36 [324/684 (47%)] loss: 0.0242 L_si: 0.0056 L_grad: 0.0186 
Train Epoch: 36 [360/684 (53%)] loss: 0.0352 L_si: 0.0092 L_grad: 0.0260 
Train Epoch: 36 [396/684 (58%)] loss: 0.0416 L_si: 0.0111 L_grad: 0.0305 
Train Epoch: 36 [432/684 (63%)] loss: 0.0174 L_si: 0.0023 L_grad: 0.0151 
Train Epoch: 36 [468/684 (68%)] loss: 0.0209 L_si: 0.0032 L_grad: 0.0177 
Train Epoch: 36 [504/684 (74%)] loss: 0.0635 L_si: 0.0269 L_grad: 0.0367 
Train Epoch: 36 [540/684 (79%)] loss: 0.0465 L_si: 0.0203 L_grad: 0.0262 
Train Epoch: 36 [576/684 (84%)] loss: 0.0656 L_si: 0.0286 L_grad: 0.0370 
Train Epoch: 36 [612/684 (89%)] loss: 0.0416 L_si: 0.0134 L_grad: 0.0282 
Train Epoch: 36 [648/684 (95%)] loss: 0.0757 L_si: 0.0313 L_grad: 0.0445 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010466106235980988, 0.020827652886509895, 0.023058606311678886, 0.008861292153596878, 0.009895753115415573, 0.01488543301820755, 0.014092108234763145, 0.0335400253534317, 0.014502995647490025, 0.009821978397667408, 0.010534689761698246, 0.030296629294753075, 0.00874447450041771, 0.0105093102902174, 0.018001701682806015], 'L_si': [0.0016504153609275818, 0.006619669497013092, 0.008660249412059784, 0.0008851736783981323, 0.001365073025226593, 0.0033040642738342285, 0.0021376311779022217, 0.014096274971961975, 0.0029640868306159973, 0.0013055279850959778, 0.0011624544858932495, 0.011329233646392822, 0.0011067315936088562, 0.001101657748222351, 0.005890011787414551], 'L_grad': [0.008815690875053406, 0.014207983389496803, 0.014398356899619102, 0.007976118475198746, 0.00853068009018898, 0.011581368744373322, 0.011954477056860924, 0.019443750381469727, 0.011538908816874027, 0.00851645041257143, 0.009372235275804996, 0.018967395648360252, 0.007637742441147566, 0.009407652541995049, 0.012111689895391464]}
Train Epoch: 37 [0/684 (0%)] loss: 0.0275 L_si: 0.0059 L_grad: 0.0216 
Train Epoch: 37 [36/684 (5%)] loss: 0.0529 L_si: 0.0180 L_grad: 0.0349 
Train Epoch: 37 [72/684 (11%)] loss: 0.0596 L_si: 0.0211 L_grad: 0.0385 
Train Epoch: 37 [108/684 (16%)] loss: 0.0408 L_si: 0.0110 L_grad: 0.0298 
Train Epoch: 37 [144/684 (21%)] loss: 0.0503 L_si: 0.0172 L_grad: 0.0331 
Train Epoch: 37 [180/684 (26%)] loss: 0.0653 L_si: 0.0257 L_grad: 0.0397 
Train Epoch: 37 [216/684 (32%)] loss: 0.0382 L_si: 0.0097 L_grad: 0.0285 
Train Epoch: 37 [252/684 (37%)] loss: 0.0576 L_si: 0.0182 L_grad: 0.0393 
Train Epoch: 37 [288/684 (42%)] loss: 0.0820 L_si: 0.0368 L_grad: 0.0452 
Train Epoch: 37 [324/684 (47%)] loss: 0.0309 L_si: 0.0064 L_grad: 0.0245 
Train Epoch: 37 [360/684 (53%)] loss: 0.0807 L_si: 0.0407 L_grad: 0.0399 
Train Epoch: 37 [396/684 (58%)] loss: 0.0515 L_si: 0.0229 L_grad: 0.0286 
Train Epoch: 37 [432/684 (63%)] loss: 0.0396 L_si: 0.0118 L_grad: 0.0278 
Train Epoch: 37 [468/684 (68%)] loss: 0.0526 L_si: 0.0172 L_grad: 0.0354 
Train Epoch: 37 [504/684 (74%)] loss: 0.0420 L_si: 0.0142 L_grad: 0.0277 
Train Epoch: 37 [540/684 (79%)] loss: 0.0591 L_si: 0.0201 L_grad: 0.0390 
Train Epoch: 37 [576/684 (84%)] loss: 0.0424 L_si: 0.0158 L_grad: 0.0266 
Train Epoch: 37 [612/684 (89%)] loss: 0.0529 L_si: 0.0193 L_grad: 0.0336 
Train Epoch: 37 [648/684 (95%)] loss: 0.0572 L_si: 0.0246 L_grad: 0.0326 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.00950857624411583, 0.025389380753040314, 0.010525213554501534, 0.012887220829725266, 0.010404834523797035, 0.008102254010736942, 0.015554996207356453, 0.019813470542430878, 0.02048567309975624, 0.02029559575021267, 0.009389040991663933, 0.02297239564359188, 0.020025035366415977, 0.024526800960302353, 0.01552550494670868], 'L_si': [0.001020379364490509, 0.009142376482486725, 0.0011234134435653687, 0.001873806118965149, 0.0011146068572998047, 0.0008306950330734253, 0.0032596513628959656, 0.004574619233608246, 0.006578035652637482, 0.0063177719712257385, 0.0011254027485847473, 0.008886344730854034, 0.006455153226852417, 0.00913926213979721, 0.0031871795654296875], 'L_grad': [0.00848819687962532, 0.01624700427055359, 0.009401800110936165, 0.011013414710760117, 0.00929022766649723, 0.007271558977663517, 0.012295344844460487, 0.015238850377500057, 0.013907638378441334, 0.01397782377898693, 0.008263638243079185, 0.014086050912737846, 0.01356988213956356, 0.015387539751827717, 0.012338325381278992]}
Train Epoch: 38 [0/684 (0%)] loss: 0.0509 L_si: 0.0172 L_grad: 0.0337 
Train Epoch: 38 [36/684 (5%)] loss: 0.0307 L_si: 0.0070 L_grad: 0.0237 
Train Epoch: 38 [72/684 (11%)] loss: 0.0452 L_si: 0.0166 L_grad: 0.0286 
Train Epoch: 38 [108/684 (16%)] loss: 0.0317 L_si: 0.0077 L_grad: 0.0240 
Train Epoch: 38 [144/684 (21%)] loss: 0.0438 L_si: 0.0135 L_grad: 0.0303 
Train Epoch: 38 [180/684 (26%)] loss: 0.0562 L_si: 0.0231 L_grad: 0.0331 
Train Epoch: 38 [216/684 (32%)] loss: 0.0526 L_si: 0.0180 L_grad: 0.0346 
Train Epoch: 38 [252/684 (37%)] loss: 0.0671 L_si: 0.0323 L_grad: 0.0348 
Train Epoch: 38 [288/684 (42%)] loss: 0.0563 L_si: 0.0188 L_grad: 0.0375 
Train Epoch: 38 [324/684 (47%)] loss: 0.0285 L_si: 0.0053 L_grad: 0.0232 
Train Epoch: 38 [360/684 (53%)] loss: 0.0553 L_si: 0.0211 L_grad: 0.0342 
Train Epoch: 38 [396/684 (58%)] loss: 0.0498 L_si: 0.0151 L_grad: 0.0347 
Train Epoch: 38 [432/684 (63%)] loss: 0.0204 L_si: 0.0034 L_grad: 0.0170 
Train Epoch: 38 [468/684 (68%)] loss: 0.0486 L_si: 0.0142 L_grad: 0.0344 
Train Epoch: 38 [504/684 (74%)] loss: 0.0274 L_si: 0.0050 L_grad: 0.0225 
Train Epoch: 38 [540/684 (79%)] loss: 0.0340 L_si: 0.0103 L_grad: 0.0237 
Train Epoch: 38 [576/684 (84%)] loss: 0.0242 L_si: 0.0054 L_grad: 0.0188 
Train Epoch: 38 [612/684 (89%)] loss: 0.0376 L_si: 0.0122 L_grad: 0.0254 
Train Epoch: 38 [648/684 (95%)] loss: 0.0571 L_si: 0.0210 L_grad: 0.0361 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008803172037005424, 0.010376779362559319, 0.017812740057706833, 0.011756399646401405, 0.010019530542194843, 0.028749102726578712, 0.025021890178322792, 0.023891782388091087, 0.016437534242868423, 0.015877574682235718, 0.010963542386889458, 0.010411107912659645, 0.023213766515254974, 0.020154235884547234, 0.011285612359642982], 'L_si': [0.0009797140955924988, 0.0013129711151123047, 0.003885023295879364, 0.001748405396938324, 0.0013511255383491516, 0.011131919920444489, 0.00927291065454483, 0.009139388799667358, 0.003362596035003662, 0.003536239266395569, 0.0016859769821166992, 0.0014958903193473816, 0.008715033531188965, 0.006498150527477264, 0.0015127286314964294], 'L_grad': [0.007823457941412926, 0.009063808247447014, 0.013927716761827469, 0.010007994249463081, 0.008668405003845692, 0.017617182806134224, 0.01574897952377796, 0.014752393588423729, 0.013074939139187336, 0.012341336347162724, 0.009277565404772758, 0.008915217593312263, 0.01449873298406601, 0.01365608535706997, 0.009772883728146553]}
Train Epoch: 39 [0/684 (0%)] loss: 0.0482 L_si: 0.0211 L_grad: 0.0272 
Train Epoch: 39 [36/684 (5%)] loss: 0.0305 L_si: 0.0072 L_grad: 0.0233 
Train Epoch: 39 [72/684 (11%)] loss: 0.0502 L_si: 0.0209 L_grad: 0.0293 
Train Epoch: 39 [108/684 (16%)] loss: 0.0430 L_si: 0.0183 L_grad: 0.0247 
Train Epoch: 39 [144/684 (21%)] loss: 0.0381 L_si: 0.0148 L_grad: 0.0233 
Train Epoch: 39 [180/684 (26%)] loss: 0.0510 L_si: 0.0195 L_grad: 0.0315 
Train Epoch: 39 [216/684 (32%)] loss: 0.0578 L_si: 0.0205 L_grad: 0.0373 
Train Epoch: 39 [252/684 (37%)] loss: 0.0330 L_si: 0.0103 L_grad: 0.0227 
Train Epoch: 39 [288/684 (42%)] loss: 0.0307 L_si: 0.0075 L_grad: 0.0232 
Train Epoch: 39 [324/684 (47%)] loss: 0.0364 L_si: 0.0122 L_grad: 0.0242 
Train Epoch: 39 [360/684 (53%)] loss: 0.0331 L_si: 0.0102 L_grad: 0.0229 
Train Epoch: 39 [396/684 (58%)] loss: 0.0758 L_si: 0.0313 L_grad: 0.0446 
Train Epoch: 39 [432/684 (63%)] loss: 0.0404 L_si: 0.0110 L_grad: 0.0294 
Train Epoch: 39 [468/684 (68%)] loss: 0.0543 L_si: 0.0223 L_grad: 0.0319 
Train Epoch: 39 [504/684 (74%)] loss: 0.0613 L_si: 0.0245 L_grad: 0.0369 
Train Epoch: 39 [540/684 (79%)] loss: 0.0381 L_si: 0.0127 L_grad: 0.0254 
Train Epoch: 39 [576/684 (84%)] loss: 0.0439 L_si: 0.0141 L_grad: 0.0298 
Train Epoch: 39 [612/684 (89%)] loss: 0.0552 L_si: 0.0207 L_grad: 0.0345 
Train Epoch: 39 [648/684 (95%)] loss: 0.0403 L_si: 0.0176 L_grad: 0.0227 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010819105431437492, 0.010094840079545975, 0.010494951158761978, 0.038741275668144226, 0.009981229901313782, 0.010216624476015568, 0.01781647466123104, 0.0191663671284914, 0.02593565732240677, 0.01035366766154766, 0.02692115679383278, 0.022639866918325424, 0.02035520225763321, 0.009451132267713547, 0.009734691120684147], 'L_si': [0.0017243027687072754, 0.0010941028594970703, 0.001510724425315857, 0.01674657315015793, 0.0014484524726867676, 0.0012147873640060425, 0.0035879313945770264, 0.004077091813087463, 0.010019004344940186, 0.0010294392704963684, 0.008854568004608154, 0.0071759894490242004, 0.006188161671161652, 0.0011034831404685974, 0.0010768026113510132], 'L_grad': [0.009094802662730217, 0.009000737220048904, 0.008984226733446121, 0.021994704380631447, 0.008532777428627014, 0.009001837112009525, 0.014228543266654015, 0.015089275315403938, 0.015916652977466583, 0.009324228391051292, 0.018066588789224625, 0.015463877469301224, 0.014167041517794132, 0.00834764912724495, 0.008657888509333134]}
Train Epoch: 40 [0/684 (0%)] loss: 0.0539 L_si: 0.0220 L_grad: 0.0319 
Train Epoch: 40 [36/684 (5%)] loss: 0.0448 L_si: 0.0189 L_grad: 0.0259 
Train Epoch: 40 [72/684 (11%)] loss: 0.0562 L_si: 0.0190 L_grad: 0.0372 
Train Epoch: 40 [108/684 (16%)] loss: 0.0663 L_si: 0.0266 L_grad: 0.0397 
Train Epoch: 40 [144/684 (21%)] loss: 0.0565 L_si: 0.0223 L_grad: 0.0341 
Train Epoch: 40 [180/684 (26%)] loss: 0.0338 L_si: 0.0137 L_grad: 0.0201 
Train Epoch: 40 [216/684 (32%)] loss: 0.0634 L_si: 0.0288 L_grad: 0.0346 
Train Epoch: 40 [252/684 (37%)] loss: 0.0332 L_si: 0.0072 L_grad: 0.0260 
Train Epoch: 40 [288/684 (42%)] loss: 0.0552 L_si: 0.0250 L_grad: 0.0302 
Train Epoch: 40 [324/684 (47%)] loss: 0.0450 L_si: 0.0158 L_grad: 0.0292 
Train Epoch: 40 [360/684 (53%)] loss: 0.0441 L_si: 0.0170 L_grad: 0.0271 
Train Epoch: 40 [396/684 (58%)] loss: 0.0454 L_si: 0.0140 L_grad: 0.0314 
Train Epoch: 40 [432/684 (63%)] loss: 0.0381 L_si: 0.0127 L_grad: 0.0254 
Train Epoch: 40 [468/684 (68%)] loss: 0.0501 L_si: 0.0170 L_grad: 0.0331 
Train Epoch: 40 [504/684 (74%)] loss: 0.0295 L_si: 0.0067 L_grad: 0.0228 
Train Epoch: 40 [540/684 (79%)] loss: 0.0239 L_si: 0.0054 L_grad: 0.0185 
Train Epoch: 40 [576/684 (84%)] loss: 0.0571 L_si: 0.0252 L_grad: 0.0319 
Train Epoch: 40 [612/684 (89%)] loss: 0.0687 L_si: 0.0257 L_grad: 0.0430 
Train Epoch: 40 [648/684 (95%)] loss: 0.0205 L_si: 0.0037 L_grad: 0.0168 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch040-loss-0.0444.pth.tar ...
all losses in batch in validation:  {'loss': [0.011696111410856247, 0.02236788347363472, 0.01614605449140072, 0.013181256130337715, 0.009115306660532951, 0.011873723939061165, 0.011538502760231495, 0.009626240469515324, 0.016135215759277344, 0.02033664658665657, 0.01158418320119381, 0.016829341650009155, 0.009632812812924385, 0.04033821076154709, 0.03585578873753548], 'L_si': [0.0014916136860847473, 0.006885789334774017, 0.003425516188144684, 0.0020720064640045166, 0.0008471161127090454, 0.0015923082828521729, 0.0016138553619384766, 0.0012824684381484985, 0.0033769607543945312, 0.006551265716552734, 0.001498207449913025, 0.003283575177192688, 0.0012320950627326965, 0.01787080615758896, 0.01505257934331894], 'L_grad': [0.0102044977247715, 0.015482093207538128, 0.012720538303256035, 0.011109249666333199, 0.008268190547823906, 0.010281415656208992, 0.009924647398293018, 0.008343772031366825, 0.012758254073560238, 0.013785380870103836, 0.010085975751280785, 0.013545767404139042, 0.008400717750191689, 0.02246740646660328, 0.020803209394216537]}
Train Epoch: 41 [0/684 (0%)] loss: 0.0491 L_si: 0.0211 L_grad: 0.0279 
Train Epoch: 41 [36/684 (5%)] loss: 0.0613 L_si: 0.0283 L_grad: 0.0330 
Train Epoch: 41 [72/684 (11%)] loss: 0.0856 L_si: 0.0441 L_grad: 0.0415 
Train Epoch: 41 [108/684 (16%)] loss: 0.0416 L_si: 0.0138 L_grad: 0.0277 
Train Epoch: 41 [144/684 (21%)] loss: 0.0574 L_si: 0.0228 L_grad: 0.0346 
Train Epoch: 41 [180/684 (26%)] loss: 0.0516 L_si: 0.0192 L_grad: 0.0324 
Train Epoch: 41 [216/684 (32%)] loss: 0.0543 L_si: 0.0244 L_grad: 0.0299 
Train Epoch: 41 [252/684 (37%)] loss: 0.0242 L_si: 0.0041 L_grad: 0.0201 
Train Epoch: 41 [288/684 (42%)] loss: 0.0604 L_si: 0.0204 L_grad: 0.0400 
Train Epoch: 41 [324/684 (47%)] loss: 0.0502 L_si: 0.0172 L_grad: 0.0330 
Train Epoch: 41 [360/684 (53%)] loss: 0.0457 L_si: 0.0149 L_grad: 0.0308 
Train Epoch: 41 [396/684 (58%)] loss: 0.0244 L_si: 0.0040 L_grad: 0.0204 
Train Epoch: 41 [432/684 (63%)] loss: 0.0326 L_si: 0.0076 L_grad: 0.0250 
Train Epoch: 41 [468/684 (68%)] loss: 0.0631 L_si: 0.0230 L_grad: 0.0401 
Train Epoch: 41 [504/684 (74%)] loss: 0.0208 L_si: 0.0028 L_grad: 0.0180 
Train Epoch: 41 [540/684 (79%)] loss: 0.0426 L_si: 0.0125 L_grad: 0.0301 
Train Epoch: 41 [576/684 (84%)] loss: 0.0268 L_si: 0.0061 L_grad: 0.0207 
Train Epoch: 41 [612/684 (89%)] loss: 0.0440 L_si: 0.0154 L_grad: 0.0286 
Train Epoch: 41 [648/684 (95%)] loss: 0.0707 L_si: 0.0328 L_grad: 0.0379 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008763542398810387, 0.01088486984372139, 0.011892946437001228, 0.009858230128884315, 0.010450589470565319, 0.010229836218059063, 0.009966857731342316, 0.025955988094210625, 0.024834468960762024, 0.009310893714427948, 0.025339333340525627, 0.008938426151871681, 0.02647978626191616, 0.030675571411848068, 0.018727611750364304], 'L_si': [0.0006572306156158447, 0.001722477376461029, 0.002067163586616516, 0.0009987056255340576, 0.0013010874390602112, 0.0010822564363479614, 0.0011067762970924377, 0.00858849287033081, 0.009139709174633026, 0.0009236559271812439, 0.008321143686771393, 0.0011333972215652466, 0.010030753910541534, 0.011304587125778198, 0.006035305559635162], 'L_grad': [0.008106311783194542, 0.00916239246726036, 0.009825782850384712, 0.008859524503350258, 0.009149502031505108, 0.009147579781711102, 0.008860081434249878, 0.017367495223879814, 0.015694759786128998, 0.008387237787246704, 0.017018189653754234, 0.007805028930306435, 0.016449032351374626, 0.01937098428606987, 0.012692306190729141]}
Train Epoch: 42 [0/684 (0%)] loss: 0.0329 L_si: 0.0090 L_grad: 0.0238 
Train Epoch: 42 [36/684 (5%)] loss: 0.0580 L_si: 0.0228 L_grad: 0.0352 
Train Epoch: 42 [72/684 (11%)] loss: 0.0174 L_si: 0.0038 L_grad: 0.0135 
Train Epoch: 42 [108/684 (16%)] loss: 0.0486 L_si: 0.0197 L_grad: 0.0290 
Train Epoch: 42 [144/684 (21%)] loss: 0.0493 L_si: 0.0229 L_grad: 0.0264 
Train Epoch: 42 [180/684 (26%)] loss: 0.0507 L_si: 0.0191 L_grad: 0.0316 
Train Epoch: 42 [216/684 (32%)] loss: 0.0385 L_si: 0.0097 L_grad: 0.0288 
Train Epoch: 42 [252/684 (37%)] loss: 0.0207 L_si: 0.0033 L_grad: 0.0174 
Train Epoch: 42 [288/684 (42%)] loss: 0.0545 L_si: 0.0194 L_grad: 0.0352 
Train Epoch: 42 [324/684 (47%)] loss: 0.0714 L_si: 0.0306 L_grad: 0.0408 
Train Epoch: 42 [360/684 (53%)] loss: 0.0566 L_si: 0.0193 L_grad: 0.0373 
Train Epoch: 42 [396/684 (58%)] loss: 0.0348 L_si: 0.0094 L_grad: 0.0254 
Train Epoch: 42 [432/684 (63%)] loss: 0.0504 L_si: 0.0165 L_grad: 0.0340 
Train Epoch: 42 [468/684 (68%)] loss: 0.0414 L_si: 0.0183 L_grad: 0.0231 
Train Epoch: 42 [504/684 (74%)] loss: 0.0522 L_si: 0.0192 L_grad: 0.0330 
Train Epoch: 42 [540/684 (79%)] loss: 0.0470 L_si: 0.0186 L_grad: 0.0284 
Train Epoch: 42 [576/684 (84%)] loss: 0.0487 L_si: 0.0177 L_grad: 0.0310 
Train Epoch: 42 [612/684 (89%)] loss: 0.0301 L_si: 0.0071 L_grad: 0.0230 
Train Epoch: 42 [648/684 (95%)] loss: 0.0489 L_si: 0.0134 L_grad: 0.0355 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.01020644698292017, 0.02340172976255417, 0.025484047830104828, 0.011957205832004547, 0.020603178068995476, 0.02477402426302433, 0.011030873283743858, 0.009507212787866592, 0.019109005108475685, 0.010445868596434593, 0.011123611591756344, 0.011423002928495407, 0.010675160214304924, 0.024452313780784607, 0.03113734722137451], 'L_si': [0.0010862275958061218, 0.008767172694206238, 0.0091533362865448, 0.0014429166913032532, 0.00676436722278595, 0.006225623190402985, 0.0013991594314575195, 0.0016733631491661072, 0.004009529948234558, 0.001742728054523468, 0.0015369504690170288, 0.0015423521399497986, 0.00171593576669693, 0.009170912206172943, 0.01199311763048172], 'L_grad': [0.009120219387114048, 0.014634556137025356, 0.016330711543560028, 0.010514289140701294, 0.013838810846209526, 0.018548401072621346, 0.009631713852286339, 0.007833849638700485, 0.015099475160241127, 0.008703140541911125, 0.009586661122739315, 0.009880650788545609, 0.008959224447607994, 0.015281401574611664, 0.019144229590892792]}
Train Epoch: 43 [0/684 (0%)] loss: 0.0431 L_si: 0.0132 L_grad: 0.0298 
Train Epoch: 43 [36/684 (5%)] loss: 0.0426 L_si: 0.0182 L_grad: 0.0244 
Train Epoch: 43 [72/684 (11%)] loss: 0.0629 L_si: 0.0283 L_grad: 0.0347 
Train Epoch: 43 [108/684 (16%)] loss: 0.0418 L_si: 0.0126 L_grad: 0.0292 
Train Epoch: 43 [144/684 (21%)] loss: 0.0315 L_si: 0.0099 L_grad: 0.0216 
Train Epoch: 43 [180/684 (26%)] loss: 0.0675 L_si: 0.0245 L_grad: 0.0430 
Train Epoch: 43 [216/684 (32%)] loss: 0.0454 L_si: 0.0193 L_grad: 0.0262 
Train Epoch: 43 [252/684 (37%)] loss: 0.0407 L_si: 0.0121 L_grad: 0.0286 
Train Epoch: 43 [288/684 (42%)] loss: 0.0451 L_si: 0.0120 L_grad: 0.0332 
Train Epoch: 43 [324/684 (47%)] loss: 0.0613 L_si: 0.0218 L_grad: 0.0395 
Train Epoch: 43 [360/684 (53%)] loss: 0.0212 L_si: 0.0045 L_grad: 0.0167 
Train Epoch: 43 [396/684 (58%)] loss: 0.0350 L_si: 0.0133 L_grad: 0.0217 
Train Epoch: 43 [432/684 (63%)] loss: 0.0562 L_si: 0.0209 L_grad: 0.0352 
Train Epoch: 43 [468/684 (68%)] loss: 0.0738 L_si: 0.0325 L_grad: 0.0413 
Train Epoch: 43 [504/684 (74%)] loss: 0.0428 L_si: 0.0174 L_grad: 0.0255 
Train Epoch: 43 [540/684 (79%)] loss: 0.0310 L_si: 0.0098 L_grad: 0.0212 
Train Epoch: 43 [576/684 (84%)] loss: 0.0440 L_si: 0.0140 L_grad: 0.0300 
Train Epoch: 43 [612/684 (89%)] loss: 0.0408 L_si: 0.0133 L_grad: 0.0275 
Train Epoch: 43 [648/684 (95%)] loss: 0.0574 L_si: 0.0227 L_grad: 0.0347 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.012390946969389915, 0.014079403132200241, 0.01978158950805664, 0.011606870219111443, 0.011379473842680454, 0.020982488989830017, 0.016921699047088623, 0.025508973747491837, 0.014655936509370804, 0.0222026240080595, 0.010510073974728584, 0.03544209897518158, 0.0251480620354414, 0.014093365520238876, 0.020003318786621094], 'L_si': [0.0021605417132377625, 0.0030208900570869446, 0.0054308027029037476, 0.0017506331205368042, 0.002039290964603424, 0.006903126835823059, 0.004473276436328888, 0.009583927690982819, 0.0028413385152816772, 0.007592499256134033, 0.0013137459754943848, 0.01509888470172882, 0.009489133954048157, 0.0021718814969062805, 0.004549339413642883], 'L_grad': [0.010230405256152153, 0.011058513075113297, 0.014350786805152893, 0.009856237098574638, 0.00934018287807703, 0.014079362154006958, 0.012448422610759735, 0.015925046056509018, 0.011814597994089127, 0.014610124751925468, 0.0091963279992342, 0.02034321427345276, 0.015658928081393242, 0.011921484023332596, 0.01545397937297821]}
Train Epoch: 44 [0/684 (0%)] loss: 0.0445 L_si: 0.0165 L_grad: 0.0280 
Train Epoch: 44 [36/684 (5%)] loss: 0.0454 L_si: 0.0127 L_grad: 0.0327 
Train Epoch: 44 [72/684 (11%)] loss: 0.0348 L_si: 0.0098 L_grad: 0.0250 
Train Epoch: 44 [108/684 (16%)] loss: 0.0343 L_si: 0.0070 L_grad: 0.0273 
Train Epoch: 44 [144/684 (21%)] loss: 0.0300 L_si: 0.0082 L_grad: 0.0218 
Train Epoch: 44 [180/684 (26%)] loss: 0.0418 L_si: 0.0128 L_grad: 0.0289 
Train Epoch: 44 [216/684 (32%)] loss: 0.0267 L_si: 0.0063 L_grad: 0.0204 
Train Epoch: 44 [252/684 (37%)] loss: 0.0366 L_si: 0.0096 L_grad: 0.0270 
Train Epoch: 44 [288/684 (42%)] loss: 0.0370 L_si: 0.0122 L_grad: 0.0248 
Train Epoch: 44 [324/684 (47%)] loss: 0.0615 L_si: 0.0223 L_grad: 0.0392 
Train Epoch: 44 [360/684 (53%)] loss: 0.0430 L_si: 0.0155 L_grad: 0.0275 
Train Epoch: 44 [396/684 (58%)] loss: 0.0411 L_si: 0.0193 L_grad: 0.0217 
Train Epoch: 44 [432/684 (63%)] loss: 0.0623 L_si: 0.0277 L_grad: 0.0346 
Train Epoch: 44 [468/684 (68%)] loss: 0.0296 L_si: 0.0086 L_grad: 0.0210 
Train Epoch: 44 [504/684 (74%)] loss: 0.0327 L_si: 0.0090 L_grad: 0.0237 
Train Epoch: 44 [540/684 (79%)] loss: 0.0306 L_si: 0.0097 L_grad: 0.0208 
Train Epoch: 44 [576/684 (84%)] loss: 0.0509 L_si: 0.0182 L_grad: 0.0326 
Train Epoch: 44 [612/684 (89%)] loss: 0.0262 L_si: 0.0063 L_grad: 0.0199 
Train Epoch: 44 [648/684 (95%)] loss: 0.0228 L_si: 0.0043 L_grad: 0.0184 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009357944130897522, 0.037635866552591324, 0.03423547372221947, 0.012884763069450855, 0.00928391795605421, 0.008957293815910816, 0.01854913868010044, 0.008818519301712513, 0.0156517643481493, 0.03111271560192108, 0.00966968946158886, 0.01065165176987648, 0.011581212282180786, 0.010700030252337456, 0.010317955166101456], 'L_si': [0.0011792555451393127, 0.016624413430690765, 0.013475127518177032, 0.0022395551204681396, 0.0008749663829803467, 0.0009375736117362976, 0.005795903503894806, 0.0008730590343475342, 0.0032250508666038513, 0.011568181216716766, 0.0007862821221351624, 0.0011067017912864685, 0.0016421526670455933, 0.0013484880328178406, 0.0010945498943328857], 'L_grad': [0.00817868858575821, 0.02101145312190056, 0.020760346204042435, 0.010645207948982716, 0.008408951573073864, 0.008019720204174519, 0.012753235176205635, 0.007945460267364979, 0.012426713481545448, 0.019544534385204315, 0.008883407339453697, 0.009544949978590012, 0.009939059615135193, 0.009351542219519615, 0.00922340527176857]}
Train Epoch: 45 [0/684 (0%)] loss: 0.0201 L_si: 0.0037 L_grad: 0.0164 
Train Epoch: 45 [36/684 (5%)] loss: 0.0326 L_si: 0.0095 L_grad: 0.0230 
Train Epoch: 45 [72/684 (11%)] loss: 0.0515 L_si: 0.0222 L_grad: 0.0292 
Train Epoch: 45 [108/684 (16%)] loss: 0.0239 L_si: 0.0050 L_grad: 0.0188 
Train Epoch: 45 [144/684 (21%)] loss: 0.0425 L_si: 0.0165 L_grad: 0.0260 
Train Epoch: 45 [180/684 (26%)] loss: 0.0507 L_si: 0.0172 L_grad: 0.0334 
Train Epoch: 45 [216/684 (32%)] loss: 0.0264 L_si: 0.0073 L_grad: 0.0190 
Train Epoch: 45 [252/684 (37%)] loss: 0.0538 L_si: 0.0178 L_grad: 0.0360 
Train Epoch: 45 [288/684 (42%)] loss: 0.0297 L_si: 0.0090 L_grad: 0.0207 
Train Epoch: 45 [324/684 (47%)] loss: 0.0377 L_si: 0.0140 L_grad: 0.0237 
Train Epoch: 45 [360/684 (53%)] loss: 0.0442 L_si: 0.0128 L_grad: 0.0315 
Train Epoch: 45 [396/684 (58%)] loss: 0.0434 L_si: 0.0160 L_grad: 0.0274 
Train Epoch: 45 [432/684 (63%)] loss: 0.0311 L_si: 0.0087 L_grad: 0.0224 
Train Epoch: 45 [468/684 (68%)] loss: 0.0759 L_si: 0.0346 L_grad: 0.0413 
Train Epoch: 45 [504/684 (74%)] loss: 0.0489 L_si: 0.0211 L_grad: 0.0278 
Train Epoch: 45 [540/684 (79%)] loss: 0.0473 L_si: 0.0144 L_grad: 0.0328 
Train Epoch: 45 [576/684 (84%)] loss: 0.0763 L_si: 0.0331 L_grad: 0.0433 
Train Epoch: 45 [612/684 (89%)] loss: 0.0362 L_si: 0.0095 L_grad: 0.0267 
Train Epoch: 45 [648/684 (95%)] loss: 0.0479 L_si: 0.0137 L_grad: 0.0341 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.04063495993614197, 0.011007333174347878, 0.012041470035910606, 0.011480754241347313, 0.021124456077814102, 0.01609964668750763, 0.010357632301747799, 0.020393239334225655, 0.01774384081363678, 0.027277827262878418, 0.02099897712469101, 0.01062534935772419, 0.014133982360363007, 0.010518589988350868, 0.016521112993359566], 'L_si': [0.01694372296333313, 0.001219339668750763, 0.0015348568558692932, 0.0011492818593978882, 0.006218649446964264, 0.003039345145225525, 0.0011164993047714233, 0.0061068907380104065, 0.003557145595550537, 0.009434744715690613, 0.006101161241531372, 0.0010447651147842407, 0.0020960718393325806, 0.001038968563079834, 0.003350168466567993], 'L_grad': [0.023691238835453987, 0.009787993505597115, 0.010506613180041313, 0.010331472381949425, 0.014905806630849838, 0.01306030061095953, 0.009241132996976376, 0.014286348596215248, 0.014186694286763668, 0.017843082547187805, 0.014897815883159637, 0.009580584242939949, 0.012037910521030426, 0.009479621425271034, 0.013170944526791573]}
Train Epoch: 46 [0/684 (0%)] loss: 0.0478 L_si: 0.0176 L_grad: 0.0302 
Train Epoch: 46 [36/684 (5%)] loss: 0.0470 L_si: 0.0155 L_grad: 0.0315 
Train Epoch: 46 [72/684 (11%)] loss: 0.0276 L_si: 0.0083 L_grad: 0.0193 
Train Epoch: 46 [108/684 (16%)] loss: 0.0322 L_si: 0.0086 L_grad: 0.0236 
Train Epoch: 46 [144/684 (21%)] loss: 0.0335 L_si: 0.0079 L_grad: 0.0257 
Train Epoch: 46 [180/684 (26%)] loss: 0.0719 L_si: 0.0259 L_grad: 0.0460 
Train Epoch: 46 [216/684 (32%)] loss: 0.0533 L_si: 0.0196 L_grad: 0.0338 
Train Epoch: 46 [252/684 (37%)] loss: 0.0533 L_si: 0.0187 L_grad: 0.0346 
Train Epoch: 46 [288/684 (42%)] loss: 0.0352 L_si: 0.0090 L_grad: 0.0262 
Train Epoch: 46 [324/684 (47%)] loss: 0.0383 L_si: 0.0097 L_grad: 0.0286 
Train Epoch: 46 [360/684 (53%)] loss: 0.0508 L_si: 0.0208 L_grad: 0.0300 
Train Epoch: 46 [396/684 (58%)] loss: 0.0531 L_si: 0.0205 L_grad: 0.0326 
Train Epoch: 46 [432/684 (63%)] loss: 0.0532 L_si: 0.0189 L_grad: 0.0344 
Train Epoch: 46 [468/684 (68%)] loss: 0.0649 L_si: 0.0284 L_grad: 0.0365 
Train Epoch: 46 [504/684 (74%)] loss: 0.0547 L_si: 0.0185 L_grad: 0.0362 
Train Epoch: 46 [540/684 (79%)] loss: 0.0201 L_si: 0.0042 L_grad: 0.0158 
Train Epoch: 46 [576/684 (84%)] loss: 0.0400 L_si: 0.0133 L_grad: 0.0267 
Train Epoch: 46 [612/684 (89%)] loss: 0.0308 L_si: 0.0082 L_grad: 0.0226 
Train Epoch: 46 [648/684 (95%)] loss: 0.0447 L_si: 0.0120 L_grad: 0.0327 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.02929823473095894, 0.010708862915635109, 0.02646871842443943, 0.010577673092484474, 0.011728906072676182, 0.012922022491693497, 0.023597687482833862, 0.00991072878241539, 0.009687704965472221, 0.009924793615937233, 0.025978442281484604, 0.012827116996049881, 0.009768432006239891, 0.026148853823542595, 0.01976928301155567], 'L_si': [0.011160768568515778, 0.001346103847026825, 0.009999804198741913, 0.0012521594762802124, 0.001280955970287323, 0.0017292201519012451, 0.008937612175941467, 0.0011565908789634705, 0.0012800917029380798, 0.0009599775075912476, 0.008740454912185669, 0.002609364688396454, 0.0011268258094787598, 0.008722856640815735, 0.006780162453651428], 'L_grad': [0.01813746616244316, 0.009362759068608284, 0.016468914225697517, 0.009325513616204262, 0.010447950102388859, 0.011192802339792252, 0.01466007437556982, 0.00875413790345192, 0.008407613262534142, 0.008964816108345985, 0.017237987369298935, 0.010217752307653427, 0.008641606196761131, 0.01742599718272686, 0.012989120557904243]}
Train Epoch: 47 [0/684 (0%)] loss: 0.0638 L_si: 0.0242 L_grad: 0.0397 
Train Epoch: 47 [36/684 (5%)] loss: 0.0419 L_si: 0.0121 L_grad: 0.0298 
Train Epoch: 47 [72/684 (11%)] loss: 0.0300 L_si: 0.0055 L_grad: 0.0245 
Train Epoch: 47 [108/684 (16%)] loss: 0.0627 L_si: 0.0256 L_grad: 0.0371 
Train Epoch: 47 [144/684 (21%)] loss: 0.0389 L_si: 0.0125 L_grad: 0.0263 
Train Epoch: 47 [180/684 (26%)] loss: 0.0588 L_si: 0.0201 L_grad: 0.0387 
Train Epoch: 47 [216/684 (32%)] loss: 0.0417 L_si: 0.0125 L_grad: 0.0292 
Train Epoch: 47 [252/684 (37%)] loss: 0.0358 L_si: 0.0115 L_grad: 0.0242 
Train Epoch: 47 [288/684 (42%)] loss: 0.0482 L_si: 0.0220 L_grad: 0.0262 
Train Epoch: 47 [324/684 (47%)] loss: 0.0343 L_si: 0.0107 L_grad: 0.0236 
Train Epoch: 47 [360/684 (53%)] loss: 0.0477 L_si: 0.0187 L_grad: 0.0290 
Train Epoch: 47 [396/684 (58%)] loss: 0.0696 L_si: 0.0330 L_grad: 0.0366 
Train Epoch: 47 [432/684 (63%)] loss: 0.0538 L_si: 0.0213 L_grad: 0.0325 
Train Epoch: 47 [468/684 (68%)] loss: 0.0362 L_si: 0.0094 L_grad: 0.0268 
Train Epoch: 47 [504/684 (74%)] loss: 0.0509 L_si: 0.0241 L_grad: 0.0268 
Train Epoch: 47 [540/684 (79%)] loss: 0.0353 L_si: 0.0073 L_grad: 0.0280 
Train Epoch: 47 [576/684 (84%)] loss: 0.0404 L_si: 0.0138 L_grad: 0.0266 
Train Epoch: 47 [612/684 (89%)] loss: 0.0190 L_si: 0.0045 L_grad: 0.0145 
Train Epoch: 47 [648/684 (95%)] loss: 0.0416 L_si: 0.0111 L_grad: 0.0305 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.03094923123717308, 0.018122855573892593, 0.02577592432498932, 0.01066491287201643, 0.011124029755592346, 0.009725388139486313, 0.012201052159070969, 0.010630613192915916, 0.010630500502884388, 0.024786554276943207, 0.018481090664863586, 0.016904102638363838, 0.009899773634970188, 0.019366633147001266, 0.018928438425064087], 'L_si': [0.011448323726654053, 0.003725700080394745, 0.009411707520484924, 0.00164109468460083, 0.0016456767916679382, 0.0014639273285865784, 0.0018024742603302002, 0.0011695176362991333, 0.001455552875995636, 0.009063966572284698, 0.006443776190280914, 0.0036613494157791138, 0.0011679008603096008, 0.006500750780105591, 0.006083346903324127], 'L_grad': [0.019500907510519028, 0.014397155493497849, 0.016364216804504395, 0.0090238181874156, 0.009478352963924408, 0.008261460810899734, 0.010398577898740768, 0.009461095556616783, 0.009174947626888752, 0.01572258770465851, 0.012037315405905247, 0.013242753222584724, 0.008731872774660587, 0.01286588329821825, 0.01284509152173996]}
Train Epoch: 48 [0/684 (0%)] loss: 0.0530 L_si: 0.0231 L_grad: 0.0299 
Train Epoch: 48 [36/684 (5%)] loss: 0.0256 L_si: 0.0057 L_grad: 0.0199 
Train Epoch: 48 [72/684 (11%)] loss: 0.0400 L_si: 0.0148 L_grad: 0.0252 
Train Epoch: 48 [108/684 (16%)] loss: 0.0383 L_si: 0.0116 L_grad: 0.0267 
Train Epoch: 48 [144/684 (21%)] loss: 0.0715 L_si: 0.0376 L_grad: 0.0339 
Train Epoch: 48 [180/684 (26%)] loss: 0.0490 L_si: 0.0186 L_grad: 0.0304 
Train Epoch: 48 [216/684 (32%)] loss: 0.0323 L_si: 0.0073 L_grad: 0.0250 
Train Epoch: 48 [252/684 (37%)] loss: 0.0352 L_si: 0.0069 L_grad: 0.0282 
Train Epoch: 48 [288/684 (42%)] loss: 0.0454 L_si: 0.0138 L_grad: 0.0316 
Train Epoch: 48 [324/684 (47%)] loss: 0.0210 L_si: 0.0043 L_grad: 0.0167 
Train Epoch: 48 [360/684 (53%)] loss: 0.0407 L_si: 0.0124 L_grad: 0.0282 
Train Epoch: 48 [396/684 (58%)] loss: 0.0386 L_si: 0.0102 L_grad: 0.0284 
Train Epoch: 48 [432/684 (63%)] loss: 0.0376 L_si: 0.0089 L_grad: 0.0287 
Train Epoch: 48 [468/684 (68%)] loss: 0.0370 L_si: 0.0108 L_grad: 0.0262 
Train Epoch: 48 [504/684 (74%)] loss: 0.0353 L_si: 0.0089 L_grad: 0.0264 
Train Epoch: 48 [540/684 (79%)] loss: 0.0174 L_si: 0.0026 L_grad: 0.0149 
Train Epoch: 48 [576/684 (84%)] loss: 0.0467 L_si: 0.0170 L_grad: 0.0298 
Train Epoch: 48 [612/684 (89%)] loss: 0.0621 L_si: 0.0241 L_grad: 0.0381 
Train Epoch: 48 [648/684 (95%)] loss: 0.0646 L_si: 0.0246 L_grad: 0.0400 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008679622784256935, 0.008343080058693886, 0.01225502323359251, 0.010897243395447731, 0.009596970863640308, 0.015966035425662994, 0.019290976226329803, 0.011092422530055046, 0.03506563603878021, 0.008910526521503925, 0.02430587261915207, 0.009511802345514297, 0.023259760811924934, 0.03157554939389229, 0.01087768655270338], 'L_si': [0.0008397102355957031, 0.0007553473114967346, 0.001739688217639923, 0.0015798062086105347, 0.000862419605255127, 0.0032281652092933655, 0.00594763457775116, 0.0014632269740104675, 0.01334083080291748, 0.0007148310542106628, 0.008739881217479706, 0.0008870735764503479, 0.008744858205318451, 0.011242017149925232, 0.0012046396732330322], 'L_grad': [0.007839912548661232, 0.007587732747197151, 0.010515335015952587, 0.009317437186837196, 0.008734551258385181, 0.012737870216369629, 0.01334334071725607, 0.009629195556044579, 0.021724805235862732, 0.008195695467293262, 0.015565990470349789, 0.00862472876906395, 0.014514902606606483, 0.020333532243967056, 0.009673046879470348]}
Train Epoch: 49 [0/684 (0%)] loss: 0.0246 L_si: 0.0042 L_grad: 0.0204 
Train Epoch: 49 [36/684 (5%)] loss: 0.0301 L_si: 0.0086 L_grad: 0.0215 
Train Epoch: 49 [72/684 (11%)] loss: 0.0445 L_si: 0.0181 L_grad: 0.0264 
Train Epoch: 49 [108/684 (16%)] loss: 0.0369 L_si: 0.0110 L_grad: 0.0259 
Train Epoch: 49 [144/684 (21%)] loss: 0.0522 L_si: 0.0196 L_grad: 0.0325 
Train Epoch: 49 [180/684 (26%)] loss: 0.0196 L_si: 0.0022 L_grad: 0.0174 
Train Epoch: 49 [216/684 (32%)] loss: 0.0243 L_si: 0.0045 L_grad: 0.0198 
Train Epoch: 49 [252/684 (37%)] loss: 0.0357 L_si: 0.0083 L_grad: 0.0274 
Train Epoch: 49 [288/684 (42%)] loss: 0.0742 L_si: 0.0349 L_grad: 0.0394 
Train Epoch: 49 [324/684 (47%)] loss: 0.0303 L_si: 0.0070 L_grad: 0.0233 
Train Epoch: 49 [360/684 (53%)] loss: 0.0570 L_si: 0.0203 L_grad: 0.0367 
Train Epoch: 49 [396/684 (58%)] loss: 0.0487 L_si: 0.0173 L_grad: 0.0314 
Train Epoch: 49 [432/684 (63%)] loss: 0.0393 L_si: 0.0108 L_grad: 0.0285 
Train Epoch: 49 [468/684 (68%)] loss: 0.0846 L_si: 0.0402 L_grad: 0.0444 
Train Epoch: 49 [504/684 (74%)] loss: 0.0701 L_si: 0.0275 L_grad: 0.0425 
Train Epoch: 49 [540/684 (79%)] loss: 0.0544 L_si: 0.0232 L_grad: 0.0312 
Train Epoch: 49 [576/684 (84%)] loss: 0.0330 L_si: 0.0117 L_grad: 0.0213 
Train Epoch: 49 [612/684 (89%)] loss: 0.0533 L_si: 0.0231 L_grad: 0.0302 
Train Epoch: 49 [648/684 (95%)] loss: 0.0345 L_si: 0.0077 L_grad: 0.0268 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.020519055426120758, 0.03493136540055275, 0.01800711825489998, 0.009800217114388943, 0.016231000423431396, 0.013310588896274567, 0.020721163600683212, 0.02583959698677063, 0.0308026522397995, 0.01222666073590517, 0.012663153931498528, 0.010543017648160458, 0.011530736461281776, 0.009255954995751381, 0.012134319171309471], 'L_si': [0.0062561556696891785, 0.01402483880519867, 0.004137016832828522, 0.0010697618126869202, 0.0036222711205482483, 0.0020342469215393066, 0.007040813565254211, 0.009602658450603485, 0.011751420795917511, 0.001662909984588623, 0.001752607524394989, 0.0014793425798416138, 0.0015525594353675842, 0.0012247860431671143, 0.0020819157361984253], 'L_grad': [0.01426289975643158, 0.02090652659535408, 0.013870100490748882, 0.008730455301702023, 0.012608729302883148, 0.01127634197473526, 0.013680349104106426, 0.016236938536167145, 0.01905123144388199, 0.010563750751316547, 0.010910546407103539, 0.009063675068318844, 0.009978177025914192, 0.008031168952584267, 0.010052403435111046]}
Train Epoch: 50 [0/684 (0%)] loss: 0.0659 L_si: 0.0212 L_grad: 0.0447 
Train Epoch: 50 [36/684 (5%)] loss: 0.0389 L_si: 0.0113 L_grad: 0.0276 
Train Epoch: 50 [72/684 (11%)] loss: 0.0873 L_si: 0.0323 L_grad: 0.0550 
Train Epoch: 50 [108/684 (16%)] loss: 0.0781 L_si: 0.0343 L_grad: 0.0438 
Train Epoch: 50 [144/684 (21%)] loss: 0.0260 L_si: 0.0045 L_grad: 0.0215 
Train Epoch: 50 [180/684 (26%)] loss: 0.0239 L_si: 0.0038 L_grad: 0.0201 
Train Epoch: 50 [216/684 (32%)] loss: 0.0560 L_si: 0.0235 L_grad: 0.0325 
Train Epoch: 50 [252/684 (37%)] loss: 0.0759 L_si: 0.0340 L_grad: 0.0419 
Train Epoch: 50 [288/684 (42%)] loss: 0.0537 L_si: 0.0244 L_grad: 0.0292 
Train Epoch: 50 [324/684 (47%)] loss: 0.0431 L_si: 0.0113 L_grad: 0.0319 
Train Epoch: 50 [360/684 (53%)] loss: 0.0510 L_si: 0.0202 L_grad: 0.0308 
Train Epoch: 50 [396/684 (58%)] loss: 0.0163 L_si: 0.0020 L_grad: 0.0143 
Train Epoch: 50 [432/684 (63%)] loss: 0.0365 L_si: 0.0092 L_grad: 0.0273 
Train Epoch: 50 [468/684 (68%)] loss: 0.0326 L_si: 0.0100 L_grad: 0.0225 
Train Epoch: 50 [504/684 (74%)] loss: 0.0321 L_si: 0.0094 L_grad: 0.0228 
Train Epoch: 50 [540/684 (79%)] loss: 0.0413 L_si: 0.0119 L_grad: 0.0294 
Train Epoch: 50 [576/684 (84%)] loss: 0.0547 L_si: 0.0200 L_grad: 0.0347 
Train Epoch: 50 [612/684 (89%)] loss: 0.0404 L_si: 0.0153 L_grad: 0.0251 
Train Epoch: 50 [648/684 (95%)] loss: 0.0610 L_si: 0.0339 L_grad: 0.0270 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch050-loss-0.0451.pth.tar ...
all losses in batch in validation:  {'loss': [0.015225132927298546, 0.016901450231671333, 0.009533824399113655, 0.025162000209093094, 0.014148306101560593, 0.009289016015827656, 0.02016369439661503, 0.02469920739531517, 0.009486068040132523, 0.03359806910157204, 0.009409630671143532, 0.012429459020495415, 0.024107037112116814, 0.012242035940289497, 0.011113138869404793], 'L_si': [0.00313616544008255, 0.0037071779370307922, 0.0008766055107116699, 0.00845702737569809, 0.00263165682554245, 0.0013644099235534668, 0.006557844579219818, 0.008970148861408234, 0.0010808035731315613, 0.013985544443130493, 0.0012117624282836914, 0.0022582784295082092, 0.009195975959300995, 0.0014456212520599365, 0.0013568773865699768], 'L_grad': [0.012088967487215996, 0.013194272294640541, 0.008657218888401985, 0.016704972833395004, 0.011516649276018143, 0.007924606092274189, 0.01360584981739521, 0.015729058533906937, 0.008405264467000961, 0.019612524658441544, 0.00819786824285984, 0.010171180590987206, 0.014911061152815819, 0.01079641468822956, 0.009756261482834816]}
Train Epoch: 51 [0/684 (0%)] loss: 0.0595 L_si: 0.0261 L_grad: 0.0333 
Train Epoch: 51 [36/684 (5%)] loss: 0.0353 L_si: 0.0104 L_grad: 0.0250 
Train Epoch: 51 [72/684 (11%)] loss: 0.0244 L_si: 0.0041 L_grad: 0.0202 
Train Epoch: 51 [108/684 (16%)] loss: 0.0819 L_si: 0.0392 L_grad: 0.0427 
Train Epoch: 51 [144/684 (21%)] loss: 0.0532 L_si: 0.0170 L_grad: 0.0362 
Train Epoch: 51 [180/684 (26%)] loss: 0.0516 L_si: 0.0159 L_grad: 0.0357 
Train Epoch: 51 [216/684 (32%)] loss: 0.0537 L_si: 0.0174 L_grad: 0.0364 
Train Epoch: 51 [252/684 (37%)] loss: 0.0565 L_si: 0.0215 L_grad: 0.0351 
Train Epoch: 51 [288/684 (42%)] loss: 0.0405 L_si: 0.0112 L_grad: 0.0294 
Train Epoch: 51 [324/684 (47%)] loss: 0.0366 L_si: 0.0097 L_grad: 0.0269 
Train Epoch: 51 [360/684 (53%)] loss: 0.0238 L_si: 0.0046 L_grad: 0.0193 
Train Epoch: 51 [396/684 (58%)] loss: 0.0868 L_si: 0.0328 L_grad: 0.0540 
Train Epoch: 51 [432/684 (63%)] loss: 0.0215 L_si: 0.0051 L_grad: 0.0165 
Train Epoch: 51 [468/684 (68%)] loss: 0.0262 L_si: 0.0058 L_grad: 0.0204 
Train Epoch: 51 [504/684 (74%)] loss: 0.0214 L_si: 0.0042 L_grad: 0.0171 
Train Epoch: 51 [540/684 (79%)] loss: 0.0328 L_si: 0.0075 L_grad: 0.0253 
Train Epoch: 51 [576/684 (84%)] loss: 0.0196 L_si: 0.0032 L_grad: 0.0164 
Train Epoch: 51 [612/684 (89%)] loss: 0.0315 L_si: 0.0097 L_grad: 0.0218 
Train Epoch: 51 [648/684 (95%)] loss: 0.0306 L_si: 0.0075 L_grad: 0.0231 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.021784823387861252, 0.009098351001739502, 0.02628851681947708, 0.014602893963456154, 0.00983911007642746, 0.010691499337553978, 0.009165624156594276, 0.009888854809105396, 0.036862920969724655, 0.009495965205132961, 0.02407166361808777, 0.009157638996839523, 0.01859252154827118, 0.019336191937327385, 0.009537745267152786], 'L_si': [0.005416639149188995, 0.0008196532726287842, 0.009820692241191864, 0.0031289011240005493, 0.0011942461133003235, 0.00134335458278656, 0.0008353143930435181, 0.0012963935732841492, 0.014816120266914368, 0.0012620314955711365, 0.008940301835536957, 0.001170724630355835, 0.0062450021505355835, 0.006148874759674072, 0.001186870038509369], 'L_grad': [0.016368184238672256, 0.008278697729110718, 0.016467824578285217, 0.011473992839455605, 0.008644863963127136, 0.009348144754767418, 0.008330309763550758, 0.008592461235821247, 0.022046800702810287, 0.008233933709561825, 0.015131362713873386, 0.007986914366483688, 0.012347519397735596, 0.013187317177653313, 0.008350875228643417]}
Train Epoch: 52 [0/684 (0%)] loss: 0.0441 L_si: 0.0166 L_grad: 0.0275 
Train Epoch: 52 [36/684 (5%)] loss: 0.0741 L_si: 0.0360 L_grad: 0.0381 
Train Epoch: 52 [72/684 (11%)] loss: 0.0276 L_si: 0.0067 L_grad: 0.0208 
Train Epoch: 52 [108/684 (16%)] loss: 0.0403 L_si: 0.0099 L_grad: 0.0304 
Train Epoch: 52 [144/684 (21%)] loss: 0.0325 L_si: 0.0097 L_grad: 0.0228 
Train Epoch: 52 [180/684 (26%)] loss: 0.0258 L_si: 0.0054 L_grad: 0.0205 
Train Epoch: 52 [216/684 (32%)] loss: 0.0508 L_si: 0.0187 L_grad: 0.0321 
Train Epoch: 52 [252/684 (37%)] loss: 0.0342 L_si: 0.0087 L_grad: 0.0255 
Train Epoch: 52 [288/684 (42%)] loss: 0.0453 L_si: 0.0195 L_grad: 0.0258 
Train Epoch: 52 [324/684 (47%)] loss: 0.0728 L_si: 0.0301 L_grad: 0.0427 
Train Epoch: 52 [360/684 (53%)] loss: 0.0458 L_si: 0.0151 L_grad: 0.0307 
Train Epoch: 52 [396/684 (58%)] loss: 0.0564 L_si: 0.0187 L_grad: 0.0378 
Train Epoch: 52 [432/684 (63%)] loss: 0.0252 L_si: 0.0052 L_grad: 0.0200 
Train Epoch: 52 [468/684 (68%)] loss: 0.0477 L_si: 0.0212 L_grad: 0.0266 
Train Epoch: 52 [504/684 (74%)] loss: 0.0754 L_si: 0.0254 L_grad: 0.0500 
Train Epoch: 52 [540/684 (79%)] loss: 0.0785 L_si: 0.0380 L_grad: 0.0405 
Train Epoch: 52 [576/684 (84%)] loss: 0.0336 L_si: 0.0075 L_grad: 0.0261 
Train Epoch: 52 [612/684 (89%)] loss: 0.0458 L_si: 0.0160 L_grad: 0.0298 
Train Epoch: 52 [648/684 (95%)] loss: 0.0376 L_si: 0.0096 L_grad: 0.0280 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009284569881856441, 0.03325716406106949, 0.009192952886223793, 0.010636689141392708, 0.02356419712305069, 0.008010495454072952, 0.030539579689502716, 0.018653403967618942, 0.01497548259794712, 0.015551852062344551, 0.011883800849318504, 0.020658455789089203, 0.011321288533508778, 0.010841703042387962, 0.009302858263254166], 'L_si': [0.0009144246578216553, 0.013814181089401245, 0.0009634792804718018, 0.0013472512364387512, 0.00887461006641388, 0.00106058269739151, 0.011216916143894196, 0.006012044847011566, 0.003159366548061371, 0.0036470964550971985, 0.0015882551670074463, 0.006493657827377319, 0.0016963332891464233, 0.0017483457922935486, 0.0008308067917823792], 'L_grad': [0.008370145224034786, 0.019442982971668243, 0.008229473605751991, 0.009289437904953957, 0.014689587987959385, 0.006949912291020155, 0.01932266354560852, 0.01264136005192995, 0.01181611604988575, 0.011904755607247353, 0.010295545682311058, 0.014164797961711884, 0.009624955244362354, 0.009093357250094414, 0.008472051471471786]}
Train Epoch: 53 [0/684 (0%)] loss: 0.0407 L_si: 0.0141 L_grad: 0.0266 
Train Epoch: 53 [36/684 (5%)] loss: 0.0297 L_si: 0.0073 L_grad: 0.0224 
Train Epoch: 53 [72/684 (11%)] loss: 0.0315 L_si: 0.0088 L_grad: 0.0227 
Train Epoch: 53 [108/684 (16%)] loss: 0.0359 L_si: 0.0097 L_grad: 0.0262 
Train Epoch: 53 [144/684 (21%)] loss: 0.0394 L_si: 0.0120 L_grad: 0.0274 
Train Epoch: 53 [180/684 (26%)] loss: 0.0179 L_si: 0.0031 L_grad: 0.0148 
Train Epoch: 53 [216/684 (32%)] loss: 0.0246 L_si: 0.0069 L_grad: 0.0177 
Train Epoch: 53 [252/684 (37%)] loss: 0.0973 L_si: 0.0431 L_grad: 0.0542 
Train Epoch: 53 [288/684 (42%)] loss: 0.0670 L_si: 0.0271 L_grad: 0.0399 
Train Epoch: 53 [324/684 (47%)] loss: 0.0472 L_si: 0.0162 L_grad: 0.0310 
Train Epoch: 53 [360/684 (53%)] loss: 0.0625 L_si: 0.0218 L_grad: 0.0407 
Train Epoch: 53 [396/684 (58%)] loss: 0.0827 L_si: 0.0407 L_grad: 0.0419 
Train Epoch: 53 [432/684 (63%)] loss: 0.0273 L_si: 0.0070 L_grad: 0.0202 
Train Epoch: 53 [468/684 (68%)] loss: 0.0531 L_si: 0.0192 L_grad: 0.0339 
Train Epoch: 53 [504/684 (74%)] loss: 0.0488 L_si: 0.0218 L_grad: 0.0270 
Train Epoch: 53 [540/684 (79%)] loss: 0.0627 L_si: 0.0173 L_grad: 0.0454 
Train Epoch: 53 [576/684 (84%)] loss: 0.0370 L_si: 0.0153 L_grad: 0.0217 
Train Epoch: 53 [612/684 (89%)] loss: 0.0364 L_si: 0.0103 L_grad: 0.0261 
Train Epoch: 53 [648/684 (95%)] loss: 0.0496 L_si: 0.0188 L_grad: 0.0308 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009310180321335793, 0.02395283617079258, 0.02576468512415886, 0.009615073911845684, 0.028147293254733086, 0.009095681831240654, 0.015509102493524551, 0.008382379077374935, 0.00993341114372015, 0.01656585931777954, 0.010194379836320877, 0.03925955295562744, 0.011797094717621803, 0.01081016007810831, 0.010549025610089302], 'L_si': [0.001247316598892212, 0.00869731605052948, 0.009323015809059143, 0.0013713687658309937, 0.010966174304485321, 0.000851161777973175, 0.0035457760095596313, 0.0008589327335357666, 0.0010031014680862427, 0.003414541482925415, 0.0015097856521606445, 0.016446858644485474, 0.0013501346111297607, 0.0015185847878456116, 0.0014104247093200684], 'L_grad': [0.00806286372244358, 0.0152555201202631, 0.016441669315099716, 0.00824370514601469, 0.017181118950247765, 0.008244520053267479, 0.01196332648396492, 0.0075234463438391685, 0.008930309675633907, 0.013151317834854126, 0.008684594184160233, 0.02281269244849682, 0.010446960106492043, 0.009291575290262699, 0.009138600900769234]}
Train Epoch: 54 [0/684 (0%)] loss: 0.0229 L_si: 0.0035 L_grad: 0.0194 
Train Epoch: 54 [36/684 (5%)] loss: 0.0499 L_si: 0.0185 L_grad: 0.0313 
Train Epoch: 54 [72/684 (11%)] loss: 0.0321 L_si: 0.0128 L_grad: 0.0193 
Train Epoch: 54 [108/684 (16%)] loss: 0.0353 L_si: 0.0102 L_grad: 0.0251 
Train Epoch: 54 [144/684 (21%)] loss: 0.0353 L_si: 0.0097 L_grad: 0.0256 
Train Epoch: 54 [180/684 (26%)] loss: 0.0497 L_si: 0.0186 L_grad: 0.0311 
Train Epoch: 54 [216/684 (32%)] loss: 0.0260 L_si: 0.0059 L_grad: 0.0201 
Train Epoch: 54 [252/684 (37%)] loss: 0.0710 L_si: 0.0342 L_grad: 0.0368 
Train Epoch: 54 [288/684 (42%)] loss: 0.0408 L_si: 0.0130 L_grad: 0.0278 
Train Epoch: 54 [324/684 (47%)] loss: 0.0430 L_si: 0.0148 L_grad: 0.0282 
Train Epoch: 54 [360/684 (53%)] loss: 0.0251 L_si: 0.0061 L_grad: 0.0190 
Train Epoch: 54 [396/684 (58%)] loss: 0.0405 L_si: 0.0113 L_grad: 0.0292 
Train Epoch: 54 [432/684 (63%)] loss: 0.0296 L_si: 0.0088 L_grad: 0.0208 
Train Epoch: 54 [468/684 (68%)] loss: 0.0375 L_si: 0.0092 L_grad: 0.0283 
Train Epoch: 54 [504/684 (74%)] loss: 0.0291 L_si: 0.0074 L_grad: 0.0218 
Train Epoch: 54 [540/684 (79%)] loss: 0.0249 L_si: 0.0051 L_grad: 0.0198 
Train Epoch: 54 [576/684 (84%)] loss: 0.0309 L_si: 0.0111 L_grad: 0.0199 
Train Epoch: 54 [612/684 (89%)] loss: 0.0365 L_si: 0.0095 L_grad: 0.0270 
Train Epoch: 54 [648/684 (95%)] loss: 0.0515 L_si: 0.0192 L_grad: 0.0323 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.02693740837275982, 0.0103963203728199, 0.008377259597182274, 0.011032266542315483, 0.01908847875893116, 0.01555006392300129, 0.008054482750594616, 0.0422322079539299, 0.009838019497692585, 0.01576855592429638, 0.008259654976427555, 0.010654247365891933, 0.011095146648585796, 0.016273558139801025, 0.02435487136244774], 'L_si': [0.009866952896118164, 0.0010872259736061096, 0.0007340610027313232, 0.0019215196371078491, 0.005948908627033234, 0.003782212734222412, 0.0008033886551856995, 0.018723510205745697, 0.0012554675340652466, 0.0033748745918273926, 0.0007898733019828796, 0.0011732280254364014, 0.0014550015330314636, 0.0034920424222946167, 0.008997052907943726], 'L_grad': [0.017070455476641655, 0.009309094399213791, 0.007643198128789663, 0.009110746905207634, 0.013139570131897926, 0.011767851188778877, 0.0072510940954089165, 0.023508699610829353, 0.008582551963627338, 0.012393681332468987, 0.0074697816744446754, 0.009481019340455532, 0.009640145115554333, 0.012781515717506409, 0.015357818454504013]}
Train Epoch: 55 [0/684 (0%)] loss: 0.0275 L_si: 0.0053 L_grad: 0.0221 
Train Epoch: 55 [36/684 (5%)] loss: 0.0561 L_si: 0.0237 L_grad: 0.0324 
Train Epoch: 55 [72/684 (11%)] loss: 0.0730 L_si: 0.0339 L_grad: 0.0391 
Train Epoch: 55 [108/684 (16%)] loss: 0.0414 L_si: 0.0145 L_grad: 0.0268 
Train Epoch: 55 [144/684 (21%)] loss: 0.0214 L_si: 0.0032 L_grad: 0.0183 
Train Epoch: 55 [180/684 (26%)] loss: 0.0383 L_si: 0.0167 L_grad: 0.0216 
Train Epoch: 55 [216/684 (32%)] loss: 0.0486 L_si: 0.0139 L_grad: 0.0347 
Train Epoch: 55 [252/684 (37%)] loss: 0.0460 L_si: 0.0162 L_grad: 0.0298 
Train Epoch: 55 [288/684 (42%)] loss: 0.0559 L_si: 0.0239 L_grad: 0.0320 
Train Epoch: 55 [324/684 (47%)] loss: 0.0459 L_si: 0.0149 L_grad: 0.0310 
Train Epoch: 55 [360/684 (53%)] loss: 0.0742 L_si: 0.0308 L_grad: 0.0434 
Train Epoch: 55 [396/684 (58%)] loss: 0.0460 L_si: 0.0123 L_grad: 0.0337 
Train Epoch: 55 [432/684 (63%)] loss: 0.0230 L_si: 0.0040 L_grad: 0.0190 
Train Epoch: 55 [468/684 (68%)] loss: 0.0511 L_si: 0.0209 L_grad: 0.0302 
Train Epoch: 55 [504/684 (74%)] loss: 0.0495 L_si: 0.0176 L_grad: 0.0319 
Train Epoch: 55 [540/684 (79%)] loss: 0.0350 L_si: 0.0103 L_grad: 0.0246 
Train Epoch: 55 [576/684 (84%)] loss: 0.0759 L_si: 0.0272 L_grad: 0.0487 
Train Epoch: 55 [612/684 (89%)] loss: 0.0636 L_si: 0.0282 L_grad: 0.0354 
Train Epoch: 55 [648/684 (95%)] loss: 0.0279 L_si: 0.0046 L_grad: 0.0233 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.023773131892085075, 0.008946713991463184, 0.01115763932466507, 0.023564033210277557, 0.019644197076559067, 0.008972777053713799, 0.008919933810830116, 0.02540285512804985, 0.012237311340868473, 0.02435210719704628, 0.018427658826112747, 0.024676650762557983, 0.009130313992500305, 0.008998211473226547, 0.011122209019958973], 'L_si': [0.009044647216796875, 0.0008644461631774902, 0.001555509865283966, 0.0061339884996414185, 0.006066255271434784, 0.0008985549211502075, 0.0010176822543144226, 0.008262209594249725, 0.0020096823573112488, 0.008837595582008362, 0.006181016564369202, 0.008957378566265106, 0.0010912269353866577, 0.0011660605669021606, 0.0015266835689544678], 'L_grad': [0.0147284846752882, 0.008082267828285694, 0.009602129459381104, 0.01743004471063614, 0.013577940873801708, 0.008074222132563591, 0.007902251556515694, 0.017140645533800125, 0.010227628983557224, 0.015514510683715343, 0.012246642261743546, 0.015719272196292877, 0.008039087057113647, 0.007832150906324387, 0.009595525451004505]}
Train Epoch: 56 [0/684 (0%)] loss: 0.0531 L_si: 0.0194 L_grad: 0.0337 
Train Epoch: 56 [36/684 (5%)] loss: 0.0351 L_si: 0.0089 L_grad: 0.0262 
Train Epoch: 56 [72/684 (11%)] loss: 0.0596 L_si: 0.0198 L_grad: 0.0399 
Train Epoch: 56 [108/684 (16%)] loss: 0.0316 L_si: 0.0078 L_grad: 0.0239 
Train Epoch: 56 [144/684 (21%)] loss: 0.0498 L_si: 0.0205 L_grad: 0.0293 
Train Epoch: 56 [180/684 (26%)] loss: 0.0455 L_si: 0.0165 L_grad: 0.0289 
Train Epoch: 56 [216/684 (32%)] loss: 0.0628 L_si: 0.0277 L_grad: 0.0350 
Train Epoch: 56 [252/684 (37%)] loss: 0.0676 L_si: 0.0274 L_grad: 0.0402 
Train Epoch: 56 [288/684 (42%)] loss: 0.0558 L_si: 0.0196 L_grad: 0.0363 
Train Epoch: 56 [324/684 (47%)] loss: 0.0520 L_si: 0.0167 L_grad: 0.0353 
Train Epoch: 56 [360/684 (53%)] loss: 0.0423 L_si: 0.0117 L_grad: 0.0306 
Train Epoch: 56 [396/684 (58%)] loss: 0.0768 L_si: 0.0393 L_grad: 0.0376 
Train Epoch: 56 [432/684 (63%)] loss: 0.0680 L_si: 0.0265 L_grad: 0.0414 
Train Epoch: 56 [468/684 (68%)] loss: 0.0296 L_si: 0.0069 L_grad: 0.0227 
Train Epoch: 56 [504/684 (74%)] loss: 0.0450 L_si: 0.0200 L_grad: 0.0249 
Train Epoch: 56 [540/684 (79%)] loss: 0.0432 L_si: 0.0171 L_grad: 0.0261 
Train Epoch: 56 [576/684 (84%)] loss: 0.0885 L_si: 0.0415 L_grad: 0.0470 
Train Epoch: 56 [612/684 (89%)] loss: 0.0521 L_si: 0.0174 L_grad: 0.0347 
Train Epoch: 56 [648/684 (95%)] loss: 0.0487 L_si: 0.0154 L_grad: 0.0333 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010055337101221085, 0.00905925314873457, 0.01998135820031166, 0.03374337777495384, 0.009153209626674652, 0.010144137777388096, 0.01736282743513584, 0.009650463238358498, 0.023715022951364517, 0.017777681350708008, 0.010760858654975891, 0.008936027064919472, 0.031209789216518402, 0.018982620909810066, 0.007981332018971443], 'L_si': [0.0010755807161331177, 0.0014106929302215576, 0.006101325154304504, 0.013996757566928864, 0.0008206963539123535, 0.0011242851614952087, 0.003878258168697357, 0.0009663254022598267, 0.008787423372268677, 0.004161275923252106, 0.0017034932971000671, 0.001055501401424408, 0.011353053152561188, 0.006147727370262146, 0.0009004399180412292], 'L_grad': [0.008979756385087967, 0.007648560218513012, 0.013880032114684582, 0.01974662020802498, 0.008332513272762299, 0.009019852615892887, 0.013484569266438484, 0.008684137836098671, 0.014927598647773266, 0.013616406358778477, 0.009057365357875824, 0.007880525663495064, 0.019856736063957214, 0.01283489353954792, 0.007080892566591501]}
Train Epoch: 57 [0/684 (0%)] loss: 0.0424 L_si: 0.0130 L_grad: 0.0294 
Train Epoch: 57 [36/684 (5%)] loss: 0.1102 L_si: 0.0589 L_grad: 0.0512 
Train Epoch: 57 [72/684 (11%)] loss: 0.0197 L_si: 0.0053 L_grad: 0.0145 
Train Epoch: 57 [108/684 (16%)] loss: 0.0367 L_si: 0.0111 L_grad: 0.0256 
Train Epoch: 57 [144/684 (21%)] loss: 0.0539 L_si: 0.0266 L_grad: 0.0274 
Train Epoch: 57 [180/684 (26%)] loss: 0.0430 L_si: 0.0123 L_grad: 0.0307 
Train Epoch: 57 [216/684 (32%)] loss: 0.0246 L_si: 0.0061 L_grad: 0.0185 
Train Epoch: 57 [252/684 (37%)] loss: 0.0380 L_si: 0.0113 L_grad: 0.0267 
Train Epoch: 57 [288/684 (42%)] loss: 0.0366 L_si: 0.0111 L_grad: 0.0255 
Train Epoch: 57 [324/684 (47%)] loss: 0.0319 L_si: 0.0079 L_grad: 0.0241 
Train Epoch: 57 [360/684 (53%)] loss: 0.0503 L_si: 0.0146 L_grad: 0.0357 
Train Epoch: 57 [396/684 (58%)] loss: 0.0277 L_si: 0.0066 L_grad: 0.0211 
Train Epoch: 57 [432/684 (63%)] loss: 0.0495 L_si: 0.0195 L_grad: 0.0301 
Train Epoch: 57 [468/684 (68%)] loss: 0.0457 L_si: 0.0116 L_grad: 0.0341 
Train Epoch: 57 [504/684 (74%)] loss: 0.0438 L_si: 0.0163 L_grad: 0.0274 
Train Epoch: 57 [540/684 (79%)] loss: 0.0804 L_si: 0.0345 L_grad: 0.0460 
Train Epoch: 57 [576/684 (84%)] loss: 0.0463 L_si: 0.0173 L_grad: 0.0290 
Train Epoch: 57 [612/684 (89%)] loss: 0.0207 L_si: 0.0038 L_grad: 0.0170 
Train Epoch: 57 [648/684 (95%)] loss: 0.0451 L_si: 0.0146 L_grad: 0.0305 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.017934530973434448, 0.025527656078338623, 0.019163358956575394, 0.009669981896877289, 0.040633440017700195, 0.009586583822965622, 0.010217725299298763, 0.00978054478764534, 0.014883767813444138, 0.026020748540759087, 0.008794642984867096, 0.00837064441293478, 0.018600858747959137, 0.010098151862621307, 0.007984667085111141], 'L_si': [0.004157721996307373, 0.009707652032375336, 0.006070449948310852, 0.001376233994960785, 0.017430126667022705, 0.001040920615196228, 0.0011436119675636292, 0.0010164454579353333, 0.0032855644822120667, 0.008621342480182648, 0.0007738247513771057, 0.000883743166923523, 0.005907870829105377, 0.0010173171758651733, 0.0008696243166923523], 'L_grad': [0.013776808977127075, 0.015820004045963287, 0.013092909008264542, 0.008293747901916504, 0.02320331521332264, 0.008545663207769394, 0.009074113331735134, 0.008764099329710007, 0.011598203331232071, 0.01739940606057644, 0.00802081823348999, 0.007486901246011257, 0.01269298791885376, 0.009080834686756134, 0.007115042768418789]}
Train Epoch: 58 [0/684 (0%)] loss: 0.0364 L_si: 0.0148 L_grad: 0.0216 
Train Epoch: 58 [36/684 (5%)] loss: 0.0313 L_si: 0.0087 L_grad: 0.0226 
Train Epoch: 58 [72/684 (11%)] loss: 0.0385 L_si: 0.0144 L_grad: 0.0240 
Train Epoch: 58 [108/684 (16%)] loss: 0.0737 L_si: 0.0290 L_grad: 0.0448 
Train Epoch: 58 [144/684 (21%)] loss: 0.0404 L_si: 0.0098 L_grad: 0.0305 
Train Epoch: 58 [180/684 (26%)] loss: 0.0471 L_si: 0.0163 L_grad: 0.0309 
Train Epoch: 58 [216/684 (32%)] loss: 0.0561 L_si: 0.0233 L_grad: 0.0328 
Train Epoch: 58 [252/684 (37%)] loss: 0.0290 L_si: 0.0062 L_grad: 0.0227 
Train Epoch: 58 [288/684 (42%)] loss: 0.0570 L_si: 0.0267 L_grad: 0.0303 
Train Epoch: 58 [324/684 (47%)] loss: 0.0427 L_si: 0.0175 L_grad: 0.0252 
Train Epoch: 58 [360/684 (53%)] loss: 0.0627 L_si: 0.0319 L_grad: 0.0309 
Train Epoch: 58 [396/684 (58%)] loss: 0.0398 L_si: 0.0101 L_grad: 0.0298 
Train Epoch: 58 [432/684 (63%)] loss: 0.0515 L_si: 0.0210 L_grad: 0.0305 
Train Epoch: 58 [468/684 (68%)] loss: 0.0495 L_si: 0.0194 L_grad: 0.0301 
Train Epoch: 58 [504/684 (74%)] loss: 0.0255 L_si: 0.0056 L_grad: 0.0200 
Train Epoch: 58 [540/684 (79%)] loss: 0.0356 L_si: 0.0116 L_grad: 0.0241 
Train Epoch: 58 [576/684 (84%)] loss: 0.0229 L_si: 0.0066 L_grad: 0.0164 
Train Epoch: 58 [612/684 (89%)] loss: 0.0559 L_si: 0.0217 L_grad: 0.0342 
Train Epoch: 58 [648/684 (95%)] loss: 0.0388 L_si: 0.0133 L_grad: 0.0255 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.025859234854578972, 0.008969128131866455, 0.009121919050812721, 0.018919965252280235, 0.01674710586667061, 0.012421240098774433, 0.015852345153689384, 0.016949016600847244, 0.03278617933392525, 0.010639062151312828, 0.023872917518019676, 0.009097622707486153, 0.009786710143089294, 0.0084491316229105, 0.018958624452352524], 'L_si': [0.009349159896373749, 0.000844128429889679, 0.0012209117412567139, 0.005962491035461426, 0.0037891417741775513, 0.001833312213420868, 0.003198981285095215, 0.0036662518978118896, 0.013825677335262299, 0.0015665069222450256, 0.009111694991588593, 0.0007417798042297363, 0.0012747421860694885, 0.0009845122694969177, 0.005982041358947754], 'L_grad': [0.016510074958205223, 0.008124999701976776, 0.007901007309556007, 0.01295747421681881, 0.012957964092493057, 0.010587927885353565, 0.01265336386859417, 0.013282764703035355, 0.01896050199866295, 0.009072555229067802, 0.014761222526431084, 0.008355842903256416, 0.008511967957019806, 0.0074646188877522945, 0.01297658309340477]}
Train Epoch: 59 [0/684 (0%)] loss: 0.0432 L_si: 0.0154 L_grad: 0.0279 
Train Epoch: 59 [36/684 (5%)] loss: 0.0510 L_si: 0.0191 L_grad: 0.0319 
Train Epoch: 59 [72/684 (11%)] loss: 0.0543 L_si: 0.0178 L_grad: 0.0365 
Train Epoch: 59 [108/684 (16%)] loss: 0.0544 L_si: 0.0236 L_grad: 0.0307 
Train Epoch: 59 [144/684 (21%)] loss: 0.0521 L_si: 0.0184 L_grad: 0.0336 
Train Epoch: 59 [180/684 (26%)] loss: 0.0475 L_si: 0.0143 L_grad: 0.0332 
Train Epoch: 59 [216/684 (32%)] loss: 0.0280 L_si: 0.0066 L_grad: 0.0214 
Train Epoch: 59 [252/684 (37%)] loss: 0.0413 L_si: 0.0182 L_grad: 0.0231 
Train Epoch: 59 [288/684 (42%)] loss: 0.0527 L_si: 0.0207 L_grad: 0.0320 
Train Epoch: 59 [324/684 (47%)] loss: 0.0320 L_si: 0.0091 L_grad: 0.0229 
Train Epoch: 59 [360/684 (53%)] loss: 0.0282 L_si: 0.0066 L_grad: 0.0216 
Train Epoch: 59 [396/684 (58%)] loss: 0.0337 L_si: 0.0080 L_grad: 0.0256 
Train Epoch: 59 [432/684 (63%)] loss: 0.0359 L_si: 0.0105 L_grad: 0.0253 
Train Epoch: 59 [468/684 (68%)] loss: 0.0587 L_si: 0.0292 L_grad: 0.0295 
Train Epoch: 59 [504/684 (74%)] loss: 0.0429 L_si: 0.0177 L_grad: 0.0252 
Train Epoch: 59 [540/684 (79%)] loss: 0.0352 L_si: 0.0111 L_grad: 0.0241 
Train Epoch: 59 [576/684 (84%)] loss: 0.0327 L_si: 0.0079 L_grad: 0.0248 
Train Epoch: 59 [612/684 (89%)] loss: 0.0623 L_si: 0.0277 L_grad: 0.0346 
Train Epoch: 59 [648/684 (95%)] loss: 0.0527 L_si: 0.0211 L_grad: 0.0316 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010949289426207542, 0.035029273480176926, 0.010287711396813393, 0.010372494347393513, 0.02388385869562626, 0.008451391011476517, 0.024267073720693588, 0.014857202768325806, 0.01847882941365242, 0.01568363793194294, 0.01092761754989624, 0.01128443144261837, 0.018473302945494652, 0.010354145430028439, 0.014612577855587006], 'L_si': [0.0013071298599243164, 0.014385566115379333, 0.0014168918132781982, 0.0015865638852119446, 0.00881175696849823, 0.0009846314787864685, 0.009008370339870453, 0.003318503499031067, 0.0059584155678749084, 0.0030881687998771667, 0.0014834403991699219, 0.0012339651584625244, 0.006033092737197876, 0.0014790073037147522, 0.003078453242778778], 'L_grad': [0.009642159566283226, 0.020643707364797592, 0.008870819583535194, 0.008785930462181568, 0.015072101727128029, 0.0074667599983513355, 0.015258703380823135, 0.011538699269294739, 0.012520413845777512, 0.012595469132065773, 0.009444177150726318, 0.010050466284155846, 0.012440210208296776, 0.008875138126313686, 0.011534124612808228]}
Train Epoch: 60 [0/684 (0%)] loss: 0.0294 L_si: 0.0077 L_grad: 0.0217 
Train Epoch: 60 [36/684 (5%)] loss: 0.0533 L_si: 0.0225 L_grad: 0.0308 
Train Epoch: 60 [72/684 (11%)] loss: 0.0405 L_si: 0.0116 L_grad: 0.0289 
Train Epoch: 60 [108/684 (16%)] loss: 0.0747 L_si: 0.0322 L_grad: 0.0425 
Train Epoch: 60 [144/684 (21%)] loss: 0.0491 L_si: 0.0225 L_grad: 0.0266 
Train Epoch: 60 [180/684 (26%)] loss: 0.0332 L_si: 0.0124 L_grad: 0.0208 
Train Epoch: 60 [216/684 (32%)] loss: 0.0634 L_si: 0.0269 L_grad: 0.0366 
Train Epoch: 60 [252/684 (37%)] loss: 0.0195 L_si: 0.0030 L_grad: 0.0165 
Train Epoch: 60 [288/684 (42%)] loss: 0.0235 L_si: 0.0039 L_grad: 0.0196 
Train Epoch: 60 [324/684 (47%)] loss: 0.0229 L_si: 0.0043 L_grad: 0.0185 
Train Epoch: 60 [360/684 (53%)] loss: 0.0650 L_si: 0.0267 L_grad: 0.0383 
Train Epoch: 60 [396/684 (58%)] loss: 0.0385 L_si: 0.0144 L_grad: 0.0241 
Train Epoch: 60 [432/684 (63%)] loss: 0.0458 L_si: 0.0155 L_grad: 0.0303 
Train Epoch: 60 [468/684 (68%)] loss: 0.0483 L_si: 0.0150 L_grad: 0.0333 
Train Epoch: 60 [504/684 (74%)] loss: 0.0262 L_si: 0.0050 L_grad: 0.0213 
Train Epoch: 60 [540/684 (79%)] loss: 0.0367 L_si: 0.0105 L_grad: 0.0262 
Train Epoch: 60 [576/684 (84%)] loss: 0.0494 L_si: 0.0220 L_grad: 0.0274 
Train Epoch: 60 [612/684 (89%)] loss: 0.0353 L_si: 0.0158 L_grad: 0.0195 
Train Epoch: 60 [648/684 (95%)] loss: 0.0504 L_si: 0.0172 L_grad: 0.0332 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch060-loss-0.0445.pth.tar ...
New Learning Rate: 0.000075
all losses in batch in validation:  {'loss': [0.009368173778057098, 0.017764439806342125, 0.010549245402216911, 0.016090957447886467, 0.009564654901623726, 0.01813865825533867, 0.044522929936647415, 0.01856766641139984, 0.0194636769592762, 0.009468188509345055, 0.010401180014014244, 0.010435957461595535, 0.02681000903248787, 0.008321426808834076, 0.008540456183254719], 'L_si': [0.001005716621875763, 0.004060216248035431, 0.0011739581823349, 0.0032196417450904846, 0.0011225640773773193, 0.0062688663601875305, 0.018919549882411957, 0.006090141832828522, 0.00603320449590683, 0.0012199357151985168, 0.0011289119720458984, 0.0015940666198730469, 0.009874150156974792, 0.0008846074342727661, 0.0009140968322753906], 'L_grad': [0.008362457156181335, 0.013704223558306694, 0.009375287219882011, 0.012871315702795982, 0.008442090824246407, 0.011869792826473713, 0.02560338005423546, 0.012477523647248745, 0.013430471532046795, 0.008248252794146538, 0.009272268041968346, 0.008841890841722488, 0.016935858875513077, 0.00743681937456131, 0.007626359350979328]}
Train Epoch: 61 [0/684 (0%)] loss: 0.0603 L_si: 0.0303 L_grad: 0.0300 
Train Epoch: 61 [36/684 (5%)] loss: 0.0312 L_si: 0.0086 L_grad: 0.0226 
Train Epoch: 61 [72/684 (11%)] loss: 0.0578 L_si: 0.0238 L_grad: 0.0340 
Train Epoch: 61 [108/684 (16%)] loss: 0.0455 L_si: 0.0166 L_grad: 0.0288 
Train Epoch: 61 [144/684 (21%)] loss: 0.0409 L_si: 0.0159 L_grad: 0.0249 
Train Epoch: 61 [180/684 (26%)] loss: 0.0343 L_si: 0.0095 L_grad: 0.0248 
Train Epoch: 61 [216/684 (32%)] loss: 0.0423 L_si: 0.0101 L_grad: 0.0322 
Train Epoch: 61 [252/684 (37%)] loss: 0.0389 L_si: 0.0116 L_grad: 0.0273 
Train Epoch: 61 [288/684 (42%)] loss: 0.0372 L_si: 0.0111 L_grad: 0.0261 
Train Epoch: 61 [324/684 (47%)] loss: 0.0494 L_si: 0.0230 L_grad: 0.0264 
Train Epoch: 61 [360/684 (53%)] loss: 0.0652 L_si: 0.0249 L_grad: 0.0403 
Train Epoch: 61 [396/684 (58%)] loss: 0.0504 L_si: 0.0186 L_grad: 0.0318 
Train Epoch: 61 [432/684 (63%)] loss: 0.0528 L_si: 0.0196 L_grad: 0.0331 
Train Epoch: 61 [468/684 (68%)] loss: 0.0557 L_si: 0.0272 L_grad: 0.0285 
Train Epoch: 61 [504/684 (74%)] loss: 0.0472 L_si: 0.0171 L_grad: 0.0301 
Train Epoch: 61 [540/684 (79%)] loss: 0.0214 L_si: 0.0035 L_grad: 0.0180 
Train Epoch: 61 [576/684 (84%)] loss: 0.0578 L_si: 0.0195 L_grad: 0.0383 
Train Epoch: 61 [612/684 (89%)] loss: 0.0294 L_si: 0.0090 L_grad: 0.0204 
Train Epoch: 61 [648/684 (95%)] loss: 0.0241 L_si: 0.0051 L_grad: 0.0190 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.029171859845519066, 0.0098183648660779, 0.03540351241827011, 0.01551825925707817, 0.016191406175494194, 0.028267566114664078, 0.02489631250500679, 0.009612200781702995, 0.008799348026514053, 0.009480895474553108, 0.012333713471889496, 0.009889679029583931, 0.009326867759227753, 0.0093621164560318, 0.009614203125238419], 'L_si': [0.011312820017337799, 0.001137860119342804, 0.014295056462287903, 0.0033175647258758545, 0.00344289094209671, 0.010929562151432037, 0.009336620569229126, 0.0013505220413208008, 0.0008817762136459351, 0.0011338070034980774, 0.002061225473880768, 0.0014006271958351135, 0.0010738745331764221, 0.0008593946695327759, 0.001127101480960846], 'L_grad': [0.017859039828181267, 0.008680504746735096, 0.021108455955982208, 0.012200694531202316, 0.012748515233397484, 0.01733800396323204, 0.015559691935777664, 0.008261678740382195, 0.007917571812868118, 0.00834708847105503, 0.010272487998008728, 0.008489051833748817, 0.00825299322605133, 0.008502721786499023, 0.008487101644277573]}
Train Epoch: 62 [0/684 (0%)] loss: 0.0540 L_si: 0.0173 L_grad: 0.0366 
Train Epoch: 62 [36/684 (5%)] loss: 0.0598 L_si: 0.0247 L_grad: 0.0351 
Train Epoch: 62 [72/684 (11%)] loss: 0.0385 L_si: 0.0153 L_grad: 0.0232 
Train Epoch: 62 [108/684 (16%)] loss: 0.0579 L_si: 0.0273 L_grad: 0.0306 
Train Epoch: 62 [144/684 (21%)] loss: 0.0695 L_si: 0.0287 L_grad: 0.0408 
Train Epoch: 62 [180/684 (26%)] loss: 0.0777 L_si: 0.0388 L_grad: 0.0389 
Train Epoch: 62 [216/684 (32%)] loss: 0.0398 L_si: 0.0168 L_grad: 0.0230 
Train Epoch: 62 [252/684 (37%)] loss: 0.0278 L_si: 0.0051 L_grad: 0.0227 
Train Epoch: 62 [288/684 (42%)] loss: 0.0686 L_si: 0.0244 L_grad: 0.0442 
Train Epoch: 62 [324/684 (47%)] loss: 0.0575 L_si: 0.0212 L_grad: 0.0362 
Train Epoch: 62 [360/684 (53%)] loss: 0.0291 L_si: 0.0071 L_grad: 0.0220 
Train Epoch: 62 [396/684 (58%)] loss: 0.0616 L_si: 0.0246 L_grad: 0.0370 
Train Epoch: 62 [432/684 (63%)] loss: 0.0361 L_si: 0.0086 L_grad: 0.0275 
Train Epoch: 62 [468/684 (68%)] loss: 0.0512 L_si: 0.0140 L_grad: 0.0372 
Train Epoch: 62 [504/684 (74%)] loss: 0.0677 L_si: 0.0248 L_grad: 0.0430 
Train Epoch: 62 [540/684 (79%)] loss: 0.0402 L_si: 0.0156 L_grad: 0.0246 
Train Epoch: 62 [576/684 (84%)] loss: 0.0399 L_si: 0.0148 L_grad: 0.0250 
Train Epoch: 62 [612/684 (89%)] loss: 0.0309 L_si: 0.0068 L_grad: 0.0241 
Train Epoch: 62 [648/684 (95%)] loss: 0.0539 L_si: 0.0180 L_grad: 0.0359 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.014505939558148384, 0.011797940358519554, 0.008863726630806923, 0.013613108545541763, 0.008285614661872387, 0.010850949212908745, 0.02390635572373867, 0.01885511539876461, 0.0194924995303154, 0.029332656413316727, 0.009757054969668388, 0.008822351694107056, 0.018680613487958908, 0.030310384929180145, 0.01065219659358263], 'L_si': [0.0032986849546432495, 0.0018099397420883179, 0.0008177533745765686, 0.0022221654653549194, 0.000997401773929596, 0.0013265758752822876, 0.009061850607395172, 0.005954161286354065, 0.006336644291877747, 0.011058412492275238, 0.0010041967034339905, 0.0010592341423034668, 0.0060266777873039246, 0.011244654655456543, 0.0011692866683006287], 'L_grad': [0.011207254603505135, 0.009988000616431236, 0.008045973256230354, 0.011390943080186844, 0.007288212887942791, 0.009524373337626457, 0.014844505116343498, 0.012900954112410545, 0.013155854307115078, 0.01827424392104149, 0.008752858266234398, 0.0077631170861423016, 0.012653935700654984, 0.019065730273723602, 0.009482909925282001]}
Train Epoch: 63 [0/684 (0%)] loss: 0.0233 L_si: 0.0049 L_grad: 0.0184 
Train Epoch: 63 [36/684 (5%)] loss: 0.0447 L_si: 0.0179 L_grad: 0.0268 
Train Epoch: 63 [72/684 (11%)] loss: 0.0544 L_si: 0.0174 L_grad: 0.0370 
Train Epoch: 63 [108/684 (16%)] loss: 0.0352 L_si: 0.0094 L_grad: 0.0258 
Train Epoch: 63 [144/684 (21%)] loss: 0.0593 L_si: 0.0206 L_grad: 0.0387 
Train Epoch: 63 [180/684 (26%)] loss: 0.0531 L_si: 0.0228 L_grad: 0.0304 
Train Epoch: 63 [216/684 (32%)] loss: 0.0499 L_si: 0.0184 L_grad: 0.0315 
Train Epoch: 63 [252/684 (37%)] loss: 0.0545 L_si: 0.0220 L_grad: 0.0324 
Train Epoch: 63 [288/684 (42%)] loss: 0.0485 L_si: 0.0209 L_grad: 0.0276 
Train Epoch: 63 [324/684 (47%)] loss: 0.0507 L_si: 0.0231 L_grad: 0.0276 
Train Epoch: 63 [360/684 (53%)] loss: 0.0616 L_si: 0.0254 L_grad: 0.0362 
Train Epoch: 63 [396/684 (58%)] loss: 0.0538 L_si: 0.0194 L_grad: 0.0344 
Train Epoch: 63 [432/684 (63%)] loss: 0.0325 L_si: 0.0105 L_grad: 0.0220 
Train Epoch: 63 [468/684 (68%)] loss: 0.0371 L_si: 0.0109 L_grad: 0.0262 
Train Epoch: 63 [504/684 (74%)] loss: 0.0468 L_si: 0.0167 L_grad: 0.0301 
Train Epoch: 63 [540/684 (79%)] loss: 0.0685 L_si: 0.0265 L_grad: 0.0419 
Train Epoch: 63 [576/684 (84%)] loss: 0.0630 L_si: 0.0241 L_grad: 0.0389 
Train Epoch: 63 [612/684 (89%)] loss: 0.0406 L_si: 0.0149 L_grad: 0.0257 
Train Epoch: 63 [648/684 (95%)] loss: 0.0638 L_si: 0.0251 L_grad: 0.0387 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.00852240715175867, 0.015517785213887691, 0.026181155815720558, 0.024623025208711624, 0.032960809767246246, 0.00952228531241417, 0.01790822669863701, 0.008607023395597935, 0.008757767267525196, 0.00987032987177372, 0.013330614194273949, 0.03199736028909683, 0.008533187210559845, 0.010855487547814846, 0.010441159829497337], 'L_si': [0.0009033605456352234, 0.0032624900341033936, 0.009535863995552063, 0.009226001799106598, 0.01389271765947342, 0.0011163130402565002, 0.006026759743690491, 0.0007661357522010803, 0.001114174723625183, 0.0011671483516693115, 0.0021964460611343384, 0.010810330510139465, 0.0008866637945175171, 0.0010979175567626953, 0.0015356242656707764], 'L_grad': [0.007619046606123447, 0.012255295179784298, 0.016645291820168495, 0.015397023409605026, 0.019068092107772827, 0.008405972272157669, 0.011881466023623943, 0.007840887643396854, 0.007643592543900013, 0.008703181520104408, 0.01113416813313961, 0.021187029778957367, 0.007646523416042328, 0.00975756999105215, 0.008905535563826561]}
Train Epoch: 64 [0/684 (0%)] loss: 0.0432 L_si: 0.0176 L_grad: 0.0257 
Train Epoch: 64 [36/684 (5%)] loss: 0.0576 L_si: 0.0212 L_grad: 0.0364 
Train Epoch: 64 [72/684 (11%)] loss: 0.0658 L_si: 0.0277 L_grad: 0.0381 
Train Epoch: 64 [108/684 (16%)] loss: 0.0470 L_si: 0.0181 L_grad: 0.0289 
Train Epoch: 64 [144/684 (21%)] loss: 0.0345 L_si: 0.0136 L_grad: 0.0209 
Train Epoch: 64 [180/684 (26%)] loss: 0.0381 L_si: 0.0117 L_grad: 0.0264 
Train Epoch: 64 [216/684 (32%)] loss: 0.0274 L_si: 0.0061 L_grad: 0.0212 
Train Epoch: 64 [252/684 (37%)] loss: 0.0185 L_si: 0.0033 L_grad: 0.0152 
Train Epoch: 64 [288/684 (42%)] loss: 0.0597 L_si: 0.0237 L_grad: 0.0361 
Train Epoch: 64 [324/684 (47%)] loss: 0.0650 L_si: 0.0222 L_grad: 0.0427 
Train Epoch: 64 [360/684 (53%)] loss: 0.0694 L_si: 0.0294 L_grad: 0.0400 
Train Epoch: 64 [396/684 (58%)] loss: 0.0506 L_si: 0.0170 L_grad: 0.0336 
Train Epoch: 64 [432/684 (63%)] loss: 0.0348 L_si: 0.0078 L_grad: 0.0270 
Train Epoch: 64 [468/684 (68%)] loss: 0.0361 L_si: 0.0110 L_grad: 0.0251 
Train Epoch: 64 [504/684 (74%)] loss: 0.0579 L_si: 0.0211 L_grad: 0.0368 
Train Epoch: 64 [540/684 (79%)] loss: 0.0435 L_si: 0.0123 L_grad: 0.0311 
Train Epoch: 64 [576/684 (84%)] loss: 0.0352 L_si: 0.0167 L_grad: 0.0185 
Train Epoch: 64 [612/684 (89%)] loss: 0.0541 L_si: 0.0210 L_grad: 0.0330 
Train Epoch: 64 [648/684 (95%)] loss: 0.0356 L_si: 0.0103 L_grad: 0.0253 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.015316499397158623, 0.02030016854405403, 0.02515457198023796, 0.009256845340132713, 0.020216600969433784, 0.009716147556900978, 0.029418429359793663, 0.016087064519524574, 0.010143253952264786, 0.01267889142036438, 0.023207131773233414, 0.008321764878928661, 0.01909874565899372, 0.009492868557572365, 0.009645259007811546], 'L_si': [0.0035290569067001343, 0.006496831774711609, 0.009043760597705841, 0.0010190308094024658, 0.006554014980792999, 0.0009508952498435974, 0.011199839413166046, 0.003607742488384247, 0.001023799180984497, 0.0020461678504943848, 0.009071730077266693, 0.0008380487561225891, 0.00592050701379776, 0.00133533775806427, 0.001135408878326416], 'L_grad': [0.011787442490458488, 0.013803336769342422, 0.01611081138253212, 0.008237814530730247, 0.013662585988640785, 0.00876525230705738, 0.018218589946627617, 0.012479322031140327, 0.009119454771280289, 0.010632723569869995, 0.01413540169596672, 0.007483716122806072, 0.013178238645195961, 0.008157530799508095, 0.00850985012948513]}
Train Epoch: 65 [0/684 (0%)] loss: 0.0405 L_si: 0.0145 L_grad: 0.0260 
Train Epoch: 65 [36/684 (5%)] loss: 0.0453 L_si: 0.0162 L_grad: 0.0291 
Train Epoch: 65 [72/684 (11%)] loss: 0.0568 L_si: 0.0190 L_grad: 0.0378 
Train Epoch: 65 [108/684 (16%)] loss: 0.0674 L_si: 0.0280 L_grad: 0.0393 
Train Epoch: 65 [144/684 (21%)] loss: 0.0211 L_si: 0.0035 L_grad: 0.0176 
Train Epoch: 65 [180/684 (26%)] loss: 0.0487 L_si: 0.0170 L_grad: 0.0317 
Train Epoch: 65 [216/684 (32%)] loss: 0.0561 L_si: 0.0290 L_grad: 0.0272 
Train Epoch: 65 [252/684 (37%)] loss: 0.0455 L_si: 0.0165 L_grad: 0.0290 
Train Epoch: 65 [288/684 (42%)] loss: 0.0811 L_si: 0.0359 L_grad: 0.0452 
Train Epoch: 65 [324/684 (47%)] loss: 0.0323 L_si: 0.0076 L_grad: 0.0247 
Train Epoch: 65 [360/684 (53%)] loss: 0.0673 L_si: 0.0247 L_grad: 0.0427 
Train Epoch: 65 [396/684 (58%)] loss: 0.0393 L_si: 0.0114 L_grad: 0.0279 
Train Epoch: 65 [432/684 (63%)] loss: 0.0589 L_si: 0.0270 L_grad: 0.0319 
Train Epoch: 65 [468/684 (68%)] loss: 0.0463 L_si: 0.0146 L_grad: 0.0317 
Train Epoch: 65 [504/684 (74%)] loss: 0.0724 L_si: 0.0329 L_grad: 0.0395 
Train Epoch: 65 [540/684 (79%)] loss: 0.0186 L_si: 0.0023 L_grad: 0.0163 
Train Epoch: 65 [576/684 (84%)] loss: 0.0278 L_si: 0.0100 L_grad: 0.0178 
Train Epoch: 65 [612/684 (89%)] loss: 0.0629 L_si: 0.0272 L_grad: 0.0357 
Train Epoch: 65 [648/684 (95%)] loss: 0.0484 L_si: 0.0165 L_grad: 0.0319 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009702007286250591, 0.018261905759572983, 0.02428574115037918, 0.02528628334403038, 0.016382738947868347, 0.010177439078688622, 0.01755828596651554, 0.01821768842637539, 0.009526744484901428, 0.010508978739380836, 0.023496389389038086, 0.009063897654414177, 0.024146221578121185, 0.009455244988203049, 0.011978888884186745], 'L_si': [0.0013371482491493225, 0.005926944315433502, 0.009099319577217102, 0.0082574263215065, 0.003641463816165924, 0.001177184283733368, 0.0039244890213012695, 0.005895189940929413, 0.00130511075258255, 0.001505151391029358, 0.008897855877876282, 0.000822603702545166, 0.009074918925762177, 0.0013513267040252686, 0.0016033053398132324], 'L_grad': [0.008364859037101269, 0.01233496144413948, 0.015186421573162079, 0.01702885702252388, 0.012741275131702423, 0.009000254794955254, 0.013633796945214272, 0.012322498485445976, 0.008221633732318878, 0.009003827348351479, 0.014598533511161804, 0.008241293951869011, 0.015071302652359009, 0.00810391828417778, 0.010375583544373512]}
Train Epoch: 66 [0/684 (0%)] loss: 0.0318 L_si: 0.0066 L_grad: 0.0252 
Train Epoch: 66 [36/684 (5%)] loss: 0.0332 L_si: 0.0085 L_grad: 0.0247 
Train Epoch: 66 [72/684 (11%)] loss: 0.0259 L_si: 0.0052 L_grad: 0.0207 
Train Epoch: 66 [108/684 (16%)] loss: 0.0305 L_si: 0.0098 L_grad: 0.0208 
Train Epoch: 66 [144/684 (21%)] loss: 0.0548 L_si: 0.0166 L_grad: 0.0381 
Train Epoch: 66 [180/684 (26%)] loss: 0.0288 L_si: 0.0066 L_grad: 0.0222 
Train Epoch: 66 [216/684 (32%)] loss: 0.0488 L_si: 0.0192 L_grad: 0.0297 
Train Epoch: 66 [252/684 (37%)] loss: 0.0244 L_si: 0.0054 L_grad: 0.0190 
Train Epoch: 66 [288/684 (42%)] loss: 0.0491 L_si: 0.0237 L_grad: 0.0255 
Train Epoch: 66 [324/684 (47%)] loss: 0.0386 L_si: 0.0116 L_grad: 0.0270 
Train Epoch: 66 [360/684 (53%)] loss: 0.0270 L_si: 0.0045 L_grad: 0.0226 
Train Epoch: 66 [396/684 (58%)] loss: 0.0472 L_si: 0.0136 L_grad: 0.0337 
Train Epoch: 66 [432/684 (63%)] loss: 0.0526 L_si: 0.0244 L_grad: 0.0282 
Train Epoch: 66 [468/684 (68%)] loss: 0.0642 L_si: 0.0295 L_grad: 0.0347 
Train Epoch: 66 [504/684 (74%)] loss: 0.0505 L_si: 0.0159 L_grad: 0.0345 
Train Epoch: 66 [540/684 (79%)] loss: 0.0493 L_si: 0.0196 L_grad: 0.0297 
Train Epoch: 66 [576/684 (84%)] loss: 0.0330 L_si: 0.0098 L_grad: 0.0232 
Train Epoch: 66 [612/684 (89%)] loss: 0.0575 L_si: 0.0197 L_grad: 0.0378 
Train Epoch: 66 [648/684 (95%)] loss: 0.0411 L_si: 0.0109 L_grad: 0.0301 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.015613098628818989, 0.01494981162250042, 0.0153846126049757, 0.04835803434252739, 0.01796901412308216, 0.008950168266892433, 0.013240361586213112, 0.012201186269521713, 0.020395677536725998, 0.009428758174180984, 0.011624515056610107, 0.009833252057433128, 0.008625509217381477, 0.023746494203805923, 0.008760906755924225], 'L_si': [0.003378160297870636, 0.003066800534725189, 0.0034938305616378784, 0.021720491349697113, 0.006153225898742676, 0.0009028613567352295, 0.0019019469618797302, 0.0019301921129226685, 0.00653471052646637, 0.0012517645955085754, 0.0015184134244918823, 0.0011385083198547363, 0.000817224383354187, 0.008745826780796051, 0.0009395405650138855], 'L_grad': [0.012234938330948353, 0.01188301108777523, 0.011890782043337822, 0.026637542992830276, 0.011815788224339485, 0.008047306910157204, 0.011338414624333382, 0.010270994156599045, 0.013860967010259628, 0.008176993578672409, 0.010106101632118225, 0.008694743737578392, 0.00780828483402729, 0.015000668354332447, 0.00782136619091034]}
Train Epoch: 67 [0/684 (0%)] loss: 0.0829 L_si: 0.0353 L_grad: 0.0476 
Train Epoch: 67 [36/684 (5%)] loss: 0.0261 L_si: 0.0048 L_grad: 0.0212 
Train Epoch: 67 [72/684 (11%)] loss: 0.0321 L_si: 0.0065 L_grad: 0.0257 
Train Epoch: 67 [108/684 (16%)] loss: 0.0170 L_si: 0.0032 L_grad: 0.0139 
Train Epoch: 67 [144/684 (21%)] loss: 0.0602 L_si: 0.0200 L_grad: 0.0402 
Train Epoch: 67 [180/684 (26%)] loss: 0.0338 L_si: 0.0077 L_grad: 0.0261 
Train Epoch: 67 [216/684 (32%)] loss: 0.0489 L_si: 0.0156 L_grad: 0.0333 
Train Epoch: 67 [252/684 (37%)] loss: 0.0631 L_si: 0.0242 L_grad: 0.0389 
Train Epoch: 67 [288/684 (42%)] loss: 0.0337 L_si: 0.0077 L_grad: 0.0260 
Train Epoch: 67 [324/684 (47%)] loss: 0.0695 L_si: 0.0279 L_grad: 0.0416 
Train Epoch: 67 [360/684 (53%)] loss: 0.0183 L_si: 0.0032 L_grad: 0.0151 
Train Epoch: 67 [396/684 (58%)] loss: 0.0617 L_si: 0.0289 L_grad: 0.0328 
Train Epoch: 67 [432/684 (63%)] loss: 0.0560 L_si: 0.0232 L_grad: 0.0328 
Train Epoch: 67 [468/684 (68%)] loss: 0.0898 L_si: 0.0408 L_grad: 0.0489 
Train Epoch: 67 [504/684 (74%)] loss: 0.0306 L_si: 0.0064 L_grad: 0.0242 
Train Epoch: 67 [540/684 (79%)] loss: 0.0321 L_si: 0.0080 L_grad: 0.0241 
Train Epoch: 67 [576/684 (84%)] loss: 0.0432 L_si: 0.0192 L_grad: 0.0241 
Train Epoch: 67 [612/684 (89%)] loss: 0.0262 L_si: 0.0056 L_grad: 0.0206 
Train Epoch: 67 [648/684 (95%)] loss: 0.0596 L_si: 0.0221 L_grad: 0.0376 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.028062015771865845, 0.026824334636330605, 0.009908575564622879, 0.0104322899132967, 0.008719822391867638, 0.029773518443107605, 0.010831082239747047, 0.03331286087632179, 0.009780628606677055, 0.009316695854067802, 0.017680823802947998, 0.008654741570353508, 0.00820836890488863, 0.012395400553941727, 0.014448423869907856], 'L_si': [0.0101371631026268, 0.009136363863945007, 0.0012646317481994629, 0.0012562870979309082, 0.0007533207535743713, 0.011280246078968048, 0.0012791454792022705, 0.01391233503818512, 0.0012536123394966125, 0.0007644370198249817, 0.006016232073307037, 0.00105305016040802, 0.0009893998503684998, 0.0018204674124717712, 0.0032098516821861267], 'L_grad': [0.017924852669239044, 0.017687970772385597, 0.008643943816423416, 0.009176002815365791, 0.007966501638293266, 0.018493272364139557, 0.009551936760544777, 0.019400525838136673, 0.008527016267180443, 0.00855225883424282, 0.01166459172964096, 0.007601691409945488, 0.00721896905452013, 0.010574933141469955, 0.01123857218772173]}
Train Epoch: 68 [0/684 (0%)] loss: 0.0446 L_si: 0.0149 L_grad: 0.0297 
Train Epoch: 68 [36/684 (5%)] loss: 0.0266 L_si: 0.0084 L_grad: 0.0182 
Train Epoch: 68 [72/684 (11%)] loss: 0.0228 L_si: 0.0043 L_grad: 0.0186 
Train Epoch: 68 [108/684 (16%)] loss: 0.0492 L_si: 0.0136 L_grad: 0.0356 
Train Epoch: 68 [144/684 (21%)] loss: 0.0650 L_si: 0.0257 L_grad: 0.0393 
Train Epoch: 68 [180/684 (26%)] loss: 0.0453 L_si: 0.0158 L_grad: 0.0295 
Train Epoch: 68 [216/684 (32%)] loss: 0.0459 L_si: 0.0187 L_grad: 0.0272 
Train Epoch: 68 [252/684 (37%)] loss: 0.0368 L_si: 0.0119 L_grad: 0.0249 
Train Epoch: 68 [288/684 (42%)] loss: 0.0327 L_si: 0.0094 L_grad: 0.0233 
Train Epoch: 68 [324/684 (47%)] loss: 0.0358 L_si: 0.0101 L_grad: 0.0257 
Train Epoch: 68 [360/684 (53%)] loss: 0.0511 L_si: 0.0230 L_grad: 0.0281 
Train Epoch: 68 [396/684 (58%)] loss: 0.0483 L_si: 0.0155 L_grad: 0.0328 
Train Epoch: 68 [432/684 (63%)] loss: 0.0245 L_si: 0.0075 L_grad: 0.0170 
Train Epoch: 68 [468/684 (68%)] loss: 0.0525 L_si: 0.0215 L_grad: 0.0310 
Train Epoch: 68 [504/684 (74%)] loss: 0.0360 L_si: 0.0093 L_grad: 0.0266 
Train Epoch: 68 [540/684 (79%)] loss: 0.0489 L_si: 0.0229 L_grad: 0.0259 
Train Epoch: 68 [576/684 (84%)] loss: 0.0656 L_si: 0.0258 L_grad: 0.0398 
Train Epoch: 68 [612/684 (89%)] loss: 0.0549 L_si: 0.0211 L_grad: 0.0338 
Train Epoch: 68 [648/684 (95%)] loss: 0.0397 L_si: 0.0146 L_grad: 0.0251 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008996855467557907, 0.0154967550188303, 0.019381266087293625, 0.010248973034322262, 0.015441704541444778, 0.029609866440296173, 0.008215965703129768, 0.012843247503042221, 0.026701126247644424, 0.011167329736053944, 0.024052193388342857, 0.00955172535032034, 0.010904225520789623, 0.008785232901573181, 0.02759115770459175], 'L_si': [0.0008972510695457458, 0.003227606415748596, 0.006076604127883911, 0.0011546239256858826, 0.003394514322280884, 0.011141598224639893, 0.000662386417388916, 0.001800835132598877, 0.009587347507476807, 0.001315481960773468, 0.008668608963489532, 0.0009182840585708618, 0.0016048550605773926, 0.0008615702390670776, 0.010912731289863586], 'L_grad': [0.008099604398012161, 0.012269148603081703, 0.013304661959409714, 0.00909434910863638, 0.012047190219163895, 0.01846826821565628, 0.007553579285740852, 0.011042412370443344, 0.017113778740167618, 0.009851847775280476, 0.015383584424853325, 0.008633441291749477, 0.00929937046021223, 0.007923662662506104, 0.016678426414728165]}
Train Epoch: 69 [0/684 (0%)] loss: 0.0509 L_si: 0.0212 L_grad: 0.0297 
Train Epoch: 69 [36/684 (5%)] loss: 0.0652 L_si: 0.0284 L_grad: 0.0368 
Train Epoch: 69 [72/684 (11%)] loss: 0.0258 L_si: 0.0065 L_grad: 0.0193 
Train Epoch: 69 [108/684 (16%)] loss: 0.0382 L_si: 0.0118 L_grad: 0.0265 
Train Epoch: 69 [144/684 (21%)] loss: 0.0314 L_si: 0.0078 L_grad: 0.0236 
Train Epoch: 69 [180/684 (26%)] loss: 0.0543 L_si: 0.0198 L_grad: 0.0345 
Train Epoch: 69 [216/684 (32%)] loss: 0.0390 L_si: 0.0106 L_grad: 0.0285 
Train Epoch: 69 [252/684 (37%)] loss: 0.0431 L_si: 0.0129 L_grad: 0.0302 
Train Epoch: 69 [288/684 (42%)] loss: 0.0338 L_si: 0.0082 L_grad: 0.0255 
Train Epoch: 69 [324/684 (47%)] loss: 0.0418 L_si: 0.0104 L_grad: 0.0315 
Train Epoch: 69 [360/684 (53%)] loss: 0.0527 L_si: 0.0166 L_grad: 0.0361 
Train Epoch: 69 [396/684 (58%)] loss: 0.0244 L_si: 0.0058 L_grad: 0.0186 
Train Epoch: 69 [432/684 (63%)] loss: 0.0882 L_si: 0.0424 L_grad: 0.0458 
Train Epoch: 69 [468/684 (68%)] loss: 0.0256 L_si: 0.0048 L_grad: 0.0207 
Train Epoch: 69 [504/684 (74%)] loss: 0.0359 L_si: 0.0103 L_grad: 0.0255 
Train Epoch: 69 [540/684 (79%)] loss: 0.0224 L_si: 0.0040 L_grad: 0.0184 
Train Epoch: 69 [576/684 (84%)] loss: 0.0681 L_si: 0.0304 L_grad: 0.0378 
Train Epoch: 69 [612/684 (89%)] loss: 0.0382 L_si: 0.0115 L_grad: 0.0267 
Train Epoch: 69 [648/684 (95%)] loss: 0.0540 L_si: 0.0192 L_grad: 0.0347 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.030070699751377106, 0.013963771983981133, 0.010745847597718239, 0.015272633172571659, 0.008885405957698822, 0.009197331964969635, 0.009189876727759838, 0.020162606611847878, 0.008139575831592083, 0.035768188536167145, 0.041147179901599884, 0.00995447114109993, 0.00868940819054842, 0.009906676597893238, 0.009879427030682564], 'L_si': [0.01151728630065918, 0.002390742301940918, 0.001283109188079834, 0.003211580216884613, 0.0008211210370063782, 0.0009343326091766357, 0.0007964223623275757, 0.006388477981090546, 0.0007314682006835938, 0.01506197452545166, 0.01682543009519577, 0.0013941898941993713, 0.0008969306945800781, 0.0013665556907653809, 0.0009253919124603271], 'L_grad': [0.018553413450717926, 0.011573029682040215, 0.009462738409638405, 0.012061052955687046, 0.008064284920692444, 0.008262999355793, 0.008393454365432262, 0.013774128630757332, 0.007408107630908489, 0.020706214010715485, 0.024321747943758965, 0.008560281246900558, 0.007792477495968342, 0.008540120907127857, 0.008954035118222237]}
Train Epoch: 70 [0/684 (0%)] loss: 0.0477 L_si: 0.0199 L_grad: 0.0278 
Train Epoch: 70 [36/684 (5%)] loss: 0.0231 L_si: 0.0046 L_grad: 0.0185 
Train Epoch: 70 [72/684 (11%)] loss: 0.0315 L_si: 0.0067 L_grad: 0.0248 
Train Epoch: 70 [108/684 (16%)] loss: 0.0435 L_si: 0.0132 L_grad: 0.0303 
Train Epoch: 70 [144/684 (21%)] loss: 0.0522 L_si: 0.0217 L_grad: 0.0304 
Train Epoch: 70 [180/684 (26%)] loss: 0.0265 L_si: 0.0055 L_grad: 0.0210 
Train Epoch: 70 [216/684 (32%)] loss: 0.0700 L_si: 0.0233 L_grad: 0.0467 
Train Epoch: 70 [252/684 (37%)] loss: 0.0395 L_si: 0.0098 L_grad: 0.0297 
Train Epoch: 70 [288/684 (42%)] loss: 0.0501 L_si: 0.0171 L_grad: 0.0330 
Train Epoch: 70 [324/684 (47%)] loss: 0.0469 L_si: 0.0143 L_grad: 0.0326 
Train Epoch: 70 [360/684 (53%)] loss: 0.0520 L_si: 0.0136 L_grad: 0.0383 
Train Epoch: 70 [396/684 (58%)] loss: 0.0176 L_si: 0.0027 L_grad: 0.0149 
Train Epoch: 70 [432/684 (63%)] loss: 0.0621 L_si: 0.0233 L_grad: 0.0388 
Train Epoch: 70 [468/684 (68%)] loss: 0.0313 L_si: 0.0076 L_grad: 0.0237 
Train Epoch: 70 [504/684 (74%)] loss: 0.0512 L_si: 0.0133 L_grad: 0.0379 
Train Epoch: 70 [540/684 (79%)] loss: 0.0687 L_si: 0.0309 L_grad: 0.0378 
Train Epoch: 70 [576/684 (84%)] loss: 0.0427 L_si: 0.0114 L_grad: 0.0313 
Train Epoch: 70 [612/684 (89%)] loss: 0.0751 L_si: 0.0323 L_grad: 0.0428 
Train Epoch: 70 [648/684 (95%)] loss: 0.0358 L_si: 0.0145 L_grad: 0.0214 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch070-loss-0.0446.pth.tar ...
all losses in batch in validation:  {'loss': [0.033034417778253555, 0.01615913398563862, 0.019459184259176254, 0.008700273931026459, 0.01606803573668003, 0.008503594435751438, 0.010929982177913189, 0.011316141113638878, 0.010557971894741058, 0.008750581182539463, 0.023040521889925003, 0.012682737782597542, 0.020874569192528725, 0.009635671973228455, 0.03183095529675484], 'L_si': [0.013852715492248535, 0.0033248141407966614, 0.005915030837059021, 0.0009249001741409302, 0.003576047718524933, 0.0007091984152793884, 0.0010368824005126953, 0.0015509948134422302, 0.0010896697640419006, 0.000692509114742279, 0.008727788925170898, 0.0018888786435127258, 0.0067649707198143005, 0.0008434504270553589, 0.011761464178562164], 'L_grad': [0.01918170228600502, 0.012834319844841957, 0.013544153422117233, 0.0077753737568855286, 0.012491988018155098, 0.00779439602047205, 0.009893099777400494, 0.009765146300196648, 0.009468302130699158, 0.008058072067797184, 0.014312732964754105, 0.010793859139084816, 0.014109598472714424, 0.008792221546173096, 0.020069491118192673]}
Train Epoch: 71 [0/684 (0%)] loss: 0.0435 L_si: 0.0129 L_grad: 0.0306 
Train Epoch: 71 [36/684 (5%)] loss: 0.0381 L_si: 0.0099 L_grad: 0.0282 
Train Epoch: 71 [72/684 (11%)] loss: 0.0452 L_si: 0.0133 L_grad: 0.0319 
Train Epoch: 71 [108/684 (16%)] loss: 0.0209 L_si: 0.0037 L_grad: 0.0172 
Train Epoch: 71 [144/684 (21%)] loss: 0.0394 L_si: 0.0125 L_grad: 0.0270 
Train Epoch: 71 [180/684 (26%)] loss: 0.0930 L_si: 0.0483 L_grad: 0.0448 
Train Epoch: 71 [216/684 (32%)] loss: 0.0432 L_si: 0.0147 L_grad: 0.0285 
Train Epoch: 71 [252/684 (37%)] loss: 0.0431 L_si: 0.0148 L_grad: 0.0283 
Train Epoch: 71 [288/684 (42%)] loss: 0.0506 L_si: 0.0178 L_grad: 0.0329 
Train Epoch: 71 [324/684 (47%)] loss: 0.0653 L_si: 0.0304 L_grad: 0.0349 
Train Epoch: 71 [360/684 (53%)] loss: 0.0598 L_si: 0.0263 L_grad: 0.0335 
Train Epoch: 71 [396/684 (58%)] loss: 0.0479 L_si: 0.0157 L_grad: 0.0322 
Train Epoch: 71 [432/684 (63%)] loss: 0.0538 L_si: 0.0191 L_grad: 0.0347 
Train Epoch: 71 [468/684 (68%)] loss: 0.0460 L_si: 0.0145 L_grad: 0.0314 
Train Epoch: 71 [504/684 (74%)] loss: 0.0495 L_si: 0.0162 L_grad: 0.0333 
Train Epoch: 71 [540/684 (79%)] loss: 0.0428 L_si: 0.0149 L_grad: 0.0280 
Train Epoch: 71 [576/684 (84%)] loss: 0.0505 L_si: 0.0155 L_grad: 0.0350 
Train Epoch: 71 [612/684 (89%)] loss: 0.0487 L_si: 0.0182 L_grad: 0.0305 
Train Epoch: 71 [648/684 (95%)] loss: 0.0174 L_si: 0.0032 L_grad: 0.0142 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009333346970379353, 0.011416258290410042, 0.009304030798375607, 0.037258557975292206, 0.009889858774840832, 0.010844483971595764, 0.037242211401462555, 0.019230911508202553, 0.008741491474211216, 0.009135482832789421, 0.027392953634262085, 0.008300949819386005, 0.008044176734983921, 0.02105727046728134, 0.015081302262842655], 'L_si': [0.0009926408529281616, 0.0017973855137825012, 0.0007837340235710144, 0.013934038579463959, 0.0011315494775772095, 0.001152820885181427, 0.015700452029705048, 0.006086230278015137, 0.0008361637592315674, 0.0010251328349113464, 0.009904012084007263, 0.0007346346974372864, 0.0008419789373874664, 0.006571382284164429, 0.003197222948074341], 'L_grad': [0.008340706117451191, 0.00961887277662754, 0.008520296774804592, 0.023324517533183098, 0.008758309297263622, 0.009691663086414337, 0.021541757509112358, 0.013144681230187416, 0.007905327714979649, 0.008110349997878075, 0.017488941550254822, 0.007566315121948719, 0.007202197797596455, 0.014485888183116913, 0.011884079314768314]}
Train Epoch: 72 [0/684 (0%)] loss: 0.0526 L_si: 0.0157 L_grad: 0.0369 
Train Epoch: 72 [36/684 (5%)] loss: 0.0360 L_si: 0.0110 L_grad: 0.0251 
Train Epoch: 72 [72/684 (11%)] loss: 0.0275 L_si: 0.0086 L_grad: 0.0189 
Train Epoch: 72 [108/684 (16%)] loss: 0.0231 L_si: 0.0036 L_grad: 0.0194 
Train Epoch: 72 [144/684 (21%)] loss: 0.0502 L_si: 0.0194 L_grad: 0.0308 
Train Epoch: 72 [180/684 (26%)] loss: 0.0388 L_si: 0.0114 L_grad: 0.0275 
Train Epoch: 72 [216/684 (32%)] loss: 0.0444 L_si: 0.0180 L_grad: 0.0264 
Train Epoch: 72 [252/684 (37%)] loss: 0.0617 L_si: 0.0239 L_grad: 0.0378 
Train Epoch: 72 [288/684 (42%)] loss: 0.0647 L_si: 0.0260 L_grad: 0.0387 
Train Epoch: 72 [324/684 (47%)] loss: 0.0488 L_si: 0.0128 L_grad: 0.0360 
Train Epoch: 72 [360/684 (53%)] loss: 0.0228 L_si: 0.0041 L_grad: 0.0187 
Train Epoch: 72 [396/684 (58%)] loss: 0.0319 L_si: 0.0081 L_grad: 0.0237 
Train Epoch: 72 [432/684 (63%)] loss: 0.0529 L_si: 0.0207 L_grad: 0.0321 
Train Epoch: 72 [468/684 (68%)] loss: 0.0388 L_si: 0.0123 L_grad: 0.0265 
Train Epoch: 72 [504/684 (74%)] loss: 0.0259 L_si: 0.0054 L_grad: 0.0205 
Train Epoch: 72 [540/684 (79%)] loss: 0.0328 L_si: 0.0088 L_grad: 0.0240 
Train Epoch: 72 [576/684 (84%)] loss: 0.0577 L_si: 0.0257 L_grad: 0.0320 
Train Epoch: 72 [612/684 (89%)] loss: 0.0687 L_si: 0.0228 L_grad: 0.0460 
Train Epoch: 72 [648/684 (95%)] loss: 0.0485 L_si: 0.0143 L_grad: 0.0342 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.027945660054683685, 0.01128610409796238, 0.010578096844255924, 0.019414998590946198, 0.00936398096382618, 0.031496353447437286, 0.01557009108364582, 0.009123611263930798, 0.023572493344545364, 0.011201072484254837, 0.01242130994796753, 0.008513503707945347, 0.0311483945697546, 0.009441744536161423, 0.015423081815242767], 'L_si': [0.010381698608398438, 0.0015176907181739807, 0.0010750815272331238, 0.0061387717723846436, 0.0010313689708709717, 0.011924892663955688, 0.003554902970790863, 0.0010668262839317322, 0.008765541017055511, 0.0016029700636863708, 0.001501128077507019, 0.0008966848254203796, 0.011661022901535034, 0.0014150887727737427, 0.0033962950110435486], 'L_grad': [0.017563961446285248, 0.009768413379788399, 0.0095030153170228, 0.013276227749884129, 0.008332611992955208, 0.019571460783481598, 0.012015188112854958, 0.008056784979999065, 0.014806953258812428, 0.009598102420568466, 0.01092018187046051, 0.007616818882524967, 0.019487371668219566, 0.00802665576338768, 0.012026786804199219]}
Train Epoch: 73 [0/684 (0%)] loss: 0.0720 L_si: 0.0304 L_grad: 0.0415 
Train Epoch: 73 [36/684 (5%)] loss: 0.0505 L_si: 0.0217 L_grad: 0.0287 
Train Epoch: 73 [72/684 (11%)] loss: 0.0587 L_si: 0.0233 L_grad: 0.0354 
Train Epoch: 73 [108/684 (16%)] loss: 0.0514 L_si: 0.0168 L_grad: 0.0345 
Train Epoch: 73 [144/684 (21%)] loss: 0.0405 L_si: 0.0108 L_grad: 0.0297 
Train Epoch: 73 [180/684 (26%)] loss: 0.0516 L_si: 0.0248 L_grad: 0.0268 
Train Epoch: 73 [216/684 (32%)] loss: 0.0544 L_si: 0.0238 L_grad: 0.0306 
Train Epoch: 73 [252/684 (37%)] loss: 0.0506 L_si: 0.0180 L_grad: 0.0326 
Train Epoch: 73 [288/684 (42%)] loss: 0.0465 L_si: 0.0147 L_grad: 0.0318 
Train Epoch: 73 [324/684 (47%)] loss: 0.0264 L_si: 0.0066 L_grad: 0.0197 
Train Epoch: 73 [360/684 (53%)] loss: 0.0265 L_si: 0.0062 L_grad: 0.0203 
Train Epoch: 73 [396/684 (58%)] loss: 0.0434 L_si: 0.0151 L_grad: 0.0284 
Train Epoch: 73 [432/684 (63%)] loss: 0.0390 L_si: 0.0090 L_grad: 0.0300 
Train Epoch: 73 [468/684 (68%)] loss: 0.0787 L_si: 0.0359 L_grad: 0.0428 
Train Epoch: 73 [504/684 (74%)] loss: 0.0401 L_si: 0.0133 L_grad: 0.0267 
Train Epoch: 73 [540/684 (79%)] loss: 0.0601 L_si: 0.0236 L_grad: 0.0364 
Train Epoch: 73 [576/684 (84%)] loss: 0.0458 L_si: 0.0163 L_grad: 0.0295 
Train Epoch: 73 [612/684 (89%)] loss: 0.0555 L_si: 0.0201 L_grad: 0.0354 
Train Epoch: 73 [648/684 (95%)] loss: 0.0331 L_si: 0.0103 L_grad: 0.0228 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010693401098251343, 0.010063575580716133, 0.023294158279895782, 0.026675090193748474, 0.008332076482474804, 0.008959459140896797, 0.008493633940815926, 0.01002827100455761, 0.02652204968035221, 0.02059929072856903, 0.011339173652231693, 0.030742600560188293, 0.01242363266646862, 0.016296861693263054, 0.01817597821354866], 'L_si': [0.0011341497302055359, 0.0012822896242141724, 0.008841089904308319, 0.009641870856285095, 0.0008272826671600342, 0.0010063424706459045, 0.0008000731468200684, 0.0012080967426300049, 0.009784862399101257, 0.006301328539848328, 0.001409575343132019, 0.010850951075553894, 0.001763962209224701, 0.0035048499703407288, 0.005944371223449707], 'L_grad': [0.009559251368045807, 0.00878128595650196, 0.014453067444264889, 0.01703321933746338, 0.00750479381531477, 0.007953116670250893, 0.007693560793995857, 0.008820174261927605, 0.016737187281250954, 0.014297963120043278, 0.009929598309099674, 0.0198916494846344, 0.01065967045724392, 0.012792011722922325, 0.012231606990098953]}
Train Epoch: 74 [0/684 (0%)] loss: 0.0256 L_si: 0.0060 L_grad: 0.0195 
Train Epoch: 74 [36/684 (5%)] loss: 0.0417 L_si: 0.0115 L_grad: 0.0302 
Train Epoch: 74 [72/684 (11%)] loss: 0.0325 L_si: 0.0070 L_grad: 0.0255 
Train Epoch: 74 [108/684 (16%)] loss: 0.0601 L_si: 0.0274 L_grad: 0.0327 
Train Epoch: 74 [144/684 (21%)] loss: 0.0732 L_si: 0.0307 L_grad: 0.0425 
Train Epoch: 74 [180/684 (26%)] loss: 0.0359 L_si: 0.0101 L_grad: 0.0258 
Train Epoch: 74 [216/684 (32%)] loss: 0.0205 L_si: 0.0034 L_grad: 0.0171 
Train Epoch: 74 [252/684 (37%)] loss: 0.0608 L_si: 0.0221 L_grad: 0.0387 
Train Epoch: 74 [288/684 (42%)] loss: 0.0417 L_si: 0.0111 L_grad: 0.0306 
Train Epoch: 74 [324/684 (47%)] loss: 0.0219 L_si: 0.0047 L_grad: 0.0172 
Train Epoch: 74 [360/684 (53%)] loss: 0.0447 L_si: 0.0143 L_grad: 0.0304 
Train Epoch: 74 [396/684 (58%)] loss: 0.0536 L_si: 0.0208 L_grad: 0.0328 
Train Epoch: 74 [432/684 (63%)] loss: 0.0901 L_si: 0.0335 L_grad: 0.0566 
Train Epoch: 74 [468/684 (68%)] loss: 0.0341 L_si: 0.0094 L_grad: 0.0246 
Train Epoch: 74 [504/684 (74%)] loss: 0.0423 L_si: 0.0130 L_grad: 0.0293 
Train Epoch: 74 [540/684 (79%)] loss: 0.0400 L_si: 0.0116 L_grad: 0.0284 
Train Epoch: 74 [576/684 (84%)] loss: 0.0240 L_si: 0.0064 L_grad: 0.0176 
Train Epoch: 74 [612/684 (89%)] loss: 0.0278 L_si: 0.0055 L_grad: 0.0222 
Train Epoch: 74 [648/684 (95%)] loss: 0.0393 L_si: 0.0102 L_grad: 0.0291 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.018550416454672813, 0.00986249465495348, 0.009485010989010334, 0.03392982855439186, 0.017251212149858475, 0.0239427350461483, 0.03515268862247467, 0.00999440811574459, 0.014731254428625107, 0.009333538822829723, 0.012943411245942116, 0.010937214829027653, 0.009742560796439648, 0.009441220201551914, 0.019252002239227295], 'L_si': [0.004304960370063782, 0.0011126473546028137, 0.0011381730437278748, 0.014001093804836273, 0.0036129802465438843, 0.00904422253370285, 0.014462903141975403, 0.0009733662009239197, 0.0033043846487998962, 0.0009300783276557922, 0.0021589472889900208, 0.0016507580876350403, 0.0007973983883857727, 0.0013536512851715088, 0.006237946450710297], 'L_grad': [0.014245456084609032, 0.008749847300350666, 0.00834683794528246, 0.019928734749555588, 0.013638232834637165, 0.014898513443768024, 0.020689785480499268, 0.009021041914820671, 0.01142686977982521, 0.008403460495173931, 0.010784463956952095, 0.009286456741392612, 0.008945162408053875, 0.008087568916380405, 0.013014056719839573]}
Train Epoch: 75 [0/684 (0%)] loss: 0.0626 L_si: 0.0245 L_grad: 0.0381 
Train Epoch: 75 [36/684 (5%)] loss: 0.0395 L_si: 0.0182 L_grad: 0.0213 
Train Epoch: 75 [72/684 (11%)] loss: 0.0222 L_si: 0.0054 L_grad: 0.0168 
Train Epoch: 75 [108/684 (16%)] loss: 0.0635 L_si: 0.0226 L_grad: 0.0409 
Train Epoch: 75 [144/684 (21%)] loss: 0.0462 L_si: 0.0131 L_grad: 0.0331 
Train Epoch: 75 [180/684 (26%)] loss: 0.0528 L_si: 0.0184 L_grad: 0.0344 
Train Epoch: 75 [216/684 (32%)] loss: 0.0488 L_si: 0.0209 L_grad: 0.0279 
Train Epoch: 75 [252/684 (37%)] loss: 0.0485 L_si: 0.0182 L_grad: 0.0303 
Train Epoch: 75 [288/684 (42%)] loss: 0.0304 L_si: 0.0064 L_grad: 0.0240 
Train Epoch: 75 [324/684 (47%)] loss: 0.0334 L_si: 0.0070 L_grad: 0.0264 
Train Epoch: 75 [360/684 (53%)] loss: 0.0435 L_si: 0.0197 L_grad: 0.0238 
Train Epoch: 75 [396/684 (58%)] loss: 0.0321 L_si: 0.0138 L_grad: 0.0183 
Train Epoch: 75 [432/684 (63%)] loss: 0.0357 L_si: 0.0087 L_grad: 0.0270 
Train Epoch: 75 [468/684 (68%)] loss: 0.0428 L_si: 0.0160 L_grad: 0.0268 
Train Epoch: 75 [504/684 (74%)] loss: 0.0372 L_si: 0.0122 L_grad: 0.0250 
Train Epoch: 75 [540/684 (79%)] loss: 0.0340 L_si: 0.0082 L_grad: 0.0258 
Train Epoch: 75 [576/684 (84%)] loss: 0.0541 L_si: 0.0186 L_grad: 0.0355 
Train Epoch: 75 [612/684 (89%)] loss: 0.0321 L_si: 0.0066 L_grad: 0.0255 
Train Epoch: 75 [648/684 (95%)] loss: 0.0477 L_si: 0.0163 L_grad: 0.0314 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009731176309287548, 0.010199541226029396, 0.019888263195753098, 0.00925411842763424, 0.030961746349930763, 0.01033160649240017, 0.01193955633789301, 0.010839485563337803, 0.026162274181842804, 0.03799036145210266, 0.02045520395040512, 0.012561151757836342, 0.020484082400798798, 0.014830309897661209, 0.011643357574939728], 'L_si': [0.0010460838675498962, 0.0010235011577606201, 0.006503075361251831, 0.0011405274271965027, 0.011256620287895203, 0.0015290752053260803, 0.001561187207698822, 0.0011209622025489807, 0.009308308362960815, 0.01382138580083847, 0.006402522325515747, 0.001996062695980072, 0.006636381149291992, 0.002492375671863556, 0.0017394721508026123], 'L_grad': [0.008685092441737652, 0.009176040068268776, 0.013385186903178692, 0.008113591000437737, 0.01970512606203556, 0.008802531287074089, 0.010378369130194187, 0.009718523360788822, 0.01685396581888199, 0.02416897751390934, 0.0140526806935668, 0.01056508906185627, 0.01384770032018423, 0.012337934225797653, 0.009903885424137115]}
Train Epoch: 76 [0/684 (0%)] loss: 0.0416 L_si: 0.0133 L_grad: 0.0283 
Train Epoch: 76 [36/684 (5%)] loss: 0.0208 L_si: 0.0047 L_grad: 0.0161 
Train Epoch: 76 [72/684 (11%)] loss: 0.0414 L_si: 0.0128 L_grad: 0.0286 
Train Epoch: 76 [108/684 (16%)] loss: 0.0582 L_si: 0.0260 L_grad: 0.0322 
Train Epoch: 76 [144/684 (21%)] loss: 0.0438 L_si: 0.0132 L_grad: 0.0306 
Train Epoch: 76 [180/684 (26%)] loss: 0.0582 L_si: 0.0253 L_grad: 0.0329 
Train Epoch: 76 [216/684 (32%)] loss: 0.0417 L_si: 0.0099 L_grad: 0.0318 
Train Epoch: 76 [252/684 (37%)] loss: 0.0620 L_si: 0.0315 L_grad: 0.0305 
Train Epoch: 76 [288/684 (42%)] loss: 0.0488 L_si: 0.0198 L_grad: 0.0290 
Train Epoch: 76 [324/684 (47%)] loss: 0.0394 L_si: 0.0125 L_grad: 0.0269 
Train Epoch: 76 [360/684 (53%)] loss: 0.0500 L_si: 0.0194 L_grad: 0.0306 
Train Epoch: 76 [396/684 (58%)] loss: 0.0363 L_si: 0.0105 L_grad: 0.0258 
Train Epoch: 76 [432/684 (63%)] loss: 0.0407 L_si: 0.0132 L_grad: 0.0275 
Train Epoch: 76 [468/684 (68%)] loss: 0.0305 L_si: 0.0057 L_grad: 0.0248 
Train Epoch: 76 [504/684 (74%)] loss: 0.0550 L_si: 0.0225 L_grad: 0.0325 
Train Epoch: 76 [540/684 (79%)] loss: 0.0360 L_si: 0.0078 L_grad: 0.0282 
Train Epoch: 76 [576/684 (84%)] loss: 0.0420 L_si: 0.0142 L_grad: 0.0277 
Train Epoch: 76 [612/684 (89%)] loss: 0.0473 L_si: 0.0150 L_grad: 0.0324 
Train Epoch: 76 [648/684 (95%)] loss: 0.0384 L_si: 0.0127 L_grad: 0.0257 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009000315330922604, 0.010849937796592712, 0.021036295220255852, 0.038262199610471725, 0.013499749824404716, 0.01787520758807659, 0.009284380823373795, 0.013326500542461872, 0.01207773294299841, 0.011664081364870071, 0.00987593736499548, 0.00980391725897789, 0.05211002007126808, 0.015175048261880875, 0.01566224917769432], 'L_si': [0.0007758736610412598, 0.0011714622378349304, 0.007118754088878632, 0.015679314732551575, 0.0021785125136375427, 0.0036635100841522217, 0.0007923319935798645, 0.0021212399005889893, 0.0015693902969360352, 0.0017381832003593445, 0.0013055503368377686, 0.0009009316563606262, 0.023021236062049866, 0.003305688500404358, 0.0033929795026779175], 'L_grad': [0.008224441669881344, 0.009678475558757782, 0.01391754113137722, 0.02258288487792015, 0.011321237310767174, 0.01421169750392437, 0.00849204882979393, 0.011205260641872883, 0.010508342646062374, 0.009925898164510727, 0.008570387028157711, 0.008902985602617264, 0.029088784009218216, 0.011869359761476517, 0.012269268743693829]}
Train Epoch: 77 [0/684 (0%)] loss: 0.0366 L_si: 0.0109 L_grad: 0.0257 
Train Epoch: 77 [36/684 (5%)] loss: 0.0600 L_si: 0.0187 L_grad: 0.0413 
Train Epoch: 77 [72/684 (11%)] loss: 0.0345 L_si: 0.0119 L_grad: 0.0226 
Train Epoch: 77 [108/684 (16%)] loss: 0.0501 L_si: 0.0149 L_grad: 0.0353 
Train Epoch: 77 [144/684 (21%)] loss: 0.0413 L_si: 0.0148 L_grad: 0.0265 
Train Epoch: 77 [180/684 (26%)] loss: 0.0235 L_si: 0.0065 L_grad: 0.0171 
Train Epoch: 77 [216/684 (32%)] loss: 0.0641 L_si: 0.0273 L_grad: 0.0369 
Train Epoch: 77 [252/684 (37%)] loss: 0.0367 L_si: 0.0086 L_grad: 0.0281 
Train Epoch: 77 [288/684 (42%)] loss: 0.0503 L_si: 0.0172 L_grad: 0.0331 
Train Epoch: 77 [324/684 (47%)] loss: 0.0537 L_si: 0.0169 L_grad: 0.0368 
Train Epoch: 77 [360/684 (53%)] loss: 0.0532 L_si: 0.0272 L_grad: 0.0261 
Train Epoch: 77 [396/684 (58%)] loss: 0.0364 L_si: 0.0116 L_grad: 0.0248 
Train Epoch: 77 [432/684 (63%)] loss: 0.0759 L_si: 0.0363 L_grad: 0.0396 
Train Epoch: 77 [468/684 (68%)] loss: 0.0463 L_si: 0.0165 L_grad: 0.0298 
Train Epoch: 77 [504/684 (74%)] loss: 0.0189 L_si: 0.0031 L_grad: 0.0158 
Train Epoch: 77 [540/684 (79%)] loss: 0.0570 L_si: 0.0198 L_grad: 0.0372 
Train Epoch: 77 [576/684 (84%)] loss: 0.0355 L_si: 0.0080 L_grad: 0.0276 
Train Epoch: 77 [612/684 (89%)] loss: 0.0219 L_si: 0.0040 L_grad: 0.0179 
Train Epoch: 77 [648/684 (95%)] loss: 0.0155 L_si: 0.0024 L_grad: 0.0132 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.02430924028158188, 0.01191643625497818, 0.008022398687899113, 0.022238457575440407, 0.014122984372079372, 0.026917850598692894, 0.01192512921988964, 0.021682899445295334, 0.02544296532869339, 0.020676858723163605, 0.018249431625008583, 0.016666574403643608, 0.01677730493247509, 0.013199743814766407, 0.013181688264012337], 'L_si': [0.009177841246128082, 0.0017719343304634094, 0.0010150596499443054, 0.007787026464939117, 0.002628408372402191, 0.009965553879737854, 0.0020058900117874146, 0.007429666817188263, 0.009424269199371338, 0.0069077834486961365, 0.004176586866378784, 0.003681749105453491, 0.003957197070121765, 0.002042710781097412, 0.0022719725966453552], 'L_grad': [0.015131399035453796, 0.01014450192451477, 0.007007339037954807, 0.01445143111050129, 0.011494575999677181, 0.01695229671895504, 0.009919239208102226, 0.014253231696784496, 0.016018696129322052, 0.013769074343144894, 0.014072844758629799, 0.012984825298190117, 0.012820107862353325, 0.011157033033668995, 0.010909715667366982]}
Train Epoch: 78 [0/684 (0%)] loss: 0.0507 L_si: 0.0172 L_grad: 0.0335 
Train Epoch: 78 [36/684 (5%)] loss: 0.0521 L_si: 0.0180 L_grad: 0.0341 
Train Epoch: 78 [72/684 (11%)] loss: 0.0196 L_si: 0.0028 L_grad: 0.0169 
Train Epoch: 78 [108/684 (16%)] loss: 0.0251 L_si: 0.0070 L_grad: 0.0181 
Train Epoch: 78 [144/684 (21%)] loss: 0.0282 L_si: 0.0046 L_grad: 0.0236 
Train Epoch: 78 [180/684 (26%)] loss: 0.0553 L_si: 0.0203 L_grad: 0.0350 
Train Epoch: 78 [216/684 (32%)] loss: 0.0726 L_si: 0.0300 L_grad: 0.0425 
Train Epoch: 78 [252/684 (37%)] loss: 0.0546 L_si: 0.0225 L_grad: 0.0321 
Train Epoch: 78 [288/684 (42%)] loss: 0.0310 L_si: 0.0060 L_grad: 0.0249 
Train Epoch: 78 [324/684 (47%)] loss: 0.0268 L_si: 0.0053 L_grad: 0.0214 
Train Epoch: 78 [360/684 (53%)] loss: 0.0601 L_si: 0.0286 L_grad: 0.0316 
Train Epoch: 78 [396/684 (58%)] loss: 0.0273 L_si: 0.0068 L_grad: 0.0205 
Train Epoch: 78 [432/684 (63%)] loss: 0.0458 L_si: 0.0164 L_grad: 0.0293 
Train Epoch: 78 [468/684 (68%)] loss: 0.0726 L_si: 0.0253 L_grad: 0.0473 
Train Epoch: 78 [504/684 (74%)] loss: 0.0186 L_si: 0.0033 L_grad: 0.0154 
Train Epoch: 78 [540/684 (79%)] loss: 0.0317 L_si: 0.0111 L_grad: 0.0206 
Train Epoch: 78 [576/684 (84%)] loss: 0.0384 L_si: 0.0111 L_grad: 0.0274 
Train Epoch: 78 [612/684 (89%)] loss: 0.0865 L_si: 0.0376 L_grad: 0.0489 
Train Epoch: 78 [648/684 (95%)] loss: 0.0701 L_si: 0.0263 L_grad: 0.0438 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.013294290751218796, 0.021240809932351112, 0.009856780990958214, 0.015448731370270252, 0.025235287845134735, 0.010440491139888763, 0.026790518313646317, 0.009963221848011017, 0.020527837797999382, 0.02593005821108818, 0.010522897355258465, 0.02520757168531418, 0.013543818145990372, 0.010013754479587078, 0.018366539850831032], 'L_si': [0.0020146965980529785, 0.006634540855884552, 0.0014586597681045532, 0.0034789294004440308, 0.009812146425247192, 0.0009791404008865356, 0.010294146835803986, 0.0016497969627380371, 0.0068679675459861755, 0.008891627192497253, 0.001683846116065979, 0.010125793516635895, 0.002103842794895172, 0.0012798383831977844, 0.004482753574848175], 'L_grad': [0.011279594153165817, 0.01460626907646656, 0.00839812122285366, 0.011969801969826221, 0.015423140488564968, 0.009461350739002228, 0.01649637147784233, 0.00831342488527298, 0.013659870252013206, 0.017038431018590927, 0.008839051239192486, 0.015081778168678284, 0.0114399753510952, 0.008733916096389294, 0.013883786275982857]}
Train Epoch: 79 [0/684 (0%)] loss: 0.0480 L_si: 0.0189 L_grad: 0.0291 
Train Epoch: 79 [36/684 (5%)] loss: 0.0438 L_si: 0.0160 L_grad: 0.0279 
Train Epoch: 79 [72/684 (11%)] loss: 0.0746 L_si: 0.0303 L_grad: 0.0444 
Train Epoch: 79 [108/684 (16%)] loss: 0.0318 L_si: 0.0105 L_grad: 0.0213 
Train Epoch: 79 [144/684 (21%)] loss: 0.0326 L_si: 0.0120 L_grad: 0.0206 
Train Epoch: 79 [180/684 (26%)] loss: 0.0577 L_si: 0.0179 L_grad: 0.0398 
Train Epoch: 79 [216/684 (32%)] loss: 0.0483 L_si: 0.0160 L_grad: 0.0323 
Train Epoch: 79 [252/684 (37%)] loss: 0.0393 L_si: 0.0102 L_grad: 0.0291 
Train Epoch: 79 [288/684 (42%)] loss: 0.0792 L_si: 0.0334 L_grad: 0.0458 
Train Epoch: 79 [324/684 (47%)] loss: 0.0400 L_si: 0.0176 L_grad: 0.0224 
Train Epoch: 79 [360/684 (53%)] loss: 0.0324 L_si: 0.0100 L_grad: 0.0224 
Train Epoch: 79 [396/684 (58%)] loss: 0.0452 L_si: 0.0169 L_grad: 0.0283 
Train Epoch: 79 [432/684 (63%)] loss: 0.0486 L_si: 0.0160 L_grad: 0.0326 
Train Epoch: 79 [468/684 (68%)] loss: 0.0392 L_si: 0.0114 L_grad: 0.0278 
Train Epoch: 79 [504/684 (74%)] loss: 0.0409 L_si: 0.0105 L_grad: 0.0304 
Train Epoch: 79 [540/684 (79%)] loss: 0.0302 L_si: 0.0072 L_grad: 0.0230 
Train Epoch: 79 [576/684 (84%)] loss: 0.0286 L_si: 0.0056 L_grad: 0.0230 
Train Epoch: 79 [612/684 (89%)] loss: 0.0751 L_si: 0.0301 L_grad: 0.0450 
Train Epoch: 79 [648/684 (95%)] loss: 0.0391 L_si: 0.0104 L_grad: 0.0287 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009959593415260315, 0.009956726804375648, 0.010549472644925117, 0.019479071721434593, 0.03032342903316021, 0.018889449536800385, 0.009334053844213486, 0.01643494889140129, 0.024135161191225052, 0.029920140281319618, 0.01235107146203518, 0.011577188037335873, 0.010270563885569572, 0.025754788890480995, 0.010269767604768276], 'L_si': [0.001250721514225006, 0.001037009060382843, 0.0010031834244728088, 0.004108592867851257, 0.011307232081890106, 0.006115563213825226, 0.0014569088816642761, 0.0031510964035987854, 0.009197823703289032, 0.011629343032836914, 0.0015316754579544067, 0.0015542879700660706, 0.0015760138630867004, 0.009769178926944733, 0.001210331916809082], 'L_grad': [0.008708871901035309, 0.008919717743992805, 0.009546289220452309, 0.015370478853583336, 0.019016196951270103, 0.012773885391652584, 0.00787714496254921, 0.01328385341912508, 0.01493733748793602, 0.018290797248482704, 0.010819396004080772, 0.010022900067269802, 0.008694550022482872, 0.015985609963536263, 0.009059435687959194]}
Train Epoch: 80 [0/684 (0%)] loss: 0.0239 L_si: 0.0054 L_grad: 0.0185 
Train Epoch: 80 [36/684 (5%)] loss: 0.0328 L_si: 0.0074 L_grad: 0.0254 
Train Epoch: 80 [72/684 (11%)] loss: 0.0499 L_si: 0.0158 L_grad: 0.0341 
Train Epoch: 80 [108/684 (16%)] loss: 0.0227 L_si: 0.0046 L_grad: 0.0182 
Train Epoch: 80 [144/684 (21%)] loss: 0.0389 L_si: 0.0113 L_grad: 0.0275 
Train Epoch: 80 [180/684 (26%)] loss: 0.0625 L_si: 0.0231 L_grad: 0.0395 
Train Epoch: 80 [216/684 (32%)] loss: 0.0475 L_si: 0.0173 L_grad: 0.0303 
Train Epoch: 80 [252/684 (37%)] loss: 0.0497 L_si: 0.0151 L_grad: 0.0346 
Train Epoch: 80 [288/684 (42%)] loss: 0.0354 L_si: 0.0099 L_grad: 0.0255 
Train Epoch: 80 [324/684 (47%)] loss: 0.0469 L_si: 0.0202 L_grad: 0.0267 
Train Epoch: 80 [360/684 (53%)] loss: 0.0294 L_si: 0.0080 L_grad: 0.0214 
Train Epoch: 80 [396/684 (58%)] loss: 0.0546 L_si: 0.0208 L_grad: 0.0338 
Train Epoch: 80 [432/684 (63%)] loss: 0.0442 L_si: 0.0144 L_grad: 0.0298 
Train Epoch: 80 [468/684 (68%)] loss: 0.0600 L_si: 0.0217 L_grad: 0.0383 
Train Epoch: 80 [504/684 (74%)] loss: 0.0596 L_si: 0.0245 L_grad: 0.0351 
Train Epoch: 80 [540/684 (79%)] loss: 0.0688 L_si: 0.0323 L_grad: 0.0365 
Train Epoch: 80 [576/684 (84%)] loss: 0.0447 L_si: 0.0152 L_grad: 0.0295 
Train Epoch: 80 [612/684 (89%)] loss: 0.0542 L_si: 0.0162 L_grad: 0.0381 
Train Epoch: 80 [648/684 (95%)] loss: 0.0366 L_si: 0.0102 L_grad: 0.0264 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch080-loss-0.0440.pth.tar ...
all losses in batch in validation:  {'loss': [0.01652950793504715, 0.03704313561320305, 0.013555388897657394, 0.012515006586909294, 0.022828737273812294, 0.012688877061009407, 0.013742233626544476, 0.01980314776301384, 0.02297876589000225, 0.024149106815457344, 0.011341609060764313, 0.01212720200419426, 0.026959717273712158, 0.010066220536828041, 0.023896582424640656], 'L_si': [0.0034332871437072754, 0.014837421476840973, 0.0029748082160949707, 0.0014316365122795105, 0.0075518786907196045, 0.0020151734352111816, 0.0037946850061416626, 0.006661944091320038, 0.0057896822690963745, 0.008951790630817413, 0.002276398241519928, 0.0019979923963546753, 0.010177373886108398, 0.0013482049107551575, 0.008979640901088715], 'L_grad': [0.013096221722662449, 0.022205714136362076, 0.010580580681562424, 0.011083370074629784, 0.01527685858309269, 0.010673703625798225, 0.009947548620402813, 0.013141204603016376, 0.017189083620905876, 0.01519731618463993, 0.009065210819244385, 0.010129209607839584, 0.01678234338760376, 0.008718015626072884, 0.014916941523551941]}
Train Epoch: 81 [0/684 (0%)] loss: 0.0208 L_si: 0.0032 L_grad: 0.0176 
Train Epoch: 81 [36/684 (5%)] loss: 0.0407 L_si: 0.0120 L_grad: 0.0286 
Train Epoch: 81 [72/684 (11%)] loss: 0.0302 L_si: 0.0063 L_grad: 0.0239 
Train Epoch: 81 [108/684 (16%)] loss: 0.0478 L_si: 0.0183 L_grad: 0.0295 
Train Epoch: 81 [144/684 (21%)] loss: 0.0225 L_si: 0.0041 L_grad: 0.0184 
Train Epoch: 81 [180/684 (26%)] loss: 0.0535 L_si: 0.0202 L_grad: 0.0333 
Train Epoch: 81 [216/684 (32%)] loss: 0.0181 L_si: 0.0045 L_grad: 0.0136 
Train Epoch: 81 [252/684 (37%)] loss: 0.0682 L_si: 0.0254 L_grad: 0.0428 
Train Epoch: 81 [288/684 (42%)] loss: 0.0704 L_si: 0.0238 L_grad: 0.0466 
Train Epoch: 81 [324/684 (47%)] loss: 0.0548 L_si: 0.0201 L_grad: 0.0347 
Train Epoch: 81 [360/684 (53%)] loss: 0.0594 L_si: 0.0228 L_grad: 0.0366 
Train Epoch: 81 [396/684 (58%)] loss: 0.0546 L_si: 0.0181 L_grad: 0.0365 
Train Epoch: 81 [432/684 (63%)] loss: 0.0672 L_si: 0.0327 L_grad: 0.0346 
Train Epoch: 81 [468/684 (68%)] loss: 0.0220 L_si: 0.0043 L_grad: 0.0177 
Train Epoch: 81 [504/684 (74%)] loss: 0.0184 L_si: 0.0025 L_grad: 0.0159 
Train Epoch: 81 [540/684 (79%)] loss: 0.0347 L_si: 0.0101 L_grad: 0.0246 
Train Epoch: 81 [576/684 (84%)] loss: 0.0198 L_si: 0.0042 L_grad: 0.0155 
Train Epoch: 81 [612/684 (89%)] loss: 0.0469 L_si: 0.0181 L_grad: 0.0287 
Train Epoch: 81 [648/684 (95%)] loss: 0.0642 L_si: 0.0243 L_grad: 0.0399 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.02534228377044201, 0.015577330254018307, 0.009409312158823013, 0.025723079219460487, 0.009678641334176064, 0.025704776868224144, 0.015914227813482285, 0.008748108521103859, 0.02897365763783455, 0.0147999357432127, 0.010452665388584137, 0.008811596781015396, 0.009655013680458069, 0.008815458044409752, 0.021423542872071266], 'L_si': [0.009189769625663757, 0.0032422468066215515, 0.0012797340750694275, 0.009420245885848999, 0.0011213943362236023, 0.009676046669483185, 0.0034430846571922302, 0.0009292438626289368, 0.011015184223651886, 0.003238096833229065, 0.0009629130363464355, 0.0011034831404685974, 0.0007542967796325684, 0.0010091587901115417, 0.0068491920828819275], 'L_grad': [0.01615251414477825, 0.012335083447396755, 0.008129578083753586, 0.01630283333361149, 0.008557246997952461, 0.01602873019874096, 0.012471143156290054, 0.007818864658474922, 0.017958473414182663, 0.011561838909983635, 0.009489752352237701, 0.007708113640546799, 0.0089007169008255, 0.007806298788636923, 0.014574350789189339]}
Train Epoch: 82 [0/684 (0%)] loss: 0.0339 L_si: 0.0105 L_grad: 0.0234 
Train Epoch: 82 [36/684 (5%)] loss: 0.0406 L_si: 0.0150 L_grad: 0.0256 
Train Epoch: 82 [72/684 (11%)] loss: 0.0485 L_si: 0.0147 L_grad: 0.0339 
Train Epoch: 82 [108/684 (16%)] loss: 0.0210 L_si: 0.0039 L_grad: 0.0171 
Train Epoch: 82 [144/684 (21%)] loss: 0.0579 L_si: 0.0232 L_grad: 0.0346 
Train Epoch: 82 [180/684 (26%)] loss: 0.0545 L_si: 0.0198 L_grad: 0.0347 
Train Epoch: 82 [216/684 (32%)] loss: 0.0584 L_si: 0.0204 L_grad: 0.0380 
Train Epoch: 82 [252/684 (37%)] loss: 0.0589 L_si: 0.0208 L_grad: 0.0381 
Train Epoch: 82 [288/684 (42%)] loss: 0.0185 L_si: 0.0038 L_grad: 0.0147 
Train Epoch: 82 [324/684 (47%)] loss: 0.0611 L_si: 0.0219 L_grad: 0.0392 
Train Epoch: 82 [360/684 (53%)] loss: 0.0394 L_si: 0.0161 L_grad: 0.0233 
Train Epoch: 82 [396/684 (58%)] loss: 0.0187 L_si: 0.0027 L_grad: 0.0160 
Train Epoch: 82 [432/684 (63%)] loss: 0.0471 L_si: 0.0195 L_grad: 0.0276 
Train Epoch: 82 [468/684 (68%)] loss: 0.0226 L_si: 0.0044 L_grad: 0.0182 
Train Epoch: 82 [504/684 (74%)] loss: 0.0198 L_si: 0.0033 L_grad: 0.0165 
Train Epoch: 82 [540/684 (79%)] loss: 0.0385 L_si: 0.0125 L_grad: 0.0261 
Train Epoch: 82 [576/684 (84%)] loss: 0.0212 L_si: 0.0041 L_grad: 0.0171 
Train Epoch: 82 [612/684 (89%)] loss: 0.0533 L_si: 0.0230 L_grad: 0.0303 
Train Epoch: 82 [648/684 (95%)] loss: 0.0384 L_si: 0.0081 L_grad: 0.0303 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009845889173448086, 0.012343693524599075, 0.020830433815717697, 0.008799400180578232, 0.009638362564146519, 0.024624187499284744, 0.018929358571767807, 0.010761808604001999, 0.020953115075826645, 0.024570021778345108, 0.015132483094930649, 0.03266574442386627, 0.01640333980321884, 0.010607661679387093, 0.010216223075985909], 'L_si': [0.0009563341736793518, 0.001629367470741272, 0.006605133414268494, 0.001187935471534729, 0.0010335296392440796, 0.009113684296607971, 0.006058640778064728, 0.0013849735260009766, 0.006669782102108002, 0.008862294256687164, 0.003581725060939789, 0.012259334325790405, 0.003630414605140686, 0.0014259368181228638, 0.0011583566665649414], 'L_grad': [0.008889554999768734, 0.010714326053857803, 0.014225300401449203, 0.007611464709043503, 0.008604832924902439, 0.015510503202676773, 0.012870716862380505, 0.009376835078001022, 0.014283332973718643, 0.015707727521657944, 0.01155075803399086, 0.020406408235430717, 0.01277292612940073, 0.009181724861264229, 0.009057866409420967]}
Train Epoch: 83 [0/684 (0%)] loss: 0.0381 L_si: 0.0105 L_grad: 0.0277 
Train Epoch: 83 [36/684 (5%)] loss: 0.0808 L_si: 0.0330 L_grad: 0.0478 
Train Epoch: 83 [72/684 (11%)] loss: 0.0291 L_si: 0.0071 L_grad: 0.0219 
Train Epoch: 83 [108/684 (16%)] loss: 0.0365 L_si: 0.0086 L_grad: 0.0279 
Train Epoch: 83 [144/684 (21%)] loss: 0.0351 L_si: 0.0084 L_grad: 0.0266 
Train Epoch: 83 [180/684 (26%)] loss: 0.0380 L_si: 0.0109 L_grad: 0.0272 
Train Epoch: 83 [216/684 (32%)] loss: 0.0448 L_si: 0.0178 L_grad: 0.0270 
Train Epoch: 83 [252/684 (37%)] loss: 0.0355 L_si: 0.0077 L_grad: 0.0278 
Train Epoch: 83 [288/684 (42%)] loss: 0.0550 L_si: 0.0249 L_grad: 0.0302 
Train Epoch: 83 [324/684 (47%)] loss: 0.0272 L_si: 0.0050 L_grad: 0.0222 
Train Epoch: 83 [360/684 (53%)] loss: 0.0168 L_si: 0.0027 L_grad: 0.0141 
Train Epoch: 83 [396/684 (58%)] loss: 0.0298 L_si: 0.0069 L_grad: 0.0229 
Train Epoch: 83 [432/684 (63%)] loss: 0.0215 L_si: 0.0031 L_grad: 0.0184 
Train Epoch: 83 [468/684 (68%)] loss: 0.0273 L_si: 0.0073 L_grad: 0.0200 
Train Epoch: 83 [504/684 (74%)] loss: 0.0609 L_si: 0.0225 L_grad: 0.0384 
Train Epoch: 83 [540/684 (79%)] loss: 0.0819 L_si: 0.0454 L_grad: 0.0365 
Train Epoch: 83 [576/684 (84%)] loss: 0.0625 L_si: 0.0207 L_grad: 0.0417 
Train Epoch: 83 [612/684 (89%)] loss: 0.0498 L_si: 0.0169 L_grad: 0.0329 
Train Epoch: 83 [648/684 (95%)] loss: 0.0247 L_si: 0.0063 L_grad: 0.0184 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008985551074147224, 0.011526880785822868, 0.010618397034704685, 0.00874584075063467, 0.029594505205750465, 0.025371044874191284, 0.019456690177321434, 0.010673951357603073, 0.014338511973619461, 0.0357150174677372, 0.01227078028023243, 0.010530881583690643, 0.008869724348187447, 0.015283193439245224, 0.019394630566239357], 'L_si': [0.0008551329374313354, 0.00206737220287323, 0.0013357773423194885, 0.0009946301579475403, 0.010905355215072632, 0.009013883769512177, 0.006194457411766052, 0.0014309585094451904, 0.003188610076904297, 0.014492876827716827, 0.0022243186831474304, 0.001169733703136444, 0.000874049961566925, 0.003429502248764038, 0.006526634097099304], 'L_grad': [0.008130418136715889, 0.009459508582949638, 0.009282619692385197, 0.00775121059268713, 0.018689149990677834, 0.016357161104679108, 0.013262232765555382, 0.009242992848157883, 0.011149901896715164, 0.02122214064002037, 0.010046461597084999, 0.0093611478805542, 0.007995674386620522, 0.011853691190481186, 0.012867996469140053]}
Train Epoch: 84 [0/684 (0%)] loss: 0.0637 L_si: 0.0332 L_grad: 0.0306 
Train Epoch: 84 [36/684 (5%)] loss: 0.0597 L_si: 0.0274 L_grad: 0.0322 
Train Epoch: 84 [72/684 (11%)] loss: 0.0271 L_si: 0.0052 L_grad: 0.0219 
Train Epoch: 84 [108/684 (16%)] loss: 0.0447 L_si: 0.0157 L_grad: 0.0290 
Train Epoch: 84 [144/684 (21%)] loss: 0.0317 L_si: 0.0078 L_grad: 0.0238 
Train Epoch: 84 [180/684 (26%)] loss: 0.0864 L_si: 0.0368 L_grad: 0.0496 
Train Epoch: 84 [216/684 (32%)] loss: 0.0316 L_si: 0.0092 L_grad: 0.0224 
Train Epoch: 84 [252/684 (37%)] loss: 0.0414 L_si: 0.0124 L_grad: 0.0290 
Train Epoch: 84 [288/684 (42%)] loss: 0.0480 L_si: 0.0204 L_grad: 0.0276 
Train Epoch: 84 [324/684 (47%)] loss: 0.0487 L_si: 0.0203 L_grad: 0.0284 
Train Epoch: 84 [360/684 (53%)] loss: 0.0450 L_si: 0.0117 L_grad: 0.0333 
Train Epoch: 84 [396/684 (58%)] loss: 0.0256 L_si: 0.0058 L_grad: 0.0198 
Train Epoch: 84 [432/684 (63%)] loss: 0.0574 L_si: 0.0193 L_grad: 0.0381 
Train Epoch: 84 [468/684 (68%)] loss: 0.0421 L_si: 0.0125 L_grad: 0.0295 
Train Epoch: 84 [504/684 (74%)] loss: 0.0479 L_si: 0.0159 L_grad: 0.0320 
Train Epoch: 84 [540/684 (79%)] loss: 0.0216 L_si: 0.0058 L_grad: 0.0158 
Train Epoch: 84 [576/684 (84%)] loss: 0.0463 L_si: 0.0166 L_grad: 0.0296 
Train Epoch: 84 [612/684 (89%)] loss: 0.0451 L_si: 0.0165 L_grad: 0.0286 
Train Epoch: 84 [648/684 (95%)] loss: 0.0316 L_si: 0.0061 L_grad: 0.0255 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.03539275377988815, 0.010442771017551422, 0.029668059200048447, 0.0095259053632617, 0.015889808535575867, 0.026705976575613022, 0.021000392735004425, 0.011076295748353004, 0.010670194402337074, 0.008906858041882515, 0.01674373261630535, 0.009227212518453598, 0.009670618921518326, 0.0199759341776371, 0.010322829708456993], 'L_si': [0.014713093638420105, 0.0011984407901763916, 0.011457055807113647, 0.0012257024645805359, 0.0034748613834381104, 0.00972362607717514, 0.007352031767368317, 0.0010892003774642944, 0.0014864206314086914, 0.001033499836921692, 0.0034641772508621216, 0.0009279027581214905, 0.001316957175731659, 0.006338551640510559, 0.0012275874614715576], 'L_grad': [0.020679662004113197, 0.00924433022737503, 0.0182110033929348, 0.008300202898681164, 0.012414946220815182, 0.01698235049843788, 0.013648361898958683, 0.00998709537088871, 0.009183773770928383, 0.007873358204960823, 0.01327955536544323, 0.008299309760332108, 0.008353661745786667, 0.013637382537126541, 0.009095242246985435]}
Train Epoch: 85 [0/684 (0%)] loss: 0.0368 L_si: 0.0099 L_grad: 0.0269 
Train Epoch: 85 [36/684 (5%)] loss: 0.0674 L_si: 0.0311 L_grad: 0.0364 
Train Epoch: 85 [72/684 (11%)] loss: 0.0441 L_si: 0.0126 L_grad: 0.0315 
Train Epoch: 85 [108/684 (16%)] loss: 0.0350 L_si: 0.0079 L_grad: 0.0271 
Train Epoch: 85 [144/684 (21%)] loss: 0.0534 L_si: 0.0203 L_grad: 0.0331 
Train Epoch: 85 [180/684 (26%)] loss: 0.0483 L_si: 0.0191 L_grad: 0.0292 
Train Epoch: 85 [216/684 (32%)] loss: 0.0435 L_si: 0.0127 L_grad: 0.0308 
Train Epoch: 85 [252/684 (37%)] loss: 0.0471 L_si: 0.0168 L_grad: 0.0304 
Train Epoch: 85 [288/684 (42%)] loss: 0.0553 L_si: 0.0201 L_grad: 0.0351 
Train Epoch: 85 [324/684 (47%)] loss: 0.0620 L_si: 0.0228 L_grad: 0.0392 
Train Epoch: 85 [360/684 (53%)] loss: 0.0406 L_si: 0.0112 L_grad: 0.0294 
Train Epoch: 85 [396/684 (58%)] loss: 0.0423 L_si: 0.0149 L_grad: 0.0274 
Train Epoch: 85 [432/684 (63%)] loss: 0.0434 L_si: 0.0117 L_grad: 0.0316 
Train Epoch: 85 [468/684 (68%)] loss: 0.0437 L_si: 0.0164 L_grad: 0.0273 
Train Epoch: 85 [504/684 (74%)] loss: 0.0516 L_si: 0.0129 L_grad: 0.0387 
Train Epoch: 85 [540/684 (79%)] loss: 0.0507 L_si: 0.0129 L_grad: 0.0378 
Train Epoch: 85 [576/684 (84%)] loss: 0.0294 L_si: 0.0088 L_grad: 0.0206 
Train Epoch: 85 [612/684 (89%)] loss: 0.0455 L_si: 0.0207 L_grad: 0.0248 
Train Epoch: 85 [648/684 (95%)] loss: 0.0430 L_si: 0.0116 L_grad: 0.0314 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.012018095701932907, 0.04170059785246849, 0.01128587406128645, 0.02651514858007431, 0.017381444573402405, 0.010125778615474701, 0.019309647381305695, 0.02058395743370056, 0.017215557396411896, 0.012083230540156364, 0.013226866722106934, 0.011463296599686146, 0.009573474526405334, 0.010998722165822983, 0.02653152495622635], 'L_si': [0.0017779096961021423, 0.018023036420345306, 0.001971028745174408, 0.009461432695388794, 0.003997057676315308, 0.001554630696773529, 0.0063760653138160706, 0.006795041263103485, 0.003435872495174408, 0.002498343586921692, 0.0026222020387649536, 0.0015305355191230774, 0.0011033564805984497, 0.0014612749218940735, 0.008882656693458557], 'L_grad': [0.010240186005830765, 0.023677561432123184, 0.009314845316112041, 0.017053715884685516, 0.013384385965764523, 0.008571147918701172, 0.01293358113616705, 0.013788916170597076, 0.013779685832560062, 0.009584886953234673, 0.01060466468334198, 0.009932761080563068, 0.008470118045806885, 0.00953744724392891, 0.017648868262767792]}
Train Epoch: 86 [0/684 (0%)] loss: 0.0566 L_si: 0.0205 L_grad: 0.0361 
Train Epoch: 86 [36/684 (5%)] loss: 0.0573 L_si: 0.0235 L_grad: 0.0338 
Train Epoch: 86 [72/684 (11%)] loss: 0.0663 L_si: 0.0252 L_grad: 0.0411 
Train Epoch: 86 [108/684 (16%)] loss: 0.0347 L_si: 0.0099 L_grad: 0.0248 
Train Epoch: 86 [144/684 (21%)] loss: 0.0238 L_si: 0.0046 L_grad: 0.0192 
Train Epoch: 86 [180/684 (26%)] loss: 0.0330 L_si: 0.0070 L_grad: 0.0260 
Train Epoch: 86 [216/684 (32%)] loss: 0.0454 L_si: 0.0151 L_grad: 0.0303 
Train Epoch: 86 [252/684 (37%)] loss: 0.0382 L_si: 0.0079 L_grad: 0.0303 
Train Epoch: 86 [288/684 (42%)] loss: 0.0392 L_si: 0.0122 L_grad: 0.0270 
Train Epoch: 86 [324/684 (47%)] loss: 0.0577 L_si: 0.0260 L_grad: 0.0317 
Train Epoch: 86 [360/684 (53%)] loss: 0.0347 L_si: 0.0095 L_grad: 0.0251 
Train Epoch: 86 [396/684 (58%)] loss: 0.0477 L_si: 0.0219 L_grad: 0.0258 
Train Epoch: 86 [432/684 (63%)] loss: 0.0881 L_si: 0.0325 L_grad: 0.0556 
Train Epoch: 86 [468/684 (68%)] loss: 0.0388 L_si: 0.0123 L_grad: 0.0265 
Train Epoch: 86 [504/684 (74%)] loss: 0.0441 L_si: 0.0171 L_grad: 0.0270 
Train Epoch: 86 [540/684 (79%)] loss: 0.0731 L_si: 0.0285 L_grad: 0.0446 
Train Epoch: 86 [576/684 (84%)] loss: 0.0386 L_si: 0.0170 L_grad: 0.0216 
Train Epoch: 86 [612/684 (89%)] loss: 0.0456 L_si: 0.0198 L_grad: 0.0258 
Train Epoch: 86 [648/684 (95%)] loss: 0.0745 L_si: 0.0306 L_grad: 0.0439 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009947712533175945, 0.009935838170349598, 0.04530896991491318, 0.010311668738722801, 0.012145580723881721, 0.014130331575870514, 0.010540937073528767, 0.017973199486732483, 0.009783733636140823, 0.02529148757457733, 0.009704053401947021, 0.03558454290032387, 0.009891266003251076, 0.009754113852977753, 0.008563629351556301], 'L_si': [0.001167982816696167, 0.0010977089405059814, 0.019379541277885437, 0.0011185631155967712, 0.0019325613975524902, 0.003103479743003845, 0.001215025782585144, 0.005949534475803375, 0.001170031726360321, 0.009410977363586426, 0.0011356472969055176, 0.013550467789173126, 0.00122910737991333, 0.0012068673968315125, 0.0007328018546104431], 'L_grad': [0.008779729716479778, 0.008838129229843616, 0.02592942863702774, 0.00919310562312603, 0.010213019326329231, 0.011026851832866669, 0.009325911290943623, 0.012023665942251682, 0.008613701909780502, 0.015880510210990906, 0.008568406105041504, 0.02203407511115074, 0.008662158623337746, 0.00854724645614624, 0.007830827496945858]}
Train Epoch: 87 [0/684 (0%)] loss: 0.0476 L_si: 0.0197 L_grad: 0.0279 
Train Epoch: 87 [36/684 (5%)] loss: 0.0382 L_si: 0.0087 L_grad: 0.0295 
Train Epoch: 87 [72/684 (11%)] loss: 0.0357 L_si: 0.0120 L_grad: 0.0237 
Train Epoch: 87 [108/684 (16%)] loss: 0.0564 L_si: 0.0202 L_grad: 0.0363 
Train Epoch: 87 [144/684 (21%)] loss: 0.0419 L_si: 0.0159 L_grad: 0.0260 
Train Epoch: 87 [180/684 (26%)] loss: 0.0743 L_si: 0.0338 L_grad: 0.0406 
Train Epoch: 87 [216/684 (32%)] loss: 0.0435 L_si: 0.0133 L_grad: 0.0302 
Train Epoch: 87 [252/684 (37%)] loss: 0.0278 L_si: 0.0071 L_grad: 0.0206 
Train Epoch: 87 [288/684 (42%)] loss: 0.0400 L_si: 0.0110 L_grad: 0.0290 
Train Epoch: 87 [324/684 (47%)] loss: 0.0546 L_si: 0.0210 L_grad: 0.0336 
Train Epoch: 87 [360/684 (53%)] loss: 0.0526 L_si: 0.0204 L_grad: 0.0322 
Train Epoch: 87 [396/684 (58%)] loss: 0.0374 L_si: 0.0107 L_grad: 0.0268 
Train Epoch: 87 [432/684 (63%)] loss: 0.0393 L_si: 0.0166 L_grad: 0.0227 
Train Epoch: 87 [468/684 (68%)] loss: 0.0422 L_si: 0.0149 L_grad: 0.0273 
Train Epoch: 87 [504/684 (74%)] loss: 0.0795 L_si: 0.0350 L_grad: 0.0445 
Train Epoch: 87 [540/684 (79%)] loss: 0.0445 L_si: 0.0111 L_grad: 0.0334 
Train Epoch: 87 [576/684 (84%)] loss: 0.0358 L_si: 0.0127 L_grad: 0.0230 
Train Epoch: 87 [612/684 (89%)] loss: 0.0816 L_si: 0.0284 L_grad: 0.0532 
Train Epoch: 87 [648/684 (95%)] loss: 0.0481 L_si: 0.0164 L_grad: 0.0317 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.014987591654062271, 0.011204754933714867, 0.024901486933231354, 0.025498133152723312, 0.014391077682375908, 0.010767421685159206, 0.01249248068779707, 0.009214607998728752, 0.009527754038572311, 0.028123024851083755, 0.008951427415013313, 0.01975792646408081, 0.010105987079441547, 0.011235319077968597, 0.03432349115610123], 'L_si': [0.003413461148738861, 0.001616545021533966, 0.008856840431690216, 0.009439878165721893, 0.003334321081638336, 0.001381009817123413, 0.0018770620226860046, 0.0011164695024490356, 0.00093812495470047, 0.009439468383789062, 0.0008748844265937805, 0.00598454475402832, 0.00133514404296875, 0.0013271719217300415, 0.014436103403568268], 'L_grad': [0.01157413050532341, 0.0095882099121809, 0.016044646501541138, 0.01605825498700142, 0.011056756600737572, 0.009386411868035793, 0.010615418665111065, 0.008098138496279716, 0.008589629083871841, 0.018683556467294693, 0.008076542988419533, 0.01377338171005249, 0.008770843036472797, 0.009908147156238556, 0.01988738588988781]}
Train Epoch: 88 [0/684 (0%)] loss: 0.0303 L_si: 0.0085 L_grad: 0.0217 
Train Epoch: 88 [36/684 (5%)] loss: 0.0579 L_si: 0.0223 L_grad: 0.0356 
Train Epoch: 88 [72/684 (11%)] loss: 0.0524 L_si: 0.0162 L_grad: 0.0363 
Train Epoch: 88 [108/684 (16%)] loss: 0.0222 L_si: 0.0038 L_grad: 0.0184 
Train Epoch: 88 [144/684 (21%)] loss: 0.0431 L_si: 0.0106 L_grad: 0.0326 
Train Epoch: 88 [180/684 (26%)] loss: 0.0384 L_si: 0.0089 L_grad: 0.0295 
Train Epoch: 88 [216/684 (32%)] loss: 0.0410 L_si: 0.0115 L_grad: 0.0295 
Train Epoch: 88 [252/684 (37%)] loss: 0.0485 L_si: 0.0165 L_grad: 0.0319 
Train Epoch: 88 [288/684 (42%)] loss: 0.0730 L_si: 0.0350 L_grad: 0.0381 
Train Epoch: 88 [324/684 (47%)] loss: 0.0692 L_si: 0.0297 L_grad: 0.0395 
Train Epoch: 88 [360/684 (53%)] loss: 0.0401 L_si: 0.0098 L_grad: 0.0304 
Train Epoch: 88 [396/684 (58%)] loss: 0.0279 L_si: 0.0075 L_grad: 0.0205 
Train Epoch: 88 [432/684 (63%)] loss: 0.0392 L_si: 0.0143 L_grad: 0.0250 
Train Epoch: 88 [468/684 (68%)] loss: 0.0577 L_si: 0.0166 L_grad: 0.0411 
Train Epoch: 88 [504/684 (74%)] loss: 0.0425 L_si: 0.0118 L_grad: 0.0308 
Train Epoch: 88 [540/684 (79%)] loss: 0.0336 L_si: 0.0082 L_grad: 0.0254 
Train Epoch: 88 [576/684 (84%)] loss: 0.0344 L_si: 0.0086 L_grad: 0.0258 
Train Epoch: 88 [612/684 (89%)] loss: 0.0384 L_si: 0.0105 L_grad: 0.0279 
Train Epoch: 88 [648/684 (95%)] loss: 0.0286 L_si: 0.0089 L_grad: 0.0198 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.010864008218050003, 0.026114698499441147, 0.010755399242043495, 0.01723557338118553, 0.025344425812363625, 0.023376308381557465, 0.018924333155155182, 0.009267536923289299, 0.008391400799155235, 0.012598810717463493, 0.00946847815066576, 0.024112187325954437, 0.011389996856451035, 0.02481955848634243, 0.011124975979328156], 'L_si': [0.0013325512409210205, 0.008504435420036316, 0.0014154687523841858, 0.003550320863723755, 0.009216181933879852, 0.008671127259731293, 0.006132863461971283, 0.0009363740682601929, 0.0009073540568351746, 0.002039015293121338, 0.001076139509677887, 0.008826754987239838, 0.0014042258262634277, 0.008420176804065704, 0.001500353217124939], 'L_grad': [0.009531456977128983, 0.01761026307940483, 0.00933993048965931, 0.013685251586139202, 0.016128243878483772, 0.014705181121826172, 0.012791470624506474, 0.008331162855029106, 0.007484046276658773, 0.010559795424342155, 0.008392338640987873, 0.015285431407392025, 0.009985771030187607, 0.016399381682276726, 0.009624622762203217]}
Train Epoch: 89 [0/684 (0%)] loss: 0.0445 L_si: 0.0141 L_grad: 0.0304 
Train Epoch: 89 [36/684 (5%)] loss: 0.0359 L_si: 0.0087 L_grad: 0.0272 
Train Epoch: 89 [72/684 (11%)] loss: 0.0438 L_si: 0.0114 L_grad: 0.0324 
Train Epoch: 89 [108/684 (16%)] loss: 0.0339 L_si: 0.0076 L_grad: 0.0262 
Train Epoch: 89 [144/684 (21%)] loss: 0.0397 L_si: 0.0112 L_grad: 0.0286 
Train Epoch: 89 [180/684 (26%)] loss: 0.0429 L_si: 0.0128 L_grad: 0.0302 
Train Epoch: 89 [216/684 (32%)] loss: 0.0701 L_si: 0.0305 L_grad: 0.0396 
Train Epoch: 89 [252/684 (37%)] loss: 0.0745 L_si: 0.0356 L_grad: 0.0388 
Train Epoch: 89 [288/684 (42%)] loss: 0.0477 L_si: 0.0195 L_grad: 0.0282 
Train Epoch: 89 [324/684 (47%)] loss: 0.0639 L_si: 0.0260 L_grad: 0.0379 
Train Epoch: 89 [360/684 (53%)] loss: 0.0369 L_si: 0.0095 L_grad: 0.0274 
Train Epoch: 89 [396/684 (58%)] loss: 0.0375 L_si: 0.0139 L_grad: 0.0236 
Train Epoch: 89 [432/684 (63%)] loss: 0.0467 L_si: 0.0185 L_grad: 0.0282 
Train Epoch: 89 [468/684 (68%)] loss: 0.0531 L_si: 0.0231 L_grad: 0.0300 
Train Epoch: 89 [504/684 (74%)] loss: 0.0733 L_si: 0.0313 L_grad: 0.0420 
Train Epoch: 89 [540/684 (79%)] loss: 0.0322 L_si: 0.0072 L_grad: 0.0250 
Train Epoch: 89 [576/684 (84%)] loss: 0.0475 L_si: 0.0181 L_grad: 0.0294 
Train Epoch: 89 [612/684 (89%)] loss: 0.0832 L_si: 0.0367 L_grad: 0.0464 
Train Epoch: 89 [648/684 (95%)] loss: 0.0379 L_si: 0.0083 L_grad: 0.0297 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.011202976107597351, 0.011138198897242546, 0.01070505939424038, 0.023838110268115997, 0.017895404249429703, 0.00905470922589302, 0.008172175846993923, 0.009116586297750473, 0.01910831406712532, 0.010559272021055222, 0.0388980396091938, 0.01869424618780613, 0.016193822026252747, 0.026822000741958618, 0.010662051849067211], 'L_si': [0.0014848336577415466, 0.0016311928629875183, 0.0012952163815498352, 0.008941136300563812, 0.004043512046337128, 0.0008744522929191589, 0.0009243488311767578, 0.0008864104747772217, 0.006031200289726257, 0.0013328343629837036, 0.016856171190738678, 0.005854930728673935, 0.003630310297012329, 0.008847124874591827, 0.001333393156528473], 'L_grad': [0.009718142449855804, 0.009507006034255028, 0.009409843012690544, 0.01489697489887476, 0.013851892203092575, 0.008180256932973862, 0.007247827015817165, 0.008230175822973251, 0.013077113777399063, 0.009226437658071518, 0.022041868418455124, 0.012839315459132195, 0.012563511729240417, 0.01797487586736679, 0.009328658692538738]}
Train Epoch: 90 [0/684 (0%)] loss: 0.0516 L_si: 0.0183 L_grad: 0.0333 
Train Epoch: 90 [36/684 (5%)] loss: 0.0564 L_si: 0.0197 L_grad: 0.0367 
Train Epoch: 90 [72/684 (11%)] loss: 0.0333 L_si: 0.0066 L_grad: 0.0267 
Train Epoch: 90 [108/684 (16%)] loss: 0.0533 L_si: 0.0148 L_grad: 0.0385 
Train Epoch: 90 [144/684 (21%)] loss: 0.0531 L_si: 0.0196 L_grad: 0.0336 
Train Epoch: 90 [180/684 (26%)] loss: 0.0384 L_si: 0.0133 L_grad: 0.0251 
Train Epoch: 90 [216/684 (32%)] loss: 0.0574 L_si: 0.0184 L_grad: 0.0390 
Train Epoch: 90 [252/684 (37%)] loss: 0.0489 L_si: 0.0164 L_grad: 0.0325 
Train Epoch: 90 [288/684 (42%)] loss: 0.0432 L_si: 0.0115 L_grad: 0.0317 
Train Epoch: 90 [324/684 (47%)] loss: 0.0511 L_si: 0.0183 L_grad: 0.0328 
Train Epoch: 90 [360/684 (53%)] loss: 0.0564 L_si: 0.0174 L_grad: 0.0389 
Train Epoch: 90 [396/684 (58%)] loss: 0.0382 L_si: 0.0096 L_grad: 0.0287 
Train Epoch: 90 [432/684 (63%)] loss: 0.0486 L_si: 0.0144 L_grad: 0.0342 
Train Epoch: 90 [468/684 (68%)] loss: 0.0442 L_si: 0.0132 L_grad: 0.0310 
Train Epoch: 90 [504/684 (74%)] loss: 0.0573 L_si: 0.0203 L_grad: 0.0370 
Train Epoch: 90 [540/684 (79%)] loss: 0.0277 L_si: 0.0052 L_grad: 0.0224 
Train Epoch: 90 [576/684 (84%)] loss: 0.0254 L_si: 0.0055 L_grad: 0.0199 
Train Epoch: 90 [612/684 (89%)] loss: 0.0307 L_si: 0.0102 L_grad: 0.0205 
Train Epoch: 90 [648/684 (95%)] loss: 0.0326 L_si: 0.0066 L_grad: 0.0259 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch090-loss-0.0437.pth.tar ...
New Learning Rate: 0.000037
all losses in batch in validation:  {'loss': [0.03587813302874565, 0.010735632851719856, 0.011371484026312828, 0.012661459855735302, 0.016717005521059036, 0.009857438504695892, 0.009663984179496765, 0.008791654370725155, 0.01573207974433899, 0.02791188657283783, 0.025134069845080376, 0.013269832357764244, 0.023381218314170837, 0.013219740241765976, 0.02962215431034565], 'L_si': [0.01380571722984314, 0.0017780140042304993, 0.0021250247955322266, 0.0019731447100639343, 0.003598935902118683, 0.0011701956391334534, 0.0011391639709472656, 0.0006963759660720825, 0.003341659903526306, 0.010501660406589508, 0.008285105228424072, 0.001957327127456665, 0.008903339505195618, 0.002821974456310272, 0.010872915387153625], 'L_grad': [0.02207241579890251, 0.008957618847489357, 0.009246459230780602, 0.010688315145671368, 0.013118069618940353, 0.008687242865562439, 0.0085248202085495, 0.008095278404653072, 0.012390419840812683, 0.01741022616624832, 0.016848964616656303, 0.011312505230307579, 0.01447787880897522, 0.010397765785455704, 0.018749238923192024]}
Train Epoch: 91 [0/684 (0%)] loss: 0.0618 L_si: 0.0191 L_grad: 0.0428 
Train Epoch: 91 [36/684 (5%)] loss: 0.0686 L_si: 0.0328 L_grad: 0.0358 
Train Epoch: 91 [72/684 (11%)] loss: 0.0526 L_si: 0.0179 L_grad: 0.0346 
Train Epoch: 91 [108/684 (16%)] loss: 0.0438 L_si: 0.0144 L_grad: 0.0294 
Train Epoch: 91 [144/684 (21%)] loss: 0.0338 L_si: 0.0093 L_grad: 0.0245 
Train Epoch: 91 [180/684 (26%)] loss: 0.0384 L_si: 0.0131 L_grad: 0.0253 
Train Epoch: 91 [216/684 (32%)] loss: 0.0444 L_si: 0.0125 L_grad: 0.0318 
Train Epoch: 91 [252/684 (37%)] loss: 0.0496 L_si: 0.0134 L_grad: 0.0362 
Train Epoch: 91 [288/684 (42%)] loss: 0.0334 L_si: 0.0090 L_grad: 0.0244 
Train Epoch: 91 [324/684 (47%)] loss: 0.0374 L_si: 0.0095 L_grad: 0.0279 
Train Epoch: 91 [360/684 (53%)] loss: 0.0213 L_si: 0.0042 L_grad: 0.0172 
Train Epoch: 91 [396/684 (58%)] loss: 0.0379 L_si: 0.0099 L_grad: 0.0280 
Train Epoch: 91 [432/684 (63%)] loss: 0.0179 L_si: 0.0038 L_grad: 0.0141 
Train Epoch: 91 [468/684 (68%)] loss: 0.0313 L_si: 0.0089 L_grad: 0.0224 
Train Epoch: 91 [504/684 (74%)] loss: 0.0728 L_si: 0.0311 L_grad: 0.0417 
Train Epoch: 91 [540/684 (79%)] loss: 0.0556 L_si: 0.0143 L_grad: 0.0413 
Train Epoch: 91 [576/684 (84%)] loss: 0.0426 L_si: 0.0120 L_grad: 0.0306 
Train Epoch: 91 [612/684 (89%)] loss: 0.0290 L_si: 0.0076 L_grad: 0.0214 
Train Epoch: 91 [648/684 (95%)] loss: 0.0288 L_si: 0.0054 L_grad: 0.0234 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009727939032018185, 0.026575567200779915, 0.016402335837483406, 0.0241151861846447, 0.030152399092912674, 0.016362804919481277, 0.010455693118274212, 0.009378748014569283, 0.00865824893116951, 0.013647481799125671, 0.019779831171035767, 0.019235476851463318, 0.008871912956237793, 0.010246522724628448, 0.022434819489717484], 'L_si': [0.0009641349315643311, 0.009341433644294739, 0.003467954695224762, 0.00896645337343216, 0.011140495538711548, 0.003494858741760254, 0.0014161542057991028, 0.0008967816829681396, 0.0008840486407279968, 0.002493947744369507, 0.006257854402065277, 0.006156168878078461, 0.0006502121686935425, 0.0011388063430786133, 0.007291942834854126], 'L_grad': [0.008763804100453854, 0.017234133556485176, 0.012934381142258644, 0.01514873281121254, 0.019011903554201126, 0.012867946177721024, 0.009039538912475109, 0.008481966331601143, 0.0077742007561028, 0.011153534054756165, 0.013521975837647915, 0.013079307973384857, 0.00822170078754425, 0.009107716381549835, 0.015142876654863358]}
Train Epoch: 92 [0/684 (0%)] loss: 0.0334 L_si: 0.0082 L_grad: 0.0252 
Train Epoch: 92 [36/684 (5%)] loss: 0.0400 L_si: 0.0161 L_grad: 0.0240 
Train Epoch: 92 [72/684 (11%)] loss: 0.0527 L_si: 0.0174 L_grad: 0.0354 
Train Epoch: 92 [108/684 (16%)] loss: 0.0717 L_si: 0.0320 L_grad: 0.0397 
Train Epoch: 92 [144/684 (21%)] loss: 0.0477 L_si: 0.0157 L_grad: 0.0320 
Train Epoch: 92 [180/684 (26%)] loss: 0.0492 L_si: 0.0172 L_grad: 0.0320 
Train Epoch: 92 [216/684 (32%)] loss: 0.0332 L_si: 0.0117 L_grad: 0.0215 
Train Epoch: 92 [252/684 (37%)] loss: 0.0348 L_si: 0.0088 L_grad: 0.0260 
Train Epoch: 92 [288/684 (42%)] loss: 0.0837 L_si: 0.0307 L_grad: 0.0530 
Train Epoch: 92 [324/684 (47%)] loss: 0.0393 L_si: 0.0151 L_grad: 0.0242 
Train Epoch: 92 [360/684 (53%)] loss: 0.0559 L_si: 0.0172 L_grad: 0.0388 
Train Epoch: 92 [396/684 (58%)] loss: 0.0682 L_si: 0.0271 L_grad: 0.0411 
Train Epoch: 92 [432/684 (63%)] loss: 0.0486 L_si: 0.0140 L_grad: 0.0346 
Train Epoch: 92 [468/684 (68%)] loss: 0.0215 L_si: 0.0025 L_grad: 0.0191 
Train Epoch: 92 [504/684 (74%)] loss: 0.0558 L_si: 0.0181 L_grad: 0.0376 
Train Epoch: 92 [540/684 (79%)] loss: 0.0461 L_si: 0.0156 L_grad: 0.0305 
Train Epoch: 92 [576/684 (84%)] loss: 0.0264 L_si: 0.0052 L_grad: 0.0211 
Train Epoch: 92 [612/684 (89%)] loss: 0.0510 L_si: 0.0167 L_grad: 0.0343 
Train Epoch: 92 [648/684 (95%)] loss: 0.0242 L_si: 0.0040 L_grad: 0.0202 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.025090740993618965, 0.04057476669549942, 0.011373046785593033, 0.013354470953345299, 0.017147086560726166, 0.012300434522330761, 0.028833787888288498, 0.01547474879771471, 0.025198951363563538, 0.02336067333817482, 0.015072448179125786, 0.013606179505586624, 0.014640353620052338, 0.011079702526330948, 0.02602163702249527], 'L_si': [0.009236685931682587, 0.014648273587226868, 0.00140390545129776, 0.0028526857495307922, 0.0044998228549957275, 0.0019758641719818115, 0.011172235012054443, 0.0035611391067504883, 0.00833902508020401, 0.006006799638271332, 0.0035917162895202637, 0.0030075833201408386, 0.0038938522338867188, 0.0016951188445091248, 0.009080618619918823], 'L_grad': [0.01585405506193638, 0.025926493108272552, 0.009969141334295273, 0.010501785203814507, 0.012647264637053013, 0.01032457035034895, 0.017661552876234055, 0.011913609690964222, 0.016859926283359528, 0.017353873699903488, 0.011480731889605522, 0.010598596185445786, 0.010746501386165619, 0.009384583681821823, 0.016941018402576447]}
Train Epoch: 93 [0/684 (0%)] loss: 0.0379 L_si: 0.0085 L_grad: 0.0295 
Train Epoch: 93 [36/684 (5%)] loss: 0.0593 L_si: 0.0206 L_grad: 0.0387 
Train Epoch: 93 [72/684 (11%)] loss: 0.0305 L_si: 0.0067 L_grad: 0.0238 
Train Epoch: 93 [108/684 (16%)] loss: 0.0309 L_si: 0.0066 L_grad: 0.0243 
Train Epoch: 93 [144/684 (21%)] loss: 0.0189 L_si: 0.0035 L_grad: 0.0155 
Train Epoch: 93 [180/684 (26%)] loss: 0.0262 L_si: 0.0057 L_grad: 0.0204 
Train Epoch: 93 [216/684 (32%)] loss: 0.0203 L_si: 0.0038 L_grad: 0.0164 
Train Epoch: 93 [252/684 (37%)] loss: 0.0409 L_si: 0.0091 L_grad: 0.0317 
Train Epoch: 93 [288/684 (42%)] loss: 0.0464 L_si: 0.0140 L_grad: 0.0324 
Train Epoch: 93 [324/684 (47%)] loss: 0.0648 L_si: 0.0254 L_grad: 0.0393 
Train Epoch: 93 [360/684 (53%)] loss: 0.0488 L_si: 0.0163 L_grad: 0.0325 
Train Epoch: 93 [396/684 (58%)] loss: 0.0336 L_si: 0.0086 L_grad: 0.0251 
Train Epoch: 93 [432/684 (63%)] loss: 0.0515 L_si: 0.0167 L_grad: 0.0347 
Train Epoch: 93 [468/684 (68%)] loss: 0.0501 L_si: 0.0142 L_grad: 0.0359 
Train Epoch: 93 [504/684 (74%)] loss: 0.0459 L_si: 0.0163 L_grad: 0.0297 
Train Epoch: 93 [540/684 (79%)] loss: 0.0269 L_si: 0.0052 L_grad: 0.0217 
Train Epoch: 93 [576/684 (84%)] loss: 0.0453 L_si: 0.0135 L_grad: 0.0318 
Train Epoch: 93 [612/684 (89%)] loss: 0.0990 L_si: 0.0480 L_grad: 0.0510 
Train Epoch: 93 [648/684 (95%)] loss: 0.0380 L_si: 0.0107 L_grad: 0.0273 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.020098477602005005, 0.03329648822546005, 0.01900126226246357, 0.027778761461377144, 0.023188380524516106, 0.009482411667704582, 0.008487692102789879, 0.00964733213186264, 0.008870184421539307, 0.018132105469703674, 0.01486341841518879, 0.00884203240275383, 0.016505984589457512, 0.011980893090367317, 0.011073397472500801], 'L_si': [0.0064988210797309875, 0.013927049934864044, 0.0060858651995658875, 0.009766899049282074, 0.008742697536945343, 0.0006973519921302795, 0.0008289366960525513, 0.0008959472179412842, 0.0009391158819198608, 0.003984004259109497, 0.003011934459209442, 0.0008611083030700684, 0.0034580454230308533, 0.0014639496803283691, 0.0014402493834495544], 'L_grad': [0.013599656522274017, 0.01936943829059601, 0.012915397062897682, 0.01801186241209507, 0.014445682987570763, 0.008785059675574303, 0.00765875494107604, 0.008751384913921356, 0.007931068539619446, 0.014148100279271603, 0.011851483955979347, 0.007980924099683762, 0.013047939166426659, 0.010516943410038948, 0.009633148089051247]}
Train Epoch: 94 [0/684 (0%)] loss: 0.0558 L_si: 0.0194 L_grad: 0.0364 
Train Epoch: 94 [36/684 (5%)] loss: 0.0394 L_si: 0.0101 L_grad: 0.0293 
Train Epoch: 94 [72/684 (11%)] loss: 0.0451 L_si: 0.0164 L_grad: 0.0287 
Train Epoch: 94 [108/684 (16%)] loss: 0.0317 L_si: 0.0084 L_grad: 0.0232 
Train Epoch: 94 [144/684 (21%)] loss: 0.0729 L_si: 0.0297 L_grad: 0.0431 
Train Epoch: 94 [180/684 (26%)] loss: 0.0295 L_si: 0.0058 L_grad: 0.0237 
Train Epoch: 94 [216/684 (32%)] loss: 0.0467 L_si: 0.0126 L_grad: 0.0341 
Train Epoch: 94 [252/684 (37%)] loss: 0.0260 L_si: 0.0051 L_grad: 0.0209 
Train Epoch: 94 [288/684 (42%)] loss: 0.0407 L_si: 0.0111 L_grad: 0.0297 
Train Epoch: 94 [324/684 (47%)] loss: 0.0302 L_si: 0.0073 L_grad: 0.0229 
Train Epoch: 94 [360/684 (53%)] loss: 0.0411 L_si: 0.0116 L_grad: 0.0295 
Train Epoch: 94 [396/684 (58%)] loss: 0.0327 L_si: 0.0074 L_grad: 0.0253 
Train Epoch: 94 [432/684 (63%)] loss: 0.0549 L_si: 0.0213 L_grad: 0.0336 
Train Epoch: 94 [468/684 (68%)] loss: 0.0431 L_si: 0.0167 L_grad: 0.0264 
Train Epoch: 94 [504/684 (74%)] loss: 0.0290 L_si: 0.0078 L_grad: 0.0212 
Train Epoch: 94 [540/684 (79%)] loss: 0.0286 L_si: 0.0060 L_grad: 0.0226 
Train Epoch: 94 [576/684 (84%)] loss: 0.0515 L_si: 0.0151 L_grad: 0.0364 
Train Epoch: 94 [612/684 (89%)] loss: 0.0664 L_si: 0.0239 L_grad: 0.0425 
Train Epoch: 94 [648/684 (95%)] loss: 0.0258 L_si: 0.0049 L_grad: 0.0209 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.011833579279482365, 0.014669504016637802, 0.013035356998443604, 0.02393481135368347, 0.0362444669008255, 0.03111175075173378, 0.022736631333827972, 0.01639833115041256, 0.013553464785218239, 0.023702867329120636, 0.019935254007577896, 0.028337586671113968, 0.015612274408340454, 0.011126487515866756, 0.010659568011760712], 'L_si': [0.0019076541066169739, 0.0027153119444847107, 0.0032066404819488525, 0.008405767381191254, 0.014092296361923218, 0.011186718940734863, 0.006865009665489197, 0.005295291543006897, 0.0032716915011405945, 0.008461244404315948, 0.00410296767950058, 0.01117456704378128, 0.004222184419631958, 0.001336805522441864, 0.0015701502561569214], 'L_grad': [0.00992592517286539, 0.011954192072153091, 0.009828716516494751, 0.015529043972492218, 0.022152172401547432, 0.019925031810998917, 0.015871621668338776, 0.011103039607405663, 0.010281773284077644, 0.015241621993482113, 0.015832286328077316, 0.017163019627332687, 0.011390089988708496, 0.009789681993424892, 0.00908941775560379]}
Train Epoch: 95 [0/684 (0%)] loss: 0.0445 L_si: 0.0113 L_grad: 0.0332 
Train Epoch: 95 [36/684 (5%)] loss: 0.0485 L_si: 0.0158 L_grad: 0.0326 
Train Epoch: 95 [72/684 (11%)] loss: 0.0583 L_si: 0.0199 L_grad: 0.0384 
Train Epoch: 95 [108/684 (16%)] loss: 0.0356 L_si: 0.0120 L_grad: 0.0236 
Train Epoch: 95 [144/684 (21%)] loss: 0.0757 L_si: 0.0296 L_grad: 0.0461 
Train Epoch: 95 [180/684 (26%)] loss: 0.0403 L_si: 0.0105 L_grad: 0.0298 
Train Epoch: 95 [216/684 (32%)] loss: 0.0253 L_si: 0.0052 L_grad: 0.0201 
Train Epoch: 95 [252/684 (37%)] loss: 0.0779 L_si: 0.0252 L_grad: 0.0527 
Train Epoch: 95 [288/684 (42%)] loss: 0.0457 L_si: 0.0131 L_grad: 0.0326 
Train Epoch: 95 [324/684 (47%)] loss: 0.0626 L_si: 0.0221 L_grad: 0.0405 
Train Epoch: 95 [360/684 (53%)] loss: 0.0186 L_si: 0.0039 L_grad: 0.0147 
Train Epoch: 95 [396/684 (58%)] loss: 0.0409 L_si: 0.0109 L_grad: 0.0300 
Train Epoch: 95 [432/684 (63%)] loss: 0.0536 L_si: 0.0149 L_grad: 0.0387 
Train Epoch: 95 [468/684 (68%)] loss: 0.0352 L_si: 0.0083 L_grad: 0.0269 
Train Epoch: 95 [504/684 (74%)] loss: 0.0254 L_si: 0.0058 L_grad: 0.0197 
Train Epoch: 95 [540/684 (79%)] loss: 0.0503 L_si: 0.0118 L_grad: 0.0385 
Train Epoch: 95 [576/684 (84%)] loss: 0.0499 L_si: 0.0177 L_grad: 0.0322 
Train Epoch: 95 [612/684 (89%)] loss: 0.0402 L_si: 0.0100 L_grad: 0.0302 
Train Epoch: 95 [648/684 (95%)] loss: 0.0204 L_si: 0.0034 L_grad: 0.0170 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.013081640936434269, 0.008093473501503468, 0.01080336794257164, 0.00892217643558979, 0.012233925051987171, 0.01237604022026062, 0.027243465185165405, 0.018955588340759277, 0.009682400152087212, 0.011899348348379135, 0.011254595592617989, 0.038813553750514984, 0.031839217990636826, 0.00996018759906292, 0.024691453203558922], 'L_si': [0.0020788908004760742, 0.0009091794490814209, 0.001493699848651886, 0.0009881705045700073, 0.0016424506902694702, 0.0015074238181114197, 0.009937845170497894, 0.005946226418018341, 0.001017354428768158, 0.0020805448293685913, 0.0010138750076293945, 0.016819484531879425, 0.010531753301620483, 0.0012795031070709229, 0.008327104151248932], 'L_grad': [0.011002750135958195, 0.007184294052422047, 0.009309668093919754, 0.007934005931019783, 0.010591474361717701, 0.0108686164021492, 0.01730562001466751, 0.013009362854063511, 0.008665045723319054, 0.009818803519010544, 0.010240720584988594, 0.02199406735599041, 0.021307464689016342, 0.008680684491991997, 0.01636434905230999]}
Train Epoch: 96 [0/684 (0%)] loss: 0.0457 L_si: 0.0116 L_grad: 0.0341 
Train Epoch: 96 [36/684 (5%)] loss: 0.0256 L_si: 0.0051 L_grad: 0.0205 
Train Epoch: 96 [72/684 (11%)] loss: 0.0244 L_si: 0.0050 L_grad: 0.0194 
Train Epoch: 96 [108/684 (16%)] loss: 0.0442 L_si: 0.0105 L_grad: 0.0337 
Train Epoch: 96 [144/684 (21%)] loss: 0.0451 L_si: 0.0106 L_grad: 0.0344 
Train Epoch: 96 [180/684 (26%)] loss: 0.0263 L_si: 0.0067 L_grad: 0.0197 
Train Epoch: 96 [216/684 (32%)] loss: 0.0471 L_si: 0.0138 L_grad: 0.0332 
Train Epoch: 96 [252/684 (37%)] loss: 0.0365 L_si: 0.0120 L_grad: 0.0246 
Train Epoch: 96 [288/684 (42%)] loss: 0.0776 L_si: 0.0332 L_grad: 0.0445 
Train Epoch: 96 [324/684 (47%)] loss: 0.0302 L_si: 0.0065 L_grad: 0.0237 
Train Epoch: 96 [360/684 (53%)] loss: 0.0986 L_si: 0.0395 L_grad: 0.0591 
Train Epoch: 96 [396/684 (58%)] loss: 0.0143 L_si: 0.0024 L_grad: 0.0119 
Train Epoch: 96 [432/684 (63%)] loss: 0.0329 L_si: 0.0095 L_grad: 0.0234 
Train Epoch: 96 [468/684 (68%)] loss: 0.0361 L_si: 0.0074 L_grad: 0.0287 
Train Epoch: 96 [504/684 (74%)] loss: 0.0540 L_si: 0.0173 L_grad: 0.0368 
Train Epoch: 96 [540/684 (79%)] loss: 0.0625 L_si: 0.0226 L_grad: 0.0400 
Train Epoch: 96 [576/684 (84%)] loss: 0.0510 L_si: 0.0165 L_grad: 0.0345 
Train Epoch: 96 [612/684 (89%)] loss: 0.0429 L_si: 0.0123 L_grad: 0.0307 
Train Epoch: 96 [648/684 (95%)] loss: 0.0442 L_si: 0.0121 L_grad: 0.0320 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.009530488401651382, 0.016174739226698875, 0.0224313922226429, 0.02571447193622589, 0.013323931023478508, 0.011306801810860634, 0.02741292119026184, 0.028310611844062805, 0.01046801172196865, 0.0397125743329525, 0.01961803250014782, 0.022265709936618805, 0.017769010737538338, 0.01598994992673397, 0.014088913798332214], 'L_si': [0.0009056106209754944, 0.004504859447479248, 0.007045619189739227, 0.006649412214756012, 0.0036220699548721313, 0.0015654638409614563, 0.009390965104103088, 0.011109218001365662, 0.0013120397925376892, 0.017123617231845856, 0.005944982171058655, 0.007088802754878998, 0.004773959517478943, 0.0047126710414886475, 0.0038411468267440796], 'L_grad': [0.008624877780675888, 0.011669879779219627, 0.015385773032903671, 0.01906505972146988, 0.009701861068606377, 0.009741337969899178, 0.018021956086158752, 0.017201393842697144, 0.009155971929430962, 0.022588957101106644, 0.013673050329089165, 0.015176906250417233, 0.012995051220059395, 0.011277278885245323, 0.010247766971588135]}
Train Epoch: 97 [0/684 (0%)] loss: 0.0235 L_si: 0.0049 L_grad: 0.0187 
Train Epoch: 97 [36/684 (5%)] loss: 0.0409 L_si: 0.0118 L_grad: 0.0290 
Train Epoch: 97 [72/684 (11%)] loss: 0.0392 L_si: 0.0108 L_grad: 0.0284 
Train Epoch: 97 [108/684 (16%)] loss: 0.0600 L_si: 0.0183 L_grad: 0.0417 
Train Epoch: 97 [144/684 (21%)] loss: 0.0579 L_si: 0.0187 L_grad: 0.0392 
Train Epoch: 97 [180/684 (26%)] loss: 0.0492 L_si: 0.0172 L_grad: 0.0320 
Train Epoch: 97 [216/684 (32%)] loss: 0.0264 L_si: 0.0062 L_grad: 0.0202 
Train Epoch: 97 [252/684 (37%)] loss: 0.0294 L_si: 0.0087 L_grad: 0.0207 
Train Epoch: 97 [288/684 (42%)] loss: 0.0549 L_si: 0.0178 L_grad: 0.0371 
Train Epoch: 97 [324/684 (47%)] loss: 0.0406 L_si: 0.0097 L_grad: 0.0309 
Train Epoch: 97 [360/684 (53%)] loss: 0.0477 L_si: 0.0169 L_grad: 0.0308 
Train Epoch: 97 [396/684 (58%)] loss: 0.0469 L_si: 0.0130 L_grad: 0.0340 
Train Epoch: 97 [432/684 (63%)] loss: 0.0286 L_si: 0.0060 L_grad: 0.0226 
Train Epoch: 97 [468/684 (68%)] loss: 0.0441 L_si: 0.0158 L_grad: 0.0283 
Train Epoch: 97 [504/684 (74%)] loss: 0.0583 L_si: 0.0226 L_grad: 0.0357 
Train Epoch: 97 [540/684 (79%)] loss: 0.0235 L_si: 0.0046 L_grad: 0.0189 
Train Epoch: 97 [576/684 (84%)] loss: 0.0174 L_si: 0.0032 L_grad: 0.0143 
Train Epoch: 97 [612/684 (89%)] loss: 0.0223 L_si: 0.0031 L_grad: 0.0192 
Train Epoch: 97 [648/684 (95%)] loss: 0.0234 L_si: 0.0038 L_grad: 0.0196 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.013342700898647308, 0.0279121994972229, 0.021591098979115486, 0.02365563064813614, 0.041485466063022614, 0.013742470182478428, 0.02373502217233181, 0.016321513801813126, 0.0232669897377491, 0.008634461089968681, 0.023157360032200813, 0.028290962800383568, 0.016642220318317413, 0.011066900566220284, 0.013398207724094391], 'L_si': [0.0024668127298355103, 0.010035641491413116, 0.006513588130474091, 0.008585125207901001, 0.01811150461435318, 0.0032045841217041016, 0.006435282528400421, 0.004165366291999817, 0.007205851376056671, 0.0007096752524375916, 0.007227204740047455, 0.009638361632823944, 0.0038515180349349976, 0.001865878701210022, 0.0033882930874824524], 'L_grad': [0.010875888168811798, 0.017876558005809784, 0.015077510848641396, 0.015070505440235138, 0.023373959586024284, 0.010537886060774326, 0.01729973964393139, 0.012156147509813309, 0.01606113836169243, 0.00792478583753109, 0.01593015529215336, 0.018652601167559624, 0.01279070321470499, 0.009201021865010262, 0.010009914636611938]}
Train Epoch: 98 [0/684 (0%)] loss: 0.0482 L_si: 0.0170 L_grad: 0.0312 
Train Epoch: 98 [36/684 (5%)] loss: 0.0294 L_si: 0.0061 L_grad: 0.0232 
Train Epoch: 98 [72/684 (11%)] loss: 0.0415 L_si: 0.0104 L_grad: 0.0311 
Train Epoch: 98 [108/684 (16%)] loss: 0.0467 L_si: 0.0141 L_grad: 0.0327 
Train Epoch: 98 [144/684 (21%)] loss: 0.0520 L_si: 0.0181 L_grad: 0.0339 
Train Epoch: 98 [180/684 (26%)] loss: 0.0266 L_si: 0.0058 L_grad: 0.0209 
Train Epoch: 98 [216/684 (32%)] loss: 0.0306 L_si: 0.0074 L_grad: 0.0232 
Train Epoch: 98 [252/684 (37%)] loss: 0.0484 L_si: 0.0159 L_grad: 0.0325 
Train Epoch: 98 [288/684 (42%)] loss: 0.0708 L_si: 0.0292 L_grad: 0.0416 
Train Epoch: 98 [324/684 (47%)] loss: 0.0269 L_si: 0.0056 L_grad: 0.0213 
Train Epoch: 98 [360/684 (53%)] loss: 0.0461 L_si: 0.0127 L_grad: 0.0333 
Train Epoch: 98 [396/684 (58%)] loss: 0.0501 L_si: 0.0143 L_grad: 0.0358 
Train Epoch: 98 [432/684 (63%)] loss: 0.0294 L_si: 0.0069 L_grad: 0.0226 
Train Epoch: 98 [468/684 (68%)] loss: 0.0583 L_si: 0.0196 L_grad: 0.0388 
Train Epoch: 98 [504/684 (74%)] loss: 0.0506 L_si: 0.0139 L_grad: 0.0367 
Train Epoch: 98 [540/684 (79%)] loss: 0.0600 L_si: 0.0192 L_grad: 0.0408 
Train Epoch: 98 [576/684 (84%)] loss: 0.0234 L_si: 0.0065 L_grad: 0.0169 
Train Epoch: 98 [612/684 (89%)] loss: 0.0270 L_si: 0.0049 L_grad: 0.0221 
Train Epoch: 98 [648/684 (95%)] loss: 0.0549 L_si: 0.0177 L_grad: 0.0372 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.008636066690087318, 0.01528670359402895, 0.018218383193016052, 0.02279878966510296, 0.028215579688549042, 0.02067321538925171, 0.025473199784755707, 0.015230817720293999, 0.033315129578113556, 0.014965157955884933, 0.010863615199923515, 0.023514989763498306, 0.012868724763393402, 0.024999676272273064, 0.01049693301320076], 'L_si': [0.0006894022226333618, 0.003516770899295807, 0.004324212670326233, 0.008143872022628784, 0.010263495147228241, 0.006341606378555298, 0.009553074836730957, 0.0030553415417671204, 0.012769825756549835, 0.00337277352809906, 0.0016143172979354858, 0.008487038314342499, 0.002895146608352661, 0.009139671921730042, 0.0012549832463264465], 'L_grad': [0.007946664467453957, 0.011769932694733143, 0.013894169591367245, 0.014654917642474174, 0.0179520845413208, 0.014331609010696411, 0.01592012494802475, 0.012175476178526878, 0.02054530382156372, 0.011592384427785873, 0.00924929790198803, 0.015027951449155807, 0.009973578155040741, 0.015860004350543022, 0.009241949766874313]}
Train Epoch: 99 [0/684 (0%)] loss: 0.0464 L_si: 0.0168 L_grad: 0.0296 
Train Epoch: 99 [36/684 (5%)] loss: 0.0480 L_si: 0.0119 L_grad: 0.0361 
Train Epoch: 99 [72/684 (11%)] loss: 0.0364 L_si: 0.0088 L_grad: 0.0276 
Train Epoch: 99 [108/684 (16%)] loss: 0.0492 L_si: 0.0123 L_grad: 0.0369 
Train Epoch: 99 [144/684 (21%)] loss: 0.0246 L_si: 0.0063 L_grad: 0.0182 
Train Epoch: 99 [180/684 (26%)] loss: 0.0786 L_si: 0.0357 L_grad: 0.0429 
Train Epoch: 99 [216/684 (32%)] loss: 0.0470 L_si: 0.0125 L_grad: 0.0344 
Train Epoch: 99 [252/684 (37%)] loss: 0.0421 L_si: 0.0159 L_grad: 0.0262 
Train Epoch: 99 [288/684 (42%)] loss: 0.0525 L_si: 0.0196 L_grad: 0.0329 
Train Epoch: 99 [324/684 (47%)] loss: 0.0182 L_si: 0.0032 L_grad: 0.0150 
Train Epoch: 99 [360/684 (53%)] loss: 0.0210 L_si: 0.0032 L_grad: 0.0178 
Train Epoch: 99 [396/684 (58%)] loss: 0.0233 L_si: 0.0042 L_grad: 0.0192 
Train Epoch: 99 [432/684 (63%)] loss: 0.0521 L_si: 0.0153 L_grad: 0.0368 
Train Epoch: 99 [468/684 (68%)] loss: 0.0210 L_si: 0.0034 L_grad: 0.0176 
Train Epoch: 99 [504/684 (74%)] loss: 0.0366 L_si: 0.0085 L_grad: 0.0282 
Train Epoch: 99 [540/684 (79%)] loss: 0.0497 L_si: 0.0132 L_grad: 0.0366 
Train Epoch: 99 [576/684 (84%)] loss: 0.0293 L_si: 0.0065 L_grad: 0.0228 
Train Epoch: 99 [612/684 (89%)] loss: 0.0392 L_si: 0.0121 L_grad: 0.0271 
Train Epoch: 99 [648/684 (95%)] loss: 0.0444 L_si: 0.0160 L_grad: 0.0284 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
all losses in batch in validation:  {'loss': [0.029880132526159286, 0.02082054689526558, 0.00900235679000616, 0.02944479137659073, 0.01862049289047718, 0.019572101533412933, 0.011053112335503101, 0.02091541513800621, 0.029716752469539642, 0.029017677530646324, 0.011183392256498337, 0.022991880774497986, 0.024906815961003304, 0.016209781169891357, 0.029394544661045074], 'L_si': [0.01173451542854309, 0.005929999053478241, 0.0007920488715171814, 0.010009363293647766, 0.005463756620883942, 0.004870183765888214, 0.0013886913657188416, 0.0069490522146224976, 0.012065835297107697, 0.010630309581756592, 0.001186475157737732, 0.008445560932159424, 0.009366355836391449, 0.004799693822860718, 0.011271767318248749], 'L_grad': [0.018145617097616196, 0.014890547841787338, 0.00821030791848898, 0.019435428082942963, 0.013156736269593239, 0.01470191776752472, 0.00966442096978426, 0.013966363854706287, 0.017650917172431946, 0.018387367948889732, 0.009996917098760605, 0.014546320773661137, 0.015540460124611855, 0.011410088278353214, 0.018122777342796326]}
Train Epoch: 100 [0/684 (0%)] loss: 0.0273 L_si: 0.0052 L_grad: 0.0222 
Train Epoch: 100 [36/684 (5%)] loss: 0.0492 L_si: 0.0160 L_grad: 0.0332 
Train Epoch: 100 [72/684 (11%)] loss: 0.0491 L_si: 0.0175 L_grad: 0.0316 
Train Epoch: 100 [108/684 (16%)] loss: 0.0500 L_si: 0.0170 L_grad: 0.0329 
Train Epoch: 100 [144/684 (21%)] loss: 0.0573 L_si: 0.0192 L_grad: 0.0381 
Train Epoch: 100 [180/684 (26%)] loss: 0.0320 L_si: 0.0070 L_grad: 0.0251 
Train Epoch: 100 [216/684 (32%)] loss: 0.0456 L_si: 0.0177 L_grad: 0.0279 
Train Epoch: 100 [252/684 (37%)] loss: 0.0380 L_si: 0.0090 L_grad: 0.0290 
Train Epoch: 100 [288/684 (42%)] loss: 0.0352 L_si: 0.0105 L_grad: 0.0246 
Train Epoch: 100 [324/684 (47%)] loss: 0.0509 L_si: 0.0146 L_grad: 0.0363 
Train Epoch: 100 [360/684 (53%)] loss: 0.0515 L_si: 0.0216 L_grad: 0.0298 
Train Epoch: 100 [396/684 (58%)] loss: 0.0455 L_si: 0.0125 L_grad: 0.0330 
Train Epoch: 100 [432/684 (63%)] loss: 0.0253 L_si: 0.0046 L_grad: 0.0207 
Train Epoch: 100 [468/684 (68%)] loss: 0.0467 L_si: 0.0124 L_grad: 0.0343 
Train Epoch: 100 [504/684 (74%)] loss: 0.0342 L_si: 0.0068 L_grad: 0.0274 
Train Epoch: 100 [540/684 (79%)] loss: 0.0200 L_si: 0.0040 L_grad: 0.0160 
Train Epoch: 100 [576/684 (84%)] loss: 0.0244 L_si: 0.0054 L_grad: 0.0191 
Train Epoch: 100 [612/684 (89%)] loss: 0.0348 L_si: 0.0096 L_grad: 0.0253 
Train Epoch: 100 [648/684 (95%)] loss: 0.0272 L_si: 0.0071 L_grad: 0.0201 
Validation: [0/180 (0%)]
Validation: [36/180 (20%)]
Validation: [72/180 (40%)]
Validation: [108/180 (60%)]
Validation: [144/180 (80%)]
Saving checkpoint: /root/autodl-tmp/train_ol_100e/train_s2d_SpikeTransformer/checkpoint-epoch100-loss-0.0416.pth.tar ...
all losses in batch in validation:  {'loss': [0.02387915551662445, 0.015649227425456047, 0.01703800819814205, 0.017939092591404915, 0.02299218624830246, 0.016361359506845474, 0.009568425826728344, 0.034384213387966156, 0.026341546326875687, 0.03225603699684143, 0.008894745260477066, 0.015465202741324902, 0.021869946271181107, 0.021519042551517487, 0.03421697020530701], 'L_si': [0.007911361753940582, 0.004897475242614746, 0.004153996706008911, 0.005873382091522217, 0.008872129023075104, 0.003289952874183655, 0.0007847696542739868, 0.014069043099880219, 0.009901575744152069, 0.012769147753715515, 0.0010304823517799377, 0.004379101097583771, 0.0059413909912109375, 0.007274642586708069, 0.013935424387454987], 'L_grad': [0.01596779376268387, 0.010751752182841301, 0.01288401149213314, 0.012065710499882698, 0.014120057225227356, 0.013071405701339245, 0.008783656172454357, 0.020315172150731087, 0.016439970582723618, 0.019486889243125916, 0.007864262908697128, 0.01108610164374113, 0.01592855527997017, 0.014244399964809418, 0.02028154395520687]}
