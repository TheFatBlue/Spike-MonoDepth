/root/miniconda3/envs/scv/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Trainable parameters: 20545951
S2DepthTransformerUNetConv(
  (encoder): LongSpikeStreamEncoderConv(
    (swin3d): SwinTransformer3D(
      (patch_embed): PatchEmbedLocalGlobal(
        (head): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (global_head): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (global_residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (global_proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=384, out_features=192, bias=False)
            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=768, out_features=384, bias=False)
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
    (conv_layers): ModuleList(
      (0): ModuleList(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ModuleList(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ModuleList(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (resblocks): ModuleList(
    (0): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (decoders): ModuleList(
    (0): UpsampleConvLayer(
      (conv2d): Conv2d(384, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (1): UpsampleConvLayer(
      (conv2d): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (2): UpsampleConvLayer(
      (conv2d): Conv2d(96, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (pred): ConvLayer(
    (conv2d): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)
Setting up Multi Scale Gradient loss...
Done
---- Single Training ----
Use GPU: 0 for training
Found 26 samples in /root/autodl-tmp/Spike-Stero/train
Found 8 samples in /root/autodl-tmp/Spike-Stero/validation
-----  [3, 6, 12]
---- new version 4 ----
Model Initialized
Using scale_invariant_loss with config {'weight': 1.0, 'n_lambda': 1.0}
Will not use phased architecture
Using Multi Scale Gradient loss with weight=0.25
Will not use MSE loss
Train Epoch: 1 [0/816 (0%)] loss: 0.0224 L_si: 0.0003 L_grad: 0.0221 
Train Epoch: 1 [36/816 (4%)] loss: 0.0090 L_si: 0.0001 L_grad: 0.0089 
Train Epoch: 1 [72/816 (9%)] loss: 0.0055 L_si: 0.0000 L_grad: 0.0055 
Train Epoch: 1 [108/816 (13%)] loss: 0.0034 L_si: 0.0000 L_grad: 0.0034 
Train Epoch: 1 [144/816 (18%)] loss: 0.0020 L_si: 0.0000 L_grad: 0.0020 
Train Epoch: 1 [180/816 (22%)] loss: 0.0014 L_si: 0.0000 L_grad: 0.0014 
Train Epoch: 1 [216/816 (26%)] loss: 0.0012 L_si: 0.0000 L_grad: 0.0012 
Train Epoch: 1 [252/816 (31%)] loss: 0.0010 L_si: 0.0000 L_grad: 0.0010 
Train Epoch: 1 [288/816 (35%)] loss: 0.0007 L_si: 0.0000 L_grad: 0.0007 
Train Epoch: 1 [324/816 (40%)] loss: 0.0005 L_si: 0.0000 L_grad: 0.0005 
Train Epoch: 1 [360/816 (44%)] loss: 0.0005 L_si: 0.0000 L_grad: 0.0005 
Train Epoch: 1 [396/816 (49%)] loss: 0.0004 L_si: 0.0000 L_grad: 0.0004 
Train Epoch: 1 [432/816 (53%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [468/816 (57%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [504/816 (62%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 1 [540/816 (66%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [576/816 (71%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [612/816 (75%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [648/816 (79%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [684/816 (84%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [720/816 (88%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [756/816 (93%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 1 [792/816 (97%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.0002739441697485745, 0.00027147948276251554, 0.0002911029732786119, 0.0002981367288157344, 0.00022104327217675745, 0.0002601194428279996, 0.00026767654344439507, 0.00024438503896817565, 0.00021767686121165752, 0.00026285371859557927, 0.0003010699583683163, 0.00023059561499394476, 0.0002865957503672689, 0.00024781847605481744, 0.00023570052871946245, 0.00028000204474665225, 0.000248311145696789, 0.0002718385949265212, 7.45136130717583e-05], 'L_si': [1.1920928955078125e-07, 1.1920928955078125e-07, 1.4901161193847656e-07, 1.1920928955078125e-07, 1.4901161193847656e-07, 8.940696716308594e-08, 1.4901161193847656e-07, 2.9802322387695312e-08, 8.940696716308594e-08, 1.1920928955078125e-07, 2.9802322387695312e-08, 5.960464477539063e-08, 8.940696716308594e-08, 5.960464477539063e-08, 8.940696716308594e-08, 1.4901161193847656e-07, 1.1920928955078125e-07, 8.940696716308594e-08, 1.7881393432617188e-07], 'L_grad': [0.0002738249604590237, 0.00027136027347296476, 0.0002909539616666734, 0.0002980175195261836, 0.00022089426056481898, 0.0002600300358608365, 0.0002675275318324566, 0.00024435523664578795, 0.00021758745424449444, 0.0002627345093060285, 0.0003010401560459286, 0.00023053601034916937, 0.00028650634340010583, 0.00024775887141004205, 0.00023561112175229937, 0.00027985303313471377, 0.00024819193640723825, 0.0002717491879593581, 7.433479913743213e-05]}
Train Epoch: 2 [0/816 (0%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 2 [36/816 (4%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [72/816 (9%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [108/816 (13%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 2 [144/816 (18%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [180/816 (22%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [216/816 (26%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [252/816 (31%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [288/816 (35%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [360/816 (44%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [396/816 (49%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [432/816 (53%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [468/816 (57%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [504/816 (62%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [540/816 (66%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 2 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [648/816 (79%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 2 [756/816 (93%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 2 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.00025871358229778707, 0.0002578969288151711, 0.0002609178773127496, 0.0002605755580589175, 0.0002507950412109494, 0.00026462526875548065, 0.00026971223996952176, 0.00026136578526347876, 0.00025110479327850044, 0.0002592272649053484, 0.00025294843362644315, 0.0002473285421729088, 0.0002528251789044589, 0.0002678586170077324, 0.00025823237956501544, 0.0002518068940844387, 0.0002524015144445002, 0.00025181533419527113, 6.364187720464543e-05], 'L_si': [1.4901161193847656e-07, 8.940696716308594e-08, 1.4901161193847656e-07, 1.1920928955078125e-07, 1.4901161193847656e-07, 1.4901161193847656e-07, 8.940696716308594e-08, 2.086162567138672e-07, 1.1920928955078125e-07, 1.1920928955078125e-07, 5.960464477539063e-08, 1.7881393432617188e-07, 1.1920928955078125e-07, 1.7881393432617188e-07, 1.1920928955078125e-07, 1.4901161193847656e-07, 1.4901161193847656e-07, 1.4901161193847656e-07, 1.1920928955078125e-07], 'L_grad': [0.0002585645706858486, 0.00025780752184800804, 0.00026076886570081115, 0.00026045634876936674, 0.00025064602959901094, 0.00026447625714354217, 0.0002696228330023587, 0.0002611571690067649, 0.00025098558398894966, 0.00025910805561579764, 0.00025288882898166776, 0.0002471497282385826, 0.0002527059696149081, 0.0002676798030734062, 0.00025811317027546465, 0.0002516578824725002, 0.00025225250283256173, 0.00025166632258333266, 6.352266791509464e-05]}
Train Epoch: 3 [0/816 (0%)] loss: 0.0003 L_si: 0.0000 L_grad: 0.0003 
Train Epoch: 3 [36/816 (4%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [72/816 (9%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [108/816 (13%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [144/816 (18%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 3 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [216/816 (26%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [288/816 (35%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [360/816 (44%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [396/816 (49%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [468/816 (57%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [576/816 (71%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 3 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 3 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.0001610543840797618, 0.00016021108604036272, 0.00017917115474119782, 0.000176698638824746, 0.00017164088785648346, 0.0001680291461525485, 0.00016458335448987782, 0.00017036158533301204, 0.00016723931184969842, 0.00016950946883298457, 0.00016224494902417064, 0.00017298593593295664, 0.0001573499321239069, 0.00016139248327817768, 0.00017084932187572122, 0.00016179494559764862, 0.00015582385822199285, 0.00015994533896446228, 4.320928928791545e-05], 'L_si': [2.9802322387695312e-08, 5.960464477539063e-08, 8.940696716308594e-08, 5.960464477539063e-08, 8.940696716308594e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 1.4901161193847656e-07, 8.940696716308594e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 8.940696716308594e-08], 'L_grad': [0.0001610245817573741, 0.00016015148139558733, 0.00017908174777403474, 0.00017663903417997062, 0.00017155148088932037, 0.0001679993438301608, 0.00016452374984510243, 0.00017036158533301204, 0.00016723931184969842, 0.00016944986418820918, 0.00016209593741223216, 0.00017289652896579355, 0.00015729032747913152, 0.00016136268095578998, 0.00017081951955333352, 0.00016176514327526093, 0.00015579405589960515, 0.00015994533896446228, 4.311988232075237e-05]}
Train Epoch: 4 [0/816 (0%)] loss: 0.0002 L_si: 0.0000 L_grad: 0.0002 
Train Epoch: 4 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [108/816 (13%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [180/816 (22%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [216/816 (26%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [360/816 (44%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [396/816 (49%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [684/816 (84%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 4 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 4 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch004-loss-0.0001.pth.tar ...
all losses in batch in validation:  {'loss': [8.267483644885942e-05, 8.882823021849617e-05, 9.129865793511271e-05, 8.749702101340517e-05, 8.101115963654593e-05, 8.188070933101699e-05, 8.432717731921002e-05, 8.560853893868625e-05, 8.407738641835749e-05, 8.844977855915204e-05, 9.057823626790196e-05, 7.927528349682689e-05, 8.800075011095032e-05, 9.890789806377143e-05, 8.714980504009873e-05, 8.36407343740575e-05, 9.435926767764613e-05, 8.724626968614757e-05, 2.0897583453916013e-05], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [8.264503412647173e-05, 8.882823021849617e-05, 9.129865793511271e-05, 8.755662565818056e-05, 8.098135731415823e-05, 8.188070933101699e-05, 8.429737499682233e-05, 8.560853893868625e-05, 8.40475840959698e-05, 8.839017391437665e-05, 9.057823626790196e-05, 7.924548117443919e-05, 8.800075011095032e-05, 9.896750270854682e-05, 8.709020039532334e-05, 8.36407343740575e-05, 9.432946535525844e-05, 8.718666504137218e-05, 2.0867781131528318e-05]}
Train Epoch: 5 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [180/816 (22%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [216/816 (26%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [324/816 (40%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [360/816 (44%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [396/816 (49%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 5 [720/816 (88%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [756/816 (93%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 5 [792/816 (97%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [8.14919185359031e-05, 8.081115083768964e-05, 8.25231327326037e-05, 7.483201625291258e-05, 7.889004336902872e-05, 7.631690095877275e-05, 8.15427047200501e-05, 8.170345245162025e-05, 7.471600838471204e-05, 8.024717681109905e-05, 8.38575215311721e-05, 7.721788279013708e-05, 7.999139052117243e-05, 7.568740693386644e-05, 7.959987851791084e-05, 8.266919030575082e-05, 8.285854710265994e-05, 7.646791345905513e-05, 2.154210233129561e-05], 'L_si': [2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [8.14621162135154e-05, 8.081115083768964e-05, 8.2493330410216e-05, 7.483201625291258e-05, 7.883043872425333e-05, 7.628709863638505e-05, 8.15129023976624e-05, 8.176305709639564e-05, 7.474581070709974e-05, 8.027697913348675e-05, 8.38277192087844e-05, 7.721788279013708e-05, 7.996158819878474e-05, 7.565760461147875e-05, 7.959987851791084e-05, 8.266919030575082e-05, 8.285854710265994e-05, 7.649771578144282e-05, 2.1512300008907914e-05]}
Train Epoch: 6 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [36/816 (4%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 6 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [216/816 (26%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [324/816 (40%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 6 [360/816 (44%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [396/816 (49%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 6 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [468/816 (57%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [504/816 (62%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [540/816 (66%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [576/816 (71%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [648/816 (79%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 6 [792/816 (97%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [6.242270319489762e-05, 6.24856329523027e-05, 6.612914148718119e-05, 6.363682769006118e-05, 7.085602555889636e-05, 6.194879824761301e-05, 6.911031232448295e-05, 7.391026156255975e-05, 6.806581222917885e-05, 6.759902316844091e-05, 6.149210821604356e-05, 6.749968451913446e-05, 6.565733201568946e-05, 6.270718586165458e-05, 6.798144022468477e-05, 7.097538764355704e-05, 6.661916995653883e-05, 6.651441071880981e-05, 1.5607711247866973e-05], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0], 'L_grad': [6.236309855012223e-05, 6.2455830629915e-05, 6.60397345200181e-05, 6.357722304528579e-05, 7.085602555889636e-05, 6.194879824761301e-05, 6.914011464687064e-05, 7.394006388494745e-05, 6.809561455156654e-05, 6.756922084605321e-05, 6.140270124888048e-05, 6.746988219674677e-05, 6.571693666046485e-05, 6.267738353926688e-05, 6.798144022468477e-05, 7.100518996594474e-05, 6.658936763415113e-05, 6.645480607403442e-05, 1.5607711247866973e-05]}
Train Epoch: 7 [0/816 (0%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 7 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [216/816 (26%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [252/816 (31%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [288/816 (35%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [432/816 (53%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 7 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 7 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [648/816 (79%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 7 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 7 [756/816 (93%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 7 [792/816 (97%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [5.288918691803701e-05, 5.672851330018602e-05, 5.552741640713066e-05, 5.0574115448398516e-05, 5.452060213428922e-05, 5.055298242950812e-05, 4.9965266953222454e-05, 5.764160232502036e-05, 5.756322934757918e-05, 5.4303876822814345e-05, 5.503463762579486e-05, 5.735389640904032e-05, 5.0389870011713356e-05, 5.1044942665612325e-05, 5.3430496336659417e-05, 5.53558420506306e-05, 5.754169978899881e-05, 5.4949618061073124e-05, 1.1519492545630783e-05], 'L_si': [5.960464477539063e-08, 0.0, 1.1920928955078125e-07, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, 8.940696716308594e-08, 0.0], 'L_grad': [5.282958227326162e-05, 5.672851330018602e-05, 5.540820711757988e-05, 5.060391777078621e-05, 5.4490799811901525e-05, 5.0523180107120425e-05, 4.999506927561015e-05, 5.770120696979575e-05, 5.7593031669966877e-05, 5.427407450042665e-05, 5.497503298101947e-05, 5.741350105381571e-05, 5.036006768932566e-05, 5.1044942665612325e-05, 5.3430496336659417e-05, 5.541544669540599e-05, 5.76013044337742e-05, 5.486021109391004e-05, 1.1519492545630783e-05]}
Train Epoch: 8 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [108/816 (13%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [288/816 (35%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 8 [324/816 (40%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 8 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 8 [720/816 (88%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [756/816 (93%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 8 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch008-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [5.935649460298009e-05, 5.9961828810628504e-05, 5.5399126722477376e-05, 5.2418508857954293e-05, 6.171380664454773e-05, 6.362608110066503e-05, 5.781856089015491e-05, 5.603032695944421e-05, 5.7728517276700586e-05, 5.8489778893999755e-05, 6.112971459515393e-05, 5.791655712528154e-05, 5.742335633840412e-05, 5.812431118101813e-05, 5.7923884014599025e-05, 6.342677806969732e-05, 5.8574129070620984e-05, 5.3729338105767965e-05, 1.4862051102682017e-05], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [5.93266922805924e-05, 5.99916311330162e-05, 5.5339522077701986e-05, 5.2418508857954293e-05, 6.174360896693543e-05, 6.365588342305273e-05, 5.778875856776722e-05, 5.597072231466882e-05, 5.7728517276700586e-05, 5.840037192683667e-05, 6.115951691754162e-05, 5.788675480289385e-05, 5.736375169362873e-05, 5.812431118101813e-05, 5.7923884014599025e-05, 6.345658039208502e-05, 5.854432674823329e-05, 5.3669733460992575e-05, 1.4802446457906626e-05]}
Train Epoch: 9 [0/816 (0%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 9 [36/816 (4%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 9 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [144/816 (18%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 9 [180/816 (22%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 9 [216/816 (26%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 9 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 9 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 9 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.098998659988865e-05, 8.584998431615531e-05, 7.528260175604373e-05, 7.842941704438999e-05, 8.395985059905797e-05, 8.626745693618432e-05, 7.376012217719108e-05, 7.535637269029394e-05, 7.734504470136017e-05, 7.656066736672074e-05, 8.614038961241022e-05, 7.948268466861919e-05, 8.580058056395501e-05, 7.684688898734748e-05, 8.465061546303332e-05, 8.359046478290111e-05, 8.055208309087902e-05, 7.922304939711466e-05, 1.928371420945041e-05], 'L_si': [-2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [8.101978892227635e-05, 8.584998431615531e-05, 7.525279943365604e-05, 7.83698123996146e-05, 8.393004827667028e-05, 8.626745693618432e-05, 7.376012217719108e-05, 7.529676804551855e-05, 7.734504470136017e-05, 7.650106272194535e-05, 8.614038961241022e-05, 7.945288234623149e-05, 8.577077824156731e-05, 7.681708666495979e-05, 8.465061546303332e-05, 8.356066246051341e-05, 8.052228076849133e-05, 7.928265404189005e-05, 1.93433188542258e-05]}
Train Epoch: 10 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 10 [36/816 (4%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 10 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [108/816 (13%)] loss: 0.0001 L_si: -0.0000 L_grad: 0.0001 
Train Epoch: 10 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [612/816 (75%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 10 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [684/816 (84%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 10 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 10 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 10 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.8258076023776084e-05, 5.5398817494278774e-05, 5.763374792877585e-05, 5.9587844589259475e-05, 5.87091053603217e-05, 5.48244861420244e-05, 5.7447927247267216e-05, 5.613456596620381e-05, 5.643820622935891e-05, 5.977265027468093e-05, 5.6036726164165884e-05, 5.5842247093096375e-05, 5.343786324374378e-05, 5.817165947519243e-05, 5.896338552702218e-05, 5.930932820774615e-05, 5.7497225498082116e-05, 5.373713793233037e-05, 1.3046305866737384e-05], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 8.940696716308594e-08, -5.960464477539063e-08], 'L_grad': [5.822827370138839e-05, 5.542861981666647e-05, 5.760394560638815e-05, 5.9587844589259475e-05, 5.876871000509709e-05, 5.47946838196367e-05, 5.735852028010413e-05, 5.6164368288591504e-05, 5.6408403906971216e-05, 5.977265027468093e-05, 5.6036726164165884e-05, 5.581244477070868e-05, 5.340806092135608e-05, 5.820146179758012e-05, 5.893358320463449e-05, 5.930932820774615e-05, 5.7497225498082116e-05, 5.3647730965167284e-05, 1.3105910511512775e-05]}
Train Epoch: 11 [0/816 (0%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 11 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [72/816 (9%)] loss: 0.0001 L_si: 0.0000 L_grad: 0.0001 
Train Epoch: 11 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 11 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 11 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.0439827241934836e-05, 3.30550319631584e-05, 2.9838176487828605e-05, 2.7283598683425225e-05, 3.0097482522251084e-05, 3.263184044044465e-05, 3.2618496334180236e-05, 2.4461023713229224e-05, 3.5708420909941196e-05, 3.246635969844647e-05, 3.670353180496022e-05, 3.123471833532676e-05, 3.285567800048739e-05, 3.165638554492034e-05, 3.3704254747135565e-05, 2.9971324693178758e-05, 3.08510207105428e-05, 2.957621472887695e-05, 5.809058166050818e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [3.046962956432253e-05, 3.3025229640770704e-05, 2.98679788102163e-05, 2.725379636103753e-05, 3.012728484463878e-05, 3.257223579566926e-05, 3.2558891689404845e-05, 2.443122139084153e-05, 3.5708420909941196e-05, 3.246635969844647e-05, 3.6733334127347916e-05, 3.1204916012939066e-05, 3.2796073355711997e-05, 3.171599018969573e-05, 3.373405706952326e-05, 2.9941522370791063e-05, 3.079141606576741e-05, 2.9606017051264644e-05, 5.838860488438513e-06]}
Train Epoch: 12 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 12 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 12 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch012-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.0147273719194345e-05, 2.878530358429998e-05, 3.1696996302343905e-05, 2.9441020160447806e-05, 3.0447781682596542e-05, 2.838885302480776e-05, 3.07747395709157e-05, 3.111587284365669e-05, 2.9248300052131526e-05, 2.8989921702304855e-05, 3.0052928195800632e-05, 2.9950535463285632e-05, 2.7249356207903475e-05, 3.067972284043208e-05, 3.0288534617284313e-05, 3.0114118999335915e-05, 2.8113801818108186e-05, 2.9294084015418775e-05, 7.175180599006126e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08], 'L_grad': [3.011747139680665e-05, 2.8815105906687677e-05, 3.166719397995621e-05, 2.9441020160447806e-05, 3.0447781682596542e-05, 2.8418655347195454e-05, 3.083434421569109e-05, 3.1086070521268994e-05, 2.9248300052131526e-05, 2.8930317057529464e-05, 3.0023125873412937e-05, 2.9861128496122546e-05, 2.7249356207903475e-05, 3.070952516281977e-05, 3.0318336939672008e-05, 3.0054514354560524e-05, 2.814360414049588e-05, 2.9294084015418775e-05, 7.204982921393821e-06]}
Train Epoch: 13 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 13 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 13 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.5207678340375423e-05, 3.9813916373532265e-05, 4.422740312293172e-05, 4.3827345507452264e-05, 3.5867124097421765e-05, 4.1281597077613696e-05, 3.9122780435718596e-05, 4.9954545829677954e-05, 4.950840229867026e-05, 4.510295912041329e-05, 4.1157385567203164e-05, 3.869077409035526e-05, 4.3994441512040794e-05, 4.1092098399531096e-05, 3.823266888502985e-05, 4.477171751204878e-05, 4.666380482376553e-05, 4.669204281526618e-05, 9.787039743969217e-06], 'L_si': [5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 8.940696716308594e-08, 2.9802322387695312e-08, 0.0], 'L_grad': [4.514807369560003e-05, 3.9813916373532265e-05, 4.422740312293172e-05, 4.379754318506457e-05, 3.5867124097421765e-05, 4.1221992432838306e-05, 3.915258275810629e-05, 4.9894941184902564e-05, 4.947859997628257e-05, 4.510295912041329e-05, 4.112758324481547e-05, 3.866097176796757e-05, 4.39646391896531e-05, 4.10622960771434e-05, 3.817306424025446e-05, 4.471211286727339e-05, 4.6574397856602445e-05, 4.666224049287848e-05, 9.787039743969217e-06]}
Train Epoch: 14 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 14 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 14 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.4461412724340335e-05, 3.601691423682496e-05, 3.464505425654352e-05, 4.2340761865489185e-05, 3.489269147394225e-05, 3.2299729355145246e-05, 3.845465835183859e-05, 3.307036240585148e-05, 3.4819233405869454e-05, 4.2883089918177575e-05, 3.63992658094503e-05, 3.3119657018687576e-05, 3.065431155846454e-05, 3.946717697544955e-05, 3.739920794032514e-05, 3.652201849035919e-05, 3.1314772058976814e-05, 3.687232674565166e-05, 1.2179902114439756e-05], 'L_si': [0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [3.4461412724340335e-05, 3.5987111914437264e-05, 3.467485657893121e-05, 4.237056418787688e-05, 3.4862889151554555e-05, 3.226992703275755e-05, 3.845465835183859e-05, 3.310016472823918e-05, 3.478943108348176e-05, 4.2823485273402184e-05, 3.6429068131837994e-05, 3.3060052373912185e-05, 3.062450923607685e-05, 3.943737465306185e-05, 3.739920794032514e-05, 3.652201849035919e-05, 3.128496973658912e-05, 3.681272210087627e-05, 1.215009979205206e-05]}
Train Epoch: 15 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 15 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 15 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [2.6338610041420907e-05, 3.089611709583551e-05, 2.6190104108536616e-05, 2.7455356757855043e-05, 2.7476560717332177e-05, 2.8241858672117814e-05, 2.987158950418234e-05, 2.904358370869886e-05, 2.8381060474202968e-05, 2.7823181881103665e-05, 2.7933971068705432e-05, 2.8669328457908705e-05, 2.6779689505929127e-05, 2.6384075681562535e-05, 2.6795170924742706e-05, 2.9895642001065426e-05, 2.7217129172640853e-05, 2.900929939642083e-05, 6.973985819058726e-06], 'L_si': [0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0], 'L_grad': [2.6338610041420907e-05, 3.089611709583551e-05, 2.6190104108536616e-05, 2.7485159080242738e-05, 2.7506363039719872e-05, 2.8241858672117814e-05, 2.9901391826570034e-05, 2.904358370869886e-05, 2.8410862796590663e-05, 2.773377491394058e-05, 2.7904168746317737e-05, 2.86991307802964e-05, 2.6720084861153737e-05, 2.635427335917484e-05, 2.6795170924742706e-05, 2.986583967867773e-05, 2.7217129172640853e-05, 2.900929939642083e-05, 6.973985819058726e-06]}
Train Epoch: 16 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 16 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 16 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch016-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.293673787789885e-05, 2.187230347772129e-05, 2.15861637116177e-05, 2.1473068045452237e-05, 2.1627562091453e-05, 2.2043153876438737e-05, 2.162673627026379e-05, 2.057415258605033e-05, 1.946080919879023e-05, 1.9981454897788353e-05, 2.124549610016402e-05, 2.0307496015448123e-05, 2.045663131866604e-05, 2.1933177777100354e-05, 2.0943220079061575e-05, 2.1006897441111505e-05, 2.0416224288055673e-05, 2.1241257854853757e-05, 5.1458150664984714e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 8.940696716308594e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [2.2906935555511154e-05, 2.1902105800108984e-05, 2.1556361389230005e-05, 2.1413463400676847e-05, 2.1538155124289915e-05, 2.2043153876438737e-05, 2.1596933947876096e-05, 2.0544350263662636e-05, 1.9550216165953316e-05, 1.9951652575400658e-05, 2.1215693777776323e-05, 2.0277693693060428e-05, 2.045663131866604e-05, 2.196298009948805e-05, 2.0883615434286185e-05, 2.0947292796336114e-05, 2.0356619643280283e-05, 2.121145553246606e-05, 5.086210421723081e-06]}
Train Epoch: 17 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 17 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 17 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.9307995898998342e-05, 1.961959969776217e-05, 1.823985621740576e-05, 1.911867002490908e-05, 1.9141338270856068e-05, 2.0733874407596886e-05, 1.658636574575212e-05, 1.8223812730866484e-05, 2.0258336007827893e-05, 2.236550790257752e-05, 2.1158979507163167e-05, 1.702714325801935e-05, 2.0561708879540674e-05, 1.8220638594357297e-05, 1.9248731405241415e-05, 1.977604188141413e-05, 2.0476321878959425e-05, 1.893161970656365e-05, 6.116395070421277e-06], 'L_si': [2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08], 'L_grad': [1.9278193576610647e-05, 1.961959969776217e-05, 1.8180251572630368e-05, 1.9148472347296774e-05, 1.9200942915631458e-05, 2.0674269762821496e-05, 1.6616168068139814e-05, 1.8164208086091094e-05, 2.0288138330215588e-05, 2.236550790257752e-05, 2.1158979507163167e-05, 1.708674790279474e-05, 2.059151120192837e-05, 1.8220638594357297e-05, 1.927853372762911e-05, 1.971643723663874e-05, 2.0476321878959425e-05, 1.893161970656365e-05, 6.086592748033581e-06]}
Train Epoch: 18 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 18 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 18 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.3428794773062691e-05, 1.4115979865891859e-05, 1.5662484656786546e-05, 1.5429008271894418e-05, 1.4073485544940922e-05, 1.3559363651438616e-05, 1.2668299859797116e-05, 1.3519515960069839e-05, 1.2802178389392793e-05, 1.3982431482872926e-05, 1.3965707694296725e-05, 1.4596228538721334e-05, 1.5048656678118277e-05, 1.459173290641047e-05, 1.572630753798876e-05, 1.4888920304656494e-05, 1.4158292287902441e-05, 1.456277459510602e-05, 3.8895022953511216e-06], 'L_si': [0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08], 'L_grad': [1.3428794773062691e-05, 1.4145782188279554e-05, 1.5722089301561937e-05, 1.5399205949506722e-05, 1.4043683222553227e-05, 1.3499759006663226e-05, 1.2638497537409421e-05, 1.3519515960069839e-05, 1.2802178389392793e-05, 1.3922826838097535e-05, 1.3965707694296725e-05, 1.4596228538721334e-05, 1.5048656678118277e-05, 1.4621535228798166e-05, 1.5756109860376455e-05, 1.4888920304656494e-05, 1.4158292287902441e-05, 1.456277459510602e-05, 3.829897650575731e-06]}
Train Epoch: 19 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 19 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 19 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.1192728379683103e-05, 1.5222827641991898e-05, 1.2039130524499342e-05, 1.0509642379474826e-05, 1.1437770808697678e-05, 1.2369550859148148e-05, 1.085132134903688e-05, 1.2387999959173612e-05, 1.1228664334339555e-05, 1.187149973702617e-05, 1.2672909178945702e-05, 1.222784339915961e-05, 1.2368547686492093e-05, 9.730180863698479e-06, 1.149184572568629e-05, 1.4440252925851382e-05, 9.382767530041747e-06, 1.148835781350499e-05, 2.819575456669554e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0], 'L_grad': [1.1162926057295408e-05, 1.5252629964379594e-05, 1.2039130524499342e-05, 1.0509642379474826e-05, 1.1407968486309983e-05, 1.2309946214372758e-05, 1.085132134903688e-05, 1.2328395314398222e-05, 1.1228664334339555e-05, 1.187149973702617e-05, 1.2702711501333397e-05, 1.222784339915961e-05, 1.2308943041716702e-05, 9.759983186086174e-06, 1.149184572568629e-05, 1.4350845958688296e-05, 9.323162885266356e-06, 1.14287531687296e-05, 2.819575456669554e-06]}
Train Epoch: 20 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 20 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 20 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch020-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.063830652332399e-05, 2.3107468223315664e-05, 2.4183122150134295e-05, 2.4212480639107525e-05, 2.1393205315689556e-05, 1.8621534763951786e-05, 3.0170373065629974e-05, 1.8714556063059717e-05, 1.8780787286232226e-05, 2.4253329684142955e-05, 2.2732114302925766e-05, 1.8016397007158957e-05, 1.872278517112136e-05, 1.7487476725364104e-05, 2.8626898711081594e-05, 2.3445612896466628e-05, 2.060562837868929e-05, 2.336702891625464e-05, 8.24779363028938e-06], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [2.063830652332399e-05, 2.313727054570336e-05, 2.4183122150134295e-05, 2.418267831671983e-05, 2.142300763807725e-05, 1.859173244156409e-05, 3.0170373065629974e-05, 1.8684753740672022e-05, 1.8780787286232226e-05, 2.4193725039367564e-05, 2.2732114302925766e-05, 1.7986594684771262e-05, 1.8752587493509054e-05, 1.745767440297641e-05, 2.8626898711081594e-05, 2.3445612896466628e-05, 2.0516221411526203e-05, 2.3337226593866944e-05, 8.277595952677075e-06]}
Train Epoch: 21 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 21 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 21 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.2195779163448606e-05, 9.731953468872234e-06, 1.0757246855064295e-05, 1.0382011168985628e-05, 1.1396517948014662e-05, 1.0142934115719981e-05, 1.043512747855857e-05, 9.480995686317328e-06, 1.0223327990388498e-05, 1.1160450412717182e-05, 8.76211743161548e-06, 1.0802230463013984e-05, 9.956059329851996e-06, 1.1018346413038671e-05, 1.0110285074915737e-05, 1.0740277502918616e-05, 1.1356931281625293e-05, 1.1340111086610705e-05, 2.619745828269515e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 1.1920928955078125e-07, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08], 'L_grad': [1.216597684106091e-05, 9.76175579125993e-06, 1.0697642210288905e-05, 1.0382011168985628e-05, 1.1396517948014662e-05, 1.0113131793332286e-05, 1.0464929800946265e-05, 9.480995686317328e-06, 1.0193525668000802e-05, 1.1041241123166401e-05, 8.791919754003175e-06, 1.0772428140626289e-05, 9.9262570074643e-06, 1.1048148735426366e-05, 1.0080482752528042e-05, 1.071047518053092e-05, 1.1386733604012989e-05, 1.1340111086610705e-05, 2.6495481506572105e-06]}
Train Epoch: 22 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 22 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 22 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.505996988271363e-05, 1.218496254296042e-05, 1.3416473848337773e-05, 1.3549937648349442e-05, 1.3548672541219275e-05, 1.1486356015666388e-05, 1.1798871128121391e-05, 1.1687872756738216e-05, 1.3244129149825312e-05, 1.2914093531435356e-05, 1.376897853333503e-05, 1.2726832210319117e-05, 1.2201971912872978e-05, 1.2383332432364114e-05, 1.1842927051475272e-05, 1.4380028915184084e-05, 1.1849196198454592e-05, 1.465118839405477e-05, 3.7117097235750407e-06], 'L_si': [5.960464477539063e-08, 0.0, -5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [1.500036523793824e-05, 1.218496254296042e-05, 1.3476078493113164e-05, 1.3490333003574051e-05, 1.351887021883158e-05, 1.1456553693278693e-05, 1.1798871128121391e-05, 1.165807043435052e-05, 1.3244129149825312e-05, 1.2914093531435356e-05, 1.3798780855722725e-05, 1.2726832210319117e-05, 1.2231774235260673e-05, 1.2383332432364114e-05, 1.1842927051475272e-05, 1.4380028915184084e-05, 1.1878998520842288e-05, 1.465118839405477e-05, 3.7117097235750407e-06]}
Train Epoch: 23 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 23 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 23 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [9.638011761126108e-06, 9.977165063901339e-06, 9.53883136389777e-06, 9.909826985676773e-06, 9.559662430547178e-06, 9.273411706089973e-06, 9.19721060199663e-06, 9.41606776905246e-06, 9.042179044627119e-06, 9.262676030630246e-06, 1.0023356480814982e-05, 8.324599548359402e-06, 1.0224712241324596e-05, 8.821774827083573e-06, 9.953897460945882e-06, 9.909931577567477e-06, 8.953820724855177e-06, 1.0117175406776369e-05, 2.2342708234646125e-06], 'L_si': [2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [9.608209438738413e-06, 9.917560419125948e-06, 9.598436008673161e-06, 9.939629308064468e-06, 9.529860108159482e-06, 9.303214028477669e-06, 9.13760595722124e-06, 9.386265446664765e-06, 9.042179044627119e-06, 9.262676030630246e-06, 9.963751836039592e-06, 8.354401870747097e-06, 1.01949099189369e-05, 8.851577149471268e-06, 9.983699783333577e-06, 9.909931577567477e-06, 8.983623047242872e-06, 1.0057570762000978e-05, 2.204468501076917e-06]}
Train Epoch: 24 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 24 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 24 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch024-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.5909539797576144e-05, 1.6244421203737147e-05, 1.4368983102031052e-05, 1.9312572476337664e-05, 1.4447150533669628e-05, 1.7592588847037405e-05, 1.3379616575548425e-05, 1.4281225958256982e-05, 1.649778278078884e-05, 1.5897927369223908e-05, 1.135263119067531e-05, 1.938677451107651e-05, 1.2418438927852549e-05, 1.3172259968996514e-05, 1.7787377146305516e-05, 1.6716596292098984e-05, 1.4950606782804243e-05, 1.5395646187243983e-05, 4.80771268485114e-06], 'L_si': [0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.5909539797576144e-05, 1.6274223526124842e-05, 1.4339180779643357e-05, 1.928277015394997e-05, 1.4476952856057324e-05, 1.7592588847037405e-05, 1.3320011930773035e-05, 1.4251423635869287e-05, 1.649778278078884e-05, 1.5897927369223908e-05, 1.1322828868287615e-05, 1.938677451107651e-05, 1.2388636605464853e-05, 1.3112655324221123e-05, 1.781717946869321e-05, 1.668679396971129e-05, 1.4920804460416548e-05, 1.542544850963168e-05, 4.837515007238835e-06]}
Train Epoch: 25 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 25 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 25 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [9.986428267438896e-06, 9.533555385132786e-06, 9.114591193792876e-06, 9.869100722426083e-06, 1.0980762453982607e-05, 1.1671058018691838e-05, 1.2231309483468067e-05, 1.2468282875488512e-05, 8.988545232568868e-06, 9.366529411636293e-06, 9.16037242859602e-06, 8.587534466641955e-06, 8.343476110894699e-06, 9.613103429728653e-06, 1.0619115528243128e-05, 1.1510481272125617e-05, 7.154019385779975e-06, 8.538742804375943e-06, 2.488886138962698e-06], 'L_si': [-2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, -8.940696716308594e-08], 'L_grad': [1.0016230589826591e-05, 9.533555385132786e-06, 9.144393516180571e-06, 9.809496077650692e-06, 1.0950960131594911e-05, 1.1611453373916447e-05, 1.2201507161080372e-05, 1.2438480553100817e-05, 8.928940587793477e-06, 9.426134056411684e-06, 9.16037242859602e-06, 8.587534466641955e-06, 8.373278433282394e-06, 9.642905752116349e-06, 1.0619115528243128e-05, 1.1510481272125617e-05, 7.18382170816767e-06, 8.538742804375943e-06, 2.578293106125784e-06]}
Train Epoch: 26 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 26 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 26 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [7.281362741196062e-06, 6.543743893416831e-06, 8.048002200666815e-06, 7.33641581973643e-06, 6.587002644664608e-06, 6.977869816182647e-06, 8.134496056300122e-06, 8.14391296444228e-06, 6.7522155404731166e-06, 7.081698640831746e-06, 7.573144557682099e-06, 6.642925654887222e-06, 8.06191746960394e-06, 7.676130735490005e-06, 6.894527359690983e-06, 6.888784355396638e-06, 7.273216397152282e-06, 5.924598553974647e-06, 1.3926552355769672e-06], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [7.311165063583758e-06, 6.573546215804527e-06, 7.958595233503729e-06, 7.33641581973643e-06, 6.6466072894399986e-06, 7.007672138570342e-06, 8.134496056300122e-06, 8.173715286829975e-06, 6.7522155404731166e-06, 7.1115009632194415e-06, 7.5433422352944035e-06, 6.6131233324995264e-06, 8.06191746960394e-06, 7.676130735490005e-06, 6.924329682078678e-06, 6.829179710621247e-06, 7.273216397152282e-06, 5.8649939091992564e-06, 1.3330505908015766e-06]}
Train Epoch: 27 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 27 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 27 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0312409358448349e-05, 9.1338406491559e-06, 1.3663557183463126e-05, 1.3211390069045592e-05, 1.1519084182509687e-05, 1.2441910257621203e-05, 1.2852225154347252e-05, 1.4717621525051072e-05, 1.6073983715614304e-05, 1.204938962473534e-05, 1.4041012946108822e-05, 1.2933578545926139e-05, 1.2079384759999812e-05, 1.1764966075133998e-05, 1.0748496606538538e-05, 1.1844677828776184e-05, 1.2530113963293843e-05, 1.0997237041010521e-05, 2.550615135987755e-06], 'L_si': [-5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [1.037201400322374e-05, 9.104038326768205e-06, 1.3633754861075431e-05, 1.3241192391433287e-05, 1.1548886504897382e-05, 1.2441910257621203e-05, 1.2822422831959557e-05, 1.4747423847438768e-05, 1.6103786038002e-05, 1.204938962473534e-05, 1.4070815268496517e-05, 1.299318319070153e-05, 1.2019780115224421e-05, 1.1794768397521693e-05, 1.0748496606538538e-05, 1.1844677828776184e-05, 1.2500311640906148e-05, 1.0967434718622826e-05, 2.6102197807631455e-06]}
Train Epoch: 28 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 28 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 28 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch028-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.2645472452277318e-05, 1.3194279745221138e-05, 1.8658291082829237e-05, 1.5597513993270695e-05, 1.596776201040484e-05, 1.520145178801613e-05, 1.9058810721617192e-05, 1.4659951375506353e-05, 1.5832469216547906e-05, 1.123386300605489e-05, 1.7019377992255613e-05, 1.7959893739316612e-05, 1.3385352758632507e-05, 1.84800592251122e-05, 1.5052479284349829e-05, 1.4151240065984894e-05, 1.640566551941447e-05, 1.6168907677638344e-05, 2.3338518531090813e-06], 'L_si': [0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.2645472452277318e-05, 1.3164477422833443e-05, 1.8688093405216932e-05, 1.562731631565839e-05, 1.590815736562945e-05, 1.5141847143240739e-05, 1.9058810721617192e-05, 1.4719556020281743e-05, 1.5832469216547906e-05, 1.1204060683667194e-05, 1.6989575669867918e-05, 1.7900289094541222e-05, 1.3385352758632507e-05, 1.84800592251122e-05, 1.5022676961962134e-05, 1.4181042388372589e-05, 1.634606087463908e-05, 1.619871000002604e-05, 2.3636541754967766e-06]}
Train Epoch: 29 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 29 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 29 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.221141004265519e-06, 5.567429070651997e-06, 7.84002349973889e-06, 7.657415153516922e-06, 6.817861958552385e-06, 6.956876404728973e-06, 7.2030506998999044e-06, 7.727550837444142e-06, 7.68090922065312e-06, 7.33614888304146e-06, 6.851534180896124e-06, 7.442307378369151e-06, 7.3908518061216455e-06, 7.571633886982454e-06, 6.97272116667591e-06, 7.647673555766232e-06, 7.10421591065824e-06, 6.708104137942428e-06, 2.11989072340657e-06], 'L_si': [5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0], 'L_grad': [7.161536359490128e-06, 5.567429070651997e-06, 7.84002349973889e-06, 7.687217475904617e-06, 6.817861958552385e-06, 6.897271759953583e-06, 7.2030506998999044e-06, 7.787155482219532e-06, 7.651106898265425e-06, 7.365951205429155e-06, 6.791929536120733e-06, 7.412505055981455e-06, 7.420654128509341e-06, 7.541831564594759e-06, 6.97272116667591e-06, 7.588068456243491e-06, 7.04461126588285e-06, 6.708104137942428e-06, 2.11989072340657e-06]}
Train Epoch: 30 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 30 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 30 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
New Learning Rate: 0.000150
all losses in batch in validation:  {'loss': [9.50609683059156e-06, 7.506038855353836e-06, 7.610370175825665e-06, 6.140007371868705e-06, 7.100381480995566e-06, 9.611736459191889e-06, 6.084239430492744e-06, 6.57961663819151e-06, 5.811913979414385e-06, 6.950881015654886e-06, 7.924300007289276e-06, 8.16691044747131e-06, 7.501534128095955e-06, 7.608040505147073e-06, 7.349275620072149e-06, 7.746133633190766e-06, 6.869093340355903e-06, 6.9468860601773486e-06, 1.6759428262957954e-06], 'L_si': [0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [9.50609683059156e-06, 7.476236532966141e-06, 7.610370175825665e-06, 6.169809694256401e-06, 7.130183803383261e-06, 9.581934136804193e-06, 6.1438440752681345e-06, 6.609418960579205e-06, 5.811913979414385e-06, 6.8912763708794955e-06, 7.95410232967697e-06, 8.16691044747131e-06, 7.53133645048365e-06, 7.578238182759378e-06, 7.349275620072149e-06, 7.775935955578461e-06, 6.839291017968208e-06, 6.976688382565044e-06, 1.735547471071186e-06]}
Train Epoch: 31 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 31 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 31 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.048876583809033e-05, 9.751317520567682e-06, 7.723551789240446e-06, 9.71704866969958e-06, 1.015096677292604e-05, 8.931461707106791e-06, 9.867571861832403e-06, 7.80807386036031e-06, 8.668143891554791e-06, 9.112834959523752e-06, 8.403264473599847e-06, 8.276607331936248e-06, 1.131729641201673e-05, 9.74762315308908e-06, 8.095905286609195e-06, 9.393786967848428e-06, 9.723667972139083e-06, 9.619932825444266e-06, 3.0492817586491583e-06], 'L_si': [0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 8.940696716308594e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.048876583809033e-05, 9.751317520567682e-06, 7.753354111628141e-06, 9.687246347311884e-06, 1.021057141770143e-05, 8.931461707106791e-06, 9.778164894669317e-06, 7.748469215584919e-06, 8.608539246779401e-06, 9.112834959523752e-06, 8.433066795987543e-06, 8.217002687160857e-06, 1.125769176724134e-05, 9.74762315308908e-06, 8.12570760899689e-06, 9.423589290236123e-06, 9.723667972139083e-06, 9.590130503056571e-06, 3.0790840810368536e-06]}
Train Epoch: 32 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 32 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 32 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch032-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.847227162623312e-06, 4.1617959141149186e-06, 4.077345238329144e-06, 4.717601768788882e-06, 4.26075757786748e-06, 6.461450539063662e-06, 3.475995072221849e-06, 4.824502411793219e-06, 6.049890089343535e-06, 5.2217073971405625e-06, 4.8717947720433585e-06, 5.200008672545664e-06, 5.301105829857988e-06, 5.404775038186926e-06, 4.221631115797209e-06, 4.509196514845826e-06, 4.526035354501801e-06, 5.233523552305996e-06, 1.333554791926872e-06], 'L_si': [2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [3.817424840235617e-06, 4.1617959141149186e-06, 4.047542915941449e-06, 4.717601768788882e-06, 4.290559900255175e-06, 6.461450539063662e-06, 3.5057973946095444e-06, 4.824502411793219e-06, 6.049890089343535e-06, 5.251509719528258e-06, 4.931399416818749e-06, 5.200008672545664e-06, 5.271303507470293e-06, 5.404775038186926e-06, 4.221631115797209e-06, 4.538998837233521e-06, 4.496233032114105e-06, 5.293128197081387e-06, 1.3633571143145673e-06]}
Train Epoch: 33 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 33 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 33 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [5.321005119185429e-06, 4.804867330676643e-06, 4.0623081076773815e-06, 4.182421889709076e-06, 4.561153673421359e-06, 3.7184358916420024e-06, 4.950765742250951e-06, 4.557364263746422e-06, 5.677928129443899e-06, 4.5555311771749984e-06, 5.570824214373715e-06, 4.887877366854809e-06, 4.289397111278959e-06, 3.7037737001810456e-06, 3.684332114062272e-06, 3.995425686298404e-06, 5.3389589993457776e-06, 4.317806087783538e-06, 1.1518051223902148e-06], 'L_si': [0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 8.940696716308594e-08], 'L_grad': [5.321005119185429e-06, 4.7452626859012526e-06, 4.0623081076773815e-06, 4.122817244933685e-06, 4.561153673421359e-06, 3.7482382140296977e-06, 4.89116109747556e-06, 4.616968908521812e-06, 5.618323484668508e-06, 4.615135821950389e-06, 5.570824214373715e-06, 4.828272722079419e-06, 4.259594788891263e-06, 3.733576022568741e-06, 3.7141344364499673e-06, 3.935821041523013e-06, 5.309156676958082e-06, 4.3774107325589284e-06, 1.0623981552271289e-06]}
Train Epoch: 34 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 34 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 34 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [4.00832004743279e-06, 3.614929255491006e-06, 3.081641125390888e-06, 3.7223187518975465e-06, 3.732401410161401e-06, 3.624587634476484e-06, 4.442734734766418e-06, 3.3165451895911247e-06, 3.842646947305184e-06, 3.474009190540528e-06, 2.9510479180316906e-06, 3.8015491554688197e-06, 3.370400008861907e-06, 4.038474344270071e-06, 3.6848680338152917e-06, 3.2207226468017325e-06, 3.269758508395171e-06, 3.659235062514199e-06, 1.0025969459093176e-06], 'L_si': [5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, -8.940696716308594e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08], 'L_grad': [3.948715402657399e-06, 3.614929255491006e-06, 3.1114434477785835e-06, 3.7223187518975465e-06, 3.7920060549367918e-06, 3.654389956864179e-06, 4.442734734766418e-06, 3.3165451895911247e-06, 3.93205391446827e-06, 3.474009190540528e-06, 2.980850240419386e-06, 3.7717468330811244e-06, 3.370400008861907e-06, 4.068276666657766e-06, 3.6848680338152917e-06, 3.2207226468017325e-06, 3.3293631531705614e-06, 3.7188397072895896e-06, 1.0622015906847082e-06]}
Train Epoch: 35 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 35 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 35 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.3317245247890241e-05, 9.021325240610167e-06, 1.4351639038068242e-05, 9.54164261202095e-06, 1.6375572158722207e-05, 1.4981998901930638e-05, 9.512355063634459e-06, 1.1752208592952229e-05, 1.3159604350221343e-05, 1.5896839613560587e-05, 1.282668745261617e-05, 1.3494866834662389e-05, 1.2056065315846354e-05, 1.1976622772635892e-05, 1.3455634871206712e-05, 1.0396982361271512e-05, 9.777021659829188e-06, 1.1495358194224536e-05, 3.880824351654155e-06], 'L_si': [0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.3317245247890241e-05, 8.991522918222472e-06, 1.4351639038068242e-05, 9.511840289633255e-06, 1.6405374481109902e-05, 1.5011801224318333e-05, 9.512355063634459e-06, 1.181181323772762e-05, 1.3219208994996734e-05, 1.5867037291172892e-05, 1.2856489775003865e-05, 1.3465064512274694e-05, 1.2026262993458658e-05, 1.1946820450248197e-05, 1.3485437193594407e-05, 1.0396982361271512e-05, 9.777021659829188e-06, 1.1525160516612232e-05, 3.85102202926646e-06]}
Train Epoch: 36 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 36 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 36 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch036-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.5113847439351957e-05, 1.6254953152383678e-05, 1.3584027328761294e-05, 1.7101745470426977e-05, 1.0715167263697367e-05, 1.3327045053301845e-05, 9.355642760056071e-06, 1.706273360468913e-05, 8.836937922751531e-06, 1.4102787645242643e-05, 1.3673883586307056e-05, 1.858374525909312e-05, 1.5953986803651787e-05, 9.783454515854828e-06, 1.34104338940233e-05, 1.4481083780992776e-05, 1.75731438503135e-05, 1.7741309420671314e-05, 3.1526797101832926e-06], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [1.5084045116964262e-05, 1.6254953152383678e-05, 1.3584027328761294e-05, 1.707194314803928e-05, 1.0715167263697367e-05, 1.3327045053301845e-05, 9.266235792892985e-06, 1.7032931282301433e-05, 8.807135600363836e-06, 1.4102787645242643e-05, 1.3673883586307056e-05, 1.8553942936705425e-05, 1.5924184481264092e-05, 9.813256838242523e-06, 1.3380631571635604e-05, 1.4481083780992776e-05, 1.7543341527925804e-05, 1.771150709828362e-05, 3.093075065407902e-06]}
Train Epoch: 37 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 37 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 37 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.0396289983182214e-05, 1.8996295693796128e-05, 1.7588798073120415e-05, 1.817851807572879e-05, 1.9189310478395782e-05, 1.6143263565027155e-05, 2.1952477254671976e-05, 1.78392838279251e-05, 1.9425468053668737e-05, 1.9964418243034743e-05, 2.248220880574081e-05, 2.115057395712938e-05, 2.1938334612059407e-05, 2.214333289884962e-05, 1.7397112969774753e-05, 1.922909177665133e-05, 1.2808593055524398e-05, 1.8658342014532536e-05, 5.448505362437572e-06], 'L_si': [-2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [2.042609230556991e-05, 1.8936691049020737e-05, 1.761860039550811e-05, 1.823812272050418e-05, 1.9159508156008087e-05, 1.6143263565027155e-05, 2.1952477254671976e-05, 1.7809481505537406e-05, 1.9425468053668737e-05, 1.9964418243034743e-05, 2.2452406483353116e-05, 2.1180376279517077e-05, 2.190853228967171e-05, 2.2113530576461926e-05, 1.7426915292162448e-05, 1.9199289454263635e-05, 1.2838395377912093e-05, 1.8658342014532536e-05, 5.448505362437572e-06]}
Train Epoch: 38 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 38 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 38 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.2506341085536405e-06, 2.840155502781272e-06, 3.1781953566678567e-06, 3.2332036425941624e-06, 3.86331839763443e-06, 3.3162523322971538e-06, 3.5342247883818345e-06, 3.064569227717584e-06, 3.565477982192533e-06, 2.609284365462372e-06, 2.5934423319995403e-06, 3.224145075364504e-06, 2.8136332730355207e-06, 3.305958216515137e-06, 3.2855723475222476e-06, 2.8869553716504015e-06, 3.350860879436368e-06, 3.4922900340461638e-06, 4.2021159174510103e-07], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [3.2208317861659452e-06, 2.840155502781272e-06, 3.1781953566678567e-06, 3.203401320206467e-06, 3.86331839763443e-06, 3.346054654684849e-06, 3.5342247883818345e-06, 3.064569227717584e-06, 3.5356756598048378e-06, 2.6688890102377627e-06, 2.563640009611845e-06, 3.224145075364504e-06, 2.75402862826013e-06, 3.305958216515137e-06, 3.2557700251345523e-06, 2.857153049262706e-06, 3.4104655242117587e-06, 3.522092356433859e-06, 3.904092693574057e-07]}
Train Epoch: 39 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 39 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 39 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.6470783521072008e-05, 1.3206277799326926e-05, 1.198296195070725e-05, 8.65411311679054e-06, 1.51132535393117e-05, 1.6139456420205534e-05, 1.0365574780735187e-05, 1.4874764019623399e-05, 1.3618900993606076e-05, 1.568240077176597e-05, 1.442884786229115e-05, 1.3243345165392384e-05, 1.3134460459696129e-05, 1.4640063454862684e-05, 1.4269864550442435e-05, 1.2362372217467055e-05, 1.5844092558836564e-05, 1.2377068742353003e-05, 1.057552253769245e-06], 'L_si': [-5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.65303881658474e-05, 1.3176475476939231e-05, 1.1923357305931859e-05, 8.59450847201515e-06, 1.5053648894536309e-05, 1.6079851775430143e-05, 1.0305970135959797e-05, 1.493436866439879e-05, 1.3648703315993771e-05, 1.568240077176597e-05, 1.4458650184678845e-05, 1.327314748778008e-05, 1.3104658137308434e-05, 1.466986577725038e-05, 1.4269864550442435e-05, 1.2362372217467055e-05, 1.5844092558836564e-05, 1.2406871064740699e-05, 1.0873545761569403e-06]}
Train Epoch: 40 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 40 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 40 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch040-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.4840645235381089e-05, 1.5864416127442382e-05, 1.5134063687582966e-05, 1.672394500928931e-05, 1.605235956958495e-05, 1.2117861842853017e-05, 1.2025649084534962e-05, 1.6754476746427827e-05, 1.3503738955478184e-05, 1.5053545212140307e-05, 1.1318980796204414e-05, 1.2921905181428883e-05, 1.815545510908123e-05, 1.3757197848462965e-05, 1.614767825230956e-05, 1.2824372788600158e-05, 1.2963201697857585e-05, 1.5328598237829283e-05, 2.4532898805773584e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.4870447557768784e-05, 1.5834613805054687e-05, 1.5134063687582966e-05, 1.672394500928931e-05, 1.599275492480956e-05, 1.2117861842853017e-05, 1.2025649084534962e-05, 1.6754476746427827e-05, 1.3503738955478184e-05, 1.5083347534528002e-05, 1.1318980796204414e-05, 1.2921905181428883e-05, 1.815545510908123e-05, 1.372739552607527e-05, 1.620728289708495e-05, 1.2854175110987853e-05, 1.299300402024528e-05, 1.5298795915441588e-05, 2.4830922029650537e-06]}
Train Epoch: 41 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 41 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 41 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [3.533422614054871e-06, 2.8967765501874965e-06, 2.5261385871999664e-06, 3.1608628887624945e-06, 2.675972609722521e-06, 2.719991243793629e-06, 2.5403342078789137e-06, 2.949902636828483e-06, 2.7861590297106886e-06, 2.251653768325923e-06, 3.0405026336666197e-06, 2.845210474333726e-06, 2.0139605112490244e-06, 3.290268068667501e-06, 2.8911777008033823e-06, 3.0912019610696007e-06, 3.918964466720354e-06, 2.5909139367286116e-06, 8.116514891298721e-07], 'L_si': [0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 0.0], 'L_grad': [3.533422614054871e-06, 2.956381194962887e-06, 2.5559409095876617e-06, 3.1608628887624945e-06, 2.675972609722521e-06, 2.719991243793629e-06, 2.480729563103523e-06, 2.949902636828483e-06, 2.7563567073229933e-06, 2.2814560907136183e-06, 3.1001072784420103e-06, 2.875012796721421e-06, 2.073565156024415e-06, 3.260465746279806e-06, 2.861375378415687e-06, 3.0613996386819053e-06, 3.8891621443326585e-06, 2.6505185815040022e-06, 8.116514891298721e-07]}
Train Epoch: 42 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 42 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 42 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.5611072740284726e-05, 1.3837824553775135e-05, 1.736749618430622e-05, 1.8685579561861232e-05, 1.3326706721272785e-05, 2.045659493887797e-05, 1.936558874149341e-05, 1.948363205883652e-05, 2.1363726773415692e-05, 1.6689216863596812e-05, 1.1641835044429172e-05, 1.3647667401528452e-05, 1.3535278412746266e-05, 1.5379118849523365e-05, 1.6293153748847544e-05, 9.763887646840885e-06, 1.2004462405457161e-05, 1.7117517927545123e-05, 3.4640729609236587e-06], 'L_si': [0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.5611072740284726e-05, 1.386762687616283e-05, 1.730789153953083e-05, 1.8685579561861232e-05, 1.335650904366048e-05, 2.0486397261265665e-05, 1.9395391063881107e-05, 1.9453829736448824e-05, 2.1393529095803387e-05, 1.6689216863596812e-05, 1.1641835044429172e-05, 1.3647667401528452e-05, 1.3535278412746266e-05, 1.534931652713567e-05, 1.6293153748847544e-05, 9.763887646840885e-06, 1.194485776068177e-05, 1.7087715605157427e-05, 3.493875283311354e-06]}
Train Epoch: 43 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 43 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 43 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.630103937117383e-06, 1.103490558307385e-05, 1.1870910384459421e-05, 1.3993809261592105e-05, 1.0693798685679212e-05, 8.56038423080463e-06, 1.029120812745532e-05, 1.0972604286507703e-05, 1.3023493011132814e-05, 5.623021934297867e-06, 1.5152227206272073e-05, 8.736530617170502e-06, 1.1749252735171467e-05, 1.4381420442077797e-05, 1.2801029697584454e-05, 1.3480464986059815e-05, 1.1954613000852987e-05, 7.641681804670952e-06, 4.273490958439652e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 8.940696716308594e-08, 0.0, 8.940696716308594e-08], 'L_grad': [7.600301159982337e-06, 1.1005103260686155e-05, 1.1900712706847116e-05, 1.40236115839798e-05, 1.0634194040903822e-05, 8.530581908416934e-06, 1.035081277223071e-05, 1.1002406608895399e-05, 1.3023493011132814e-05, 5.593219611910172e-06, 1.5152227206272073e-05, 8.766332939558197e-06, 1.1689648090396076e-05, 1.4381420442077797e-05, 1.2741425052809063e-05, 1.3480464986059815e-05, 1.1865206033689901e-05, 7.641681804670952e-06, 4.184083991276566e-06]}
Train Epoch: 44 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 44 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 44 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch044-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.5038292985991575e-05, 2.2463700588559732e-05, 1.8372164049651474e-05, 2.2023781639290974e-05, 2.150860382243991e-05, 2.1885705791646615e-05, 2.227530967502389e-05, 2.2764843379263766e-05, 2.266543742734939e-05, 2.1639820261043496e-05, 1.693953890935518e-05, 2.0884624973405153e-05, 2.2584157704841346e-05, 1.7372234651702456e-05, 1.4997982361819595e-05, 2.0768111426150426e-05, 2.0399973436724395e-05, 9.295205927628558e-06, 2.263748456243775e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.500849066360388e-05, 2.2433898266172037e-05, 1.834236172726378e-05, 2.2023781639290974e-05, 2.144899917766452e-05, 2.1885705791646615e-05, 2.227530967502389e-05, 2.273504105687607e-05, 2.266543742734939e-05, 2.16100179386558e-05, 1.693953890935518e-05, 2.0884624973405153e-05, 2.2584157704841346e-05, 1.734243232931476e-05, 1.49681800394319e-05, 2.073830910376273e-05, 2.042977575911209e-05, 9.325008250016253e-06, 2.2339461338560795e-06]}
Train Epoch: 45 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 45 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 45 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.426936771371402e-05, 2.8486279916251078e-05, 3.10910509142559e-05, 2.4133416445693e-05, 2.8306194508331828e-05, 2.5860194000415504e-05, 2.6563349820207804e-05, 2.8964612283743918e-05, 1.2155926015111618e-05, 3.746755464817397e-05, 2.6876434276346117e-05, 2.5512910724501126e-05, 2.5217950678779744e-05, 3.132264828309417e-05, 2.6748017262434587e-05, 2.7727806809707545e-05, 2.0171642972854897e-05, 2.5531346182106063e-05, 7.847073902667034e-06], 'L_si': [8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [2.4179960746550933e-05, 2.8456477593863383e-05, 3.106124859186821e-05, 2.4193021090468392e-05, 2.8335996830719523e-05, 2.5860194000415504e-05, 2.65931521425955e-05, 2.8964612283743918e-05, 1.2126123692723922e-05, 3.743775232578628e-05, 2.6906236598733813e-05, 2.5453306079725735e-05, 2.5188148356392048e-05, 3.135245060548186e-05, 2.6807621907209978e-05, 2.7668202164932154e-05, 2.0201445295242593e-05, 2.5531346182106063e-05, 7.817271580279339e-06]}
Train Epoch: 46 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 46 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 46 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.387618562555872e-06, 3.6007415928906994e-06, 2.4925684556365013e-06, 3.2614175324852113e-06, 2.9511766115319915e-06, 3.4529339245636947e-06, 2.7533289994607912e-06, 3.749817778953002e-06, 3.245711241106619e-06, 3.8709899854438845e-06, 4.008543328382075e-06, 3.2551736239838647e-06, 3.84973964173696e-06, 4.463862751435954e-06, 3.545460458553862e-06, 3.1842896532907616e-06, 3.448582447163062e-06, 3.8307007343973964e-06, 8.325668545694498e-07], 'L_si': [2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [3.3578162401681766e-06, 3.6007415928906994e-06, 2.4925684556365013e-06, 3.2018128877098206e-06, 3.010781256307382e-06, 3.48273624695139e-06, 2.7533289994607912e-06, 3.7200154565653065e-06, 3.245711241106619e-06, 3.90079230783158e-06, 3.9787410059943795e-06, 3.2551736239838647e-06, 3.819937319349265e-06, 4.4936650738236494e-06, 3.545460458553862e-06, 3.124685008515371e-06, 3.448582447163062e-06, 3.860503056785092e-06, 8.027645321817545e-07]}
Train Epoch: 47 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 47 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 47 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.3659035175805911e-05, 9.123179552261718e-06, 8.115723176160827e-06, 1.0458647011546418e-05, 1.2054434591846075e-05, 1.718890416668728e-05, 1.2313834304222837e-05, 9.394231710757595e-06, 1.0618911801429931e-05, 1.4872608517180197e-05, 1.5072479072841816e-05, 9.2606005637208e-06, 1.6346371921827085e-05, 1.39995518111391e-05, 1.2942062312504277e-05, 8.546132448827848e-06, 1.96888177015353e-05, 1.2454617717594374e-05, 2.360823145863833e-06], 'L_si': [2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.3629232853418216e-05, 9.182784197037108e-06, 8.145525498548523e-06, 1.0458647011546418e-05, 1.2054434591846075e-05, 1.718890416668728e-05, 1.2284031981835142e-05, 9.3644293883699e-06, 1.0618911801429931e-05, 1.4842806194792502e-05, 1.5072479072841816e-05, 9.290402886108495e-06, 1.637617424421478e-05, 1.3939947166363709e-05, 1.2882457667728886e-05, 8.546132448827848e-06, 1.96888177015353e-05, 1.2424815395206679e-05, 2.3906254682515282e-06]}
Train Epoch: 48 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 48 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 48 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch048-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [4.274103957868647e-06, 4.69425458504702e-06, 3.6222040762368124e-06, 3.7566064747807104e-06, 3.6720139178214595e-06, 3.5700213629752398e-06, 3.6676919989986345e-06, 3.700448132804013e-06, 4.145108050579438e-06, 3.856696821458172e-06, 3.077914243476698e-06, 3.224613919883268e-06, 4.915606950817164e-06, 4.534885192697402e-06, 3.7217805584077723e-06, 3.3769331366784172e-06, 3.580366865207907e-06, 4.736446499009617e-06, 6.337976401482592e-07], 'L_si': [2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0], 'L_grad': [4.2443016354809515e-06, 4.69425458504702e-06, 3.5625994314614218e-06, 3.7566064747807104e-06, 3.642211595433764e-06, 3.599823685362935e-06, 3.69749432138633e-06, 3.6706458104163175e-06, 4.145108050579438e-06, 3.826894499070477e-06, 3.137518888252089e-06, 3.1650092751078773e-06, 4.915606950817164e-06, 4.534885192697402e-06, 3.7217805584077723e-06, 3.4067354590661125e-06, 3.610169187595602e-06, 4.706644176621921e-06, 6.337976401482592e-07]}
Train Epoch: 49 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 49 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 49 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [3.2308562367688864e-05, 1.5117713701329194e-05, 2.324754859728273e-05, 1.9290335330879316e-05, 2.0659623260144144e-05, 2.2609539882978424e-05, 2.2102494767750613e-05, 1.811144466046244e-05, 1.9456952941254713e-05, 1.2508779036579654e-05, 2.0768828107975423e-05, 2.4284359824378043e-05, 2.2748092305846512e-05, 2.5494864530628547e-05, 2.1643965737894177e-05, 1.9819730368908495e-05, 1.718745261314325e-05, 2.011550350289326e-05, 3.848902906611329e-06], 'L_si': [-2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 8.940696716308594e-08], 'L_grad': [3.233836469007656e-05, 1.5117713701329194e-05, 2.3217746274895035e-05, 1.920092836371623e-05, 2.0659623260144144e-05, 2.2609539882978424e-05, 2.2042890122975223e-05, 1.8081642338074744e-05, 1.9486755263642408e-05, 1.2508779036579654e-05, 2.079863043036312e-05, 2.4284359824378043e-05, 2.2748092305846512e-05, 2.5435259885853156e-05, 2.1614163415506482e-05, 1.9819730368908495e-05, 1.7157650290755555e-05, 2.005589885811787e-05, 3.759495939448243e-06]}
Train Epoch: 50 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 50 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 50 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0973341886710841e-05, 7.856230695324484e-06, 9.318056072515901e-06, 1.2434360542101786e-05, 7.40936775400769e-06, 8.485054422635585e-06, 8.919138053897768e-06, 8.744097613089252e-06, 1.1810388059529942e-05, 1.1669519153656438e-05, 1.1714492757164408e-05, 1.1276435543550178e-05, 1.1406904377508909e-05, 9.419995876669418e-06, 1.0324104550818447e-05, 8.515267836628482e-06, 1.1335169801895972e-05, 8.919118954509031e-06, 1.1364436431904323e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [1.1003144209098537e-05, 7.826428372936789e-06, 9.347858394903596e-06, 1.2434360542101786e-05, 7.40936775400769e-06, 8.45525210024789e-06, 8.948940376285464e-06, 8.773899935476948e-06, 1.1810388059529942e-05, 1.1669519153656438e-05, 1.1684690434776712e-05, 1.1246633221162483e-05, 1.1377102055121213e-05, 9.449798199057113e-06, 1.0383709195593838e-05, 8.515267836628482e-06, 1.1275565157120582e-05, 8.948921276896726e-06, 1.1662459655781277e-06]}
Train Epoch: 51 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 51 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 51 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.187716199841816e-05, 1.7440077499486506e-05, 1.8021200958173722e-05, 2.357692937948741e-05, 1.7414369722246192e-05, 1.6482961655128747e-05, 2.094623414450325e-05, 1.5721247109468095e-05, 1.956206870090682e-05, 1.861464261310175e-05, 1.6614172636764124e-05, 2.2798767531639896e-05, 2.03759173018625e-05, 1.6872692867764272e-05, 1.7390562788932584e-05, 1.8059039575746283e-05, 2.649398629728239e-05, 1.9140807125950232e-05, 6.989124358369736e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0], 'L_grad': [2.1847359676030464e-05, 1.741027517709881e-05, 1.8021200958173722e-05, 2.351732473471202e-05, 1.7414369722246192e-05, 1.6482961655128747e-05, 2.0916431822115555e-05, 1.575104943185579e-05, 1.9651475668069907e-05, 1.8584840290714055e-05, 1.664397495915182e-05, 2.2798767531639896e-05, 2.03759173018625e-05, 1.6872692867764272e-05, 1.736076046654489e-05, 1.8029237253358588e-05, 2.649398629728239e-05, 1.9140807125950232e-05, 6.989124358369736e-06]}
Train Epoch: 52 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 52 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 52 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch052-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.160999247280415e-05, 2.561694236646872e-05, 3.139299951726571e-05, 2.7686064640874974e-05, 2.6232670279568993e-05, 1.5341795005952008e-05, 2.1578234736807644e-05, 3.206067776773125e-05, 2.8271457267692313e-05, 2.7408548703533597e-05, 2.6164130758843385e-05, 2.6223438908345997e-05, 2.8537004254758358e-05, 2.620921441121027e-05, 1.9976789189968258e-05, 2.2550520952790976e-05, 2.3118678655009717e-05, 2.8676044166786596e-05, 5.487058842845727e-06], 'L_si': [-2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 0.0, 0.0], 'L_grad': [2.1639794795191847e-05, 2.5646744688856415e-05, 3.139299951726571e-05, 2.771586696326267e-05, 2.6202867957181297e-05, 1.5341795005952008e-05, 2.154843241441995e-05, 3.206067776773125e-05, 2.8301259590080008e-05, 2.7408548703533597e-05, 2.6164130758843385e-05, 2.6193636585958302e-05, 2.8477399609982967e-05, 2.6179412088822573e-05, 1.9946986867580563e-05, 2.246111398562789e-05, 2.3118678655009717e-05, 2.8676044166786596e-05, 5.487058842845727e-06]}
Train Epoch: 53 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 53 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 53 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.91869785846211e-06, 9.649122148402967e-06, 9.951918400474824e-06, 6.46307034912752e-06, 1.0142863175133243e-05, 7.248272595461458e-06, 1.0840833056136034e-05, 6.954138370929286e-06, 9.448733180761337e-06, 1.1415000699344091e-05, 8.554515261494089e-06, 1.0641915650921874e-05, 7.349919542321004e-06, 8.94412187335547e-06, 7.466393981303554e-06, 1.1283062121947296e-05, 6.0602769735851325e-06, 7.968792488100007e-06, 2.0563807083817665e-06], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08], 'L_grad': [8.85909321368672e-06, 9.619319826015271e-06, 9.951918400474824e-06, 6.46307034912752e-06, 1.0142863175133243e-05, 7.218470273073763e-06, 1.087063537852373e-05, 6.9243360485415906e-06, 9.448733180761337e-06, 1.1474605344119482e-05, 8.554515261494089e-06, 1.0641915650921874e-05, 7.320117219933309e-06, 8.914319550967775e-06, 7.436591658915859e-06, 1.1312864444334991e-05, 6.090079295972828e-06, 7.938990165712312e-06, 2.0861830307694618e-06]}
Train Epoch: 54 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 54 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 54 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [1.4986827636676026e-06, 1.4054060102353105e-06, 1.3881585800845642e-06, 1.4990330328146229e-06, 1.4669249139842577e-06, 1.5737427929707337e-06, 1.4824745449004695e-06, 1.4944470194677706e-06, 1.2834127574024023e-06, 1.4270840438257437e-06, 1.5748356645417516e-06, 1.686733639871818e-06, 1.6221283658524044e-06, 1.4870666973365587e-06, 1.8625906932356884e-06, 1.4374354577739723e-06, 1.6821373947095708e-06, 1.5070982044562697e-06, 4.2231425823047175e-07], 'L_si': [-2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.5284850860552979e-06, 1.4054060102353105e-06, 1.3583562576968689e-06, 1.4990330328146229e-06, 1.407320269208867e-06, 1.5439404705830384e-06, 1.4228699001250789e-06, 1.4646446970800753e-06, 1.3132150797900977e-06, 1.4270840438257437e-06, 1.5748356645417516e-06, 1.6271289950964274e-06, 1.592326043464709e-06, 1.4572643749488634e-06, 1.8029860484602978e-06, 1.407633135386277e-06, 1.6523350723218755e-06, 1.4772958820685744e-06, 3.9251193584277644e-07]}
Train Epoch: 55 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 55 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 55 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.4196768208639696e-05, 2.5219760573236272e-05, 3.2496558560524136e-05, 2.6760122636915185e-05, 2.3065607820171863e-05, 2.0268180378479883e-05, 2.980220233439468e-05, 2.900639628933277e-05, 2.951392889372073e-05, 3.051378735108301e-05, 2.226846117991954e-05, 1.734996840241365e-05, 2.868771116482094e-05, 1.940091169672087e-05, 3.115443541901186e-05, 2.3726488507236354e-05, 2.8705631848424673e-05, 2.725264130276628e-05, 8.371601325052325e-06], 'L_si': [-5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [2.4256372853415087e-05, 2.5189958250848576e-05, 3.2436953915748745e-05, 2.673032031452749e-05, 2.2976200853008777e-05, 2.0238378056092188e-05, 2.9772400012006983e-05, 2.894679164455738e-05, 2.951392889372073e-05, 3.0483985028695315e-05, 2.2298263502307236e-05, 1.7320166080025956e-05, 2.8717513487208635e-05, 1.9371109374333173e-05, 3.109483077423647e-05, 2.3726488507236354e-05, 2.8675829526036978e-05, 2.7282443625153974e-05, 8.34179900266463e-06]}
Train Epoch: 56 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 56 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 56 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch056-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [2.6995094231097028e-06, 2.5597842068236787e-06, 2.598607352410909e-06, 3.450945769145619e-06, 3.3943128983082715e-06, 3.1521083201369038e-06, 2.940140802820679e-06, 2.3074899218045175e-06, 2.955628133349819e-06, 3.029515482921852e-06, 3.325919806229649e-06, 2.8730410122079775e-06, 2.548892553022597e-06, 2.6965637971443357e-06, 2.6716804768511793e-06, 2.5129013465630123e-06, 2.351647253817646e-06, 2.7247997422819026e-06, 5.97297002968844e-07], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [2.6697071007220075e-06, 2.5299818844359834e-06, 2.628409674798604e-06, 3.450945769145619e-06, 3.424115220695967e-06, 3.1223059977492085e-06, 2.940140802820679e-06, 2.247885277029127e-06, 2.9854304557375144e-06, 2.9997131605341565e-06, 3.296117483841954e-06, 2.9028433345956728e-06, 2.548892553022597e-06, 2.6965637971443357e-06, 2.641878154463484e-06, 2.483099024175317e-06, 2.3218449314299505e-06, 2.6949974198942073e-06, 5.674946805811487e-07]}
Train Epoch: 57 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 57 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 57 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.4835272749187425e-06, 4.797170277015539e-06, 4.599200565280626e-06, 6.327530172711704e-06, 4.0914706005423795e-06, 6.260097052290803e-06, 5.884909569431329e-06, 5.26710573467426e-06, 6.4443629526067525e-06, 5.40352539246669e-06, 4.598746727424441e-06, 4.802052899322007e-06, 6.131388545327354e-06, 7.17400826033554e-06, 5.6224744184874e-06, 5.181575488677481e-06, 6.430189387174323e-06, 5.965055152046261e-06, 1.5616993778166943e-06], 'L_si': [-5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0], 'L_grad': [5.543131919694133e-06, 4.7673679546278436e-06, 4.56939824289293e-06, 6.357332495099399e-06, 4.121272922930075e-06, 6.260097052290803e-06, 5.9147118918190245e-06, 5.296908057061955e-06, 6.4443629526067525e-06, 5.373723070078995e-06, 4.628549049812136e-06, 4.742448254546616e-06, 6.131388545327354e-06, 7.17400826033554e-06, 5.652276740875095e-06, 5.241180133452872e-06, 6.3705847423989326e-06, 5.965055152046261e-06, 1.5616993778166943e-06]}
Train Epoch: 58 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 58 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 58 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0586318239802495e-05, 1.370816880807979e-05, 1.1661782991723157e-05, 1.1329768312862143e-05, 1.4557098438672256e-05, 1.603868258825969e-05, 1.3883346582588274e-05, 1.2529088053270243e-05, 2.0572600988089107e-05, 2.0130355551373214e-05, 2.030084033322055e-05, 1.4987132999522146e-05, 1.2394254554237705e-05, 1.684199924056884e-05, 1.3784261682303622e-05, 1.1952760360145476e-05, 1.9449378669378348e-05, 1.9926384993596002e-05, 3.346415269334102e-06], 'L_si': [-5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [1.0645922884577885e-05, 1.3737971130467486e-05, 1.1661782991723157e-05, 1.1359570635249838e-05, 1.452729611628456e-05, 1.6068484910647385e-05, 1.3942951227363665e-05, 1.2558890375657938e-05, 2.054279866570141e-05, 2.0070750906597823e-05, 2.030084033322055e-05, 1.495733067713445e-05, 1.2334649909462314e-05, 1.6871801562956534e-05, 1.3724657037528232e-05, 1.1952760360145476e-05, 1.9479180991766043e-05, 1.9926384993596002e-05, 3.346415269334102e-06]}
Train Epoch: 59 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 59 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 59 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.2639551641768776e-05, 1.714440804789774e-05, 1.3439072063192725e-05, 1.1633459507720545e-05, 1.2681328371400014e-05, 1.5146390978770796e-05, 1.2657014849537518e-05, 1.553244874230586e-05, 1.4335026207845658e-05, 1.7194022802868858e-05, 1.266440267500002e-05, 1.8207165339845233e-05, 9.733378647069912e-06, 1.3698274415219203e-05, 1.81864234036766e-05, 1.6355937987100333e-05, 1.5754974810988642e-05, 1.6524025340913795e-05, 3.7984355003573e-06], 'L_si': [5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.2579946996993385e-05, 1.7174210370285437e-05, 1.3498676707968116e-05, 1.1573854862945154e-05, 1.2681328371400014e-05, 1.5146390978770796e-05, 1.2627212527149823e-05, 1.5562251064693555e-05, 1.4335026207845658e-05, 1.7194022802868858e-05, 1.272400731977541e-05, 1.8266769984620623e-05, 9.703576324682217e-06, 1.3698274415219203e-05, 1.8097016436513513e-05, 1.6355937987100333e-05, 1.5784777133376338e-05, 1.655382766330149e-05, 3.7686331779696047e-06]}
Train Epoch: 60 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 60 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 60 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch060-loss-0.0000.pth.tar ...
New Learning Rate: 0.000075
all losses in batch in validation:  {'loss': [8.419665391556919e-06, 5.502965905179735e-06, 8.061616426857654e-06, 7.416402695525903e-06, 7.254917363752611e-06, 8.397802957915701e-06, 6.976042641326785e-06, 6.489088264061138e-06, 5.707557193090906e-06, 6.93083529768046e-06, 8.776116374065168e-06, 8.74344459589338e-06, 6.894699254189618e-06, 6.564641353179468e-06, 9.334358765045181e-06, 7.846067092032172e-06, 7.038494004518725e-06, 8.503795470460318e-06, 1.8823188838723581e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 0.0], 'L_grad': [8.389863069169223e-06, 5.532768227567431e-06, 8.09141874924535e-06, 7.4462050179135986e-06, 7.254917363752611e-06, 8.33819831314031e-06, 6.94624031893909e-06, 6.459285941673443e-06, 5.677754870703211e-06, 6.960637620068155e-06, 8.776116374065168e-06, 8.773246918281075e-06, 6.864896931801923e-06, 6.594443675567163e-06, 9.334358765045181e-06, 7.786462447256781e-06, 7.038494004518725e-06, 8.533597792848013e-06, 1.8823188838723581e-06]}
Train Epoch: 61 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 61 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 61 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.589531166246161e-05, 1.356700886390172e-05, 1.2988244634470902e-05, 1.2451458133000415e-05, 1.144273755926406e-05, 9.876541298581287e-06, 8.794007953838445e-06, 1.2844402590417303e-05, 1.3978102288092487e-05, 1.2207858162582852e-05, 1.436365710105747e-05, 1.0125946573680267e-05, 1.2077851351932622e-05, 1.9584089386626147e-05, 1.3631689398607705e-05, 1.3145529919711407e-05, 1.0522066077101044e-05, 1.0571210623311345e-05, 2.0057989331689896e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08], 'L_grad': [1.5865509340073913e-05, 1.3537206541514024e-05, 1.2988244634470902e-05, 1.248126045538811e-05, 1.1412935236876365e-05, 9.846738976193592e-06, 8.794007953838445e-06, 1.2844402590417303e-05, 1.4007904610480182e-05, 1.2207858162582852e-05, 1.4274250133894384e-05, 1.0096144251292571e-05, 1.2077851351932622e-05, 1.955428706423845e-05, 1.3631689398607705e-05, 1.3085925274936017e-05, 1.0462461432325654e-05, 1.0571210623311345e-05, 2.035601255556685e-06]}
Train Epoch: 62 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 62 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 62 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [7.527505090365594e-07, 9.312053634857875e-07, 7.348295412157313e-07, 8.369397619389929e-07, 8.236009989559534e-07, 6.590947805307223e-07, 7.110667183951591e-07, 8.340961130670621e-07, 7.418577752105193e-07, 8.391570531784964e-07, 8.007361316231254e-07, 9.405110859006527e-07, 7.679248028580332e-07, 8.640594728603901e-07, 7.078637054291903e-07, 7.627645004504302e-07, 7.408571605083125e-07, 8.47988474106387e-07, 2.3671964299865067e-07], 'L_si': [0.0, 5.960464477539063e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [7.527505090365594e-07, 8.716007187103969e-07, 7.348295412157313e-07, 8.369397619389929e-07, 8.236009989559534e-07, 6.29292458143027e-07, 7.408690407828544e-07, 8.340961130670621e-07, 7.12055452822824e-07, 8.391570531784964e-07, 8.60340776398516e-07, 9.405110859006527e-07, 7.679248028580332e-07, 8.938617952480854e-07, 7.078637054291903e-07, 7.627645004504302e-07, 8.004618052837031e-07, 8.777907964940823e-07, 2.963242877740413e-07]}
Train Epoch: 63 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 63 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 63 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.3544516807305627e-06, 2.4019625470828032e-06, 2.600534799057641e-06, 3.3669757613097318e-06, 2.17029969462601e-06, 1.458233214179927e-06, 2.945383585029049e-06, 2.5641584215918556e-06, 2.395640422037104e-06, 2.485825461917557e-06, 2.00540671357885e-06, 2.7470880468172254e-06, 1.943266624948592e-06, 1.9577876173570985e-06, 2.831922529367148e-06, 2.49842605626327e-06, 2.1834739527548663e-06, 2.467718104526284e-06, 5.122531092638383e-07], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [2.3246493583428673e-06, 2.4317648694704985e-06, 2.511127831894555e-06, 3.3669757613097318e-06, 2.1106950498506194e-06, 1.458233214179927e-06, 2.945383585029049e-06, 2.593960743979551e-06, 2.3360357772617135e-06, 2.515627784305252e-06, 2.00540671357885e-06, 2.6874834020418348e-06, 1.9730689473362872e-06, 2.017392262132489e-06, 2.8617248517548433e-06, 2.4686237338755745e-06, 2.243078597530257e-06, 2.4081134597508935e-06, 4.526484929101571e-07]}
Train Epoch: 64 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 64 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 64 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch064-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.657569322967902e-05, 3.0094906833255664e-05, 2.0910722014377825e-05, 1.8897866539191455e-05, 2.727744504227303e-05, 2.471982588758692e-05, 2.268658863613382e-05, 2.751737520156894e-05, 2.4626500817248598e-05, 3.408777047297917e-05, 3.238987846998498e-05, 1.8707505660131574e-05, 3.380183261469938e-05, 2.279988257214427e-05, 3.06707042909693e-05, 2.2902189812157303e-05, 2.7477984986035153e-05, 3.072775871260092e-05, 5.659385806211503e-06], 'L_si': [2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 0.0, 0.0, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [3.654589090729132e-05, 3.0154511478031054e-05, 2.0910722014377825e-05, 1.8897866539191455e-05, 2.727744504227303e-05, 2.4779430532362312e-05, 2.268658863613382e-05, 2.7487572879181243e-05, 2.4596698494860902e-05, 3.402816582820378e-05, 3.233027382520959e-05, 1.8647901015356183e-05, 3.377203029231168e-05, 2.2829684894531965e-05, 3.06409019685816e-05, 2.2872387489769608e-05, 2.750778730842285e-05, 3.072775871260092e-05, 5.629583483823808e-06]}
Train Epoch: 65 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 65 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 65 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.139210437235306e-06, 2.3311029053729726e-06, 1.1626593732216861e-06, 1.8201769762526965e-06, 1.9840697405015817e-06, 1.498595224802557e-06, 1.8841902829080936e-06, 2.326669346075505e-06, 2.1969169665680965e-06, 1.8075290881824913e-06, 2.0794643660337897e-06, 1.7803178025133093e-06, 2.3607285584148485e-06, 1.966357785931905e-06, 2.1636865312757436e-06, 1.8990008356922772e-06, 2.8853542062279303e-06, 2.2979215827945154e-06, 6.673024017800344e-07], 'L_si': [0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [2.139210437235306e-06, 2.3013005829852773e-06, 1.1924616956093814e-06, 1.8201769762526965e-06, 1.9840697405015817e-06, 1.498595224802557e-06, 1.824585638132703e-06, 2.2968670236878097e-06, 2.1969169665680965e-06, 1.7479244434071006e-06, 2.0794643660337897e-06, 1.7207131577379187e-06, 2.330926236027153e-06, 1.966357785931905e-06, 2.193488853663439e-06, 1.8393961909168866e-06, 2.9151565286156256e-06, 2.2979215827945154e-06, 6.673024017800344e-07]}
Train Epoch: 66 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 66 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 66 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [9.816183592192829e-06, 1.2985625289729796e-05, 1.1742019523808267e-05, 9.84786129265558e-06, 1.5198284017969854e-05, 9.986396435124334e-06, 1.5208760487439577e-05, 1.4271290638134815e-05, 1.3909793779021129e-05, 1.598857852513902e-05, 8.985238309833221e-06, 1.5514477126998827e-05, 1.723987043078523e-05, 1.3002380001125857e-05, 8.605379662185442e-06, 1.5215289749903604e-05, 1.1297322998871095e-05, 1.1852692296088208e-05, 4.560492016025819e-06], 'L_si': [0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0], 'L_grad': [9.816183592192829e-06, 1.2955822967342101e-05, 1.1682414879032876e-05, 9.788256647880189e-06, 1.5198284017969854e-05, 1.0046001079899725e-05, 1.5238562809827272e-05, 1.4211685993359424e-05, 1.3939596101408824e-05, 1.598857852513902e-05, 8.985238309833221e-06, 1.548467480461113e-05, 1.7210068108397536e-05, 1.2942775356350467e-05, 8.545775017410051e-06, 1.5185487427515909e-05, 1.1237718354095705e-05, 1.1852692296088208e-05, 4.560492016025819e-06]}
Train Epoch: 67 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 67 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 67 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.284735486085992e-06, 1.759639781084843e-05, 1.0391247997176833e-05, 9.559161298966501e-06, 1.2262427844689228e-05, 1.1996553439530544e-05, 1.2694943507085554e-05, 1.6979791325866245e-05, 1.6878973838174716e-05, 1.320928095083218e-05, 9.617397154215723e-06, 1.3732714251091238e-05, 1.145489568443736e-05, 9.774788850336336e-06, 1.3511958968592808e-05, 1.3287655747262761e-05, 9.645853424444795e-06, 1.6251191482297145e-05, 2.106047077177209e-06], 'L_si': [0.0, 0.0, 0.0, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08], 'L_grad': [8.284735486085992e-06, 1.759639781084843e-05, 1.0391247997176833e-05, 9.559161298966501e-06, 1.2202823199913837e-05, 1.202635576191824e-05, 1.2665141184697859e-05, 1.6979791325866245e-05, 1.6819369193399325e-05, 1.3179478628444485e-05, 9.647199476603419e-06, 1.3732714251091238e-05, 1.1484698006825056e-05, 9.774788850336336e-06, 1.3541761290980503e-05, 1.322805110248737e-05, 9.6160511020571e-06, 1.6310796127072535e-05, 2.0464424324018182e-06]}
Train Epoch: 68 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 68 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 68 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch068-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.1510044259921415e-06, 1.05638389413798e-06, 1.239772018379881e-06, 1.016452301882964e-06, 1.0653075150912628e-06, 1.2399118531902786e-06, 8.653362897348416e-07, 1.0989447218889836e-06, 1.156482198894082e-06, 9.491091645941196e-07, 1.2072285926478799e-06, 1.2002846005998435e-06, 1.2403896789692226e-06, 1.021568095893599e-06, 1.2614151501111337e-06, 1.3039071973253158e-06, 1.284383642996545e-06, 1.357322616968304e-06, 3.27067368743883e-07], 'L_si': [0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 8.940696716308594e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.1510044259921415e-06, 1.0265815717502846e-06, 1.239772018379881e-06, 9.866499794952688e-07, 1.095109837478958e-06, 1.2101095308025833e-06, 8.355339673471462e-07, 1.128747044276679e-06, 1.0670752317309962e-06, 9.491091645941196e-07, 1.2370309150355752e-06, 1.1704822782121482e-06, 1.2105873565815273e-06, 9.32161185573932e-07, 1.2316128277234384e-06, 1.333709519713011e-06, 1.2545813206088496e-06, 1.3275202945806086e-06, 2.9726504635618767e-07]}
Train Epoch: 69 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 69 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 69 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.0739842764451168e-05, 2.4315308110089973e-05, 2.4349094019271433e-05, 1.2934129699715413e-05, 1.5328230801969767e-05, 1.5885805623838678e-05, 1.1534340956131928e-05, 1.5898962374194525e-05, 1.470787901780568e-05, 1.9931787392124534e-05, 1.47756036312785e-05, 1.650436934141908e-05, 1.9135566617478617e-05, 1.3883998690289445e-05, 1.4335773812490515e-05, 1.8343991541769356e-05, 1.8038665075437166e-05, 2.0202791347401217e-05, 3.5836790175380884e-06], 'L_si': [0.0, -2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0], 'L_grad': [1.0739842764451168e-05, 2.4345110432477668e-05, 2.4349094019271433e-05, 1.2874525054940023e-05, 1.5268626157194376e-05, 1.5856003301450983e-05, 1.1534340956131928e-05, 1.592876469658222e-05, 1.470787901780568e-05, 1.9931787392124534e-05, 1.4805405953666195e-05, 1.650436934141908e-05, 1.9135566617478617e-05, 1.391380101267714e-05, 1.4276169167715125e-05, 1.8343991541769356e-05, 1.8098269720212556e-05, 2.0232593669788912e-05, 3.5836790175380884e-06]}
Train Epoch: 70 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 70 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 70 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.0611925720004365e-05, 2.3645672627026215e-05, 2.3436972696799785e-05, 2.2748405172023922e-05, 1.495267224527197e-05, 2.1568925149040297e-05, 2.7002093702321872e-05, 2.2589061700273305e-05, 2.0030853193020448e-05, 1.9256436644354835e-05, 2.249175486213062e-05, 1.2226228136569262e-05, 1.8043512682197616e-05, 2.3418982891598716e-05, 2.7545309421839193e-05, 1.8471473595127463e-05, 1.2816542039217893e-05, 2.645226413733326e-05, 1.8120792901754612e-06], 'L_si': [5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [2.0552321075228974e-05, 2.3586067982250825e-05, 2.3436972696799785e-05, 2.2718602849636227e-05, 1.4982474567659665e-05, 2.15391228266526e-05, 2.694248905754648e-05, 2.2589061700273305e-05, 2.0001050870632753e-05, 1.928623896674253e-05, 2.255135950690601e-05, 1.2166623491793871e-05, 1.807331500458531e-05, 2.3418982891598716e-05, 2.7515507099451497e-05, 1.850127591751516e-05, 1.2786739716830198e-05, 2.645226413733326e-05, 1.782276967787766e-06]}
Train Epoch: 71 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 71 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 71 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.816861736704595e-06, 4.912908934784355e-06, 7.841636033845134e-06, 6.967813533265144e-06, 5.749387128162198e-06, 4.933759100822499e-06, 7.783443834341597e-06, 8.99575388757512e-06, 7.369517334154807e-06, 5.856022653460968e-06, 8.870205419952981e-06, 6.169191692606546e-06, 4.941190127283335e-06, 7.498882496292936e-06, 7.971088052727282e-06, 7.048443876556121e-06, 8.923912901082076e-06, 5.945961675024591e-06, 1.8517926037020516e-06], 'L_si': [0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0], 'L_grad': [8.816861736704595e-06, 4.912908934784355e-06, 7.841636033845134e-06, 6.967813533265144e-06, 5.7195848057745025e-06, 4.903956778434804e-06, 7.753641511953901e-06, 8.99575388757512e-06, 7.369517334154807e-06, 5.915627298236359e-06, 8.840403097565286e-06, 6.228796337381937e-06, 4.911387804895639e-06, 7.528684818680631e-06, 7.941285730339587e-06, 7.0186415541684255e-06, 8.923912901082076e-06, 5.945961675024591e-06, 1.8517926037020516e-06]}
Train Epoch: 72 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 72 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 72 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch072-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [5.342343229131075e-06, 5.667553523380775e-06, 6.8788676799158566e-06, 6.899958862049971e-06, 7.894039299571887e-06, 5.710945970349712e-06, 5.998079359414987e-06, 5.36256811756175e-06, 5.024247911933344e-06, 7.867603926570155e-06, 5.470376891025808e-06, 4.759330295200925e-06, 3.3290270948782563e-06, 5.033398338127881e-06, 5.96849167777691e-06, 4.829784302273765e-06, 6.339218543871539e-06, 3.916187779395841e-06, 1.6179237718461081e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 1.1920928955078125e-07, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [5.37214555151877e-06, 5.63775120099308e-06, 6.8788676799158566e-06, 6.899958862049971e-06, 7.774830010021105e-06, 5.740748292737408e-06, 5.968277037027292e-06, 5.36256811756175e-06, 4.964643267157953e-06, 7.867603926570155e-06, 5.470376891025808e-06, 4.699725650425535e-06, 3.388631739653647e-06, 5.063200660515577e-06, 6.028096322552301e-06, 4.770179657498375e-06, 6.279613899096148e-06, 3.945990101783536e-06, 1.5881214494584128e-06]}
Train Epoch: 73 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 73 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 73 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.797929588879924e-06, 5.264106221147813e-06, 6.915064659551717e-06, 7.009206456132233e-06, 8.406871529587079e-06, 6.679845228063641e-06, 7.946124242153019e-06, 8.13472070149146e-06, 7.710599675192498e-06, 4.301879926060792e-06, 5.711127414542716e-06, 6.873029633425176e-06, 5.975259227852803e-06, 6.767703780496959e-06, 7.687754077778663e-06, 7.484482921427116e-06, 7.515735887864139e-06, 7.74325235397555e-06, 1.2119492112105945e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 8.940696716308594e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08], 'L_grad': [5.768127266492229e-06, 5.234303898760118e-06, 6.915064659551717e-06, 6.9496018113568425e-06, 8.436673851974774e-06, 6.679845228063641e-06, 7.975926564540714e-06, 8.07511605671607e-06, 7.710599675192498e-06, 4.301879926060792e-06, 5.681325092155021e-06, 6.843227311037481e-06, 5.975259227852803e-06, 6.767703780496959e-06, 7.717556400166359e-06, 7.39507595426403e-06, 7.456131243088748e-06, 7.713450031587854e-06, 1.1523445664352039e-06]}
Train Epoch: 74 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 74 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 74 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [6.717346423101844e-06, 1.262394835066516e-05, 1.0452699825691525e-05, 9.458770364290103e-06, 8.372302545467392e-06, 9.570960173732601e-06, 1.1014310075552203e-05, 8.82348649611231e-06, 1.3423728887573816e-05, 1.1167740012751892e-05, 1.1481743058538996e-05, 1.4313200153992511e-05, 1.1237571015954018e-05, 1.2872201295976993e-05, 9.676636182121001e-06, 9.531658179184888e-06, 8.723472092242446e-06, 1.1760470442823134e-05, 2.1964133338769898e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [6.687544100714149e-06, 1.2594146028277464e-05, 1.0452699825691525e-05, 9.399165719514713e-06, 8.312697900692001e-06, 9.570960173732601e-06, 1.0984507753164507e-05, 8.793684173724614e-06, 1.333432192041073e-05, 1.1108135367976502e-05, 1.1422138413763605e-05, 1.4372804798767902e-05, 1.1177966371178627e-05, 1.2812596651201602e-05, 9.646833859733306e-06, 9.501855856797192e-06, 8.723472092242446e-06, 1.1730668120435439e-05, 2.1666110114892945e-06]}
Train Epoch: 75 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 75 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 75 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.543209691590164e-05, 1.9609051378211007e-05, 1.3514701095118653e-05, 1.7121808923548087e-05, 1.5742454706924036e-05, 2.0521096303127706e-05, 1.5044319297885522e-05, 1.5082774552865885e-05, 1.6563206372666173e-05, 2.1486825062311254e-05, 1.5579647879349068e-05, 2.0458479411900043e-05, 1.962495662155561e-05, 2.3170305212261155e-05, 2.143679012078792e-05, 1.897518268378917e-05, 2.6406887627672404e-05, 1.6851678083185107e-05, 2.104763552779332e-06], 'L_si': [-2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [1.5461899238289334e-05, 1.9609051378211007e-05, 1.3484898772730958e-05, 1.7121808923548087e-05, 1.577225702931173e-05, 2.0521096303127706e-05, 1.5044319297885522e-05, 1.5142379197641276e-05, 1.6593008695053868e-05, 2.1427220417535864e-05, 1.5609450201736763e-05, 2.0398874767124653e-05, 1.962495662155561e-05, 2.3170305212261155e-05, 2.1466592443175614e-05, 1.897518268378917e-05, 2.6406887627672404e-05, 1.6911282727960497e-05, 2.0749612303916365e-06]}
Train Epoch: 76 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 76 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 76 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch076-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [9.337603614767431e-07, 8.210723194679304e-07, 7.240876698233478e-07, 9.531598834655597e-07, 6.328544941425207e-07, 8.886124760465464e-07, 8.951562904258026e-07, 9.051212259691965e-07, 7.184576134022791e-07, 9.974478416552301e-07, 8.763632877162308e-07, 8.125440444928245e-07, 9.452323297409748e-07, 7.54667212277127e-07, 9.874928537101368e-07, 9.04156422620872e-07, 8.456661930722476e-07, 8.009467364900047e-07, 1.3279608879201987e-07], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 8.940696716308594e-08, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [8.741557167013525e-07, 7.91269997080235e-07, 7.240876698233478e-07, 9.82962205853255e-07, 6.62656816530216e-07, 8.886124760465464e-07, 8.057493232627166e-07, 9.051212259691965e-07, 7.184576134022791e-07, 9.974478416552301e-07, 8.167586429408402e-07, 8.125440444928245e-07, 8.856276849655842e-07, 7.54667212277127e-07, 9.576905313224415e-07, 9.04156422620872e-07, 7.860615482968569e-07, 7.413420917146141e-07, 1.6259841117971519e-07]}
Train Epoch: 77 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 77 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 77 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [8.316410458064638e-07, 9.690312481325236e-07, 9.409445738128852e-07, 8.72896464443329e-07, 6.808068633290532e-07, 9.557440989738097e-07, 8.195993359549902e-07, 8.704377023605048e-07, 7.672603601349692e-07, 7.933871302157058e-07, 1.0287785698892549e-06, 1.0233032980977441e-06, 8.757035061535134e-07, 8.999851957014471e-07, 8.144383514263609e-07, 8.405984317505499e-07, 7.360223435171065e-07, 7.735877147752035e-07, 3.184815113854711e-07], 'L_si': [0.0, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08], 'L_grad': [8.316410458064638e-07, 9.690312481325236e-07, 9.111422514251899e-07, 8.72896464443329e-07, 6.510045409413578e-07, 9.259418334295333e-07, 8.494016583426856e-07, 9.300423471358954e-07, 7.374580377472739e-07, 7.933871302157058e-07, 1.0287785698892549e-06, 1.0233032980977441e-06, 8.459011837658181e-07, 8.999851957014471e-07, 8.442406738140562e-07, 8.405984317505499e-07, 7.062200211294112e-07, 7.735877147752035e-07, 2.5887686661008047e-07]}
Train Epoch: 78 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 78 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 78 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.3233674508228432e-05, 1.6107524061226286e-05, 1.3062982361589093e-05, 7.41299481887836e-06, 1.8507538698031567e-05, 1.5570785762974992e-05, 1.0325729817850515e-05, 1.1340787750668824e-05, 1.805811007216107e-05, 1.3054481314611621e-05, 1.4777118849451654e-05, 1.72074851434445e-05, 1.3915449017076753e-05, 1.375137253489811e-05, 2.1530639060074463e-05, 1.4819979696767405e-05, 1.323317064816365e-05, 1.7321344785159454e-05, 5.0207372623845e-06], 'L_si': [-2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 8.940696716308594e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08], 'L_grad': [1.3263476830616128e-05, 1.6047919416450895e-05, 1.3003377716813702e-05, 7.323587851715274e-06, 1.8537341020419262e-05, 1.5540983440587297e-05, 1.0266125173075125e-05, 1.1340787750668824e-05, 1.805811007216107e-05, 1.3084283636999317e-05, 1.4777118849451654e-05, 1.72074851434445e-05, 1.3915449017076753e-05, 1.3661965567735024e-05, 2.1500836737686768e-05, 1.48497820191551e-05, 1.3262972970551345e-05, 1.7321344785159454e-05, 5.050539584772196e-06]}
Train Epoch: 79 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 79 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 79 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.1018512395821745e-06, 1.3445645663523464e-06, 8.6470964788532e-07, 1.0535479759710142e-06, 1.298765596402518e-06, 9.032710295286961e-07, 1.0850566241060733e-06, 1.3592316463473253e-06, 1.2685438832704676e-06, 8.250126484199427e-07, 8.984790724753111e-07, 9.269163001590641e-07, 8.367112513951724e-07, 1.3193269978728495e-06, 9.100884881263482e-07, 1.0913907999565708e-06, 7.752706778774154e-07, 1.1381049489500583e-06, 3.114669766546285e-07], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08], 'L_grad': [1.0720489171944791e-06, 1.3743668887400418e-06, 8.051050031099294e-07, 9.939433311956236e-07, 1.2689632740148227e-06, 9.032710295286961e-07, 1.1148589464937686e-06, 1.3592316463473253e-06, 1.2387415608827723e-06, 7.952103260322474e-07, 8.388744276999205e-07, 8.673116553836735e-07, 8.367112513951724e-07, 1.2895246754851541e-06, 9.398908105140436e-07, 1.0317861551811802e-06, 7.454683554897201e-07, 1.1381049489500583e-06, 2.518623318792379e-07]}
Train Epoch: 80 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 80 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 80 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch080-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.7330716218566522e-05, 9.783456334844232e-06, 2.2417749278247356e-05, 1.1991456631221808e-05, 1.792117654986214e-05, 1.9257247913628817e-05, 1.745697227306664e-05, 1.8244998500449583e-05, 1.732615419314243e-05, 1.164448622148484e-05, 1.6513597074663267e-05, 1.6875983419595286e-05, 1.3457069144351408e-05, 1.619059912627563e-05, 1.5791982150403783e-05, 1.3771777958027087e-05, 1.4905391253705602e-05, 1.3443319403450005e-05, 3.959500645578373e-06], 'L_si': [0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08], 'L_grad': [1.7330716218566522e-05, 9.753654012456536e-06, 2.2417749278247356e-05, 1.1961654308834113e-05, 1.792117654986214e-05, 1.9287050236016512e-05, 1.7486774595454335e-05, 1.8274800822837278e-05, 1.732615419314243e-05, 1.164448622148484e-05, 1.6513597074663267e-05, 1.684618109720759e-05, 1.3427266821963713e-05, 1.6160796803887933e-05, 1.5821784472791478e-05, 1.3771777958027087e-05, 1.4875588931317907e-05, 1.3383714758674614e-05, 3.929698323190678e-06]}
Train Epoch: 81 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 81 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 81 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.4196913980413228e-05, 1.7445761841372587e-05, 1.655081541684922e-05, 1.932624763867352e-05, 1.2614435945579316e-05, 1.5246247130562551e-05, 1.2639182386919856e-05, 1.7492760889581405e-05, 1.0882216884056106e-05, 1.5696463378844783e-05, 1.77591027750168e-05, 2.1085063053760678e-05, 1.657351094763726e-05, 1.747571695887018e-05, 2.032754673564341e-05, 1.4090868717175908e-05, 1.6416950529674068e-05, 1.1887521395692602e-05, 4.701616489910521e-06], 'L_si': [2.9802322387695312e-08, 5.960464477539063e-08, 5.960464477539063e-08, 8.940696716308594e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0], 'L_grad': [1.4167111658025533e-05, 1.7386157196597196e-05, 1.6491210772073828e-05, 1.9236840671510436e-05, 1.2614435945579316e-05, 1.5246247130562551e-05, 1.260938006453216e-05, 1.746295856719371e-05, 1.0882216884056106e-05, 1.5696463378844783e-05, 1.7729300452629104e-05, 2.1055260731372982e-05, 1.6543708625249565e-05, 1.741611231409479e-05, 2.032754673564341e-05, 1.4090868717175908e-05, 1.6387148207286373e-05, 1.1887521395692602e-05, 4.701616489910521e-06]}
Train Epoch: 82 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 82 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 82 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.310003881371813e-06, 8.101905564217304e-07, 1.1156587333971402e-06, 1.1783115496655228e-06, 1.1085514870501356e-06, 1.171425310531049e-06, 1.0189894510403974e-06, 8.260241202151519e-07, 8.886452178558102e-07, 1.1347568715791567e-06, 1.0747321539383847e-06, 1.0467613265063846e-06, 9.470762734054006e-07, 9.633670288167195e-07, 1.0519775059947278e-06, 9.657776445237687e-07, 9.953114386007655e-07, 9.77390641310194e-07, 2.4926316655182745e-07], 'L_si': [-2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 0.0, -5.960464477539063e-08, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, 5.960464477539063e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0], 'L_grad': [1.3398062037595082e-06, 8.697952011971211e-07, 1.1156587333971402e-06, 1.1783115496655228e-06, 1.1681561318255262e-06, 1.171425310531049e-06, 1.078594095815788e-06, 8.856287649905425e-07, 9.482498626312008e-07, 1.075152226803766e-06, 1.1343367987137754e-06, 1.0169590041186893e-06, 9.172739510177053e-07, 9.633670288167195e-07, 1.0519775059947278e-06, 9.657776445237687e-07, 9.953114386007655e-07, 9.475883189224987e-07, 2.4926316655182745e-07]}
Train Epoch: 83 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 83 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 83 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.0020386727992445e-05, 2.4816527002258226e-05, 1.7832555386121385e-05, 2.1863599613425322e-05, 1.7646088963374496e-05, 1.2935537597513758e-05, 1.9513101506163366e-05, 1.3847427908331156e-05, 1.631946361158043e-05, 2.5840488888206892e-05, 1.981432615139056e-05, 1.7714774003252387e-05, 2.3666945708100684e-05, 2.1861189452465624e-05, 2.4157539883162826e-05, 1.3660308468388394e-05, 2.339279672014527e-05, 1.698586856946349e-05, 5.077754394733347e-06], 'L_si': [-2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0], 'L_grad': [2.005018905038014e-05, 2.478672467987053e-05, 1.7832555386121385e-05, 2.1833797291037627e-05, 1.767589128576219e-05, 1.2875932952738367e-05, 1.9572706150938757e-05, 1.3877230230718851e-05, 1.6289661289192736e-05, 2.5840488888206892e-05, 1.975472150661517e-05, 1.7655169358476996e-05, 2.3666945708100684e-05, 2.1861189452465624e-05, 2.412773756077513e-05, 1.3600703823613003e-05, 2.339279672014527e-05, 1.698586856946349e-05, 5.077754394733347e-06]}
Train Epoch: 84 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 84 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 84 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch084-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [9.825114830164239e-06, 9.799348845263012e-06, 8.865122254064772e-06, 8.657355465402361e-06, 8.269200407085009e-06, 1.355609310849104e-05, 9.721607057144865e-06, 1.0240546544082463e-05, 9.598221367923543e-06, 1.3861186744179577e-05, 1.0713478332036175e-05, 6.39836707705399e-06, 1.0003044735640287e-05, 9.17602392291883e-06, 1.34825604618527e-05, 1.089956276700832e-05, 8.529936167178676e-06, 9.248638889403082e-06, 4.26148108090274e-06], 'L_si': [2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [9.795312507776543e-06, 9.799348845263012e-06, 8.894924576452468e-06, 8.657355465402361e-06, 8.3288050518604e-06, 1.349648846371565e-05, 9.75140937953256e-06, 1.0180941899307072e-05, 9.568419045535848e-06, 1.3801582099404186e-05, 1.074328065442387e-05, 6.4281693994416855e-06, 1.0032847058027983e-05, 9.11641927814344e-06, 1.3452758139465004e-05, 1.095916741178371e-05, 8.50013384479098e-06, 9.248638889403082e-06, 4.231678758515045e-06]}
Train Epoch: 85 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 85 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 85 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [2.792555096675642e-05, 1.5431452993652783e-05, 2.9426963010337204e-05, 1.591667387401685e-05, 2.6408020858070813e-05, 1.8866754544433206e-05, 2.109597517119255e-05, 1.6906120436033234e-05, 2.0469396986300126e-05, 2.319775194337126e-05, 2.465463512635324e-05, 2.9701968742301688e-05, 2.9386545065790415e-05, 1.875488305813633e-05, 3.1777530239196494e-05, 1.4606743206968531e-05, 2.8811251468141563e-05, 2.2351030565914698e-05, 4.5064939513395075e-06], 'L_si': [5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, -5.960464477539063e-08, 0.0, 0.0, -2.9802322387695312e-08], 'L_grad': [2.7865946321981028e-05, 1.546125531604048e-05, 2.94567653327249e-05, 1.591667387401685e-05, 2.643782318045851e-05, 1.8807149899657816e-05, 2.1066172848804854e-05, 1.687631811364554e-05, 2.043959466391243e-05, 2.3167949620983563e-05, 2.4624832803965546e-05, 2.9672166419913992e-05, 2.9386545065790415e-05, 1.875488305813633e-05, 3.1777530239196494e-05, 1.4666347851743922e-05, 2.8811251468141563e-05, 2.2351030565914698e-05, 4.536296273727203e-06]}
Train Epoch: 86 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 86 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 86 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.933015017944854e-06, 6.3551965467922855e-06, 5.25544555785018e-06, 6.598333129659295e-06, 9.614669579605106e-06, 5.9946096371277235e-06, 7.612887202412821e-06, 8.47106275614351e-06, 8.429313311353326e-06, 6.745652171957772e-06, 8.245427125075366e-06, 7.738655767752789e-06, 8.671982868690975e-06, 7.1515182753500994e-06, 5.587844043475343e-06, 1.0457681128173135e-05, 8.687051376909949e-06, 6.884526101202937e-06, 2.2760107185604284e-06], 'L_si': [0.0, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [5.933015017944854e-06, 6.3551965467922855e-06, 5.2852478802378755e-06, 6.657937774434686e-06, 9.644471901992802e-06, 5.9946096371277235e-06, 7.612887202412821e-06, 8.47106275614351e-06, 8.488917956128716e-06, 6.7754544943454675e-06, 8.275229447463062e-06, 7.738655767752789e-06, 8.671982868690975e-06, 7.1515182753500994e-06, 5.587844043475343e-06, 1.0457681128173135e-05, 8.716853699297644e-06, 6.914328423590632e-06, 2.246208396172733e-06]}
Train Epoch: 87 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 87 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 87 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.2914551916765049e-05, 1.6001718904590234e-05, 1.5988280210876837e-05, 1.444859299226664e-05, 9.837323887040839e-06, 1.607341255294159e-05, 1.8196522432845086e-05, 1.9404775230214e-05, 1.217034696310293e-05, 1.623553180252202e-05, 8.359386811207514e-06, 1.1359108611941338e-05, 1.956408414116595e-05, 1.5448331396328285e-05, 1.2913780665257946e-05, 1.5375313523691148e-05, 1.3594252777693328e-05, 1.543906364531722e-05, 2.8957542781427037e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -5.960464477539063e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 0.0, -8.940696716308594e-08, 0.0], 'L_grad': [1.2884749594377354e-05, 1.597191658220254e-05, 1.5958477888489142e-05, 1.4418790669878945e-05, 9.837323887040839e-06, 1.607341255294159e-05, 1.8196522432845086e-05, 1.9374972907826304e-05, 1.2200149285490625e-05, 1.6175927157746628e-05, 8.418991455982905e-06, 1.1418713256716728e-05, 1.956408414116595e-05, 1.541852907394059e-05, 1.2913780665257946e-05, 1.5434918168466538e-05, 1.3594252777693328e-05, 1.5528470612480305e-05, 2.8957542781427037e-06]}
Train Epoch: 88 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 88 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 88 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch088-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [7.020003636171168e-07, 6.161509418234346e-07, 5.435366574602085e-07, 7.310663932003081e-07, 7.218817472676164e-07, 7.669925139452971e-07, 5.150369020157086e-07, 6.334830118248647e-07, 9.156905207419186e-07, 4.642790543130104e-07, 6.492934971902287e-07, 6.500177960333531e-07, 5.919806653764681e-07, 5.619053808914032e-07, 7.889823905316007e-07, 5.899627240069094e-07, 6.841322033324104e-07, 7.091227871569572e-07, 1.4767903167012264e-07], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, -2.9802322387695312e-08], 'L_grad': [6.423957188417262e-07, 5.863486194357392e-07, 5.435366574602085e-07, 7.012640708126128e-07, 6.920794248799211e-07, 7.371901915576018e-07, 5.150369020157086e-07, 5.73878367049474e-07, 8.56085875966528e-07, 4.642790543130104e-07, 6.194911748025334e-07, 6.500177960333531e-07, 5.621783429887728e-07, 5.619053808914032e-07, 8.18784712919296e-07, 5.899627240069094e-07, 6.841322033324104e-07, 7.091227871569572e-07, 1.7748135405781795e-07]}
Train Epoch: 89 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 89 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 89 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.9646734017442213e-06, 2.0956049411324784e-06, 2.2292947505775373e-06, 2.6429102035763208e-06, 1.8677251318877097e-06, 2.655227262948756e-06, 2.3141792553360574e-06, 1.9024946595891379e-06, 1.7521335848869057e-06, 1.797545110093779e-06, 2.3949901333253365e-06, 2.228114226454636e-06, 2.515078904252732e-06, 2.2089825506554917e-06, 1.43446914080414e-06, 2.458963763274369e-06, 1.8272573925059987e-06, 1.777906390998396e-06, 4.945943601342151e-07], 'L_si': [8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08], 'L_grad': [1.8752664345811354e-06, 2.065802618744783e-06, 2.2590970729652327e-06, 2.58330555880093e-06, 1.8677251318877097e-06, 2.655227262948756e-06, 2.373783900111448e-06, 1.932296981976833e-06, 1.7521335848869057e-06, 1.797545110093779e-06, 2.365187810937641e-06, 2.1983119040669408e-06, 2.485276581865037e-06, 2.2089825506554917e-06, 1.4046668184164446e-06, 2.4291614408866735e-06, 1.857059714893694e-06, 1.777906390998396e-06, 5.541990049096057e-07]}
Train Epoch: 90 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 90 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 90 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
New Learning Rate: 0.000037
all losses in batch in validation:  {'loss': [2.623394721013028e-06, 2.6158750188187696e-06, 2.6009715838881675e-06, 2.321738975297194e-06, 3.1266777114069555e-06, 2.7829757982544834e-06, 2.4593045964138582e-06, 2.7351893550076056e-06, 2.184508048230782e-06, 2.6013353817688767e-06, 3.0587091259803856e-06, 2.5194067347911187e-06, 2.5077088139369152e-06, 2.18393233808456e-06, 3.2699203984520864e-06, 1.771724782884121e-06, 3.5433472476142924e-06, 2.7746982595999725e-06, 2.764952000688936e-07], 'L_si': [-8.940696716308594e-08, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -8.940696716308594e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -5.960464477539063e-08], 'L_grad': [2.712801688176114e-06, 2.645677341206465e-06, 2.660576228663558e-06, 2.3515412976848893e-06, 3.09687538901926e-06, 2.7829757982544834e-06, 2.4891069188015535e-06, 2.764991677395301e-06, 2.184508048230782e-06, 2.6907423489319626e-06, 3.0289068035926903e-06, 2.549209057178814e-06, 2.5077088139369152e-06, 2.213734660472255e-06, 3.240118076064391e-06, 1.8015271052718163e-06, 3.5731495700019877e-06, 2.804500581987668e-06, 3.3609984484428423e-07]}
Train Epoch: 91 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 91 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 91 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [4.646516345019336e-07, 4.4109441432738095e-07, 4.6042669055168517e-07, 5.207944013818633e-07, 4.1426235952712887e-07, 3.9732981349516194e-07, 3.7973291000525933e-07, 3.6166022709949175e-07, 3.60855608505517e-07, 4.999761245016998e-07, 4.1723060917320254e-07, 4.164787128502212e-07, 4.1660581473479397e-07, 4.993157176613749e-07, 3.9808730889490107e-07, 3.6404003367351834e-07, 3.740483407455031e-07, 3.507555561554909e-07, 5.607621034187105e-08], 'L_si': [5.960464477539063e-08, 0.0, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 0.0, 5.960464477539063e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, -2.9802322387695312e-08], 'L_grad': [4.0504698972654296e-07, 4.4109441432738095e-07, 4.6042669055168517e-07, 4.6118975660647266e-07, 4.1426235952712887e-07, 3.377251687197713e-07, 3.7973291000525933e-07, 3.020555823241011e-07, 3.012509637301264e-07, 4.999761245016998e-07, 4.1723060917320254e-07, 4.164787128502212e-07, 4.1660581473479397e-07, 4.6951339527367963e-07, 3.6828498650720576e-07, 3.6404003367351834e-07, 3.740483407455031e-07, 2.911509113801003e-07, 8.587853272956636e-08]}
Train Epoch: 92 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [612/816 (75%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 92 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 92 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch092-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [7.332437689910876e-06, 9.299902558268514e-06, 7.5619027484208345e-06, 7.136824933695607e-06, 6.386650966305751e-06, 8.427343345829286e-06, 7.597981948492816e-06, 8.376854566449765e-06, 4.822781193070114e-06, 9.036542905960232e-06, 9.443413546250667e-06, 8.88522481545806e-06, 1.0214846042799763e-05, 1.05816016002791e-05, 7.977843779372051e-06, 7.537805686297361e-06, 8.696179065736942e-06, 8.814142347546294e-06, 1.4427425867324928e-06], 'L_si': [5.960464477539063e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0], 'L_grad': [7.272833045135485e-06, 9.270100235880818e-06, 7.59170507080853e-06, 7.136824933695607e-06, 6.386650966305751e-06, 8.367738701053895e-06, 7.56817962610512e-06, 8.34705224406207e-06, 4.792978870682418e-06, 9.036542905960232e-06, 9.443413546250667e-06, 8.915027137845755e-06, 1.0155241398024373e-05, 1.0611403922666796e-05, 7.91823913459666e-06, 7.567608008685056e-06, 8.696179065736942e-06, 8.784340025158599e-06, 1.4427425867324928e-06]}
Train Epoch: 93 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [432/816 (53%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 93 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 93 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [1.5728583093732595e-05, 1.4729974282090552e-05, 1.131742465076968e-05, 1.0726330401666928e-05, 1.4733060197613668e-05, 1.08634385469486e-05, 1.569823143654503e-05, 1.2456722288334277e-05, 1.3442670024232939e-05, 1.5359333701780997e-05, 1.1396755326131824e-05, 1.336301829724107e-05, 1.6298203263431787e-05, 1.2849354789068457e-05, 1.3988843420520425e-05, 9.952586879080627e-06, 1.08108051790623e-05, 1.4842058590147644e-05, 4.919691491522826e-06], 'L_si': [2.9802322387695312e-08, -2.9802322387695312e-08, -8.940696716308594e-08, 0.0, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, 5.960464477539063e-08], 'L_grad': [1.56987807713449e-05, 1.4759776604478247e-05, 1.1406831617932767e-05, 1.0726330401666928e-05, 1.4762862520001363e-05, 1.08634385469486e-05, 1.5728033758932725e-05, 1.2426919965946581e-05, 1.3383065379457548e-05, 1.5389136024168693e-05, 1.1337150681356434e-05, 1.3392820619628765e-05, 1.6298203263431787e-05, 1.2879157111456152e-05, 1.395904109813273e-05, 9.922784556692932e-06, 1.0781002856674604e-05, 1.4752651622984558e-05, 4.860086846747436e-06]}
Train Epoch: 94 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 94 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 94 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.672782776855456e-07, 4.330638603278203e-07, 4.1841894926619716e-07, 4.3465644239404355e-07, 5.6428467587466e-07, 4.983759254173492e-07, 4.885767452833534e-07, 5.182155291549861e-07, 5.471508188747976e-07, 4.6899339167794096e-07, 4.897098051515059e-07, 5.176639774617797e-07, 4.67557924821449e-07, 4.600244665198261e-07, 4.86247074604762e-07, 4.3512767433639965e-07, 5.592561365119764e-07, 4.5282121163836564e-07, 1.481399465319555e-07], 'L_si': [0.0, 0.0, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, -2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 2.9802322387695312e-08], 'L_grad': [5.672782776855456e-07, 4.330638603278203e-07, 4.1841894926619716e-07, 4.3465644239404355e-07, 5.6428467587466e-07, 4.685736030296539e-07, 4.5877442289565806e-07, 5.182155291549861e-07, 5.769531412624929e-07, 5.285980364533316e-07, 5.195121275392012e-07, 5.176639774617797e-07, 4.973602472091443e-07, 4.302221441321308e-07, 5.458517193801526e-07, 4.6492999672409496e-07, 6.18860781287367e-07, 4.5282121163836564e-07, 1.1833762414426019e-07]}
Train Epoch: 95 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [468/816 (57%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 95 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 95 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [4.52550648333272e-06, 7.3452492870274e-06, 9.243161002814304e-06, 7.051055035844911e-06, 8.21861976874061e-06, 6.115525593486382e-06, 7.742809430055786e-06, 6.5943340814555995e-06, 6.973455128900241e-06, 9.114290151046589e-06, 8.393310054088943e-06, 6.371023573592538e-06, 7.107911187631544e-06, 6.347053385979962e-06, 8.797786904324312e-06, 5.729324584535789e-06, 9.456135558139067e-06, 4.859375167143298e-06, 2.2639617327513406e-06], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, -5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -5.960464477539063e-08, 0.0], 'L_grad': [4.495704160945024e-06, 7.315446964639705e-06, 9.243161002814304e-06, 7.051055035844911e-06, 8.21861976874061e-06, 6.115525593486382e-06, 7.772611752443481e-06, 6.564531759067904e-06, 6.884048161737155e-06, 9.17389479582198e-06, 8.393310054088943e-06, 6.371023573592538e-06, 7.078108865243848e-06, 6.347053385979962e-06, 8.827589226712007e-06, 5.6995222621480934e-06, 9.426333235751372e-06, 4.918979811918689e-06, 2.2639617327513406e-06]}
Train Epoch: 96 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [216/816 (26%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [288/816 (35%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [648/816 (79%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 96 [756/816 (93%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 96 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch096-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [1.2052134479745291e-05, 1.0699067388486583e-05, 7.665956218261272e-06, 1.3042899809079245e-05, 1.1751184501918033e-05, 1.069443351298105e-05, 1.0848234524019063e-05, 8.636413440399338e-06, 1.0873225619434379e-05, 1.0497169569134712e-05, 7.746509254502598e-06, 1.2064057955285534e-05, 9.59275166678708e-06, 8.918361345422454e-06, 1.0283773917763028e-05, 1.0185573955823202e-05, 1.1590898793656379e-05, 6.486403435701504e-06, 2.72110241894552e-06], 'L_si': [5.960464477539063e-08, -2.9802322387695312e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 2.9802322387695312e-08, 2.9802322387695312e-08], 'L_grad': [1.19925298349699e-05, 1.0728869710874278e-05, 7.636153895873576e-06, 1.301309748669155e-05, 1.1780986824305728e-05, 1.069443351298105e-05, 1.0907839168794453e-05, 8.576808795623947e-06, 1.0903027941822074e-05, 1.0497169569134712e-05, 7.776311576890294e-06, 1.2034255632897839e-05, 9.59275166678708e-06, 8.888559023034759e-06, 1.0313576240150724e-05, 1.0125969311047811e-05, 1.1590898793656379e-05, 6.456601113313809e-06, 2.691300096557825e-06]}
Train Epoch: 97 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [396/816 (49%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [504/816 (62%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 97 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 97 [792/816 (97%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.512283678399399e-06, 7.505093890358694e-06, 6.229246082511963e-06, 5.649512786476407e-06, 8.007805263332557e-06, 5.202545253268909e-06, 6.81484834785806e-06, 6.912634034961229e-06, 5.1490469559212215e-06, 8.360177162103355e-06, 7.442827154591214e-06, 1.011245694826357e-05, 7.572756658191793e-06, 6.568150638486259e-06, 6.778383976779878e-06, 6.882311936351471e-06, 7.773412107781041e-06, 7.837741577532142e-06, 8.979645826912019e-07], 'L_si': [2.9802322387695312e-08, 2.9802322387695312e-08, 0.0, 5.960464477539063e-08, 0.0, -5.960464477539063e-08, 0.0, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -5.960464477539063e-08, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0], 'L_grad': [5.482481356011704e-06, 7.475291567970999e-06, 6.229246082511963e-06, 5.5899081417010166e-06, 8.007805263332557e-06, 5.262149898044299e-06, 6.81484834785806e-06, 6.912634034961229e-06, 5.119244633533526e-06, 8.360177162103355e-06, 7.472629476978909e-06, 1.0172061593038961e-05, 7.572756658191793e-06, 6.568150638486259e-06, 6.778383976779878e-06, 6.852509613963775e-06, 7.773412107781041e-06, 7.837741577532142e-06, 8.979645826912019e-07]}
Train Epoch: 98 [0/816 (0%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [36/816 (4%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [72/816 (9%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [108/816 (13%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [180/816 (22%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [324/816 (40%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [576/816 (71%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [684/816 (84%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 98 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 98 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [5.8093801271752454e-06, 7.774631740176119e-06, 6.826457592978841e-06, 4.9743794079404324e-06, 7.171487141022226e-06, 7.457826541212853e-06, 7.783285582263488e-06, 4.7299486141128e-06, 5.923449862166308e-06, 5.386428256315412e-06, 5.417105057858862e-06, 8.41567543830024e-06, 7.0502073867828585e-06, 6.1144087339926045e-06, 9.17269426281564e-06, 9.514043995295651e-06, 5.5730338317516726e-06, 6.1580108194903005e-06, 2.079253590636654e-06], 'L_si': [0.0, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 8.940696716308594e-08, 0.0, 5.960464477539063e-08, 2.9802322387695312e-08, 2.9802322387695312e-08, 8.940696716308594e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.0, 0.0, 0.0], 'L_grad': [5.8093801271752454e-06, 7.774631740176119e-06, 6.826457592978841e-06, 4.9743794079404324e-06, 7.201289463409921e-06, 7.398221896437462e-06, 7.783285582263488e-06, 4.640541646949714e-06, 5.923449862166308e-06, 5.326823611540021e-06, 5.387302735471167e-06, 8.385873115912545e-06, 6.960800419619773e-06, 6.1442110563803e-06, 9.202496585203335e-06, 9.45443935052026e-06, 5.5730338317516726e-06, 6.1580108194903005e-06, 2.079253590636654e-06]}
Train Epoch: 99 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [144/816 (18%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [252/816 (31%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [360/816 (44%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [540/816 (66%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [720/816 (88%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 99 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 99 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [7.073196684359573e-06, 6.920909982000012e-06, 1.2014384992653504e-05, 1.2180775229353458e-05, 9.256213161279447e-06, 8.116630851873197e-06, 1.0789034604385961e-05, 1.1207122042833362e-05, 1.1008504770870786e-05, 8.615723345428705e-06, 8.018249900487717e-06, 1.2956501450389624e-05, 9.147790478891693e-06, 7.4300837695773225e-06, 5.67046481592115e-06, 1.1708480087690987e-05, 1.2838388101954479e-05, 8.940435691329185e-06, 2.1513244519155705e-06], 'L_si': [-8.940696716308594e-08, -2.9802322387695312e-08, 0.0, -2.9802322387695312e-08, -8.940696716308594e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, 0.0, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, -2.9802322387695312e-08, -8.940696716308594e-08, -8.940696716308594e-08, 0.0, 2.9802322387695312e-08, 0.0, -2.9802322387695312e-08], 'L_grad': [7.162603651522659e-06, 6.950712304387707e-06, 1.2014384992653504e-05, 1.2210577551741153e-05, 9.345620128442533e-06, 8.146433174260892e-06, 1.0818836926773656e-05, 1.1236924365221057e-05, 1.1008504770870786e-05, 8.615723345428705e-06, 7.988447578100022e-06, 1.2986303772777319e-05, 9.177592801279388e-06, 7.5194907367404085e-06, 5.759871783084236e-06, 1.1708480087690987e-05, 1.2808585779566783e-05, 8.940435691329185e-06, 2.181126774303266e-06]}
Train Epoch: 100 [0/816 (0%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [36/816 (4%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [72/816 (9%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [108/816 (13%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [144/816 (18%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [180/816 (22%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [216/816 (26%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [252/816 (31%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [288/816 (35%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [324/816 (40%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [360/816 (44%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [396/816 (49%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [432/816 (53%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [468/816 (57%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [504/816 (62%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [540/816 (66%)] loss: 0.0000 L_si: -0.0000 L_grad: 0.0000 
Train Epoch: 100 [576/816 (71%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [612/816 (75%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [648/816 (79%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [684/816 (84%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [720/816 (88%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [756/816 (93%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Train Epoch: 100 [792/816 (97%)] loss: 0.0000 L_si: 0.0000 L_grad: 0.0000 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch100-loss-0.0000.pth.tar ...
all losses in batch in validation:  {'loss': [3.270635602348193e-07, 3.3636831631156383e-07, 2.690806297778181e-07, 3.723578743120015e-07, 3.6959349358767213e-07, 3.6149737070445553e-07, 3.3304297630820656e-07, 4.051223640999524e-07, 3.46879176049697e-07, 2.987622451655625e-07, 2.503396103747946e-07, 2.890642463171389e-07, 3.2834520879987394e-07, 2.7368960786589014e-07, 2.811070487496181e-07, 2.858476193523529e-07, 2.6553365728432254e-07, 3.383365196896193e-07, 7.960025527609105e-08], 'L_si': [-2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 2.9802322387695312e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.0, 0.0, -5.960464477539063e-08, -5.960464477539063e-08, -2.9802322387695312e-08, 0.0, -5.960464477539063e-08, 0.0, -5.960464477539063e-08, 0.0, 0.0, 0.0], 'L_grad': [3.568658826225146e-07, 3.3636831631156383e-07, 3.2868527455320873e-07, 3.425555519243062e-07, 3.6959349358767213e-07, 3.316950483167602e-07, 3.3304297630820656e-07, 4.051223640999524e-07, 3.46879176049697e-07, 3.583668899409531e-07, 3.099442551501852e-07, 3.188665687048342e-07, 3.2834520879987394e-07, 3.3329425264128076e-07, 2.811070487496181e-07, 3.4545226412774355e-07, 2.6553365728432254e-07, 3.383365196896193e-07, 7.960025527609105e-08]}
