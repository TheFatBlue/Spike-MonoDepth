/root/miniconda3/envs/scv/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Trainable parameters: 20545951
S2DepthTransformerUNetConv(
  (encoder): LongSpikeStreamEncoderConv(
    (swin3d): SwinTransformer3D(
      (patch_embed): PatchEmbedLocalGlobal(
        (head): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (global_head): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (global_residual_encoding): residual_feature_generator(
          (resblock1): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock2): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock3): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
          (resblock4): ResidualBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          )
        )
        (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (global_proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=384, out_features=192, bias=False)
            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=768, out_features=384, bias=False)
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock3D(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    )
    (conv_layers): ModuleList(
      (0): ModuleList(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ModuleList(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ModuleList(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (resblocks): ModuleList(
    (0): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1): ResidualBlock(
      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (decoders): ModuleList(
    (0): UpsampleConvLayer(
      (conv2d): Conv2d(384, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (1): UpsampleConvLayer(
      (conv2d): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (2): UpsampleConvLayer(
      (conv2d): Conv2d(96, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (pred): ConvLayer(
    (conv2d): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)
Setting up Multi Scale Gradient loss...
Done
---- Single Training ----
Use GPU: 0 for training
Found 26 samples in /root/autodl-tmp/Spike-Stero/train
Found 8 samples in /root/autodl-tmp/Spike-Stero/validation
-----  [3, 6, 12]
---- new version 4 ----
Model Initialized
Using scale_invariant_loss with config {'weight': 1.0, 'n_lambda': 1.0}
Will not use phased architecture
Using Multi Scale Gradient loss with weight=0.25
Will not use MSE loss
Train Epoch: 1 [0/816 (0%)] loss: 0.0612 L_si: 0.0164 L_grad: 0.0448 
Train Epoch: 1 [36/816 (4%)] loss: 0.0500 L_si: 0.0134 L_grad: 0.0366 
Train Epoch: 1 [72/816 (9%)] loss: 0.0436 L_si: 0.0094 L_grad: 0.0341 
Train Epoch: 1 [108/816 (13%)] loss: 0.0560 L_si: 0.0197 L_grad: 0.0363 
Train Epoch: 1 [144/816 (18%)] loss: 0.0557 L_si: 0.0199 L_grad: 0.0358 
Train Epoch: 1 [180/816 (22%)] loss: 0.0518 L_si: 0.0211 L_grad: 0.0307 
Train Epoch: 1 [216/816 (26%)] loss: 0.0408 L_si: 0.0105 L_grad: 0.0303 
Train Epoch: 1 [252/816 (31%)] loss: 0.0439 L_si: 0.0113 L_grad: 0.0326 
Train Epoch: 1 [288/816 (35%)] loss: 0.0448 L_si: 0.0142 L_grad: 0.0306 
Train Epoch: 1 [324/816 (40%)] loss: 0.0509 L_si: 0.0178 L_grad: 0.0331 
Train Epoch: 1 [360/816 (44%)] loss: 0.0436 L_si: 0.0167 L_grad: 0.0269 
Train Epoch: 1 [396/816 (49%)] loss: 0.0428 L_si: 0.0116 L_grad: 0.0312 
Train Epoch: 1 [432/816 (53%)] loss: 0.0601 L_si: 0.0225 L_grad: 0.0376 
Train Epoch: 1 [468/816 (57%)] loss: 0.0416 L_si: 0.0091 L_grad: 0.0326 
Train Epoch: 1 [504/816 (62%)] loss: 0.0335 L_si: 0.0081 L_grad: 0.0254 
Train Epoch: 1 [540/816 (66%)] loss: 0.0487 L_si: 0.0167 L_grad: 0.0320 
Train Epoch: 1 [576/816 (71%)] loss: 0.0431 L_si: 0.0094 L_grad: 0.0337 
Train Epoch: 1 [612/816 (75%)] loss: 0.0430 L_si: 0.0129 L_grad: 0.0301 
Train Epoch: 1 [648/816 (79%)] loss: 0.0460 L_si: 0.0128 L_grad: 0.0332 
Train Epoch: 1 [684/816 (84%)] loss: 0.0461 L_si: 0.0123 L_grad: 0.0338 
Train Epoch: 1 [720/816 (88%)] loss: 0.0367 L_si: 0.0071 L_grad: 0.0296 
Train Epoch: 1 [756/816 (93%)] loss: 0.0404 L_si: 0.0086 L_grad: 0.0318 
Train Epoch: 1 [792/816 (97%)] loss: 0.0507 L_si: 0.0174 L_grad: 0.0333 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.047630030661821365, 0.04659382253885269, 0.04638351500034332, 0.046639956533908844, 0.04235738515853882, 0.046259596943855286, 0.04671443998813629, 0.0446682907640934, 0.040961913764476776, 0.0454912930727005, 0.048482563346624374, 0.04711614176630974, 0.04660787433385849, 0.04663488641381264, 0.042614538222551346, 0.045673348009586334, 0.046358004212379456, 0.04682557284832001, 0.02096490003168583], 'L_si': [0.011076796799898148, 0.010761914774775505, 0.011001812294125557, 0.009674148634076118, 0.007564075291156769, 0.010173328220844269, 0.011348573490977287, 0.010620582848787308, 0.007586624473333359, 0.010497944429516792, 0.011001583188772202, 0.009991232305765152, 0.010958617553114891, 0.011455807834863663, 0.008444275707006454, 0.008500348776578903, 0.010033981874585152, 0.010414833202958107, 0.010556865483522415], 'L_grad': [0.03655323386192322, 0.03583190590143204, 0.03538170084357262, 0.036965809762477875, 0.03479330986738205, 0.03608626872301102, 0.03536586835980415, 0.03404770791530609, 0.03337528929114342, 0.03499335050582886, 0.03748098015785217, 0.037124909460544586, 0.03564925491809845, 0.035179078578948975, 0.03417026251554489, 0.03717299923300743, 0.036324020475149155, 0.03641074150800705, 0.010408034548163414]}
Train Epoch: 2 [0/816 (0%)] loss: 0.0349 L_si: 0.0055 L_grad: 0.0294 
Train Epoch: 2 [36/816 (4%)] loss: 0.0411 L_si: 0.0110 L_grad: 0.0301 
Train Epoch: 2 [72/816 (9%)] loss: 0.0527 L_si: 0.0181 L_grad: 0.0346 
Train Epoch: 2 [108/816 (13%)] loss: 0.0423 L_si: 0.0126 L_grad: 0.0296 
Train Epoch: 2 [144/816 (18%)] loss: 0.0439 L_si: 0.0140 L_grad: 0.0299 
Train Epoch: 2 [180/816 (22%)] loss: 0.0341 L_si: 0.0067 L_grad: 0.0274 
Train Epoch: 2 [216/816 (26%)] loss: 0.0437 L_si: 0.0128 L_grad: 0.0309 
Train Epoch: 2 [252/816 (31%)] loss: 0.0394 L_si: 0.0092 L_grad: 0.0301 
Train Epoch: 2 [288/816 (35%)] loss: 0.0362 L_si: 0.0080 L_grad: 0.0283 
Train Epoch: 2 [324/816 (40%)] loss: 0.0480 L_si: 0.0179 L_grad: 0.0300 
Train Epoch: 2 [360/816 (44%)] loss: 0.0411 L_si: 0.0099 L_grad: 0.0312 
Train Epoch: 2 [396/816 (49%)] loss: 0.0475 L_si: 0.0133 L_grad: 0.0342 
Train Epoch: 2 [432/816 (53%)] loss: 0.0434 L_si: 0.0094 L_grad: 0.0340 
Train Epoch: 2 [468/816 (57%)] loss: 0.0367 L_si: 0.0088 L_grad: 0.0279 
Train Epoch: 2 [504/816 (62%)] loss: 0.0446 L_si: 0.0131 L_grad: 0.0315 
Train Epoch: 2 [540/816 (66%)] loss: 0.0485 L_si: 0.0164 L_grad: 0.0322 
Train Epoch: 2 [576/816 (71%)] loss: 0.0483 L_si: 0.0170 L_grad: 0.0313 
Train Epoch: 2 [612/816 (75%)] loss: 0.0516 L_si: 0.0213 L_grad: 0.0303 
Train Epoch: 2 [648/816 (79%)] loss: 0.0410 L_si: 0.0110 L_grad: 0.0300 
Train Epoch: 2 [684/816 (84%)] loss: 0.0387 L_si: 0.0074 L_grad: 0.0312 
Train Epoch: 2 [720/816 (88%)] loss: 0.0419 L_si: 0.0098 L_grad: 0.0320 
Train Epoch: 2 [756/816 (93%)] loss: 0.0438 L_si: 0.0117 L_grad: 0.0321 
Train Epoch: 2 [792/816 (97%)] loss: 0.0465 L_si: 0.0164 L_grad: 0.0301 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.044083837419748306, 0.044064417481422424, 0.0474514439702034, 0.04485001042485237, 0.041874054819345474, 0.04309459775686264, 0.044390928000211716, 0.04436783492565155, 0.04404379427433014, 0.04409953951835632, 0.04239734262228012, 0.041545890271663666, 0.043105486780405045, 0.04444000497460365, 0.04253135249018669, 0.04341890662908554, 0.04400472715497017, 0.0437195859849453, 0.017661578953266144], 'L_si': [0.009439926594495773, 0.009438620880246162, 0.010426606982946396, 0.00976305827498436, 0.008482519537210464, 0.009973805397748947, 0.010118905454874039, 0.00830003060400486, 0.0099855437874794, 0.00928925909101963, 0.009643511846661568, 0.008396569639444351, 0.01013890653848648, 0.00931733101606369, 0.009667310863733292, 0.009077608585357666, 0.009409312158823013, 0.010450538247823715, 0.009593438357114792], 'L_grad': [0.03464391082525253, 0.03462579473853111, 0.037024836987257004, 0.03508695214986801, 0.03339153528213501, 0.03312079235911369, 0.03427202254533768, 0.03606780618429184, 0.03405825048685074, 0.03481028228998184, 0.0327538326382637, 0.033149320632219315, 0.032966580241918564, 0.03512267395853996, 0.0328640416264534, 0.034341298043727875, 0.034595414996147156, 0.03326904773712158, 0.008068140596151352]}
Train Epoch: 3 [0/816 (0%)] loss: 0.0539 L_si: 0.0199 L_grad: 0.0340 
Train Epoch: 3 [36/816 (4%)] loss: 0.0373 L_si: 0.0074 L_grad: 0.0299 
Train Epoch: 3 [72/816 (9%)] loss: 0.0408 L_si: 0.0122 L_grad: 0.0285 
Train Epoch: 3 [108/816 (13%)] loss: 0.0539 L_si: 0.0200 L_grad: 0.0339 
Train Epoch: 3 [144/816 (18%)] loss: 0.0372 L_si: 0.0084 L_grad: 0.0287 
Train Epoch: 3 [180/816 (22%)] loss: 0.0379 L_si: 0.0088 L_grad: 0.0291 
Train Epoch: 3 [216/816 (26%)] loss: 0.0414 L_si: 0.0125 L_grad: 0.0288 
Train Epoch: 3 [252/816 (31%)] loss: 0.0524 L_si: 0.0153 L_grad: 0.0371 
Train Epoch: 3 [288/816 (35%)] loss: 0.0394 L_si: 0.0102 L_grad: 0.0293 
Train Epoch: 3 [324/816 (40%)] loss: 0.0429 L_si: 0.0115 L_grad: 0.0314 
Train Epoch: 3 [360/816 (44%)] loss: 0.0385 L_si: 0.0085 L_grad: 0.0299 
Train Epoch: 3 [396/816 (49%)] loss: 0.0434 L_si: 0.0107 L_grad: 0.0327 
Train Epoch: 3 [432/816 (53%)] loss: 0.0364 L_si: 0.0093 L_grad: 0.0271 
Train Epoch: 3 [468/816 (57%)] loss: 0.0330 L_si: 0.0065 L_grad: 0.0265 
Train Epoch: 3 [504/816 (62%)] loss: 0.0427 L_si: 0.0110 L_grad: 0.0316 
Train Epoch: 3 [540/816 (66%)] loss: 0.0389 L_si: 0.0090 L_grad: 0.0298 
Train Epoch: 3 [576/816 (71%)] loss: 0.0493 L_si: 0.0140 L_grad: 0.0354 
Train Epoch: 3 [612/816 (75%)] loss: 0.0429 L_si: 0.0080 L_grad: 0.0349 
Train Epoch: 3 [648/816 (79%)] loss: 0.0465 L_si: 0.0139 L_grad: 0.0326 
Train Epoch: 3 [684/816 (84%)] loss: 0.0412 L_si: 0.0103 L_grad: 0.0309 
Train Epoch: 3 [720/816 (88%)] loss: 0.0311 L_si: 0.0042 L_grad: 0.0270 
Train Epoch: 3 [756/816 (93%)] loss: 0.0448 L_si: 0.0158 L_grad: 0.0290 
Train Epoch: 3 [792/816 (97%)] loss: 0.0460 L_si: 0.0147 L_grad: 0.0312 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04345767945051193, 0.04417955502867699, 0.04770718514919281, 0.04453940689563751, 0.04451305791735649, 0.045281991362571716, 0.0438714325428009, 0.045833975076675415, 0.046039823442697525, 0.0432642363011837, 0.04559049382805824, 0.04579433798789978, 0.042769115418195724, 0.04359636455774307, 0.04412311315536499, 0.04532402381300926, 0.04395018145442009, 0.04425473138689995, 0.019992833957076073], 'L_si': [0.008980244398117065, 0.010480914264917374, 0.010471530258655548, 0.009832506999373436, 0.01014530286192894, 0.010525152087211609, 0.011129170656204224, 0.010724963620305061, 0.010869462043046951, 0.010549236088991165, 0.011408362537622452, 0.010893670842051506, 0.008350107818841934, 0.010549061000347137, 0.010821022093296051, 0.012258898466825485, 0.00812700018286705, 0.012128520756959915, 0.011069940403103828], 'L_grad': [0.03447743505239487, 0.03369864076375961, 0.03723565489053726, 0.03470689803361893, 0.03436775505542755, 0.03475683927536011, 0.03274226188659668, 0.035109009593725204, 0.035170361399650574, 0.032715000212192535, 0.03418213129043579, 0.034900665283203125, 0.03441900759935379, 0.033047303557395935, 0.03330209106206894, 0.03306512534618378, 0.03582318127155304, 0.03212621062994003, 0.008922893553972244]}
Train Epoch: 4 [0/816 (0%)] loss: 0.0367 L_si: 0.0099 L_grad: 0.0268 
Train Epoch: 4 [36/816 (4%)] loss: 0.0414 L_si: 0.0130 L_grad: 0.0284 
Train Epoch: 4 [72/816 (9%)] loss: 0.0384 L_si: 0.0095 L_grad: 0.0290 
Train Epoch: 4 [108/816 (13%)] loss: 0.0405 L_si: 0.0096 L_grad: 0.0308 
Train Epoch: 4 [144/816 (18%)] loss: 0.0398 L_si: 0.0095 L_grad: 0.0303 
Train Epoch: 4 [180/816 (22%)] loss: 0.0514 L_si: 0.0168 L_grad: 0.0346 
Train Epoch: 4 [216/816 (26%)] loss: 0.0422 L_si: 0.0093 L_grad: 0.0330 
Train Epoch: 4 [252/816 (31%)] loss: 0.0422 L_si: 0.0121 L_grad: 0.0301 
Train Epoch: 4 [288/816 (35%)] loss: 0.0421 L_si: 0.0086 L_grad: 0.0335 
Train Epoch: 4 [324/816 (40%)] loss: 0.0385 L_si: 0.0075 L_grad: 0.0310 
Train Epoch: 4 [360/816 (44%)] loss: 0.0478 L_si: 0.0162 L_grad: 0.0316 
Train Epoch: 4 [396/816 (49%)] loss: 0.0365 L_si: 0.0071 L_grad: 0.0295 
Train Epoch: 4 [432/816 (53%)] loss: 0.0656 L_si: 0.0260 L_grad: 0.0396 
Train Epoch: 4 [468/816 (57%)] loss: 0.0389 L_si: 0.0089 L_grad: 0.0300 
Train Epoch: 4 [504/816 (62%)] loss: 0.0321 L_si: 0.0071 L_grad: 0.0250 
Train Epoch: 4 [540/816 (66%)] loss: 0.0409 L_si: 0.0080 L_grad: 0.0329 
Train Epoch: 4 [576/816 (71%)] loss: 0.0464 L_si: 0.0145 L_grad: 0.0319 
Train Epoch: 4 [612/816 (75%)] loss: 0.0403 L_si: 0.0108 L_grad: 0.0295 
Train Epoch: 4 [648/816 (79%)] loss: 0.0366 L_si: 0.0092 L_grad: 0.0274 
Train Epoch: 4 [684/816 (84%)] loss: 0.0335 L_si: 0.0075 L_grad: 0.0259 
Train Epoch: 4 [720/816 (88%)] loss: 0.0396 L_si: 0.0109 L_grad: 0.0287 
Train Epoch: 4 [756/816 (93%)] loss: 0.0368 L_si: 0.0081 L_grad: 0.0286 
Train Epoch: 4 [792/816 (97%)] loss: 0.0392 L_si: 0.0115 L_grad: 0.0277 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04485880956053734, 0.04255255311727524, 0.045714911073446274, 0.04339226335287094, 0.04036147892475128, 0.039873939007520676, 0.04120147228240967, 0.04679904505610466, 0.043337106704711914, 0.04457452893257141, 0.04350961744785309, 0.04012810438871384, 0.044758956879377365, 0.04717857390642166, 0.04356937110424042, 0.043425053358078, 0.045457370579242706, 0.043309058994054794, 0.0174420066177845], 'L_si': [0.010651398450136185, 0.008922077715396881, 0.01109243556857109, 0.010243747383356094, 0.007791832089424133, 0.008099008351564407, 0.009521741420030594, 0.01099000871181488, 0.010605216026306152, 0.011201255023479462, 0.01095726527273655, 0.008787117898464203, 0.010219495743513107, 0.010553872212767601, 0.011590452864766121, 0.011006355285644531, 0.011208482086658478, 0.009384416043758392, 0.009269244968891144], 'L_grad': [0.034207411110401154, 0.03363047540187836, 0.03462247550487518, 0.03314851596951485, 0.03256964683532715, 0.03177493065595627, 0.031679730862379074, 0.03580903634428978, 0.03273189067840576, 0.03337327390909195, 0.03255235403776169, 0.031340986490249634, 0.03453946113586426, 0.03662470355629921, 0.03197891637682915, 0.03241869807243347, 0.03424888849258423, 0.0339246429502964, 0.008172760717570782]}
Train Epoch: 5 [0/816 (0%)] loss: 0.0530 L_si: 0.0205 L_grad: 0.0325 
Train Epoch: 5 [36/816 (4%)] loss: 0.0500 L_si: 0.0202 L_grad: 0.0299 
Train Epoch: 5 [72/816 (9%)] loss: 0.0491 L_si: 0.0182 L_grad: 0.0309 
Train Epoch: 5 [108/816 (13%)] loss: 0.0476 L_si: 0.0194 L_grad: 0.0282 
Train Epoch: 5 [144/816 (18%)] loss: 0.0446 L_si: 0.0143 L_grad: 0.0303 
Train Epoch: 5 [180/816 (22%)] loss: 0.0370 L_si: 0.0073 L_grad: 0.0297 
Train Epoch: 5 [216/816 (26%)] loss: 0.0370 L_si: 0.0076 L_grad: 0.0294 
Train Epoch: 5 [252/816 (31%)] loss: 0.0366 L_si: 0.0079 L_grad: 0.0287 
Train Epoch: 5 [288/816 (35%)] loss: 0.0413 L_si: 0.0098 L_grad: 0.0314 
Train Epoch: 5 [324/816 (40%)] loss: 0.0363 L_si: 0.0077 L_grad: 0.0286 
Train Epoch: 5 [360/816 (44%)] loss: 0.0373 L_si: 0.0095 L_grad: 0.0279 
Train Epoch: 5 [396/816 (49%)] loss: 0.0419 L_si: 0.0102 L_grad: 0.0317 
Train Epoch: 5 [432/816 (53%)] loss: 0.0359 L_si: 0.0087 L_grad: 0.0272 
Train Epoch: 5 [468/816 (57%)] loss: 0.0473 L_si: 0.0153 L_grad: 0.0320 
Train Epoch: 5 [504/816 (62%)] loss: 0.0349 L_si: 0.0092 L_grad: 0.0257 
Train Epoch: 5 [540/816 (66%)] loss: 0.0421 L_si: 0.0099 L_grad: 0.0322 
Train Epoch: 5 [576/816 (71%)] loss: 0.0431 L_si: 0.0146 L_grad: 0.0286 
Train Epoch: 5 [612/816 (75%)] loss: 0.0446 L_si: 0.0125 L_grad: 0.0320 
Train Epoch: 5 [648/816 (79%)] loss: 0.0392 L_si: 0.0089 L_grad: 0.0303 
Train Epoch: 5 [684/816 (84%)] loss: 0.0366 L_si: 0.0100 L_grad: 0.0266 
Train Epoch: 5 [720/816 (88%)] loss: 0.0370 L_si: 0.0064 L_grad: 0.0306 
Train Epoch: 5 [756/816 (93%)] loss: 0.0362 L_si: 0.0075 L_grad: 0.0287 
Train Epoch: 5 [792/816 (97%)] loss: 0.0360 L_si: 0.0072 L_grad: 0.0288 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04434950649738312, 0.0451846607029438, 0.04515937715768814, 0.04509507119655609, 0.04414447396993637, 0.0439024418592453, 0.044551484286785126, 0.04428333789110184, 0.042602818459272385, 0.04508551210165024, 0.04347880929708481, 0.04410712048411369, 0.046449314802885056, 0.04186199605464935, 0.04308437928557396, 0.04436337947845459, 0.043442923575639725, 0.042936671525239944, 0.016308041289448738], 'L_si': [0.008602939546108246, 0.008923441171646118, 0.009001241996884346, 0.007976241409778595, 0.007499992847442627, 0.008247092366218567, 0.009040027856826782, 0.009350083768367767, 0.007722079753875732, 0.0095217265188694, 0.008005611598491669, 0.009176287800073624, 0.009990673512220383, 0.007615402340888977, 0.00799151137471199, 0.009365679696202278, 0.008770190179347992, 0.007798168808221817, 0.007084149867296219], 'L_grad': [0.03574656695127487, 0.036261219531297684, 0.036158133298158646, 0.037118829786777496, 0.036644481122493744, 0.03565534949302673, 0.035511456429958344, 0.03493325412273407, 0.03488073870539665, 0.03556378558278084, 0.03547319769859314, 0.03493083268404007, 0.03645864129066467, 0.034246593713760376, 0.03509286791086197, 0.03499769791960716, 0.03467273339629173, 0.03513850271701813, 0.00922389142215252]}
Train Epoch: 6 [0/816 (0%)] loss: 0.0527 L_si: 0.0177 L_grad: 0.0350 
Train Epoch: 6 [36/816 (4%)] loss: 0.0355 L_si: 0.0068 L_grad: 0.0287 
Train Epoch: 6 [72/816 (9%)] loss: 0.0421 L_si: 0.0128 L_grad: 0.0293 
Train Epoch: 6 [108/816 (13%)] loss: 0.0456 L_si: 0.0126 L_grad: 0.0330 
Train Epoch: 6 [144/816 (18%)] loss: 0.0504 L_si: 0.0174 L_grad: 0.0330 
Train Epoch: 6 [180/816 (22%)] loss: 0.0454 L_si: 0.0134 L_grad: 0.0320 
Train Epoch: 6 [216/816 (26%)] loss: 0.0486 L_si: 0.0167 L_grad: 0.0320 
Train Epoch: 6 [252/816 (31%)] loss: 0.0316 L_si: 0.0059 L_grad: 0.0257 
Train Epoch: 6 [288/816 (35%)] loss: 0.0431 L_si: 0.0104 L_grad: 0.0327 
Train Epoch: 6 [324/816 (40%)] loss: 0.0382 L_si: 0.0080 L_grad: 0.0303 
Train Epoch: 6 [360/816 (44%)] loss: 0.0411 L_si: 0.0119 L_grad: 0.0292 
Train Epoch: 6 [396/816 (49%)] loss: 0.0318 L_si: 0.0049 L_grad: 0.0269 
Train Epoch: 6 [432/816 (53%)] loss: 0.0445 L_si: 0.0145 L_grad: 0.0301 
Train Epoch: 6 [468/816 (57%)] loss: 0.0394 L_si: 0.0093 L_grad: 0.0301 
Train Epoch: 6 [504/816 (62%)] loss: 0.0360 L_si: 0.0063 L_grad: 0.0297 
Train Epoch: 6 [540/816 (66%)] loss: 0.0356 L_si: 0.0066 L_grad: 0.0290 
Train Epoch: 6 [576/816 (71%)] loss: 0.0345 L_si: 0.0074 L_grad: 0.0271 
Train Epoch: 6 [612/816 (75%)] loss: 0.0350 L_si: 0.0071 L_grad: 0.0279 
Train Epoch: 6 [648/816 (79%)] loss: 0.0421 L_si: 0.0125 L_grad: 0.0296 
Train Epoch: 6 [684/816 (84%)] loss: 0.0403 L_si: 0.0094 L_grad: 0.0310 
Train Epoch: 6 [720/816 (88%)] loss: 0.0326 L_si: 0.0066 L_grad: 0.0260 
Train Epoch: 6 [756/816 (93%)] loss: 0.0382 L_si: 0.0102 L_grad: 0.0280 
Train Epoch: 6 [792/816 (97%)] loss: 0.0424 L_si: 0.0112 L_grad: 0.0311 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04038650915026665, 0.03981645032763481, 0.04247274622321129, 0.04031834378838539, 0.04491250962018967, 0.04289472848176956, 0.0441504567861557, 0.04275066778063774, 0.04379388317465782, 0.0411049947142601, 0.03928833827376366, 0.04171376675367355, 0.041085392236709595, 0.041498277336359024, 0.043387386947870255, 0.04279680550098419, 0.04347417876124382, 0.042595274746418, 0.01850096508860588], 'L_si': [0.007896114140748978, 0.008311431854963303, 0.008367139846086502, 0.006590280681848526, 0.00943833589553833, 0.008611857891082764, 0.008454479277133942, 0.008617475628852844, 0.00931454822421074, 0.008651141077280045, 0.00649314746260643, 0.008064799010753632, 0.008452318608760834, 0.008425768464803696, 0.008958246558904648, 0.00862337090075016, 0.00807434692978859, 0.008773140609264374, 0.01027856394648552], 'L_grad': [0.03249039500951767, 0.03150501847267151, 0.034105606377124786, 0.033728063106536865, 0.03547417372465134, 0.0342828705906868, 0.03569597750902176, 0.0341331921517849, 0.03447933495044708, 0.03245385363698006, 0.03279519081115723, 0.03364896774291992, 0.03263307362794876, 0.03307250887155533, 0.03442914038896561, 0.03417343646287918, 0.03539983183145523, 0.033822134137153625, 0.008222401142120361]}
Train Epoch: 7 [0/816 (0%)] loss: 0.0399 L_si: 0.0099 L_grad: 0.0300 
Train Epoch: 7 [36/816 (4%)] loss: 0.0436 L_si: 0.0165 L_grad: 0.0271 
Train Epoch: 7 [72/816 (9%)] loss: 0.0332 L_si: 0.0062 L_grad: 0.0270 
Train Epoch: 7 [108/816 (13%)] loss: 0.0381 L_si: 0.0100 L_grad: 0.0281 
Train Epoch: 7 [144/816 (18%)] loss: 0.0328 L_si: 0.0054 L_grad: 0.0274 
Train Epoch: 7 [180/816 (22%)] loss: 0.0442 L_si: 0.0138 L_grad: 0.0303 
Train Epoch: 7 [216/816 (26%)] loss: 0.0367 L_si: 0.0064 L_grad: 0.0303 
Train Epoch: 7 [252/816 (31%)] loss: 0.0343 L_si: 0.0076 L_grad: 0.0267 
Train Epoch: 7 [288/816 (35%)] loss: 0.0365 L_si: 0.0087 L_grad: 0.0278 
Train Epoch: 7 [324/816 (40%)] loss: 0.0396 L_si: 0.0092 L_grad: 0.0304 
Train Epoch: 7 [360/816 (44%)] loss: 0.0459 L_si: 0.0130 L_grad: 0.0328 
Train Epoch: 7 [396/816 (49%)] loss: 0.0435 L_si: 0.0133 L_grad: 0.0302 
Train Epoch: 7 [432/816 (53%)] loss: 0.0351 L_si: 0.0083 L_grad: 0.0268 
Train Epoch: 7 [468/816 (57%)] loss: 0.0311 L_si: 0.0048 L_grad: 0.0263 
Train Epoch: 7 [504/816 (62%)] loss: 0.0290 L_si: 0.0039 L_grad: 0.0251 
Train Epoch: 7 [540/816 (66%)] loss: 0.0326 L_si: 0.0060 L_grad: 0.0267 
Train Epoch: 7 [576/816 (71%)] loss: 0.0379 L_si: 0.0115 L_grad: 0.0264 
Train Epoch: 7 [612/816 (75%)] loss: 0.0484 L_si: 0.0158 L_grad: 0.0326 
Train Epoch: 7 [648/816 (79%)] loss: 0.0598 L_si: 0.0208 L_grad: 0.0390 
Train Epoch: 7 [684/816 (84%)] loss: 0.0400 L_si: 0.0093 L_grad: 0.0308 
Train Epoch: 7 [720/816 (88%)] loss: 0.0421 L_si: 0.0091 L_grad: 0.0330 
Train Epoch: 7 [756/816 (93%)] loss: 0.0400 L_si: 0.0099 L_grad: 0.0301 
Train Epoch: 7 [792/816 (97%)] loss: 0.0294 L_si: 0.0037 L_grad: 0.0257 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04528513550758362, 0.04625644162297249, 0.04462657496333122, 0.04355762526392937, 0.044185467064380646, 0.04535343497991562, 0.044040746986866, 0.04254605621099472, 0.04457388445734978, 0.046518273651599884, 0.045843999832868576, 0.04901523515582085, 0.04436509311199188, 0.04411368444561958, 0.045783620327711105, 0.04666706919670105, 0.04651428759098053, 0.04460808262228966, 0.014774716459214687], 'L_si': [0.008718371391296387, 0.009707566350698471, 0.008807655423879623, 0.008453954011201859, 0.009043797850608826, 0.00946086272597313, 0.00926642119884491, 0.007669702172279358, 0.008229974657297134, 0.009240172803401947, 0.00971205160021782, 0.009415064007043839, 0.00892551988363266, 0.008103545755147934, 0.008923288434743881, 0.010108951479196548, 0.009701162576675415, 0.009041700512170792, 0.005341492593288422], 'L_grad': [0.03656676411628723, 0.03654887527227402, 0.0358189195394516, 0.03510367125272751, 0.03514166921377182, 0.03589257225394249, 0.03477432578802109, 0.03487635403871536, 0.03634390980005264, 0.03727810084819794, 0.03613194823265076, 0.03960017114877701, 0.03543957322835922, 0.03601013869047165, 0.036860331892967224, 0.0365581177175045, 0.036813125014305115, 0.035566382110118866, 0.009433223865926266]}
Train Epoch: 8 [0/816 (0%)] loss: 0.0373 L_si: 0.0091 L_grad: 0.0282 
Train Epoch: 8 [36/816 (4%)] loss: 0.0363 L_si: 0.0076 L_grad: 0.0287 
Train Epoch: 8 [72/816 (9%)] loss: 0.0293 L_si: 0.0057 L_grad: 0.0236 
Train Epoch: 8 [108/816 (13%)] loss: 0.0392 L_si: 0.0095 L_grad: 0.0297 
Train Epoch: 8 [144/816 (18%)] loss: 0.0561 L_si: 0.0212 L_grad: 0.0349 
Train Epoch: 8 [180/816 (22%)] loss: 0.0371 L_si: 0.0084 L_grad: 0.0288 
Train Epoch: 8 [216/816 (26%)] loss: 0.0385 L_si: 0.0095 L_grad: 0.0289 
Train Epoch: 8 [252/816 (31%)] loss: 0.0428 L_si: 0.0112 L_grad: 0.0315 
Train Epoch: 8 [288/816 (35%)] loss: 0.0340 L_si: 0.0082 L_grad: 0.0258 
Train Epoch: 8 [324/816 (40%)] loss: 0.0428 L_si: 0.0120 L_grad: 0.0308 
Train Epoch: 8 [360/816 (44%)] loss: 0.0376 L_si: 0.0078 L_grad: 0.0298 
Train Epoch: 8 [396/816 (49%)] loss: 0.0511 L_si: 0.0195 L_grad: 0.0316 
Train Epoch: 8 [432/816 (53%)] loss: 0.0527 L_si: 0.0199 L_grad: 0.0328 
Train Epoch: 8 [468/816 (57%)] loss: 0.0364 L_si: 0.0076 L_grad: 0.0288 
Train Epoch: 8 [504/816 (62%)] loss: 0.0482 L_si: 0.0179 L_grad: 0.0303 
Train Epoch: 8 [540/816 (66%)] loss: 0.0362 L_si: 0.0072 L_grad: 0.0291 
Train Epoch: 8 [576/816 (71%)] loss: 0.0339 L_si: 0.0066 L_grad: 0.0273 
Train Epoch: 8 [612/816 (75%)] loss: 0.0345 L_si: 0.0078 L_grad: 0.0267 
Train Epoch: 8 [648/816 (79%)] loss: 0.0352 L_si: 0.0087 L_grad: 0.0264 
Train Epoch: 8 [684/816 (84%)] loss: 0.0310 L_si: 0.0059 L_grad: 0.0251 
Train Epoch: 8 [720/816 (88%)] loss: 0.0392 L_si: 0.0071 L_grad: 0.0322 
Train Epoch: 8 [756/816 (93%)] loss: 0.0354 L_si: 0.0100 L_grad: 0.0253 
Train Epoch: 8 [792/816 (97%)] loss: 0.0296 L_si: 0.0043 L_grad: 0.0252 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.044932134449481964, 0.0446159653365612, 0.04126902297139168, 0.0410296656191349, 0.043811049312353134, 0.04440709203481674, 0.0431983657181263, 0.04520425200462341, 0.04441140592098236, 0.04370766878128052, 0.045019105076789856, 0.043706294149160385, 0.04329082369804382, 0.04263370856642723, 0.043420206755399704, 0.04323508217930794, 0.04184259846806526, 0.04336231201887131, 0.018369024619460106], 'L_si': [0.00907011330127716, 0.008914757519960403, 0.008322898298501968, 0.007815402001142502, 0.0086575448513031, 0.007827574387192726, 0.008969198912382126, 0.009268932044506073, 0.009341597557067871, 0.009344704449176788, 0.008739527314901352, 0.008766699582338333, 0.009647142142057419, 0.008443661034107208, 0.00923663005232811, 0.008016765117645264, 0.008811093866825104, 0.00794992595911026, 0.009913774207234383], 'L_grad': [0.0358620211482048, 0.0357012078166008, 0.03294612467288971, 0.0332142636179924, 0.035153504461050034, 0.036579519510269165, 0.03422916680574417, 0.03593531996011734, 0.03506980836391449, 0.03436296433210373, 0.036279577761888504, 0.03493959456682205, 0.033643681555986404, 0.03419004753232002, 0.034183576703071594, 0.035218317061662674, 0.03303150460124016, 0.03541238605976105, 0.008455250412225723]}
Train Epoch: 9 [0/816 (0%)] loss: 0.0357 L_si: 0.0082 L_grad: 0.0275 
Train Epoch: 9 [36/816 (4%)] loss: 0.0331 L_si: 0.0056 L_grad: 0.0275 
Train Epoch: 9 [72/816 (9%)] loss: 0.0478 L_si: 0.0127 L_grad: 0.0351 
Train Epoch: 9 [108/816 (13%)] loss: 0.0407 L_si: 0.0119 L_grad: 0.0288 
Train Epoch: 9 [144/816 (18%)] loss: 0.0335 L_si: 0.0059 L_grad: 0.0276 
Train Epoch: 9 [180/816 (22%)] loss: 0.0507 L_si: 0.0143 L_grad: 0.0364 
Train Epoch: 9 [216/816 (26%)] loss: 0.0318 L_si: 0.0058 L_grad: 0.0261 
Train Epoch: 9 [252/816 (31%)] loss: 0.0304 L_si: 0.0043 L_grad: 0.0261 
Train Epoch: 9 [288/816 (35%)] loss: 0.0460 L_si: 0.0167 L_grad: 0.0294 
Train Epoch: 9 [324/816 (40%)] loss: 0.0394 L_si: 0.0087 L_grad: 0.0307 
Train Epoch: 9 [360/816 (44%)] loss: 0.0293 L_si: 0.0045 L_grad: 0.0248 
Train Epoch: 9 [396/816 (49%)] loss: 0.0409 L_si: 0.0110 L_grad: 0.0299 
Train Epoch: 9 [432/816 (53%)] loss: 0.0337 L_si: 0.0065 L_grad: 0.0272 
Train Epoch: 9 [468/816 (57%)] loss: 0.0308 L_si: 0.0057 L_grad: 0.0251 
Train Epoch: 9 [504/816 (62%)] loss: 0.0345 L_si: 0.0060 L_grad: 0.0285 
Train Epoch: 9 [540/816 (66%)] loss: 0.0364 L_si: 0.0079 L_grad: 0.0285 
Train Epoch: 9 [576/816 (71%)] loss: 0.0339 L_si: 0.0065 L_grad: 0.0274 
Train Epoch: 9 [612/816 (75%)] loss: 0.0354 L_si: 0.0078 L_grad: 0.0277 
Train Epoch: 9 [648/816 (79%)] loss: 0.0324 L_si: 0.0051 L_grad: 0.0273 
Train Epoch: 9 [684/816 (84%)] loss: 0.0443 L_si: 0.0122 L_grad: 0.0322 
Train Epoch: 9 [720/816 (88%)] loss: 0.0370 L_si: 0.0070 L_grad: 0.0300 
Train Epoch: 9 [756/816 (93%)] loss: 0.0307 L_si: 0.0035 L_grad: 0.0273 
Train Epoch: 9 [792/816 (97%)] loss: 0.0413 L_si: 0.0119 L_grad: 0.0294 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.042022332549095154, 0.044086430221796036, 0.04325791820883751, 0.042531296610832214, 0.04263612627983093, 0.04243845492601395, 0.04215291142463684, 0.04360973834991455, 0.041606467217206955, 0.045279424637556076, 0.04133428633213043, 0.04239313304424286, 0.042263928800821304, 0.041910137981176376, 0.04259791970252991, 0.04642586410045624, 0.04267648607492447, 0.04413933306932449, 0.016632242128252983], 'L_si': [0.007878631353378296, 0.008367303758859634, 0.009069953113794327, 0.008013177663087845, 0.00863463431596756, 0.007995657622814178, 0.008508697152137756, 0.009060516953468323, 0.007900848984718323, 0.008155152201652527, 0.008247461169958115, 0.007933534681797028, 0.007801588624715805, 0.008370261639356613, 0.007833385840058327, 0.009441088885068893, 0.008643615990877151, 0.009096566587686539, 0.008480977267026901], 'L_grad': [0.03414370119571686, 0.0357191264629364, 0.03418796509504318, 0.03451811894774437, 0.03400149196386337, 0.03444279730319977, 0.033644214272499084, 0.03454922139644623, 0.03370561823248863, 0.03712427243590355, 0.03308682516217232, 0.03445959836244583, 0.0344623401761055, 0.03353987634181976, 0.03476453572511673, 0.036984775215387344, 0.03403287008404732, 0.035042766481637955, 0.008151264861226082]}
Train Epoch: 10 [0/816 (0%)] loss: 0.0347 L_si: 0.0063 L_grad: 0.0284 
Train Epoch: 10 [36/816 (4%)] loss: 0.0476 L_si: 0.0134 L_grad: 0.0342 
Train Epoch: 10 [72/816 (9%)] loss: 0.0333 L_si: 0.0072 L_grad: 0.0262 
Train Epoch: 10 [108/816 (13%)] loss: 0.0280 L_si: 0.0041 L_grad: 0.0238 
Train Epoch: 10 [144/816 (18%)] loss: 0.0348 L_si: 0.0081 L_grad: 0.0267 
Train Epoch: 10 [180/816 (22%)] loss: 0.0365 L_si: 0.0088 L_grad: 0.0277 
Train Epoch: 10 [216/816 (26%)] loss: 0.0307 L_si: 0.0045 L_grad: 0.0262 
Train Epoch: 10 [252/816 (31%)] loss: 0.0259 L_si: 0.0029 L_grad: 0.0230 
Train Epoch: 10 [288/816 (35%)] loss: 0.0283 L_si: 0.0052 L_grad: 0.0231 
Train Epoch: 10 [324/816 (40%)] loss: 0.0355 L_si: 0.0061 L_grad: 0.0294 
Train Epoch: 10 [360/816 (44%)] loss: 0.0377 L_si: 0.0096 L_grad: 0.0281 
Train Epoch: 10 [396/816 (49%)] loss: 0.0331 L_si: 0.0069 L_grad: 0.0263 
Train Epoch: 10 [432/816 (53%)] loss: 0.0317 L_si: 0.0062 L_grad: 0.0255 
Train Epoch: 10 [468/816 (57%)] loss: 0.0409 L_si: 0.0099 L_grad: 0.0310 
Train Epoch: 10 [504/816 (62%)] loss: 0.0394 L_si: 0.0074 L_grad: 0.0320 
Train Epoch: 10 [540/816 (66%)] loss: 0.0298 L_si: 0.0031 L_grad: 0.0267 
Train Epoch: 10 [576/816 (71%)] loss: 0.0376 L_si: 0.0089 L_grad: 0.0288 
Train Epoch: 10 [612/816 (75%)] loss: 0.0443 L_si: 0.0120 L_grad: 0.0323 
Train Epoch: 10 [648/816 (79%)] loss: 0.0330 L_si: 0.0070 L_grad: 0.0260 
Train Epoch: 10 [684/816 (84%)] loss: 0.0374 L_si: 0.0122 L_grad: 0.0252 
Train Epoch: 10 [720/816 (88%)] loss: 0.0341 L_si: 0.0067 L_grad: 0.0274 
Train Epoch: 10 [756/816 (93%)] loss: 0.0384 L_si: 0.0079 L_grad: 0.0305 
Train Epoch: 10 [792/816 (97%)] loss: 0.0406 L_si: 0.0118 L_grad: 0.0288 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch010-loss-0.0362.pth.tar ...
all losses in batch in validation:  {'loss': [0.04276256635785103, 0.04305872321128845, 0.043303608894348145, 0.04283218830823898, 0.0424652136862278, 0.04197872802615166, 0.04265677183866501, 0.04410084709525108, 0.04486272856593132, 0.04385565221309662, 0.044619377702474594, 0.04505665600299835, 0.04352539777755737, 0.04331584647297859, 0.04149065166711807, 0.047621775418519974, 0.04311668500304222, 0.043123140931129456, 0.017189066857099533], 'L_si': [0.008300494402647018, 0.008708201348781586, 0.00784900039434433, 0.007942069321870804, 0.008421067148447037, 0.00786028802394867, 0.008949816226959229, 0.008220180869102478, 0.009024303406476974, 0.008130691945552826, 0.008635368198156357, 0.00887046754360199, 0.00889236107468605, 0.008103922009468079, 0.008090540766716003, 0.008553899824619293, 0.008846189826726913, 0.007904835045337677, 0.007180251181125641], 'L_grad': [0.03446207195520401, 0.034350521862506866, 0.035454608500003815, 0.03489011898636818, 0.03404414653778076, 0.03411844000220299, 0.03370695561170578, 0.035880666226148605, 0.035838425159454346, 0.03572496026754379, 0.03598400950431824, 0.03618618845939636, 0.03463303670287132, 0.03521192446351051, 0.03340011090040207, 0.03906787559390068, 0.03427049517631531, 0.03521830588579178, 0.010008815675973892]}
Train Epoch: 11 [0/816 (0%)] loss: 0.0325 L_si: 0.0061 L_grad: 0.0263 
Train Epoch: 11 [36/816 (4%)] loss: 0.0422 L_si: 0.0160 L_grad: 0.0262 
Train Epoch: 11 [72/816 (9%)] loss: 0.0388 L_si: 0.0096 L_grad: 0.0292 
Train Epoch: 11 [108/816 (13%)] loss: 0.0379 L_si: 0.0085 L_grad: 0.0293 
Train Epoch: 11 [144/816 (18%)] loss: 0.0379 L_si: 0.0084 L_grad: 0.0295 
Train Epoch: 11 [180/816 (22%)] loss: 0.0290 L_si: 0.0036 L_grad: 0.0254 
Train Epoch: 11 [216/816 (26%)] loss: 0.0329 L_si: 0.0073 L_grad: 0.0256 
Train Epoch: 11 [252/816 (31%)] loss: 0.0320 L_si: 0.0060 L_grad: 0.0261 
Train Epoch: 11 [288/816 (35%)] loss: 0.0511 L_si: 0.0158 L_grad: 0.0353 
Train Epoch: 11 [324/816 (40%)] loss: 0.0417 L_si: 0.0121 L_grad: 0.0296 
Train Epoch: 11 [360/816 (44%)] loss: 0.0295 L_si: 0.0038 L_grad: 0.0257 
Train Epoch: 11 [396/816 (49%)] loss: 0.0287 L_si: 0.0048 L_grad: 0.0239 
Train Epoch: 11 [432/816 (53%)] loss: 0.0374 L_si: 0.0103 L_grad: 0.0271 
Train Epoch: 11 [468/816 (57%)] loss: 0.0350 L_si: 0.0095 L_grad: 0.0255 
Train Epoch: 11 [504/816 (62%)] loss: 0.0409 L_si: 0.0121 L_grad: 0.0288 
Train Epoch: 11 [540/816 (66%)] loss: 0.0311 L_si: 0.0052 L_grad: 0.0260 
Train Epoch: 11 [576/816 (71%)] loss: 0.0320 L_si: 0.0040 L_grad: 0.0280 
Train Epoch: 11 [612/816 (75%)] loss: 0.0300 L_si: 0.0042 L_grad: 0.0258 
Train Epoch: 11 [648/816 (79%)] loss: 0.0355 L_si: 0.0073 L_grad: 0.0282 
Train Epoch: 11 [684/816 (84%)] loss: 0.0298 L_si: 0.0042 L_grad: 0.0256 
Train Epoch: 11 [720/816 (88%)] loss: 0.0367 L_si: 0.0090 L_grad: 0.0277 
Train Epoch: 11 [756/816 (93%)] loss: 0.0285 L_si: 0.0039 L_grad: 0.0246 
Train Epoch: 11 [792/816 (97%)] loss: 0.0269 L_si: 0.0035 L_grad: 0.0235 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04009115695953369, 0.04054306074976921, 0.040297288447618484, 0.04351966083049774, 0.043397463858127594, 0.04284213110804558, 0.040035951882600784, 0.03969091176986694, 0.03719744086265564, 0.04330354183912277, 0.04107355326414108, 0.041680656373500824, 0.04393830522894859, 0.04056906700134277, 0.03937940299510956, 0.04073774814605713, 0.041173048317432404, 0.04336929693818092, 0.014988541603088379], 'L_si': [0.00793197751045227, 0.007324244827032089, 0.007745858281850815, 0.008160345256328583, 0.008577972650527954, 0.007645174860954285, 0.00785103440284729, 0.004923708736896515, 0.005265606567263603, 0.007916204631328583, 0.006904372945427895, 0.009236454963684082, 0.008005905896425247, 0.008449345827102661, 0.00767267681658268, 0.008095301687717438, 0.008236363530158997, 0.008038382977247238, 0.005609340965747833], 'L_grad': [0.03215917944908142, 0.03321881592273712, 0.03255143016576767, 0.03535931557416916, 0.03481949120759964, 0.03519695624709129, 0.032184917479753494, 0.03476720303297043, 0.03193183243274689, 0.03538733720779419, 0.03416918218135834, 0.03244420140981674, 0.035932399332523346, 0.03211972117424011, 0.03170672804117203, 0.03264244645833969, 0.03293668478727341, 0.035330913960933685, 0.009379200637340546]}
Train Epoch: 12 [0/816 (0%)] loss: 0.0378 L_si: 0.0145 L_grad: 0.0233 
Train Epoch: 12 [36/816 (4%)] loss: 0.0343 L_si: 0.0065 L_grad: 0.0278 
Train Epoch: 12 [72/816 (9%)] loss: 0.0382 L_si: 0.0088 L_grad: 0.0295 
Train Epoch: 12 [108/816 (13%)] loss: 0.0489 L_si: 0.0134 L_grad: 0.0355 
Train Epoch: 12 [144/816 (18%)] loss: 0.0379 L_si: 0.0096 L_grad: 0.0283 
Train Epoch: 12 [180/816 (22%)] loss: 0.0359 L_si: 0.0079 L_grad: 0.0280 
Train Epoch: 12 [216/816 (26%)] loss: 0.0372 L_si: 0.0064 L_grad: 0.0308 
Train Epoch: 12 [252/816 (31%)] loss: 0.0424 L_si: 0.0118 L_grad: 0.0306 
Train Epoch: 12 [288/816 (35%)] loss: 0.0251 L_si: 0.0020 L_grad: 0.0231 
Train Epoch: 12 [324/816 (40%)] loss: 0.0473 L_si: 0.0166 L_grad: 0.0307 
Train Epoch: 12 [360/816 (44%)] loss: 0.0256 L_si: 0.0047 L_grad: 0.0209 
Train Epoch: 12 [396/816 (49%)] loss: 0.0374 L_si: 0.0086 L_grad: 0.0288 
Train Epoch: 12 [432/816 (53%)] loss: 0.0332 L_si: 0.0056 L_grad: 0.0276 
Train Epoch: 12 [468/816 (57%)] loss: 0.0330 L_si: 0.0055 L_grad: 0.0275 
Train Epoch: 12 [504/816 (62%)] loss: 0.0358 L_si: 0.0091 L_grad: 0.0267 
Train Epoch: 12 [540/816 (66%)] loss: 0.0311 L_si: 0.0053 L_grad: 0.0258 
Train Epoch: 12 [576/816 (71%)] loss: 0.0307 L_si: 0.0041 L_grad: 0.0266 
Train Epoch: 12 [612/816 (75%)] loss: 0.0361 L_si: 0.0075 L_grad: 0.0286 
Train Epoch: 12 [648/816 (79%)] loss: 0.0430 L_si: 0.0154 L_grad: 0.0276 
Train Epoch: 12 [684/816 (84%)] loss: 0.0417 L_si: 0.0135 L_grad: 0.0283 
Train Epoch: 12 [720/816 (88%)] loss: 0.0435 L_si: 0.0151 L_grad: 0.0284 
Train Epoch: 12 [756/816 (93%)] loss: 0.0418 L_si: 0.0092 L_grad: 0.0326 
Train Epoch: 12 [792/816 (97%)] loss: 0.0345 L_si: 0.0056 L_grad: 0.0289 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04480702430009842, 0.04284665361046791, 0.04018612205982208, 0.04355928674340248, 0.04212677478790283, 0.04230780154466629, 0.04525035619735718, 0.04472317546606064, 0.04227622598409653, 0.042632292956113815, 0.04341040179133415, 0.04210979864001274, 0.043954357504844666, 0.04170349985361099, 0.042340539395809174, 0.041395097970962524, 0.043141528964042664, 0.04232362285256386, 0.01647883653640747], 'L_si': [0.008892901241779327, 0.008097395300865173, 0.0075109172612428665, 0.009057845920324326, 0.007945679128170013, 0.007746748626232147, 0.008878514170646667, 0.007845483720302582, 0.008556187152862549, 0.008288506418466568, 0.008976232260465622, 0.008595872670412064, 0.0075871944427490234, 0.0084004458039999, 0.008449878543615341, 0.008669659495353699, 0.008258737623691559, 0.008642099797725677, 0.007952030748128891], 'L_grad': [0.03591412305831909, 0.03474925830960274, 0.03267520293593407, 0.034501440823078156, 0.03418109565973282, 0.03456105291843414, 0.03637184202671051, 0.03687769174575806, 0.03372003883123398, 0.03434378653764725, 0.03443416953086853, 0.03351392596960068, 0.03636716306209564, 0.03330305591225624, 0.03389066085219383, 0.032725438475608826, 0.034882791340351105, 0.03368152305483818, 0.008526804856956005]}
Train Epoch: 13 [0/816 (0%)] loss: 0.0421 L_si: 0.0101 L_grad: 0.0320 
Train Epoch: 13 [36/816 (4%)] loss: 0.0426 L_si: 0.0118 L_grad: 0.0308 
Train Epoch: 13 [72/816 (9%)] loss: 0.0315 L_si: 0.0045 L_grad: 0.0270 
Train Epoch: 13 [108/816 (13%)] loss: 0.0290 L_si: 0.0043 L_grad: 0.0247 
Train Epoch: 13 [144/816 (18%)] loss: 0.0483 L_si: 0.0153 L_grad: 0.0330 
Train Epoch: 13 [180/816 (22%)] loss: 0.0268 L_si: 0.0027 L_grad: 0.0240 
Train Epoch: 13 [216/816 (26%)] loss: 0.0275 L_si: 0.0031 L_grad: 0.0243 
Train Epoch: 13 [252/816 (31%)] loss: 0.0289 L_si: 0.0044 L_grad: 0.0246 
Train Epoch: 13 [288/816 (35%)] loss: 0.0351 L_si: 0.0099 L_grad: 0.0253 
Train Epoch: 13 [324/816 (40%)] loss: 0.0429 L_si: 0.0099 L_grad: 0.0330 
Train Epoch: 13 [360/816 (44%)] loss: 0.0308 L_si: 0.0046 L_grad: 0.0263 
Train Epoch: 13 [396/816 (49%)] loss: 0.0463 L_si: 0.0164 L_grad: 0.0299 
Train Epoch: 13 [432/816 (53%)] loss: 0.0365 L_si: 0.0084 L_grad: 0.0281 
Train Epoch: 13 [468/816 (57%)] loss: 0.0431 L_si: 0.0125 L_grad: 0.0307 
Train Epoch: 13 [504/816 (62%)] loss: 0.0445 L_si: 0.0128 L_grad: 0.0317 
Train Epoch: 13 [540/816 (66%)] loss: 0.0384 L_si: 0.0067 L_grad: 0.0317 
Train Epoch: 13 [576/816 (71%)] loss: 0.0263 L_si: 0.0029 L_grad: 0.0233 
Train Epoch: 13 [612/816 (75%)] loss: 0.0318 L_si: 0.0065 L_grad: 0.0254 
Train Epoch: 13 [648/816 (79%)] loss: 0.0255 L_si: 0.0032 L_grad: 0.0223 
Train Epoch: 13 [684/816 (84%)] loss: 0.0501 L_si: 0.0163 L_grad: 0.0338 
Train Epoch: 13 [720/816 (88%)] loss: 0.0336 L_si: 0.0091 L_grad: 0.0245 
Train Epoch: 13 [756/816 (93%)] loss: 0.0332 L_si: 0.0064 L_grad: 0.0268 
Train Epoch: 13 [792/816 (97%)] loss: 0.0272 L_si: 0.0038 L_grad: 0.0234 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04196752607822418, 0.040512606501579285, 0.04298647493124008, 0.04091956093907356, 0.03966601938009262, 0.040458906441926956, 0.041230179369449615, 0.03731813281774521, 0.0359550416469574, 0.041660286486148834, 0.04007896035909653, 0.039017800241708755, 0.04050406068563461, 0.04130095615983009, 0.03909460827708244, 0.04164985939860344, 0.03876003623008728, 0.04120616242289543, 0.016895398497581482], 'L_si': [0.008148733526468277, 0.007410131394863129, 0.008548445999622345, 0.008052218705415726, 0.006380677223205566, 0.006943035870790482, 0.008036743849515915, 0.005585983395576477, 0.004939528182148933, 0.0076667070388793945, 0.007127285003662109, 0.006829254329204559, 0.007720835506916046, 0.008202563971281052, 0.0073074474930763245, 0.007988899946212769, 0.007831737399101257, 0.007312353700399399, 0.00790666788816452], 'L_grad': [0.033818792551755905, 0.033102475106716156, 0.03443802893161774, 0.03286734223365784, 0.033285342156887054, 0.033515870571136475, 0.0331934355199337, 0.03173214942216873, 0.031015515327453613, 0.03399357944726944, 0.03295167535543442, 0.032188545912504196, 0.03278322517871857, 0.03309839218854904, 0.03178716078400612, 0.03366095945239067, 0.030928300693631172, 0.03389380872249603, 0.008988730609416962]}
Train Epoch: 14 [0/816 (0%)] loss: 0.0461 L_si: 0.0162 L_grad: 0.0299 
Train Epoch: 14 [36/816 (4%)] loss: 0.0422 L_si: 0.0086 L_grad: 0.0336 
Train Epoch: 14 [72/816 (9%)] loss: 0.0359 L_si: 0.0097 L_grad: 0.0263 
Train Epoch: 14 [108/816 (13%)] loss: 0.0395 L_si: 0.0083 L_grad: 0.0312 
Train Epoch: 14 [144/816 (18%)] loss: 0.0441 L_si: 0.0143 L_grad: 0.0298 
Train Epoch: 14 [180/816 (22%)] loss: 0.0332 L_si: 0.0067 L_grad: 0.0265 
Train Epoch: 14 [216/816 (26%)] loss: 0.0436 L_si: 0.0157 L_grad: 0.0278 
Train Epoch: 14 [252/816 (31%)] loss: 0.0309 L_si: 0.0064 L_grad: 0.0244 
Train Epoch: 14 [288/816 (35%)] loss: 0.0361 L_si: 0.0078 L_grad: 0.0283 
Train Epoch: 14 [324/816 (40%)] loss: 0.0283 L_si: 0.0061 L_grad: 0.0221 
Train Epoch: 14 [360/816 (44%)] loss: 0.0338 L_si: 0.0073 L_grad: 0.0265 
Train Epoch: 14 [396/816 (49%)] loss: 0.0384 L_si: 0.0085 L_grad: 0.0299 
Train Epoch: 14 [432/816 (53%)] loss: 0.0351 L_si: 0.0131 L_grad: 0.0220 
Train Epoch: 14 [468/816 (57%)] loss: 0.0362 L_si: 0.0079 L_grad: 0.0283 
Train Epoch: 14 [504/816 (62%)] loss: 0.0386 L_si: 0.0098 L_grad: 0.0288 
Train Epoch: 14 [540/816 (66%)] loss: 0.0306 L_si: 0.0044 L_grad: 0.0262 
Train Epoch: 14 [576/816 (71%)] loss: 0.0349 L_si: 0.0075 L_grad: 0.0275 
Train Epoch: 14 [612/816 (75%)] loss: 0.0329 L_si: 0.0054 L_grad: 0.0275 
Train Epoch: 14 [648/816 (79%)] loss: 0.0322 L_si: 0.0044 L_grad: 0.0278 
Train Epoch: 14 [684/816 (84%)] loss: 0.0339 L_si: 0.0058 L_grad: 0.0281 
Train Epoch: 14 [720/816 (88%)] loss: 0.0234 L_si: 0.0031 L_grad: 0.0203 
Train Epoch: 14 [756/816 (93%)] loss: 0.0265 L_si: 0.0042 L_grad: 0.0223 
Train Epoch: 14 [792/816 (97%)] loss: 0.0306 L_si: 0.0042 L_grad: 0.0264 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04073416069149971, 0.040505461394786835, 0.04163490608334541, 0.03852247819304466, 0.04131891950964928, 0.041738223284482956, 0.039967130869627, 0.041777104139328, 0.04139029607176781, 0.038544848561286926, 0.04397881403565407, 0.04031948000192642, 0.04166904091835022, 0.041712112724781036, 0.04262354597449303, 0.03942025080323219, 0.04442374408245087, 0.04206482693552971, 0.012864058837294579], 'L_si': [0.0073747336864471436, 0.008514244109392166, 0.008667279034852982, 0.00605083629488945, 0.007443785667419434, 0.007998701184988022, 0.0068472810089588165, 0.008308228105306625, 0.007895927876234055, 0.005759768187999725, 0.008113857358694077, 0.008332900702953339, 0.007442884147167206, 0.0074546486139297485, 0.008314225822687149, 0.008103255182504654, 0.00859101116657257, 0.009210392832756042, 0.003876347094774246], 'L_grad': [0.033359427005052567, 0.03199121728539467, 0.03296762704849243, 0.03247164189815521, 0.03387513384222984, 0.033739522099494934, 0.03311984986066818, 0.03346887603402138, 0.03349436819553375, 0.0327850803732872, 0.03586495667695999, 0.031986579298973083, 0.034226156771183014, 0.03425746411085129, 0.03430932015180588, 0.03131699562072754, 0.035832732915878296, 0.032854434102773666, 0.008987711742520332]}
Train Epoch: 15 [0/816 (0%)] loss: 0.0261 L_si: 0.0048 L_grad: 0.0213 
Train Epoch: 15 [36/816 (4%)] loss: 0.0318 L_si: 0.0037 L_grad: 0.0280 
Train Epoch: 15 [72/816 (9%)] loss: 0.0247 L_si: 0.0025 L_grad: 0.0222 
Train Epoch: 15 [108/816 (13%)] loss: 0.0313 L_si: 0.0054 L_grad: 0.0259 
Train Epoch: 15 [144/816 (18%)] loss: 0.0249 L_si: 0.0035 L_grad: 0.0214 
Train Epoch: 15 [180/816 (22%)] loss: 0.0325 L_si: 0.0061 L_grad: 0.0264 
Train Epoch: 15 [216/816 (26%)] loss: 0.0353 L_si: 0.0087 L_grad: 0.0266 
Train Epoch: 15 [252/816 (31%)] loss: 0.0318 L_si: 0.0044 L_grad: 0.0275 
Train Epoch: 15 [288/816 (35%)] loss: 0.0306 L_si: 0.0045 L_grad: 0.0261 
Train Epoch: 15 [324/816 (40%)] loss: 0.0364 L_si: 0.0082 L_grad: 0.0282 
Train Epoch: 15 [360/816 (44%)] loss: 0.0222 L_si: 0.0025 L_grad: 0.0197 
Train Epoch: 15 [396/816 (49%)] loss: 0.0270 L_si: 0.0043 L_grad: 0.0227 
Train Epoch: 15 [432/816 (53%)] loss: 0.0287 L_si: 0.0042 L_grad: 0.0246 
Train Epoch: 15 [468/816 (57%)] loss: 0.0351 L_si: 0.0081 L_grad: 0.0271 
Train Epoch: 15 [504/816 (62%)] loss: 0.0387 L_si: 0.0104 L_grad: 0.0283 
Train Epoch: 15 [540/816 (66%)] loss: 0.0383 L_si: 0.0083 L_grad: 0.0299 
Train Epoch: 15 [576/816 (71%)] loss: 0.0309 L_si: 0.0048 L_grad: 0.0261 
Train Epoch: 15 [612/816 (75%)] loss: 0.0340 L_si: 0.0064 L_grad: 0.0276 
Train Epoch: 15 [648/816 (79%)] loss: 0.0310 L_si: 0.0040 L_grad: 0.0271 
Train Epoch: 15 [684/816 (84%)] loss: 0.0377 L_si: 0.0121 L_grad: 0.0257 
Train Epoch: 15 [720/816 (88%)] loss: 0.0346 L_si: 0.0098 L_grad: 0.0248 
Train Epoch: 15 [756/816 (93%)] loss: 0.0365 L_si: 0.0075 L_grad: 0.0290 
Train Epoch: 15 [792/816 (97%)] loss: 0.0349 L_si: 0.0079 L_grad: 0.0270 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.0411335714161396, 0.03285651654005051, 0.04047543555498123, 0.04354317486286163, 0.041324686259031296, 0.04079294577240944, 0.042956359684467316, 0.041755858808755875, 0.04156310483813286, 0.043997328728437424, 0.04012521728873253, 0.042476799339056015, 0.0419972687959671, 0.040525466203689575, 0.0408640019595623, 0.04040132462978363, 0.04066617786884308, 0.04073989763855934, 0.014134177006781101], 'L_si': [0.008730817586183548, 0.0038932878524065018, 0.00802130252122879, 0.008578643202781677, 0.00792718306183815, 0.0075449831783771515, 0.009222347289323807, 0.008601021021604538, 0.008387606590986252, 0.009084377437829971, 0.00877309963107109, 0.009246818721294403, 0.009566772729158401, 0.007499035447835922, 0.007856566458940506, 0.00787479430437088, 0.007974233478307724, 0.007537573575973511, 0.006754975765943527], 'L_grad': [0.032402753829956055, 0.028963230550289154, 0.03245413303375244, 0.034964531660079956, 0.033397503197193146, 0.03324796259403229, 0.03373401239514351, 0.03315483778715134, 0.033175498247146606, 0.03491295129060745, 0.03135211765766144, 0.03322998061776161, 0.0324304960668087, 0.03302643075585365, 0.033007435500621796, 0.03252653032541275, 0.032691944390535355, 0.03320232406258583, 0.007379201240837574]}
Train Epoch: 16 [0/816 (0%)] loss: 0.0389 L_si: 0.0093 L_grad: 0.0295 
Train Epoch: 16 [36/816 (4%)] loss: 0.0224 L_si: 0.0021 L_grad: 0.0203 
Train Epoch: 16 [72/816 (9%)] loss: 0.0380 L_si: 0.0122 L_grad: 0.0259 
Train Epoch: 16 [108/816 (13%)] loss: 0.0299 L_si: 0.0040 L_grad: 0.0259 
Train Epoch: 16 [144/816 (18%)] loss: 0.0307 L_si: 0.0052 L_grad: 0.0255 
Train Epoch: 16 [180/816 (22%)] loss: 0.0277 L_si: 0.0032 L_grad: 0.0245 
Train Epoch: 16 [216/816 (26%)] loss: 0.0288 L_si: 0.0055 L_grad: 0.0233 
Train Epoch: 16 [252/816 (31%)] loss: 0.0424 L_si: 0.0125 L_grad: 0.0299 
Train Epoch: 16 [288/816 (35%)] loss: 0.0243 L_si: 0.0028 L_grad: 0.0215 
Train Epoch: 16 [324/816 (40%)] loss: 0.0395 L_si: 0.0077 L_grad: 0.0318 
Train Epoch: 16 [360/816 (44%)] loss: 0.0371 L_si: 0.0085 L_grad: 0.0286 
Train Epoch: 16 [396/816 (49%)] loss: 0.0263 L_si: 0.0041 L_grad: 0.0223 
Train Epoch: 16 [432/816 (53%)] loss: 0.0297 L_si: 0.0046 L_grad: 0.0251 
Train Epoch: 16 [468/816 (57%)] loss: 0.0380 L_si: 0.0099 L_grad: 0.0281 
Train Epoch: 16 [504/816 (62%)] loss: 0.0388 L_si: 0.0078 L_grad: 0.0310 
Train Epoch: 16 [540/816 (66%)] loss: 0.0384 L_si: 0.0109 L_grad: 0.0275 
Train Epoch: 16 [576/816 (71%)] loss: 0.0418 L_si: 0.0122 L_grad: 0.0296 
Train Epoch: 16 [612/816 (75%)] loss: 0.0435 L_si: 0.0121 L_grad: 0.0315 
Train Epoch: 16 [648/816 (79%)] loss: 0.0227 L_si: 0.0034 L_grad: 0.0193 
Train Epoch: 16 [684/816 (84%)] loss: 0.0329 L_si: 0.0077 L_grad: 0.0252 
Train Epoch: 16 [720/816 (88%)] loss: 0.0333 L_si: 0.0057 L_grad: 0.0277 
Train Epoch: 16 [756/816 (93%)] loss: 0.0278 L_si: 0.0040 L_grad: 0.0238 
Train Epoch: 16 [792/816 (97%)] loss: 0.0272 L_si: 0.0038 L_grad: 0.0234 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040132075548172, 0.042799290269613266, 0.04307084158062935, 0.04132358357310295, 0.0425269715487957, 0.04170367866754532, 0.03899317979812622, 0.03950278460979462, 0.04163873940706253, 0.040219761431217194, 0.042308591306209564, 0.03916309028863907, 0.04050219804048538, 0.04254886507987976, 0.03964516147971153, 0.04362969100475311, 0.04342822730541229, 0.039987266063690186, 0.014699086546897888], 'L_si': [0.007352985441684723, 0.008176270872354507, 0.009854454547166824, 0.008457008749246597, 0.007816512137651443, 0.008423849940299988, 0.007470808923244476, 0.00834810733795166, 0.008606284856796265, 0.007701672613620758, 0.008735992014408112, 0.008084867149591446, 0.008160606026649475, 0.008013494312763214, 0.007814157754182816, 0.008894581347703934, 0.008840404450893402, 0.007963847368955612, 0.006539426743984222], 'L_grad': [0.032779090106487274, 0.03462301939725876, 0.033216387033462524, 0.032866574823856354, 0.03471045941114426, 0.03327982872724533, 0.031522370874881744, 0.031154677271842957, 0.033032454550266266, 0.032518088817596436, 0.03357259929180145, 0.031078223139047623, 0.03234159201383591, 0.03453537076711655, 0.03183100372552872, 0.03473510965704918, 0.03458782285451889, 0.03202341869473457, 0.008159659802913666]}
Train Epoch: 17 [0/816 (0%)] loss: 0.0302 L_si: 0.0064 L_grad: 0.0238 
Train Epoch: 17 [36/816 (4%)] loss: 0.0323 L_si: 0.0054 L_grad: 0.0269 
Train Epoch: 17 [72/816 (9%)] loss: 0.0266 L_si: 0.0026 L_grad: 0.0240 
Train Epoch: 17 [108/816 (13%)] loss: 0.0229 L_si: 0.0026 L_grad: 0.0203 
Train Epoch: 17 [144/816 (18%)] loss: 0.0338 L_si: 0.0060 L_grad: 0.0278 
Train Epoch: 17 [180/816 (22%)] loss: 0.0242 L_si: 0.0031 L_grad: 0.0211 
Train Epoch: 17 [216/816 (26%)] loss: 0.0304 L_si: 0.0058 L_grad: 0.0247 
Train Epoch: 17 [252/816 (31%)] loss: 0.0363 L_si: 0.0090 L_grad: 0.0273 
Train Epoch: 17 [288/816 (35%)] loss: 0.0363 L_si: 0.0088 L_grad: 0.0275 
Train Epoch: 17 [324/816 (40%)] loss: 0.0357 L_si: 0.0090 L_grad: 0.0267 
Train Epoch: 17 [360/816 (44%)] loss: 0.0309 L_si: 0.0065 L_grad: 0.0245 
Train Epoch: 17 [396/816 (49%)] loss: 0.0248 L_si: 0.0025 L_grad: 0.0224 
Train Epoch: 17 [432/816 (53%)] loss: 0.0323 L_si: 0.0062 L_grad: 0.0262 
Train Epoch: 17 [468/816 (57%)] loss: 0.0297 L_si: 0.0049 L_grad: 0.0249 
Train Epoch: 17 [504/816 (62%)] loss: 0.0335 L_si: 0.0059 L_grad: 0.0276 
Train Epoch: 17 [540/816 (66%)] loss: 0.0311 L_si: 0.0042 L_grad: 0.0269 
Train Epoch: 17 [576/816 (71%)] loss: 0.0423 L_si: 0.0084 L_grad: 0.0338 
Train Epoch: 17 [612/816 (75%)] loss: 0.0332 L_si: 0.0057 L_grad: 0.0275 
Train Epoch: 17 [648/816 (79%)] loss: 0.0355 L_si: 0.0077 L_grad: 0.0278 
Train Epoch: 17 [684/816 (84%)] loss: 0.0424 L_si: 0.0163 L_grad: 0.0261 
Train Epoch: 17 [720/816 (88%)] loss: 0.0259 L_si: 0.0024 L_grad: 0.0235 
Train Epoch: 17 [756/816 (93%)] loss: 0.0349 L_si: 0.0073 L_grad: 0.0276 
Train Epoch: 17 [792/816 (97%)] loss: 0.0258 L_si: 0.0043 L_grad: 0.0214 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04069475829601288, 0.03945048153400421, 0.040274448692798615, 0.03743026405572891, 0.040951911360025406, 0.042830318212509155, 0.03915645554661751, 0.039212409406900406, 0.03918423876166344, 0.037618450820446014, 0.040991008281707764, 0.0410347655415535, 0.03917977586388588, 0.04082220420241356, 0.04047379270195961, 0.04477578029036522, 0.04160027951002121, 0.04112045839428902, 0.01078688446432352], 'L_si': [0.00813339278101921, 0.007881753146648407, 0.008307382464408875, 0.007482413202524185, 0.008844945579767227, 0.00838472694158554, 0.007655300199985504, 0.00731402263045311, 0.00816396251320839, 0.006706174463033676, 0.007718842476606369, 0.007199563086032867, 0.008696012198925018, 0.007714275270700455, 0.008270490914583206, 0.0084737129509449, 0.008549105376005173, 0.007628347724676132, 0.0029344074428081512], 'L_grad': [0.03256136551499367, 0.031568728387355804, 0.03196706622838974, 0.029947852715849876, 0.03210696578025818, 0.034445591270923615, 0.031501155346632004, 0.031898386776447296, 0.031020276248455048, 0.030912278220057487, 0.033272165805101395, 0.03383520245552063, 0.03048376366496086, 0.033107928931713104, 0.032203301787376404, 0.03630206733942032, 0.03305117413401604, 0.033492110669612885, 0.00785247702151537]}
Train Epoch: 18 [0/816 (0%)] loss: 0.0254 L_si: 0.0027 L_grad: 0.0228 
Train Epoch: 18 [36/816 (4%)] loss: 0.0477 L_si: 0.0212 L_grad: 0.0265 
Train Epoch: 18 [72/816 (9%)] loss: 0.0318 L_si: 0.0087 L_grad: 0.0231 
Train Epoch: 18 [108/816 (13%)] loss: 0.0348 L_si: 0.0070 L_grad: 0.0278 
Train Epoch: 18 [144/816 (18%)] loss: 0.0490 L_si: 0.0153 L_grad: 0.0337 
Train Epoch: 18 [180/816 (22%)] loss: 0.0305 L_si: 0.0049 L_grad: 0.0255 
Train Epoch: 18 [216/816 (26%)] loss: 0.0290 L_si: 0.0046 L_grad: 0.0244 
Train Epoch: 18 [252/816 (31%)] loss: 0.0397 L_si: 0.0120 L_grad: 0.0276 
Train Epoch: 18 [288/816 (35%)] loss: 0.0359 L_si: 0.0093 L_grad: 0.0267 
Train Epoch: 18 [324/816 (40%)] loss: 0.0285 L_si: 0.0046 L_grad: 0.0239 
Train Epoch: 18 [360/816 (44%)] loss: 0.0260 L_si: 0.0031 L_grad: 0.0229 
Train Epoch: 18 [396/816 (49%)] loss: 0.0324 L_si: 0.0056 L_grad: 0.0268 
Train Epoch: 18 [432/816 (53%)] loss: 0.0279 L_si: 0.0038 L_grad: 0.0241 
Train Epoch: 18 [468/816 (57%)] loss: 0.0309 L_si: 0.0058 L_grad: 0.0251 
Train Epoch: 18 [504/816 (62%)] loss: 0.0417 L_si: 0.0102 L_grad: 0.0314 
Train Epoch: 18 [540/816 (66%)] loss: 0.0424 L_si: 0.0151 L_grad: 0.0273 
Train Epoch: 18 [576/816 (71%)] loss: 0.0368 L_si: 0.0072 L_grad: 0.0296 
Train Epoch: 18 [612/816 (75%)] loss: 0.0288 L_si: 0.0039 L_grad: 0.0249 
Train Epoch: 18 [648/816 (79%)] loss: 0.0229 L_si: 0.0033 L_grad: 0.0197 
Train Epoch: 18 [684/816 (84%)] loss: 0.0406 L_si: 0.0136 L_grad: 0.0270 
Train Epoch: 18 [720/816 (88%)] loss: 0.0257 L_si: 0.0029 L_grad: 0.0228 
Train Epoch: 18 [756/816 (93%)] loss: 0.0265 L_si: 0.0037 L_grad: 0.0228 
Train Epoch: 18 [792/816 (97%)] loss: 0.0277 L_si: 0.0037 L_grad: 0.0239 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.042342569679021835, 0.04075120389461517, 0.039911750704050064, 0.03858036920428276, 0.039958056062459946, 0.040189869701862335, 0.04191194847226143, 0.04186597838997841, 0.03657355159521103, 0.03839344158768654, 0.036123886704444885, 0.04089716821908951, 0.036920543760061264, 0.040031298995018005, 0.03843596205115318, 0.04187556356191635, 0.03833453729748726, 0.03947115316987038, 0.016082976013422012], 'L_si': [0.007848165929317474, 0.008627049624919891, 0.00667935237288475, 0.0069361962378025055, 0.007570911198854446, 0.008073929697275162, 0.006313301622867584, 0.007487792521715164, 0.005717627704143524, 0.006770122796297073, 0.006560012698173523, 0.0084935761988163, 0.006720349192619324, 0.008040178567171097, 0.0064372532069683075, 0.008807849138975143, 0.007513612508773804, 0.007836569100618362, 0.007955584675073624], 'L_grad': [0.03449440374970436, 0.03212415426969528, 0.033232398331165314, 0.031644172966480255, 0.0323871448636055, 0.03211594000458717, 0.035598646849393845, 0.034378185868263245, 0.030855923891067505, 0.031623318791389465, 0.029563874006271362, 0.03240359202027321, 0.03020019456744194, 0.03199112042784691, 0.031998708844184875, 0.03306771442294121, 0.030820924788713455, 0.031634584069252014, 0.008127390407025814]}
Train Epoch: 19 [0/816 (0%)] loss: 0.0382 L_si: 0.0109 L_grad: 0.0273 
Train Epoch: 19 [36/816 (4%)] loss: 0.0265 L_si: 0.0032 L_grad: 0.0233 
Train Epoch: 19 [72/816 (9%)] loss: 0.0339 L_si: 0.0066 L_grad: 0.0273 
Train Epoch: 19 [108/816 (13%)] loss: 0.0318 L_si: 0.0067 L_grad: 0.0251 
Train Epoch: 19 [144/816 (18%)] loss: 0.0303 L_si: 0.0062 L_grad: 0.0241 
Train Epoch: 19 [180/816 (22%)] loss: 0.0350 L_si: 0.0078 L_grad: 0.0272 
Train Epoch: 19 [216/816 (26%)] loss: 0.0273 L_si: 0.0055 L_grad: 0.0218 
Train Epoch: 19 [252/816 (31%)] loss: 0.0452 L_si: 0.0120 L_grad: 0.0332 
Train Epoch: 19 [288/816 (35%)] loss: 0.0301 L_si: 0.0052 L_grad: 0.0249 
Train Epoch: 19 [324/816 (40%)] loss: 0.0269 L_si: 0.0029 L_grad: 0.0240 
Train Epoch: 19 [360/816 (44%)] loss: 0.0234 L_si: 0.0022 L_grad: 0.0213 
Train Epoch: 19 [396/816 (49%)] loss: 0.0233 L_si: 0.0029 L_grad: 0.0204 
Train Epoch: 19 [432/816 (53%)] loss: 0.0302 L_si: 0.0077 L_grad: 0.0224 
Train Epoch: 19 [468/816 (57%)] loss: 0.0295 L_si: 0.0056 L_grad: 0.0240 
Train Epoch: 19 [504/816 (62%)] loss: 0.0382 L_si: 0.0075 L_grad: 0.0307 
Train Epoch: 19 [540/816 (66%)] loss: 0.0266 L_si: 0.0031 L_grad: 0.0236 
Train Epoch: 19 [576/816 (71%)] loss: 0.0297 L_si: 0.0052 L_grad: 0.0244 
Train Epoch: 19 [612/816 (75%)] loss: 0.0284 L_si: 0.0050 L_grad: 0.0234 
Train Epoch: 19 [648/816 (79%)] loss: 0.0269 L_si: 0.0034 L_grad: 0.0236 
Train Epoch: 19 [684/816 (84%)] loss: 0.0291 L_si: 0.0058 L_grad: 0.0232 
Train Epoch: 19 [720/816 (88%)] loss: 0.0277 L_si: 0.0049 L_grad: 0.0228 
Train Epoch: 19 [756/816 (93%)] loss: 0.0358 L_si: 0.0069 L_grad: 0.0289 
Train Epoch: 19 [792/816 (97%)] loss: 0.0378 L_si: 0.0095 L_grad: 0.0284 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04342730715870857, 0.03755719214677811, 0.03815615177154541, 0.039161574095487595, 0.037588443607091904, 0.04078502953052521, 0.03977692127227783, 0.038511600345373154, 0.04454784840345383, 0.0382966548204422, 0.03844137489795685, 0.040981825441122055, 0.03929222375154495, 0.04045901447534561, 0.0417470708489418, 0.03617119789123535, 0.04231728985905647, 0.041027821600437164, 0.01743338443338871], 'L_si': [0.008205309510231018, 0.006825737655162811, 0.007357306778430939, 0.007397778332233429, 0.007716972380876541, 0.008316144347190857, 0.00766918808221817, 0.00797327235341072, 0.009942233562469482, 0.007958587259054184, 0.007446862757205963, 0.0077619291841983795, 0.007349405437707901, 0.007009275257587433, 0.007721390575170517, 0.005592580884695053, 0.007226601243019104, 0.008012443780899048, 0.008419618010520935], 'L_grad': [0.035221997648477554, 0.030731452628970146, 0.03079884499311447, 0.031763795763254166, 0.029871471226215363, 0.03246888518333435, 0.03210773319005966, 0.030538327991962433, 0.034605614840984344, 0.030338067561388016, 0.030994514003396034, 0.033219896256923676, 0.03194281831383705, 0.03344973921775818, 0.034025680273771286, 0.03057861514389515, 0.03509068861603737, 0.033015377819538116, 0.009013766422867775]}
Train Epoch: 20 [0/816 (0%)] loss: 0.0236 L_si: 0.0025 L_grad: 0.0211 
Train Epoch: 20 [36/816 (4%)] loss: 0.0239 L_si: 0.0033 L_grad: 0.0206 
Train Epoch: 20 [72/816 (9%)] loss: 0.0374 L_si: 0.0073 L_grad: 0.0301 
Train Epoch: 20 [108/816 (13%)] loss: 0.0240 L_si: 0.0020 L_grad: 0.0220 
Train Epoch: 20 [144/816 (18%)] loss: 0.0333 L_si: 0.0068 L_grad: 0.0265 
Train Epoch: 20 [180/816 (22%)] loss: 0.0266 L_si: 0.0039 L_grad: 0.0227 
Train Epoch: 20 [216/816 (26%)] loss: 0.0294 L_si: 0.0048 L_grad: 0.0246 
Train Epoch: 20 [252/816 (31%)] loss: 0.0244 L_si: 0.0039 L_grad: 0.0205 
Train Epoch: 20 [288/816 (35%)] loss: 0.0380 L_si: 0.0129 L_grad: 0.0250 
Train Epoch: 20 [324/816 (40%)] loss: 0.0324 L_si: 0.0053 L_grad: 0.0271 
Train Epoch: 20 [360/816 (44%)] loss: 0.0336 L_si: 0.0080 L_grad: 0.0257 
Train Epoch: 20 [396/816 (49%)] loss: 0.0482 L_si: 0.0142 L_grad: 0.0340 
Train Epoch: 20 [432/816 (53%)] loss: 0.0297 L_si: 0.0062 L_grad: 0.0235 
Train Epoch: 20 [468/816 (57%)] loss: 0.0328 L_si: 0.0049 L_grad: 0.0279 
Train Epoch: 20 [504/816 (62%)] loss: 0.0314 L_si: 0.0045 L_grad: 0.0269 
Train Epoch: 20 [540/816 (66%)] loss: 0.0339 L_si: 0.0067 L_grad: 0.0273 
Train Epoch: 20 [576/816 (71%)] loss: 0.0301 L_si: 0.0052 L_grad: 0.0248 
Train Epoch: 20 [612/816 (75%)] loss: 0.0281 L_si: 0.0037 L_grad: 0.0244 
Train Epoch: 20 [648/816 (79%)] loss: 0.0251 L_si: 0.0042 L_grad: 0.0209 
Train Epoch: 20 [684/816 (84%)] loss: 0.0281 L_si: 0.0038 L_grad: 0.0243 
Train Epoch: 20 [720/816 (88%)] loss: 0.0275 L_si: 0.0030 L_grad: 0.0245 
Train Epoch: 20 [756/816 (93%)] loss: 0.0407 L_si: 0.0121 L_grad: 0.0286 
Train Epoch: 20 [792/816 (97%)] loss: 0.0316 L_si: 0.0045 L_grad: 0.0271 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch020-loss-0.0300.pth.tar ...
all losses in batch in validation:  {'loss': [0.03861789032816887, 0.04227314889431, 0.03893404081463814, 0.04053560644388199, 0.040443044155836105, 0.03909216821193695, 0.04022761434316635, 0.03996460512280464, 0.03992912918329239, 0.03776872903108597, 0.04141320660710335, 0.039496563374996185, 0.04191606119275093, 0.03999340161681175, 0.04267439618706703, 0.040101394057273865, 0.04018973559141159, 0.03678291290998459, 0.011390320956707], 'L_si': [0.008693374693393707, 0.009065456688404083, 0.008215732872486115, 0.008271027356386185, 0.009511098265647888, 0.008991077542304993, 0.007047764956951141, 0.00847671553492546, 0.007998555898666382, 0.008082598447799683, 0.00819491222500801, 0.006906688213348389, 0.006997726857662201, 0.007986810058355331, 0.008444800972938538, 0.008890591561794281, 0.007610004395246506, 0.00792117789387703, 0.0038490332663059235], 'L_grad': [0.029924515634775162, 0.033207692205905914, 0.030718307942152023, 0.032264579087495804, 0.030931945890188217, 0.030101090669631958, 0.03317984938621521, 0.03148788958787918, 0.03193057328462601, 0.029686128720641136, 0.03321829438209534, 0.0325898751616478, 0.03491833433508873, 0.03200659155845642, 0.034229595214128494, 0.031210802495479584, 0.032579731196165085, 0.02886173501610756, 0.007541287690401077]}
Train Epoch: 21 [0/816 (0%)] loss: 0.0266 L_si: 0.0045 L_grad: 0.0221 
Train Epoch: 21 [36/816 (4%)] loss: 0.0320 L_si: 0.0076 L_grad: 0.0244 
Train Epoch: 21 [72/816 (9%)] loss: 0.0281 L_si: 0.0071 L_grad: 0.0210 
Train Epoch: 21 [108/816 (13%)] loss: 0.0269 L_si: 0.0044 L_grad: 0.0226 
Train Epoch: 21 [144/816 (18%)] loss: 0.0284 L_si: 0.0038 L_grad: 0.0245 
Train Epoch: 21 [180/816 (22%)] loss: 0.0372 L_si: 0.0067 L_grad: 0.0305 
Train Epoch: 21 [216/816 (26%)] loss: 0.0304 L_si: 0.0048 L_grad: 0.0256 
Train Epoch: 21 [252/816 (31%)] loss: 0.0309 L_si: 0.0075 L_grad: 0.0234 
Train Epoch: 21 [288/816 (35%)] loss: 0.0280 L_si: 0.0035 L_grad: 0.0244 
Train Epoch: 21 [324/816 (40%)] loss: 0.0267 L_si: 0.0034 L_grad: 0.0233 
Train Epoch: 21 [360/816 (44%)] loss: 0.0231 L_si: 0.0033 L_grad: 0.0198 
Train Epoch: 21 [396/816 (49%)] loss: 0.0320 L_si: 0.0074 L_grad: 0.0246 
Train Epoch: 21 [432/816 (53%)] loss: 0.0315 L_si: 0.0098 L_grad: 0.0217 
Train Epoch: 21 [468/816 (57%)] loss: 0.0360 L_si: 0.0078 L_grad: 0.0282 
Train Epoch: 21 [504/816 (62%)] loss: 0.0245 L_si: 0.0030 L_grad: 0.0216 
Train Epoch: 21 [540/816 (66%)] loss: 0.0259 L_si: 0.0035 L_grad: 0.0224 
Train Epoch: 21 [576/816 (71%)] loss: 0.0228 L_si: 0.0020 L_grad: 0.0208 
Train Epoch: 21 [612/816 (75%)] loss: 0.0280 L_si: 0.0032 L_grad: 0.0248 
Train Epoch: 21 [648/816 (79%)] loss: 0.0298 L_si: 0.0057 L_grad: 0.0241 
Train Epoch: 21 [684/816 (84%)] loss: 0.0292 L_si: 0.0045 L_grad: 0.0246 
Train Epoch: 21 [720/816 (88%)] loss: 0.0273 L_si: 0.0039 L_grad: 0.0234 
Train Epoch: 21 [756/816 (93%)] loss: 0.0336 L_si: 0.0073 L_grad: 0.0262 
Train Epoch: 21 [792/816 (97%)] loss: 0.0359 L_si: 0.0083 L_grad: 0.0276 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.03710821270942688, 0.04375709220767021, 0.03570260852575302, 0.03932903707027435, 0.03879360854625702, 0.0420462042093277, 0.039336517453193665, 0.0391397625207901, 0.04109366983175278, 0.039417240768671036, 0.04138583317399025, 0.03583985194563866, 0.041189100593328476, 0.038985587656497955, 0.04069887846708298, 0.04066526144742966, 0.03764966130256653, 0.036742255091667175, 0.016538597643375397], 'L_si': [0.006660398095846176, 0.008170299232006073, 0.007106799632310867, 0.007678348571062088, 0.007556885480880737, 0.007736414670944214, 0.0076183415949344635, 0.007439464330673218, 0.008068397641181946, 0.007081381976604462, 0.0064199939370155334, 0.006917290389537811, 0.008348129689693451, 0.00671028345823288, 0.00820992887020111, 0.00819464772939682, 0.007133737206459045, 0.006047993898391724, 0.00718843936920166], 'L_grad': [0.030447816476225853, 0.03558679297566414, 0.028595807030797005, 0.031650688499212265, 0.031236723065376282, 0.034309789538383484, 0.0317181758582592, 0.03170029819011688, 0.03302527219057083, 0.032335858792066574, 0.034965839236974716, 0.028922561556100845, 0.032840970903635025, 0.032275304198265076, 0.032488949596881866, 0.03247061371803284, 0.030515924096107483, 0.03069426119327545, 0.009350157342851162]}
Train Epoch: 22 [0/816 (0%)] loss: 0.0325 L_si: 0.0069 L_grad: 0.0256 
Train Epoch: 22 [36/816 (4%)] loss: 0.0300 L_si: 0.0057 L_grad: 0.0243 
Train Epoch: 22 [72/816 (9%)] loss: 0.0257 L_si: 0.0054 L_grad: 0.0203 
Train Epoch: 22 [108/816 (13%)] loss: 0.0274 L_si: 0.0039 L_grad: 0.0234 
Train Epoch: 22 [144/816 (18%)] loss: 0.0338 L_si: 0.0072 L_grad: 0.0266 
Train Epoch: 22 [180/816 (22%)] loss: 0.0281 L_si: 0.0049 L_grad: 0.0231 
Train Epoch: 22 [216/816 (26%)] loss: 0.0274 L_si: 0.0040 L_grad: 0.0234 
Train Epoch: 22 [252/816 (31%)] loss: 0.0244 L_si: 0.0026 L_grad: 0.0217 
Train Epoch: 22 [288/816 (35%)] loss: 0.0274 L_si: 0.0039 L_grad: 0.0235 
Train Epoch: 22 [324/816 (40%)] loss: 0.0388 L_si: 0.0093 L_grad: 0.0296 
Train Epoch: 22 [360/816 (44%)] loss: 0.0312 L_si: 0.0055 L_grad: 0.0257 
Train Epoch: 22 [396/816 (49%)] loss: 0.0327 L_si: 0.0071 L_grad: 0.0256 
Train Epoch: 22 [432/816 (53%)] loss: 0.0270 L_si: 0.0043 L_grad: 0.0227 
Train Epoch: 22 [468/816 (57%)] loss: 0.0304 L_si: 0.0056 L_grad: 0.0248 
Train Epoch: 22 [504/816 (62%)] loss: 0.0276 L_si: 0.0045 L_grad: 0.0231 
Train Epoch: 22 [540/816 (66%)] loss: 0.0394 L_si: 0.0085 L_grad: 0.0309 
Train Epoch: 22 [576/816 (71%)] loss: 0.0262 L_si: 0.0042 L_grad: 0.0220 
Train Epoch: 22 [612/816 (75%)] loss: 0.0324 L_si: 0.0043 L_grad: 0.0281 
Train Epoch: 22 [648/816 (79%)] loss: 0.0252 L_si: 0.0037 L_grad: 0.0215 
Train Epoch: 22 [684/816 (84%)] loss: 0.0227 L_si: 0.0029 L_grad: 0.0197 
Train Epoch: 22 [720/816 (88%)] loss: 0.0287 L_si: 0.0062 L_grad: 0.0225 
Train Epoch: 22 [756/816 (93%)] loss: 0.0311 L_si: 0.0066 L_grad: 0.0245 
Train Epoch: 22 [792/816 (97%)] loss: 0.0284 L_si: 0.0039 L_grad: 0.0245 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03538472577929497, 0.042131226509809494, 0.040596336126327515, 0.036817293614149094, 0.03741815313696861, 0.04141083359718323, 0.04058042913675308, 0.04095504432916641, 0.03762040287256241, 0.0404854416847229, 0.04022277891635895, 0.038535527884960175, 0.04009685665369034, 0.04043859615921974, 0.044286541640758514, 0.03962314873933792, 0.04171379655599594, 0.03499931842088699, 0.015701111406087875], 'L_si': [0.005735438317060471, 0.006883062422275543, 0.007536608725786209, 0.006727200001478195, 0.0067528896033763885, 0.0072198957204818726, 0.006740309298038483, 0.006300397217273712, 0.006707537919282913, 0.007701106369495392, 0.0063376761972904205, 0.006708644330501556, 0.007594086229801178, 0.007098626345396042, 0.006502270698547363, 0.006325636059045792, 0.006819203495979309, 0.0048912279307842255, 0.007849708199501038], 'L_grad': [0.029649287462234497, 0.03524816408753395, 0.033059727400541306, 0.0300900936126709, 0.030665263533592224, 0.034190937876701355, 0.0338401198387146, 0.0346546471118927, 0.030912866815924644, 0.03278433531522751, 0.03388510271906853, 0.03182688355445862, 0.03250277042388916, 0.0333399698138237, 0.03778427094221115, 0.03329751268029213, 0.03489459306001663, 0.030108092352747917, 0.007851404137909412]}
Train Epoch: 23 [0/816 (0%)] loss: 0.0315 L_si: 0.0057 L_grad: 0.0259 
Train Epoch: 23 [36/816 (4%)] loss: 0.0373 L_si: 0.0111 L_grad: 0.0262 
Train Epoch: 23 [72/816 (9%)] loss: 0.0290 L_si: 0.0063 L_grad: 0.0227 
Train Epoch: 23 [108/816 (13%)] loss: 0.0295 L_si: 0.0044 L_grad: 0.0251 
Train Epoch: 23 [144/816 (18%)] loss: 0.0275 L_si: 0.0031 L_grad: 0.0244 
Train Epoch: 23 [180/816 (22%)] loss: 0.0189 L_si: 0.0020 L_grad: 0.0169 
Train Epoch: 23 [216/816 (26%)] loss: 0.0266 L_si: 0.0038 L_grad: 0.0228 
Train Epoch: 23 [252/816 (31%)] loss: 0.0294 L_si: 0.0045 L_grad: 0.0249 
Train Epoch: 23 [288/816 (35%)] loss: 0.0268 L_si: 0.0033 L_grad: 0.0235 
Train Epoch: 23 [324/816 (40%)] loss: 0.0282 L_si: 0.0039 L_grad: 0.0243 
Train Epoch: 23 [360/816 (44%)] loss: 0.0234 L_si: 0.0022 L_grad: 0.0212 
Train Epoch: 23 [396/816 (49%)] loss: 0.0246 L_si: 0.0038 L_grad: 0.0207 
Train Epoch: 23 [432/816 (53%)] loss: 0.0310 L_si: 0.0084 L_grad: 0.0227 
Train Epoch: 23 [468/816 (57%)] loss: 0.0297 L_si: 0.0051 L_grad: 0.0246 
Train Epoch: 23 [504/816 (62%)] loss: 0.0358 L_si: 0.0056 L_grad: 0.0302 
Train Epoch: 23 [540/816 (66%)] loss: 0.0262 L_si: 0.0046 L_grad: 0.0217 
Train Epoch: 23 [576/816 (71%)] loss: 0.0306 L_si: 0.0089 L_grad: 0.0218 
Train Epoch: 23 [612/816 (75%)] loss: 0.0258 L_si: 0.0033 L_grad: 0.0225 
Train Epoch: 23 [648/816 (79%)] loss: 0.0296 L_si: 0.0043 L_grad: 0.0253 
Train Epoch: 23 [684/816 (84%)] loss: 0.0378 L_si: 0.0079 L_grad: 0.0299 
Train Epoch: 23 [720/816 (88%)] loss: 0.0259 L_si: 0.0030 L_grad: 0.0229 
Train Epoch: 23 [756/816 (93%)] loss: 0.0298 L_si: 0.0040 L_grad: 0.0258 
Train Epoch: 23 [792/816 (97%)] loss: 0.0296 L_si: 0.0067 L_grad: 0.0229 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040195681154727936, 0.03730396926403046, 0.04264713451266289, 0.043248165398836136, 0.03737889230251312, 0.040855616331100464, 0.04222453385591507, 0.04144524782896042, 0.04270227253437042, 0.03848010674118996, 0.040151435881853104, 0.04135634005069733, 0.038793887943029404, 0.04079940915107727, 0.04348001256585121, 0.04003777354955673, 0.04198205843567848, 0.04163460433483124, 0.013402857817709446], 'L_si': [0.007932901382446289, 0.006499260663986206, 0.008495066314935684, 0.009088627994060516, 0.007445484399795532, 0.008459120988845825, 0.009402424097061157, 0.007892180234193802, 0.008474335074424744, 0.007001746445894241, 0.00755646824836731, 0.008329078555107117, 0.006846468895673752, 0.007803134620189667, 0.009045135229825974, 0.008226718753576279, 0.00735154002904892, 0.008190002292394638, 0.005399934947490692], 'L_grad': [0.03226277977228165, 0.0308047104626894, 0.0341520681977272, 0.03415953740477562, 0.02993340604007244, 0.03239649534225464, 0.03282210975885391, 0.03355306759476662, 0.03422793745994568, 0.031478360295295715, 0.032594967633485794, 0.03302726149559021, 0.03194741904735565, 0.032996274530887604, 0.03443487733602524, 0.031811054795980453, 0.03463051840662956, 0.0334446020424366, 0.008002922870218754]}
Train Epoch: 24 [0/816 (0%)] loss: 0.0286 L_si: 0.0057 L_grad: 0.0229 
Train Epoch: 24 [36/816 (4%)] loss: 0.0241 L_si: 0.0024 L_grad: 0.0217 
Train Epoch: 24 [72/816 (9%)] loss: 0.0214 L_si: 0.0017 L_grad: 0.0198 
Train Epoch: 24 [108/816 (13%)] loss: 0.0303 L_si: 0.0047 L_grad: 0.0256 
Train Epoch: 24 [144/816 (18%)] loss: 0.0246 L_si: 0.0028 L_grad: 0.0217 
Train Epoch: 24 [180/816 (22%)] loss: 0.0372 L_si: 0.0112 L_grad: 0.0260 
Train Epoch: 24 [216/816 (26%)] loss: 0.0230 L_si: 0.0021 L_grad: 0.0209 
Train Epoch: 24 [252/816 (31%)] loss: 0.0392 L_si: 0.0085 L_grad: 0.0307 
Train Epoch: 24 [288/816 (35%)] loss: 0.0278 L_si: 0.0037 L_grad: 0.0241 
Train Epoch: 24 [324/816 (40%)] loss: 0.0288 L_si: 0.0046 L_grad: 0.0242 
Train Epoch: 24 [360/816 (44%)] loss: 0.0534 L_si: 0.0172 L_grad: 0.0362 
Train Epoch: 24 [396/816 (49%)] loss: 0.0249 L_si: 0.0039 L_grad: 0.0209 
Train Epoch: 24 [432/816 (53%)] loss: 0.0254 L_si: 0.0025 L_grad: 0.0229 
Train Epoch: 24 [468/816 (57%)] loss: 0.0345 L_si: 0.0129 L_grad: 0.0216 
Train Epoch: 24 [504/816 (62%)] loss: 0.0263 L_si: 0.0025 L_grad: 0.0238 
Train Epoch: 24 [540/816 (66%)] loss: 0.0269 L_si: 0.0033 L_grad: 0.0236 
Train Epoch: 24 [576/816 (71%)] loss: 0.0322 L_si: 0.0068 L_grad: 0.0253 
Train Epoch: 24 [612/816 (75%)] loss: 0.0319 L_si: 0.0064 L_grad: 0.0255 
Train Epoch: 24 [648/816 (79%)] loss: 0.0296 L_si: 0.0077 L_grad: 0.0219 
Train Epoch: 24 [684/816 (84%)] loss: 0.0358 L_si: 0.0097 L_grad: 0.0261 
Train Epoch: 24 [720/816 (88%)] loss: 0.0360 L_si: 0.0060 L_grad: 0.0300 
Train Epoch: 24 [756/816 (93%)] loss: 0.0360 L_si: 0.0071 L_grad: 0.0288 
Train Epoch: 24 [792/816 (97%)] loss: 0.0282 L_si: 0.0050 L_grad: 0.0232 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.039739057421684265, 0.03888819366693497, 0.038799360394477844, 0.0352790504693985, 0.038757603615522385, 0.04154511168599129, 0.04386833310127258, 0.03943122923374176, 0.04091690853238106, 0.037235356867313385, 0.037233613431453705, 0.036703549325466156, 0.03873968869447708, 0.039695218205451965, 0.03551669418811798, 0.038167815655469894, 0.03810552507638931, 0.038688577711582184, 0.013544522225856781], 'L_si': [0.007969602942466736, 0.007998265326023102, 0.007281795144081116, 0.006414193660020828, 0.0075009651482105255, 0.008037902414798737, 0.007916070520877838, 0.0073789432644844055, 0.008593380451202393, 0.007179662585258484, 0.005894854664802551, 0.006225839257240295, 0.007668726146221161, 0.00784873217344284, 0.006485778838396072, 0.007680762559175491, 0.007376376539468765, 0.007952645421028137, 0.006233397871255875], 'L_grad': [0.03176945447921753, 0.030889928340911865, 0.03151756525039673, 0.02886485680937767, 0.03125663846731186, 0.03350720927119255, 0.035952262580394745, 0.032052285969257355, 0.032323528081178665, 0.03005569614470005, 0.031338758766651154, 0.03047771006822586, 0.03107096254825592, 0.031846486032009125, 0.02903091534972191, 0.030487053096294403, 0.030729146674275398, 0.030735932290554047, 0.007311124820262194]}
Train Epoch: 25 [0/816 (0%)] loss: 0.0245 L_si: 0.0053 L_grad: 0.0192 
Train Epoch: 25 [36/816 (4%)] loss: 0.0279 L_si: 0.0043 L_grad: 0.0236 
Train Epoch: 25 [72/816 (9%)] loss: 0.0367 L_si: 0.0101 L_grad: 0.0266 
Train Epoch: 25 [108/816 (13%)] loss: 0.0289 L_si: 0.0047 L_grad: 0.0242 
Train Epoch: 25 [144/816 (18%)] loss: 0.0281 L_si: 0.0051 L_grad: 0.0230 
Train Epoch: 25 [180/816 (22%)] loss: 0.0310 L_si: 0.0046 L_grad: 0.0263 
Train Epoch: 25 [216/816 (26%)] loss: 0.0289 L_si: 0.0052 L_grad: 0.0238 
Train Epoch: 25 [252/816 (31%)] loss: 0.0286 L_si: 0.0045 L_grad: 0.0241 
Train Epoch: 25 [288/816 (35%)] loss: 0.0310 L_si: 0.0052 L_grad: 0.0258 
Train Epoch: 25 [324/816 (40%)] loss: 0.0315 L_si: 0.0069 L_grad: 0.0246 
Train Epoch: 25 [360/816 (44%)] loss: 0.0294 L_si: 0.0042 L_grad: 0.0252 
Train Epoch: 25 [396/816 (49%)] loss: 0.0399 L_si: 0.0093 L_grad: 0.0305 
Train Epoch: 25 [432/816 (53%)] loss: 0.0372 L_si: 0.0073 L_grad: 0.0300 
Train Epoch: 25 [468/816 (57%)] loss: 0.0316 L_si: 0.0062 L_grad: 0.0254 
Train Epoch: 25 [504/816 (62%)] loss: 0.0240 L_si: 0.0035 L_grad: 0.0206 
Train Epoch: 25 [540/816 (66%)] loss: 0.0367 L_si: 0.0097 L_grad: 0.0269 
Train Epoch: 25 [576/816 (71%)] loss: 0.0273 L_si: 0.0046 L_grad: 0.0226 
Train Epoch: 25 [612/816 (75%)] loss: 0.0227 L_si: 0.0029 L_grad: 0.0198 
Train Epoch: 25 [648/816 (79%)] loss: 0.0219 L_si: 0.0021 L_grad: 0.0198 
Train Epoch: 25 [684/816 (84%)] loss: 0.0264 L_si: 0.0037 L_grad: 0.0227 
Train Epoch: 25 [720/816 (88%)] loss: 0.0227 L_si: 0.0026 L_grad: 0.0201 
Train Epoch: 25 [756/816 (93%)] loss: 0.0356 L_si: 0.0056 L_grad: 0.0300 
Train Epoch: 25 [792/816 (97%)] loss: 0.0368 L_si: 0.0065 L_grad: 0.0302 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.0405593141913414, 0.03884309157729149, 0.040888674557209015, 0.043034762144088745, 0.036891575902700424, 0.040238261222839355, 0.036625225096940994, 0.035439275205135345, 0.039646491408348083, 0.03876829892396927, 0.038012776523828506, 0.04222038388252258, 0.04004065319895744, 0.03747324272990227, 0.03506162762641907, 0.03834846615791321, 0.0394042506814003, 0.040670245885849, 0.013597728684544563], 'L_si': [0.00789613276720047, 0.006690762937068939, 0.006927363574504852, 0.007538504898548126, 0.006354324519634247, 0.006752960383892059, 0.006548844277858734, 0.005771234631538391, 0.007664956152439117, 0.007368817925453186, 0.007370032370090485, 0.008500762283802032, 0.007111839950084686, 0.007279444485902786, 0.006259642541408539, 0.0074779316782951355, 0.005764476954936981, 0.007542140781879425, 0.00640508159995079], 'L_grad': [0.03266318142414093, 0.03215232864022255, 0.03396131098270416, 0.03549625724554062, 0.030537251383066177, 0.033485300838947296, 0.03007638081908226, 0.029668042436242104, 0.031981535255908966, 0.03139948099851608, 0.030642744153738022, 0.03371962159872055, 0.03292881324887276, 0.03019379824399948, 0.02880198322236538, 0.030870534479618073, 0.03363977372646332, 0.033128105103969574, 0.007192647084593773]}
Train Epoch: 26 [0/816 (0%)] loss: 0.0221 L_si: 0.0024 L_grad: 0.0197 
Train Epoch: 26 [36/816 (4%)] loss: 0.0327 L_si: 0.0106 L_grad: 0.0221 
Train Epoch: 26 [72/816 (9%)] loss: 0.0304 L_si: 0.0049 L_grad: 0.0255 
Train Epoch: 26 [108/816 (13%)] loss: 0.0323 L_si: 0.0080 L_grad: 0.0242 
Train Epoch: 26 [144/816 (18%)] loss: 0.0296 L_si: 0.0043 L_grad: 0.0253 
Train Epoch: 26 [180/816 (22%)] loss: 0.0290 L_si: 0.0053 L_grad: 0.0236 
Train Epoch: 26 [216/816 (26%)] loss: 0.0307 L_si: 0.0042 L_grad: 0.0265 
Train Epoch: 26 [252/816 (31%)] loss: 0.0376 L_si: 0.0116 L_grad: 0.0260 
Train Epoch: 26 [288/816 (35%)] loss: 0.0260 L_si: 0.0035 L_grad: 0.0226 
Train Epoch: 26 [324/816 (40%)] loss: 0.0247 L_si: 0.0036 L_grad: 0.0212 
Train Epoch: 26 [360/816 (44%)] loss: 0.0231 L_si: 0.0034 L_grad: 0.0197 
Train Epoch: 26 [396/816 (49%)] loss: 0.0322 L_si: 0.0043 L_grad: 0.0278 
Train Epoch: 26 [432/816 (53%)] loss: 0.0245 L_si: 0.0032 L_grad: 0.0213 
Train Epoch: 26 [468/816 (57%)] loss: 0.0213 L_si: 0.0020 L_grad: 0.0193 
Train Epoch: 26 [504/816 (62%)] loss: 0.0258 L_si: 0.0036 L_grad: 0.0222 
Train Epoch: 26 [540/816 (66%)] loss: 0.0277 L_si: 0.0068 L_grad: 0.0210 
Train Epoch: 26 [576/816 (71%)] loss: 0.0355 L_si: 0.0071 L_grad: 0.0284 
Train Epoch: 26 [612/816 (75%)] loss: 0.0352 L_si: 0.0051 L_grad: 0.0301 
Train Epoch: 26 [648/816 (79%)] loss: 0.0272 L_si: 0.0044 L_grad: 0.0228 
Train Epoch: 26 [684/816 (84%)] loss: 0.0350 L_si: 0.0104 L_grad: 0.0246 
Train Epoch: 26 [720/816 (88%)] loss: 0.0264 L_si: 0.0048 L_grad: 0.0215 
Train Epoch: 26 [756/816 (93%)] loss: 0.0263 L_si: 0.0033 L_grad: 0.0231 
Train Epoch: 26 [792/816 (97%)] loss: 0.0339 L_si: 0.0061 L_grad: 0.0278 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040754880756139755, 0.03906276822090149, 0.038413576781749725, 0.03820805624127388, 0.039711855351924896, 0.03848353773355484, 0.041520245373249054, 0.037896156311035156, 0.03873547166585922, 0.039029281586408615, 0.03837455064058304, 0.03828154131770134, 0.03855198621749878, 0.04013858735561371, 0.037891119718551636, 0.04051575809717178, 0.03768961876630783, 0.043338142335414886, 0.012168330140411854], 'L_si': [0.007932696491479874, 0.007570721209049225, 0.0066022127866744995, 0.007103681564331055, 0.007010072469711304, 0.006956227123737335, 0.007613487541675568, 0.006841365247964859, 0.007575437426567078, 0.007531043142080307, 0.007144507020711899, 0.0075012072920799255, 0.007616158574819565, 0.007827229797840118, 0.007272545248270035, 0.007963232696056366, 0.007395632565021515, 0.008744493126869202, 0.0039195045828819275], 'L_grad': [0.03282218426465988, 0.031492047011852264, 0.031811363995075226, 0.031104374676942825, 0.03270178288221359, 0.031527310609817505, 0.033906757831573486, 0.031054791063070297, 0.031160036101937294, 0.03149823844432831, 0.03123004175722599, 0.030780334025621414, 0.030935825780034065, 0.03231135755777359, 0.0306185744702816, 0.03255252540111542, 0.030293986201286316, 0.034593649208545685, 0.008248825557529926]}
Train Epoch: 27 [0/816 (0%)] loss: 0.0299 L_si: 0.0063 L_grad: 0.0235 
Train Epoch: 27 [36/816 (4%)] loss: 0.0283 L_si: 0.0036 L_grad: 0.0247 
Train Epoch: 27 [72/816 (9%)] loss: 0.0211 L_si: 0.0025 L_grad: 0.0186 
Train Epoch: 27 [108/816 (13%)] loss: 0.0313 L_si: 0.0075 L_grad: 0.0238 
Train Epoch: 27 [144/816 (18%)] loss: 0.0269 L_si: 0.0045 L_grad: 0.0224 
Train Epoch: 27 [180/816 (22%)] loss: 0.0324 L_si: 0.0063 L_grad: 0.0261 
Train Epoch: 27 [216/816 (26%)] loss: 0.0285 L_si: 0.0047 L_grad: 0.0238 
Train Epoch: 27 [252/816 (31%)] loss: 0.0315 L_si: 0.0060 L_grad: 0.0255 
Train Epoch: 27 [288/816 (35%)] loss: 0.0336 L_si: 0.0057 L_grad: 0.0279 
Train Epoch: 27 [324/816 (40%)] loss: 0.0320 L_si: 0.0060 L_grad: 0.0259 
Train Epoch: 27 [360/816 (44%)] loss: 0.0316 L_si: 0.0044 L_grad: 0.0272 
Train Epoch: 27 [396/816 (49%)] loss: 0.0215 L_si: 0.0017 L_grad: 0.0198 
Train Epoch: 27 [432/816 (53%)] loss: 0.0249 L_si: 0.0026 L_grad: 0.0223 
Train Epoch: 27 [468/816 (57%)] loss: 0.0346 L_si: 0.0066 L_grad: 0.0280 
Train Epoch: 27 [504/816 (62%)] loss: 0.0251 L_si: 0.0029 L_grad: 0.0221 
Train Epoch: 27 [540/816 (66%)] loss: 0.0198 L_si: 0.0017 L_grad: 0.0181 
Train Epoch: 27 [576/816 (71%)] loss: 0.0244 L_si: 0.0023 L_grad: 0.0221 
Train Epoch: 27 [612/816 (75%)] loss: 0.0218 L_si: 0.0019 L_grad: 0.0199 
Train Epoch: 27 [648/816 (79%)] loss: 0.0311 L_si: 0.0072 L_grad: 0.0239 
Train Epoch: 27 [684/816 (84%)] loss: 0.0351 L_si: 0.0090 L_grad: 0.0262 
Train Epoch: 27 [720/816 (88%)] loss: 0.0273 L_si: 0.0042 L_grad: 0.0231 
Train Epoch: 27 [756/816 (93%)] loss: 0.0219 L_si: 0.0022 L_grad: 0.0197 
Train Epoch: 27 [792/816 (97%)] loss: 0.0229 L_si: 0.0024 L_grad: 0.0205 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04288949444890022, 0.04034588485956192, 0.04187687113881111, 0.04112653434276581, 0.03934842720627785, 0.04077262431383133, 0.03642294555902481, 0.03685862943530083, 0.03735848516225815, 0.03826747089624405, 0.04080675169825554, 0.0383690781891346, 0.0423605777323246, 0.04023416340351105, 0.04361747205257416, 0.03951159492135048, 0.03631577640771866, 0.04065127670764923, 0.014540791511535645], 'L_si': [0.008496664464473724, 0.006286658346652985, 0.0073649100959300995, 0.008660376071929932, 0.008022870868444443, 0.008413631469011307, 0.007153861224651337, 0.0071630217134952545, 0.007103513926267624, 0.007217533886432648, 0.0078117214143276215, 0.006597500294446945, 0.008240137249231339, 0.006622582674026489, 0.00816868245601654, 0.007505826652050018, 0.007166910916566849, 0.006936065852642059, 0.006274111568927765], 'L_grad': [0.0343928299844265, 0.034059226512908936, 0.03451196104288101, 0.032466158270835876, 0.031325556337833405, 0.03235899284482002, 0.029269084334373474, 0.029695607721805573, 0.030254971235990524, 0.03104993887245655, 0.03299503028392792, 0.03177157789468765, 0.03412044048309326, 0.03361158072948456, 0.03544878959655762, 0.03200576826930046, 0.02914886735379696, 0.03371521085500717, 0.00826667994260788]}
Train Epoch: 28 [0/816 (0%)] loss: 0.0290 L_si: 0.0085 L_grad: 0.0205 
Train Epoch: 28 [36/816 (4%)] loss: 0.0291 L_si: 0.0059 L_grad: 0.0232 
Train Epoch: 28 [72/816 (9%)] loss: 0.0230 L_si: 0.0024 L_grad: 0.0206 
Train Epoch: 28 [108/816 (13%)] loss: 0.0235 L_si: 0.0029 L_grad: 0.0206 
Train Epoch: 28 [144/816 (18%)] loss: 0.0295 L_si: 0.0043 L_grad: 0.0252 
Train Epoch: 28 [180/816 (22%)] loss: 0.0299 L_si: 0.0049 L_grad: 0.0250 
Train Epoch: 28 [216/816 (26%)] loss: 0.0299 L_si: 0.0079 L_grad: 0.0220 
Train Epoch: 28 [252/816 (31%)] loss: 0.0201 L_si: 0.0018 L_grad: 0.0184 
Train Epoch: 28 [288/816 (35%)] loss: 0.0345 L_si: 0.0091 L_grad: 0.0254 
Train Epoch: 28 [324/816 (40%)] loss: 0.0277 L_si: 0.0041 L_grad: 0.0236 
Train Epoch: 28 [360/816 (44%)] loss: 0.0256 L_si: 0.0028 L_grad: 0.0228 
Train Epoch: 28 [396/816 (49%)] loss: 0.0277 L_si: 0.0045 L_grad: 0.0232 
Train Epoch: 28 [432/816 (53%)] loss: 0.0208 L_si: 0.0016 L_grad: 0.0191 
Train Epoch: 28 [468/816 (57%)] loss: 0.0275 L_si: 0.0034 L_grad: 0.0241 
Train Epoch: 28 [504/816 (62%)] loss: 0.0346 L_si: 0.0098 L_grad: 0.0248 
Train Epoch: 28 [540/816 (66%)] loss: 0.0209 L_si: 0.0020 L_grad: 0.0189 
Train Epoch: 28 [576/816 (71%)] loss: 0.0211 L_si: 0.0020 L_grad: 0.0191 
Train Epoch: 28 [612/816 (75%)] loss: 0.0298 L_si: 0.0045 L_grad: 0.0252 
Train Epoch: 28 [648/816 (79%)] loss: 0.0330 L_si: 0.0072 L_grad: 0.0258 
Train Epoch: 28 [684/816 (84%)] loss: 0.0268 L_si: 0.0028 L_grad: 0.0240 
Train Epoch: 28 [720/816 (88%)] loss: 0.0360 L_si: 0.0076 L_grad: 0.0284 
Train Epoch: 28 [756/816 (93%)] loss: 0.0255 L_si: 0.0029 L_grad: 0.0226 
Train Epoch: 28 [792/816 (97%)] loss: 0.0262 L_si: 0.0031 L_grad: 0.0231 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03926990181207657, 0.04253765568137169, 0.042540136724710464, 0.03653402626514435, 0.0394202321767807, 0.04066073149442673, 0.037434324622154236, 0.03865763917565346, 0.03893356770277023, 0.042881179600954056, 0.038145922124385834, 0.03813211992383003, 0.04337663948535919, 0.03666245937347412, 0.03917430341243744, 0.037225376814603806, 0.0387067012488842, 0.039382051676511765, 0.016194533556699753], 'L_si': [0.0063783153891563416, 0.007712945342063904, 0.006409123539924622, 0.006661929190158844, 0.006345465779304504, 0.00693153589963913, 0.005617812275886536, 0.00698259100317955, 0.007469981908798218, 0.007300674915313721, 0.00733613595366478, 0.006861183792352676, 0.00791103020310402, 0.005770791321992874, 0.006758593022823334, 0.006317693740129471, 0.0065314024686813354, 0.005744416266679764, 0.008286632597446442], 'L_grad': [0.03289158642292023, 0.034824710339307785, 0.03613101318478584, 0.029872098937630653, 0.033074766397476196, 0.0337291955947876, 0.0318165123462677, 0.03167504817247391, 0.031463585793972015, 0.035580504685640335, 0.030809786170721054, 0.031270936131477356, 0.03546560928225517, 0.030891666188836098, 0.032415710389614105, 0.030907683074474335, 0.032175298780202866, 0.033637635409832, 0.007907901890575886]}
Train Epoch: 29 [0/816 (0%)] loss: 0.0215 L_si: 0.0028 L_grad: 0.0187 
Train Epoch: 29 [36/816 (4%)] loss: 0.0306 L_si: 0.0038 L_grad: 0.0268 
Train Epoch: 29 [72/816 (9%)] loss: 0.0228 L_si: 0.0027 L_grad: 0.0201 
Train Epoch: 29 [108/816 (13%)] loss: 0.0266 L_si: 0.0028 L_grad: 0.0238 
Train Epoch: 29 [144/816 (18%)] loss: 0.0289 L_si: 0.0051 L_grad: 0.0239 
Train Epoch: 29 [180/816 (22%)] loss: 0.0271 L_si: 0.0042 L_grad: 0.0229 
Train Epoch: 29 [216/816 (26%)] loss: 0.0304 L_si: 0.0045 L_grad: 0.0259 
Train Epoch: 29 [252/816 (31%)] loss: 0.0258 L_si: 0.0039 L_grad: 0.0219 
Train Epoch: 29 [288/816 (35%)] loss: 0.0238 L_si: 0.0037 L_grad: 0.0201 
Train Epoch: 29 [324/816 (40%)] loss: 0.0215 L_si: 0.0035 L_grad: 0.0180 
Train Epoch: 29 [360/816 (44%)] loss: 0.0236 L_si: 0.0028 L_grad: 0.0208 
Train Epoch: 29 [396/816 (49%)] loss: 0.0281 L_si: 0.0044 L_grad: 0.0236 
Train Epoch: 29 [432/816 (53%)] loss: 0.0217 L_si: 0.0027 L_grad: 0.0190 
Train Epoch: 29 [468/816 (57%)] loss: 0.0223 L_si: 0.0020 L_grad: 0.0203 
Train Epoch: 29 [504/816 (62%)] loss: 0.0242 L_si: 0.0031 L_grad: 0.0211 
Train Epoch: 29 [540/816 (66%)] loss: 0.0258 L_si: 0.0038 L_grad: 0.0220 
Train Epoch: 29 [576/816 (71%)] loss: 0.0257 L_si: 0.0033 L_grad: 0.0224 
Train Epoch: 29 [612/816 (75%)] loss: 0.0249 L_si: 0.0040 L_grad: 0.0210 
Train Epoch: 29 [648/816 (79%)] loss: 0.0311 L_si: 0.0092 L_grad: 0.0219 
Train Epoch: 29 [684/816 (84%)] loss: 0.0276 L_si: 0.0062 L_grad: 0.0214 
Train Epoch: 29 [720/816 (88%)] loss: 0.0344 L_si: 0.0077 L_grad: 0.0267 
Train Epoch: 29 [756/816 (93%)] loss: 0.0253 L_si: 0.0049 L_grad: 0.0204 
Train Epoch: 29 [792/816 (97%)] loss: 0.0259 L_si: 0.0036 L_grad: 0.0223 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040547989308834076, 0.03974204882979393, 0.0376988910138607, 0.03668763116002083, 0.04074792563915253, 0.03842411935329437, 0.040562551468610764, 0.03530847281217575, 0.037781983613967896, 0.038207411766052246, 0.03977375850081444, 0.03785950690507889, 0.03835621848702431, 0.037980400025844574, 0.04039778560400009, 0.04159481078386307, 0.04003045707941055, 0.03970523178577423, 0.012785999104380608], 'L_si': [0.008171848952770233, 0.00693608820438385, 0.007055200636386871, 0.007408883422613144, 0.007759109139442444, 0.008213844150304794, 0.008162416517734528, 0.0070434920489788055, 0.007615368813276291, 0.007447719573974609, 0.00776267796754837, 0.007639065384864807, 0.007919106632471085, 0.00707099586725235, 0.00863482803106308, 0.008090667426586151, 0.007625345140695572, 0.00817716121673584, 0.005769688636064529], 'L_grad': [0.03237614035606384, 0.03280596062541008, 0.03064369037747383, 0.029278747737407684, 0.03298881649971008, 0.030210275202989578, 0.032400134950876236, 0.028264978900551796, 0.030166612938046455, 0.030759692192077637, 0.03201108053326607, 0.03022044338285923, 0.030437111854553223, 0.030909404158592224, 0.03176295757293701, 0.033504143357276917, 0.03240511193871498, 0.03152807056903839, 0.0070163109339773655]}
Train Epoch: 30 [0/816 (0%)] loss: 0.0204 L_si: 0.0020 L_grad: 0.0184 
Train Epoch: 30 [36/816 (4%)] loss: 0.0198 L_si: 0.0022 L_grad: 0.0176 
Train Epoch: 30 [72/816 (9%)] loss: 0.0353 L_si: 0.0119 L_grad: 0.0234 
Train Epoch: 30 [108/816 (13%)] loss: 0.0182 L_si: 0.0011 L_grad: 0.0171 
Train Epoch: 30 [144/816 (18%)] loss: 0.0246 L_si: 0.0035 L_grad: 0.0211 
Train Epoch: 30 [180/816 (22%)] loss: 0.0236 L_si: 0.0031 L_grad: 0.0205 
Train Epoch: 30 [216/816 (26%)] loss: 0.0268 L_si: 0.0044 L_grad: 0.0224 
Train Epoch: 30 [252/816 (31%)] loss: 0.0281 L_si: 0.0063 L_grad: 0.0218 
Train Epoch: 30 [288/816 (35%)] loss: 0.0237 L_si: 0.0031 L_grad: 0.0206 
Train Epoch: 30 [324/816 (40%)] loss: 0.0296 L_si: 0.0050 L_grad: 0.0247 
Train Epoch: 30 [360/816 (44%)] loss: 0.0270 L_si: 0.0033 L_grad: 0.0237 
Train Epoch: 30 [396/816 (49%)] loss: 0.0326 L_si: 0.0100 L_grad: 0.0227 
Train Epoch: 30 [432/816 (53%)] loss: 0.0266 L_si: 0.0043 L_grad: 0.0223 
Train Epoch: 30 [468/816 (57%)] loss: 0.0236 L_si: 0.0030 L_grad: 0.0206 
Train Epoch: 30 [504/816 (62%)] loss: 0.0206 L_si: 0.0026 L_grad: 0.0179 
Train Epoch: 30 [540/816 (66%)] loss: 0.0238 L_si: 0.0030 L_grad: 0.0209 
Train Epoch: 30 [576/816 (71%)] loss: 0.0201 L_si: 0.0020 L_grad: 0.0181 
Train Epoch: 30 [612/816 (75%)] loss: 0.0225 L_si: 0.0031 L_grad: 0.0194 
Train Epoch: 30 [648/816 (79%)] loss: 0.0294 L_si: 0.0049 L_grad: 0.0246 
Train Epoch: 30 [684/816 (84%)] loss: 0.0236 L_si: 0.0031 L_grad: 0.0204 
Train Epoch: 30 [720/816 (88%)] loss: 0.0214 L_si: 0.0029 L_grad: 0.0185 
Train Epoch: 30 [756/816 (93%)] loss: 0.0172 L_si: 0.0010 L_grad: 0.0162 
Train Epoch: 30 [792/816 (97%)] loss: 0.0335 L_si: 0.0072 L_grad: 0.0262 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch030-loss-0.0272.pth.tar ...
all losses in batch in validation:  {'loss': [0.03473569452762604, 0.04199811443686485, 0.04019004851579666, 0.041174326092004776, 0.04089600220322609, 0.033795420080423355, 0.040303949266672134, 0.039790164679288864, 0.040874749422073364, 0.03961252048611641, 0.03642335534095764, 0.037882279604673386, 0.04009700566530228, 0.040422990918159485, 0.04015713185071945, 0.04012218117713928, 0.041384778916835785, 0.038261596113443375, 0.015860654413700104], 'L_si': [0.005839869379997253, 0.007942505180835724, 0.006926141679286957, 0.008270315825939178, 0.007688790559768677, 0.004106234759092331, 0.007040180265903473, 0.007863864302635193, 0.007813617587089539, 0.008015140891075134, 0.006900351494550705, 0.006958290934562683, 0.007436208426952362, 0.007858529686927795, 0.007935956120491028, 0.007949791848659515, 0.00819937139749527, 0.006785430014133453, 0.00699809193611145], 'L_grad': [0.028895823284983635, 0.03405560925602913, 0.033263906836509705, 0.0329040102660656, 0.03320721164345741, 0.029689185321331024, 0.03326376900076866, 0.03192630037665367, 0.033061131834983826, 0.031597379595041275, 0.029523005709052086, 0.030923988670110703, 0.032660797238349915, 0.03256446123123169, 0.032221175730228424, 0.03217238932847977, 0.033185407519340515, 0.03147616609930992, 0.008862562477588654]}
Train Epoch: 31 [0/816 (0%)] loss: 0.0178 L_si: 0.0013 L_grad: 0.0165 
Train Epoch: 31 [36/816 (4%)] loss: 0.0278 L_si: 0.0036 L_grad: 0.0242 
Train Epoch: 31 [72/816 (9%)] loss: 0.0236 L_si: 0.0029 L_grad: 0.0207 
Train Epoch: 31 [108/816 (13%)] loss: 0.0209 L_si: 0.0025 L_grad: 0.0185 
Train Epoch: 31 [144/816 (18%)] loss: 0.0264 L_si: 0.0050 L_grad: 0.0214 
Train Epoch: 31 [180/816 (22%)] loss: 0.0265 L_si: 0.0025 L_grad: 0.0240 
Train Epoch: 31 [216/816 (26%)] loss: 0.0267 L_si: 0.0041 L_grad: 0.0226 
Train Epoch: 31 [252/816 (31%)] loss: 0.0224 L_si: 0.0021 L_grad: 0.0203 
Train Epoch: 31 [288/816 (35%)] loss: 0.0351 L_si: 0.0071 L_grad: 0.0279 
Train Epoch: 31 [324/816 (40%)] loss: 0.0372 L_si: 0.0098 L_grad: 0.0274 
Train Epoch: 31 [360/816 (44%)] loss: 0.0262 L_si: 0.0042 L_grad: 0.0220 
Train Epoch: 31 [396/816 (49%)] loss: 0.0263 L_si: 0.0043 L_grad: 0.0220 
Train Epoch: 31 [432/816 (53%)] loss: 0.0213 L_si: 0.0030 L_grad: 0.0183 
Train Epoch: 31 [468/816 (57%)] loss: 0.0236 L_si: 0.0029 L_grad: 0.0206 
Train Epoch: 31 [504/816 (62%)] loss: 0.0235 L_si: 0.0042 L_grad: 0.0193 
Train Epoch: 31 [540/816 (66%)] loss: 0.0278 L_si: 0.0049 L_grad: 0.0230 
Train Epoch: 31 [576/816 (71%)] loss: 0.0254 L_si: 0.0040 L_grad: 0.0215 
Train Epoch: 31 [612/816 (75%)] loss: 0.0236 L_si: 0.0033 L_grad: 0.0203 
Train Epoch: 31 [648/816 (79%)] loss: 0.0301 L_si: 0.0063 L_grad: 0.0237 
Train Epoch: 31 [684/816 (84%)] loss: 0.0216 L_si: 0.0021 L_grad: 0.0195 
Train Epoch: 31 [720/816 (88%)] loss: 0.0416 L_si: 0.0071 L_grad: 0.0346 
Train Epoch: 31 [756/816 (93%)] loss: 0.0261 L_si: 0.0047 L_grad: 0.0214 
Train Epoch: 31 [792/816 (97%)] loss: 0.0279 L_si: 0.0043 L_grad: 0.0236 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.041886840015649796, 0.03942680358886719, 0.04726563021540642, 0.04082819074392319, 0.03757483884692192, 0.042106661945581436, 0.04468736797571182, 0.04243340343236923, 0.04052262008190155, 0.037787239998579025, 0.0392460934817791, 0.045790813863277435, 0.038918446749448776, 0.03906712681055069, 0.043633684515953064, 0.045470234006643295, 0.03819681704044342, 0.03980981558561325, 0.012868834659457207], 'L_si': [0.007576771080493927, 0.006892703473567963, 0.007684096693992615, 0.007521733641624451, 0.0063880980014801025, 0.008250050246715546, 0.00783199816942215, 0.007936529815196991, 0.007060788571834564, 0.0072145238518714905, 0.007803015410900116, 0.00821898877620697, 0.006509773433208466, 0.007233358919620514, 0.008725285530090332, 0.009040206670761108, 0.007344700396060944, 0.006230711936950684, 0.005472056567668915], 'L_grad': [0.03431006893515587, 0.032534100115299225, 0.0395815335214138, 0.03330645710229874, 0.031186740845441818, 0.03385661169886589, 0.03685536980628967, 0.03449687361717224, 0.033461831510066986, 0.030572716146707535, 0.03144307807087898, 0.037571825087070465, 0.03240867331624031, 0.031833767890930176, 0.03490839898586273, 0.03643002733588219, 0.030852118507027626, 0.03357910364866257, 0.007396778091788292]}
Train Epoch: 32 [0/816 (0%)] loss: 0.0312 L_si: 0.0040 L_grad: 0.0272 
Train Epoch: 32 [36/816 (4%)] loss: 0.0291 L_si: 0.0043 L_grad: 0.0247 
Train Epoch: 32 [72/816 (9%)] loss: 0.0252 L_si: 0.0043 L_grad: 0.0210 
Train Epoch: 32 [108/816 (13%)] loss: 0.0235 L_si: 0.0026 L_grad: 0.0209 
Train Epoch: 32 [144/816 (18%)] loss: 0.0205 L_si: 0.0018 L_grad: 0.0187 
Train Epoch: 32 [180/816 (22%)] loss: 0.0236 L_si: 0.0037 L_grad: 0.0199 
Train Epoch: 32 [216/816 (26%)] loss: 0.0294 L_si: 0.0066 L_grad: 0.0227 
Train Epoch: 32 [252/816 (31%)] loss: 0.0266 L_si: 0.0040 L_grad: 0.0227 
Train Epoch: 32 [288/816 (35%)] loss: 0.0262 L_si: 0.0044 L_grad: 0.0218 
Train Epoch: 32 [324/816 (40%)] loss: 0.0216 L_si: 0.0027 L_grad: 0.0189 
Train Epoch: 32 [360/816 (44%)] loss: 0.0271 L_si: 0.0035 L_grad: 0.0236 
Train Epoch: 32 [396/816 (49%)] loss: 0.0218 L_si: 0.0022 L_grad: 0.0197 
Train Epoch: 32 [432/816 (53%)] loss: 0.0233 L_si: 0.0032 L_grad: 0.0201 
Train Epoch: 32 [468/816 (57%)] loss: 0.0290 L_si: 0.0035 L_grad: 0.0254 
Train Epoch: 32 [504/816 (62%)] loss: 0.0226 L_si: 0.0028 L_grad: 0.0198 
Train Epoch: 32 [540/816 (66%)] loss: 0.0351 L_si: 0.0068 L_grad: 0.0283 
Train Epoch: 32 [576/816 (71%)] loss: 0.0284 L_si: 0.0046 L_grad: 0.0238 
Train Epoch: 32 [612/816 (75%)] loss: 0.0214 L_si: 0.0018 L_grad: 0.0197 
Train Epoch: 32 [648/816 (79%)] loss: 0.0272 L_si: 0.0026 L_grad: 0.0245 
Train Epoch: 32 [684/816 (84%)] loss: 0.0286 L_si: 0.0072 L_grad: 0.0215 
Train Epoch: 32 [720/816 (88%)] loss: 0.0230 L_si: 0.0019 L_grad: 0.0211 
Train Epoch: 32 [756/816 (93%)] loss: 0.0343 L_si: 0.0084 L_grad: 0.0258 
Train Epoch: 32 [792/816 (97%)] loss: 0.0283 L_si: 0.0040 L_grad: 0.0243 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.042641907930374146, 0.04328925535082817, 0.044965047389268875, 0.042026087641716, 0.04464473947882652, 0.03647005185484886, 0.04357876628637314, 0.03838488459587097, 0.047875791788101196, 0.041814155876636505, 0.041560687124729156, 0.04225870966911316, 0.04208126664161682, 0.03970782086253166, 0.04292796552181244, 0.044604089111089706, 0.045669298619031906, 0.040713198482990265, 0.013234979473054409], 'L_si': [0.008951783180236816, 0.007992073893547058, 0.008265413343906403, 0.008827589452266693, 0.010089792311191559, 0.006015770137310028, 0.00792643427848816, 0.007312733680009842, 0.009374238550662994, 0.008455835282802582, 0.007186446338891983, 0.007988803088665009, 0.00794321671128273, 0.0069603100419044495, 0.0085296630859375, 0.008461333811283112, 0.009112507104873657, 0.007345769554376602, 0.005889322608709335], 'L_grad': [0.03369012475013733, 0.03529718145728111, 0.03669963404536247, 0.03319849818944931, 0.034554947167634964, 0.030454281717538834, 0.03565233200788498, 0.03107215277850628, 0.0385015532374382, 0.03335832059383392, 0.03437424078583717, 0.03426990658044815, 0.03413804993033409, 0.03274751082062721, 0.03439830243587494, 0.036142755299806595, 0.03655679151415825, 0.03336742892861366, 0.007345656864345074]}
Train Epoch: 33 [0/816 (0%)] loss: 0.0241 L_si: 0.0038 L_grad: 0.0204 
Train Epoch: 33 [36/816 (4%)] loss: 0.0164 L_si: 0.0009 L_grad: 0.0154 
Train Epoch: 33 [72/816 (9%)] loss: 0.0242 L_si: 0.0023 L_grad: 0.0219 
Train Epoch: 33 [108/816 (13%)] loss: 0.0247 L_si: 0.0027 L_grad: 0.0221 
Train Epoch: 33 [144/816 (18%)] loss: 0.0208 L_si: 0.0022 L_grad: 0.0186 
Train Epoch: 33 [180/816 (22%)] loss: 0.0264 L_si: 0.0047 L_grad: 0.0217 
Train Epoch: 33 [216/816 (26%)] loss: 0.0294 L_si: 0.0046 L_grad: 0.0249 
Train Epoch: 33 [252/816 (31%)] loss: 0.0264 L_si: 0.0036 L_grad: 0.0228 
Train Epoch: 33 [288/816 (35%)] loss: 0.0237 L_si: 0.0025 L_grad: 0.0212 
Train Epoch: 33 [324/816 (40%)] loss: 0.0361 L_si: 0.0069 L_grad: 0.0292 
Train Epoch: 33 [360/816 (44%)] loss: 0.0344 L_si: 0.0088 L_grad: 0.0256 
Train Epoch: 33 [396/816 (49%)] loss: 0.0205 L_si: 0.0022 L_grad: 0.0183 
Train Epoch: 33 [432/816 (53%)] loss: 0.0278 L_si: 0.0031 L_grad: 0.0246 
Train Epoch: 33 [468/816 (57%)] loss: 0.0249 L_si: 0.0036 L_grad: 0.0213 
Train Epoch: 33 [504/816 (62%)] loss: 0.0229 L_si: 0.0029 L_grad: 0.0201 
Train Epoch: 33 [540/816 (66%)] loss: 0.0269 L_si: 0.0048 L_grad: 0.0221 
Train Epoch: 33 [576/816 (71%)] loss: 0.0245 L_si: 0.0031 L_grad: 0.0214 
Train Epoch: 33 [612/816 (75%)] loss: 0.0291 L_si: 0.0071 L_grad: 0.0221 
Train Epoch: 33 [648/816 (79%)] loss: 0.0242 L_si: 0.0024 L_grad: 0.0218 
Train Epoch: 33 [684/816 (84%)] loss: 0.0226 L_si: 0.0021 L_grad: 0.0205 
Train Epoch: 33 [720/816 (88%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0162 
Train Epoch: 33 [756/816 (93%)] loss: 0.0269 L_si: 0.0048 L_grad: 0.0220 
Train Epoch: 33 [792/816 (97%)] loss: 0.0282 L_si: 0.0045 L_grad: 0.0237 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04098426178097725, 0.040876466780900955, 0.0410115011036396, 0.039965108036994934, 0.040396567434072495, 0.04133398085832596, 0.04239377751946449, 0.041786935180425644, 0.040872495621442795, 0.03557258099317551, 0.03627551719546318, 0.040842775255441666, 0.04392997920513153, 0.04061906039714813, 0.04461975395679474, 0.040813397616147995, 0.036278415471315384, 0.04250840097665787, 0.01667698472738266], 'L_si': [0.008834999054670334, 0.008584100753068924, 0.007913917303085327, 0.008526958525180817, 0.007470853626728058, 0.007297046482563019, 0.008100271224975586, 0.008761446923017502, 0.008698888123035431, 0.0071152374148368835, 0.008106037974357605, 0.009622689336538315, 0.009640082716941833, 0.008464492857456207, 0.00855032354593277, 0.008116774260997772, 0.0072602443397045135, 0.00879332423210144, 0.006761014461517334], 'L_grad': [0.032149262726306915, 0.03229236602783203, 0.033097583800554276, 0.03143814951181412, 0.03292571380734444, 0.03403693437576294, 0.03429350629448891, 0.03302548825740814, 0.032173607498407364, 0.028457343578338623, 0.028169479221105576, 0.03122008591890335, 0.0342898964881897, 0.032154567539691925, 0.03606943041086197, 0.03269662335515022, 0.02901817113161087, 0.03371507674455643, 0.0099159711971879]}
Train Epoch: 34 [0/816 (0%)] loss: 0.0300 L_si: 0.0050 L_grad: 0.0251 
Train Epoch: 34 [36/816 (4%)] loss: 0.0202 L_si: 0.0025 L_grad: 0.0176 
Train Epoch: 34 [72/816 (9%)] loss: 0.0211 L_si: 0.0034 L_grad: 0.0177 
Train Epoch: 34 [108/816 (13%)] loss: 0.0208 L_si: 0.0029 L_grad: 0.0179 
Train Epoch: 34 [144/816 (18%)] loss: 0.0292 L_si: 0.0041 L_grad: 0.0251 
Train Epoch: 34 [180/816 (22%)] loss: 0.0223 L_si: 0.0024 L_grad: 0.0200 
Train Epoch: 34 [216/816 (26%)] loss: 0.0227 L_si: 0.0027 L_grad: 0.0199 
Train Epoch: 34 [252/816 (31%)] loss: 0.0243 L_si: 0.0026 L_grad: 0.0217 
Train Epoch: 34 [288/816 (35%)] loss: 0.0362 L_si: 0.0083 L_grad: 0.0280 
Train Epoch: 34 [324/816 (40%)] loss: 0.0258 L_si: 0.0036 L_grad: 0.0222 
Train Epoch: 34 [360/816 (44%)] loss: 0.0260 L_si: 0.0049 L_grad: 0.0211 
Train Epoch: 34 [396/816 (49%)] loss: 0.0249 L_si: 0.0033 L_grad: 0.0216 
Train Epoch: 34 [432/816 (53%)] loss: 0.0310 L_si: 0.0072 L_grad: 0.0238 
Train Epoch: 34 [468/816 (57%)] loss: 0.0222 L_si: 0.0031 L_grad: 0.0191 
Train Epoch: 34 [504/816 (62%)] loss: 0.0280 L_si: 0.0047 L_grad: 0.0234 
Train Epoch: 34 [540/816 (66%)] loss: 0.0244 L_si: 0.0042 L_grad: 0.0202 
Train Epoch: 34 [576/816 (71%)] loss: 0.0223 L_si: 0.0029 L_grad: 0.0194 
Train Epoch: 34 [612/816 (75%)] loss: 0.0239 L_si: 0.0035 L_grad: 0.0204 
Train Epoch: 34 [648/816 (79%)] loss: 0.0247 L_si: 0.0035 L_grad: 0.0212 
Train Epoch: 34 [684/816 (84%)] loss: 0.0278 L_si: 0.0057 L_grad: 0.0220 
Train Epoch: 34 [720/816 (88%)] loss: 0.0268 L_si: 0.0039 L_grad: 0.0228 
Train Epoch: 34 [756/816 (93%)] loss: 0.0308 L_si: 0.0068 L_grad: 0.0240 
Train Epoch: 34 [792/816 (97%)] loss: 0.0284 L_si: 0.0043 L_grad: 0.0241 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04160896688699722, 0.038727808743715286, 0.0418364517390728, 0.03852582722902298, 0.039444632828235626, 0.04185304045677185, 0.036063142120838165, 0.04241503030061722, 0.03641815856099129, 0.04303023964166641, 0.040824044495821, 0.03785458207130432, 0.04073445498943329, 0.034555524587631226, 0.03685931861400604, 0.04247959330677986, 0.042456310242414474, 0.0402311235666275, 0.007553014904260635], 'L_si': [0.008261065930128098, 0.006885197013616562, 0.008401364088058472, 0.007408946752548218, 0.006088949739933014, 0.008876398205757141, 0.006035666912794113, 0.007220469415187836, 0.006216343492269516, 0.007011003792285919, 0.008130565285682678, 0.00640416145324707, 0.008281797170639038, 0.004906546324491501, 0.007921084761619568, 0.007801562547683716, 0.006885945796966553, 0.00828273594379425, 0.001338168978691101], 'L_grad': [0.033347900956869125, 0.031842611730098724, 0.03343508765101433, 0.03111688233911991, 0.03335568308830261, 0.03297664225101471, 0.0300274770706892, 0.03519456088542938, 0.03020181506872177, 0.03601923584938049, 0.03269347921013832, 0.03145042061805725, 0.03245265781879425, 0.029648978263139725, 0.028938231989741325, 0.034678030759096146, 0.03557036444544792, 0.03194838762283325, 0.006214845925569534]}
Train Epoch: 35 [0/816 (0%)] loss: 0.0248 L_si: 0.0024 L_grad: 0.0224 
Train Epoch: 35 [36/816 (4%)] loss: 0.0301 L_si: 0.0036 L_grad: 0.0265 
Train Epoch: 35 [72/816 (9%)] loss: 0.0302 L_si: 0.0069 L_grad: 0.0232 
Train Epoch: 35 [108/816 (13%)] loss: 0.0215 L_si: 0.0018 L_grad: 0.0196 
Train Epoch: 35 [144/816 (18%)] loss: 0.0289 L_si: 0.0032 L_grad: 0.0257 
Train Epoch: 35 [180/816 (22%)] loss: 0.0213 L_si: 0.0019 L_grad: 0.0193 
Train Epoch: 35 [216/816 (26%)] loss: 0.0467 L_si: 0.0148 L_grad: 0.0318 
Train Epoch: 35 [252/816 (31%)] loss: 0.0332 L_si: 0.0103 L_grad: 0.0230 
Train Epoch: 35 [288/816 (35%)] loss: 0.0188 L_si: 0.0013 L_grad: 0.0175 
Train Epoch: 35 [324/816 (40%)] loss: 0.0319 L_si: 0.0054 L_grad: 0.0265 
Train Epoch: 35 [360/816 (44%)] loss: 0.0274 L_si: 0.0040 L_grad: 0.0235 
Train Epoch: 35 [396/816 (49%)] loss: 0.0302 L_si: 0.0042 L_grad: 0.0259 
Train Epoch: 35 [432/816 (53%)] loss: 0.0258 L_si: 0.0032 L_grad: 0.0226 
Train Epoch: 35 [468/816 (57%)] loss: 0.0267 L_si: 0.0040 L_grad: 0.0227 
Train Epoch: 35 [504/816 (62%)] loss: 0.0339 L_si: 0.0095 L_grad: 0.0244 
Train Epoch: 35 [540/816 (66%)] loss: 0.0216 L_si: 0.0020 L_grad: 0.0197 
Train Epoch: 35 [576/816 (71%)] loss: 0.0223 L_si: 0.0025 L_grad: 0.0197 
Train Epoch: 35 [612/816 (75%)] loss: 0.0209 L_si: 0.0021 L_grad: 0.0188 
Train Epoch: 35 [648/816 (79%)] loss: 0.0364 L_si: 0.0121 L_grad: 0.0243 
Train Epoch: 35 [684/816 (84%)] loss: 0.0279 L_si: 0.0036 L_grad: 0.0243 
Train Epoch: 35 [720/816 (88%)] loss: 0.0177 L_si: 0.0013 L_grad: 0.0165 
Train Epoch: 35 [756/816 (93%)] loss: 0.0195 L_si: 0.0012 L_grad: 0.0183 
Train Epoch: 35 [792/816 (97%)] loss: 0.0272 L_si: 0.0043 L_grad: 0.0229 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04039914906024933, 0.04045335203409195, 0.03781551122665405, 0.04109186679124832, 0.03702981024980545, 0.037266455590724945, 0.04187854006886482, 0.03848549723625183, 0.0399174690246582, 0.03421854227781296, 0.0434611551463604, 0.03868011757731438, 0.040461406111717224, 0.037695273756980896, 0.03772637993097305, 0.038870155811309814, 0.041869960725307465, 0.0437895841896534, 0.012381947599351406], 'L_si': [0.00670449435710907, 0.007000349462032318, 0.007439643144607544, 0.006418056786060333, 0.006758049130439758, 0.006648294627666473, 0.0074746981263160706, 0.007202260196208954, 0.0067012980580329895, 0.005595080554485321, 0.007747739553451538, 0.007022440433502197, 0.007177658379077911, 0.007036574184894562, 0.006855178624391556, 0.006641559302806854, 0.00730346143245697, 0.007754489779472351, 0.005535397678613663], 'L_grad': [0.03369465470314026, 0.03345300257205963, 0.03037586808204651, 0.03467381000518799, 0.030271761119365692, 0.03061816282570362, 0.03440384194254875, 0.03128323704004288, 0.033216170966625214, 0.028623463585972786, 0.03571341559290886, 0.03165767714381218, 0.03328374773263931, 0.030658699572086334, 0.030871203169226646, 0.03222859650850296, 0.034566499292850494, 0.036035094410181046, 0.006846549920737743]}
Train Epoch: 36 [0/816 (0%)] loss: 0.0208 L_si: 0.0017 L_grad: 0.0191 
Train Epoch: 36 [36/816 (4%)] loss: 0.0264 L_si: 0.0036 L_grad: 0.0228 
Train Epoch: 36 [72/816 (9%)] loss: 0.0182 L_si: 0.0014 L_grad: 0.0168 
Train Epoch: 36 [108/816 (13%)] loss: 0.0204 L_si: 0.0012 L_grad: 0.0191 
Train Epoch: 36 [144/816 (18%)] loss: 0.0229 L_si: 0.0029 L_grad: 0.0200 
Train Epoch: 36 [180/816 (22%)] loss: 0.0243 L_si: 0.0041 L_grad: 0.0202 
Train Epoch: 36 [216/816 (26%)] loss: 0.0252 L_si: 0.0045 L_grad: 0.0207 
Train Epoch: 36 [252/816 (31%)] loss: 0.0180 L_si: 0.0017 L_grad: 0.0163 
Train Epoch: 36 [288/816 (35%)] loss: 0.0219 L_si: 0.0024 L_grad: 0.0195 
Train Epoch: 36 [324/816 (40%)] loss: 0.0198 L_si: 0.0018 L_grad: 0.0180 
Train Epoch: 36 [360/816 (44%)] loss: 0.0261 L_si: 0.0049 L_grad: 0.0212 
Train Epoch: 36 [396/816 (49%)] loss: 0.0158 L_si: 0.0009 L_grad: 0.0149 
Train Epoch: 36 [432/816 (53%)] loss: 0.0314 L_si: 0.0051 L_grad: 0.0263 
Train Epoch: 36 [468/816 (57%)] loss: 0.0329 L_si: 0.0067 L_grad: 0.0262 
Train Epoch: 36 [504/816 (62%)] loss: 0.0280 L_si: 0.0042 L_grad: 0.0237 
Train Epoch: 36 [540/816 (66%)] loss: 0.0244 L_si: 0.0035 L_grad: 0.0209 
Train Epoch: 36 [576/816 (71%)] loss: 0.0185 L_si: 0.0017 L_grad: 0.0168 
Train Epoch: 36 [612/816 (75%)] loss: 0.0238 L_si: 0.0039 L_grad: 0.0199 
Train Epoch: 36 [648/816 (79%)] loss: 0.0296 L_si: 0.0066 L_grad: 0.0230 
Train Epoch: 36 [684/816 (84%)] loss: 0.0288 L_si: 0.0046 L_grad: 0.0242 
Train Epoch: 36 [720/816 (88%)] loss: 0.0266 L_si: 0.0033 L_grad: 0.0234 
Train Epoch: 36 [756/816 (93%)] loss: 0.0235 L_si: 0.0030 L_grad: 0.0205 
Train Epoch: 36 [792/816 (97%)] loss: 0.0221 L_si: 0.0029 L_grad: 0.0192 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04051084443926811, 0.03923627361655235, 0.03844621777534485, 0.03867320716381073, 0.04434049129486084, 0.04789263755083084, 0.042898960411548615, 0.04139355570077896, 0.044326938688755035, 0.04774032533168793, 0.04370168223977089, 0.04266221448779106, 0.038383737206459045, 0.04249662905931473, 0.0414699949324131, 0.04246480017900467, 0.03921349719166756, 0.0388646274805069, 0.017746560275554657], 'L_si': [0.008984684944152832, 0.008547008037567139, 0.007961288094520569, 0.00853806734085083, 0.007865481078624725, 0.010313548147678375, 0.007181376218795776, 0.008830927312374115, 0.008123330771923065, 0.01075723022222519, 0.01056748628616333, 0.009724251925945282, 0.008157424628734589, 0.008891604840755463, 0.008403755724430084, 0.00871044397354126, 0.008704990148544312, 0.008290775120258331, 0.007671378552913666], 'L_grad': [0.03152615949511528, 0.030689265578985214, 0.03048492968082428, 0.0301351398229599, 0.036475010216236115, 0.037579089403152466, 0.03571758419275284, 0.032562628388404846, 0.03620360791683197, 0.03698309510946274, 0.03313419595360756, 0.03293796256184578, 0.030226310715079308, 0.033605024218559265, 0.03306623920798302, 0.03375435620546341, 0.030508507043123245, 0.030573850497603416, 0.010075181722640991]}
Train Epoch: 37 [0/816 (0%)] loss: 0.0205 L_si: 0.0016 L_grad: 0.0189 
Train Epoch: 37 [36/816 (4%)] loss: 0.0247 L_si: 0.0028 L_grad: 0.0219 
Train Epoch: 37 [72/816 (9%)] loss: 0.0197 L_si: 0.0022 L_grad: 0.0175 
Train Epoch: 37 [108/816 (13%)] loss: 0.0270 L_si: 0.0051 L_grad: 0.0219 
Train Epoch: 37 [144/816 (18%)] loss: 0.0183 L_si: 0.0013 L_grad: 0.0170 
Train Epoch: 37 [180/816 (22%)] loss: 0.0197 L_si: 0.0015 L_grad: 0.0182 
Train Epoch: 37 [216/816 (26%)] loss: 0.0218 L_si: 0.0018 L_grad: 0.0199 
Train Epoch: 37 [252/816 (31%)] loss: 0.0360 L_si: 0.0056 L_grad: 0.0304 
Train Epoch: 37 [288/816 (35%)] loss: 0.0262 L_si: 0.0052 L_grad: 0.0210 
Train Epoch: 37 [324/816 (40%)] loss: 0.0226 L_si: 0.0028 L_grad: 0.0198 
Train Epoch: 37 [360/816 (44%)] loss: 0.0221 L_si: 0.0026 L_grad: 0.0195 
Train Epoch: 37 [396/816 (49%)] loss: 0.0246 L_si: 0.0024 L_grad: 0.0222 
Train Epoch: 37 [432/816 (53%)] loss: 0.0259 L_si: 0.0032 L_grad: 0.0227 
Train Epoch: 37 [468/816 (57%)] loss: 0.0307 L_si: 0.0071 L_grad: 0.0237 
Train Epoch: 37 [504/816 (62%)] loss: 0.0209 L_si: 0.0031 L_grad: 0.0178 
Train Epoch: 37 [540/816 (66%)] loss: 0.0268 L_si: 0.0048 L_grad: 0.0220 
Train Epoch: 37 [576/816 (71%)] loss: 0.0285 L_si: 0.0043 L_grad: 0.0242 
Train Epoch: 37 [612/816 (75%)] loss: 0.0242 L_si: 0.0028 L_grad: 0.0214 
Train Epoch: 37 [648/816 (79%)] loss: 0.0324 L_si: 0.0063 L_grad: 0.0261 
Train Epoch: 37 [684/816 (84%)] loss: 0.0227 L_si: 0.0028 L_grad: 0.0199 
Train Epoch: 37 [720/816 (88%)] loss: 0.0197 L_si: 0.0025 L_grad: 0.0172 
Train Epoch: 37 [756/816 (93%)] loss: 0.0247 L_si: 0.0033 L_grad: 0.0214 
Train Epoch: 37 [792/816 (97%)] loss: 0.0316 L_si: 0.0057 L_grad: 0.0259 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04411891847848892, 0.03949045389890671, 0.039942845702171326, 0.04008661210536957, 0.03975510597229004, 0.04037163779139519, 0.03915245458483696, 0.04168231040239334, 0.04180985316634178, 0.03932395204901695, 0.039395082741975784, 0.04019688814878464, 0.03312334418296814, 0.0366489440202713, 0.043419238179922104, 0.03877715766429901, 0.03893472999334335, 0.03965171426534653, 0.015825849026441574], 'L_si': [0.00884537398815155, 0.008343279361724854, 0.008407361805438995, 0.008033685386180878, 0.0077500492334365845, 0.008154593408107758, 0.007455132901668549, 0.00770694762468338, 0.008612699806690216, 0.008147157728672028, 0.007345303893089294, 0.00832066684961319, 0.0055817365646362305, 0.007488958537578583, 0.00892549753189087, 0.0074413493275642395, 0.008328549563884735, 0.009018070995807648, 0.008502021431922913], 'L_grad': [0.03527354449033737, 0.031147176399827003, 0.03153548389673233, 0.03205292671918869, 0.032005056738853455, 0.03221704438328743, 0.03169732168316841, 0.03397536277770996, 0.033197153359651566, 0.031176794320344925, 0.03204977884888649, 0.03187622129917145, 0.02754160948097706, 0.02915998362004757, 0.034493740648031235, 0.03133580833673477, 0.030606180429458618, 0.03063364140689373, 0.007323827128857374]}
Train Epoch: 38 [0/816 (0%)] loss: 0.0239 L_si: 0.0030 L_grad: 0.0209 
Train Epoch: 38 [36/816 (4%)] loss: 0.0319 L_si: 0.0057 L_grad: 0.0262 
Train Epoch: 38 [72/816 (9%)] loss: 0.0321 L_si: 0.0094 L_grad: 0.0227 
Train Epoch: 38 [108/816 (13%)] loss: 0.0241 L_si: 0.0035 L_grad: 0.0206 
Train Epoch: 38 [144/816 (18%)] loss: 0.0184 L_si: 0.0014 L_grad: 0.0170 
Train Epoch: 38 [180/816 (22%)] loss: 0.0260 L_si: 0.0029 L_grad: 0.0231 
Train Epoch: 38 [216/816 (26%)] loss: 0.0316 L_si: 0.0051 L_grad: 0.0265 
Train Epoch: 38 [252/816 (31%)] loss: 0.0188 L_si: 0.0018 L_grad: 0.0169 
Train Epoch: 38 [288/816 (35%)] loss: 0.0218 L_si: 0.0029 L_grad: 0.0189 
Train Epoch: 38 [324/816 (40%)] loss: 0.0206 L_si: 0.0019 L_grad: 0.0186 
Train Epoch: 38 [360/816 (44%)] loss: 0.0261 L_si: 0.0027 L_grad: 0.0234 
Train Epoch: 38 [396/816 (49%)] loss: 0.0243 L_si: 0.0033 L_grad: 0.0210 
Train Epoch: 38 [432/816 (53%)] loss: 0.0253 L_si: 0.0029 L_grad: 0.0224 
Train Epoch: 38 [468/816 (57%)] loss: 0.0193 L_si: 0.0017 L_grad: 0.0176 
Train Epoch: 38 [504/816 (62%)] loss: 0.0263 L_si: 0.0041 L_grad: 0.0223 
Train Epoch: 38 [540/816 (66%)] loss: 0.0266 L_si: 0.0036 L_grad: 0.0230 
Train Epoch: 38 [576/816 (71%)] loss: 0.0339 L_si: 0.0111 L_grad: 0.0227 
Train Epoch: 38 [612/816 (75%)] loss: 0.0311 L_si: 0.0067 L_grad: 0.0244 
Train Epoch: 38 [648/816 (79%)] loss: 0.0217 L_si: 0.0027 L_grad: 0.0189 
Train Epoch: 38 [684/816 (84%)] loss: 0.0236 L_si: 0.0036 L_grad: 0.0200 
Train Epoch: 38 [720/816 (88%)] loss: 0.0234 L_si: 0.0038 L_grad: 0.0196 
Train Epoch: 38 [756/816 (93%)] loss: 0.0238 L_si: 0.0037 L_grad: 0.0201 
Train Epoch: 38 [792/816 (97%)] loss: 0.0279 L_si: 0.0041 L_grad: 0.0239 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03563708811998367, 0.04351828992366791, 0.03821141645312309, 0.038058262318372726, 0.03613150492310524, 0.037757985293865204, 0.034363918006420135, 0.037134986370801926, 0.03446170315146446, 0.04519001394510269, 0.03913513571023941, 0.03916589543223381, 0.0447370745241642, 0.03755170851945877, 0.03943995013833046, 0.04339417442679405, 0.04002547264099121, 0.03728761523962021, 0.01429198682308197], 'L_si': [0.006009873002767563, 0.008077725768089294, 0.007204510271549225, 0.006946355104446411, 0.0057639479637146, 0.007122494280338287, 0.006134461611509323, 0.006435565650463104, 0.006376560777425766, 0.00805596262216568, 0.006531611084938049, 0.00738108903169632, 0.009219974279403687, 0.007428012788295746, 0.006958764046430588, 0.007997371256351471, 0.0075054168701171875, 0.0062254928052425385, 0.005083434283733368], 'L_grad': [0.02962721511721611, 0.03544056415557861, 0.031006906181573868, 0.031111907213926315, 0.03036755695939064, 0.030635492876172066, 0.028229456394910812, 0.03069942072033882, 0.028085142374038696, 0.03713405132293701, 0.03260352462530136, 0.03178480640053749, 0.03551710024476051, 0.030123695731163025, 0.03248118609189987, 0.03539680317044258, 0.03252005577087402, 0.03106212057173252, 0.009208552539348602]}
Train Epoch: 39 [0/816 (0%)] loss: 0.0452 L_si: 0.0173 L_grad: 0.0279 
Train Epoch: 39 [36/816 (4%)] loss: 0.0275 L_si: 0.0039 L_grad: 0.0236 
Train Epoch: 39 [72/816 (9%)] loss: 0.0229 L_si: 0.0029 L_grad: 0.0199 
Train Epoch: 39 [108/816 (13%)] loss: 0.0336 L_si: 0.0085 L_grad: 0.0251 
Train Epoch: 39 [144/816 (18%)] loss: 0.0236 L_si: 0.0034 L_grad: 0.0202 
Train Epoch: 39 [180/816 (22%)] loss: 0.0188 L_si: 0.0014 L_grad: 0.0175 
Train Epoch: 39 [216/816 (26%)] loss: 0.0255 L_si: 0.0031 L_grad: 0.0224 
Train Epoch: 39 [252/816 (31%)] loss: 0.0255 L_si: 0.0032 L_grad: 0.0222 
Train Epoch: 39 [288/816 (35%)] loss: 0.0316 L_si: 0.0056 L_grad: 0.0260 
Train Epoch: 39 [324/816 (40%)] loss: 0.0223 L_si: 0.0020 L_grad: 0.0203 
Train Epoch: 39 [360/816 (44%)] loss: 0.0226 L_si: 0.0020 L_grad: 0.0207 
Train Epoch: 39 [396/816 (49%)] loss: 0.0275 L_si: 0.0052 L_grad: 0.0223 
Train Epoch: 39 [432/816 (53%)] loss: 0.0270 L_si: 0.0028 L_grad: 0.0243 
Train Epoch: 39 [468/816 (57%)] loss: 0.0270 L_si: 0.0070 L_grad: 0.0200 
Train Epoch: 39 [504/816 (62%)] loss: 0.0159 L_si: 0.0010 L_grad: 0.0149 
Train Epoch: 39 [540/816 (66%)] loss: 0.0300 L_si: 0.0053 L_grad: 0.0247 
Train Epoch: 39 [576/816 (71%)] loss: 0.0222 L_si: 0.0028 L_grad: 0.0194 
Train Epoch: 39 [612/816 (75%)] loss: 0.0182 L_si: 0.0013 L_grad: 0.0168 
Train Epoch: 39 [648/816 (79%)] loss: 0.0177 L_si: 0.0019 L_grad: 0.0159 
Train Epoch: 39 [684/816 (84%)] loss: 0.0222 L_si: 0.0025 L_grad: 0.0197 
Train Epoch: 39 [720/816 (88%)] loss: 0.0296 L_si: 0.0055 L_grad: 0.0241 
Train Epoch: 39 [756/816 (93%)] loss: 0.0234 L_si: 0.0050 L_grad: 0.0183 
Train Epoch: 39 [792/816 (97%)] loss: 0.0211 L_si: 0.0018 L_grad: 0.0193 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.030961740761995316, 0.03677000850439072, 0.04457908868789673, 0.04030195251107216, 0.03575712442398071, 0.03058774210512638, 0.04398465156555176, 0.03707641363143921, 0.03914155811071396, 0.03528352826833725, 0.038497429341077805, 0.03703995794057846, 0.03926485776901245, 0.03487524390220642, 0.03656693920493126, 0.04144666716456413, 0.03315582871437073, 0.04106852412223816, 0.015921518206596375], 'L_si': [0.004500597715377808, 0.006437808275222778, 0.00805819034576416, 0.007112771272659302, 0.005397055298089981, 0.0034338049590587616, 0.0071882084012031555, 0.0060033053159713745, 0.006333358585834503, 0.005856998264789581, 0.006001189351081848, 0.006083101034164429, 0.006133899092674255, 0.005920629948377609, 0.006011880934238434, 0.006851494312286377, 0.004893254488706589, 0.006918027997016907, 0.006038092076778412], 'L_grad': [0.026461143046617508, 0.030332202091813087, 0.03652089834213257, 0.03318918123841286, 0.030360069125890732, 0.02715393714606762, 0.0367964431643486, 0.031073110178112984, 0.032808199524879456, 0.02942653000354767, 0.032496239989995956, 0.030956855043768883, 0.033130958676338196, 0.02895461395382881, 0.030555058270692825, 0.034595172852277756, 0.02826257422566414, 0.03415049612522125, 0.009883426129817963]}
Train Epoch: 40 [0/816 (0%)] loss: 0.0242 L_si: 0.0030 L_grad: 0.0212 
Train Epoch: 40 [36/816 (4%)] loss: 0.0249 L_si: 0.0047 L_grad: 0.0201 
Train Epoch: 40 [72/816 (9%)] loss: 0.0250 L_si: 0.0034 L_grad: 0.0216 
Train Epoch: 40 [108/816 (13%)] loss: 0.0236 L_si: 0.0027 L_grad: 0.0209 
Train Epoch: 40 [144/816 (18%)] loss: 0.0339 L_si: 0.0059 L_grad: 0.0281 
Train Epoch: 40 [180/816 (22%)] loss: 0.0198 L_si: 0.0022 L_grad: 0.0176 
Train Epoch: 40 [216/816 (26%)] loss: 0.0286 L_si: 0.0066 L_grad: 0.0220 
Train Epoch: 40 [252/816 (31%)] loss: 0.0186 L_si: 0.0013 L_grad: 0.0173 
Train Epoch: 40 [288/816 (35%)] loss: 0.0257 L_si: 0.0039 L_grad: 0.0218 
Train Epoch: 40 [324/816 (40%)] loss: 0.0299 L_si: 0.0045 L_grad: 0.0254 
Train Epoch: 40 [360/816 (44%)] loss: 0.0298 L_si: 0.0041 L_grad: 0.0257 
Train Epoch: 40 [396/816 (49%)] loss: 0.0177 L_si: 0.0013 L_grad: 0.0164 
Train Epoch: 40 [432/816 (53%)] loss: 0.0280 L_si: 0.0046 L_grad: 0.0234 
Train Epoch: 40 [468/816 (57%)] loss: 0.0278 L_si: 0.0062 L_grad: 0.0216 
Train Epoch: 40 [504/816 (62%)] loss: 0.0311 L_si: 0.0051 L_grad: 0.0260 
Train Epoch: 40 [540/816 (66%)] loss: 0.0293 L_si: 0.0088 L_grad: 0.0205 
Train Epoch: 40 [576/816 (71%)] loss: 0.0229 L_si: 0.0032 L_grad: 0.0196 
Train Epoch: 40 [612/816 (75%)] loss: 0.0215 L_si: 0.0023 L_grad: 0.0193 
Train Epoch: 40 [648/816 (79%)] loss: 0.0259 L_si: 0.0033 L_grad: 0.0226 
Train Epoch: 40 [684/816 (84%)] loss: 0.0317 L_si: 0.0044 L_grad: 0.0273 
Train Epoch: 40 [720/816 (88%)] loss: 0.0219 L_si: 0.0050 L_grad: 0.0170 
Train Epoch: 40 [756/816 (93%)] loss: 0.0233 L_si: 0.0024 L_grad: 0.0209 
Train Epoch: 40 [792/816 (97%)] loss: 0.0217 L_si: 0.0020 L_grad: 0.0197 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch040-loss-0.0248.pth.tar ...
all losses in batch in validation:  {'loss': [0.037596650421619415, 0.03876015543937683, 0.03547656908631325, 0.035306401550769806, 0.03523140773177147, 0.036039456725120544, 0.038832634687423706, 0.03695926442742348, 0.03835562989115715, 0.03938422352075577, 0.039577461779117584, 0.040089063346385956, 0.033415574580430984, 0.034800149500370026, 0.036193810403347015, 0.03835545480251312, 0.03925503045320511, 0.03655633702874184, 0.014046610333025455], 'L_si': [0.007644727826118469, 0.0074881911277771, 0.00648561492562294, 0.005331024527549744, 0.005960971117019653, 0.006105430424213409, 0.006189785897731781, 0.005990065634250641, 0.006266295909881592, 0.0067197903990745544, 0.007086209952831268, 0.006139390170574188, 0.005576007068157196, 0.005184352397918701, 0.006147198379039764, 0.006629198789596558, 0.005676575005054474, 0.0057930126786231995, 0.006422117352485657], 'L_grad': [0.029951924458146095, 0.03127196431159973, 0.028990954160690308, 0.02997537888586521, 0.029270436614751816, 0.029934026300907135, 0.032642848789691925, 0.030969198793172836, 0.03208933398127556, 0.03266443312168121, 0.032491251826286316, 0.03394967317581177, 0.02783956751227379, 0.029615797102451324, 0.03004661202430725, 0.031726256012916565, 0.033578455448150635, 0.030763324350118637, 0.007624492980539799]}
Train Epoch: 41 [0/816 (0%)] loss: 0.0240 L_si: 0.0032 L_grad: 0.0209 
Train Epoch: 41 [36/816 (4%)] loss: 0.0282 L_si: 0.0040 L_grad: 0.0242 
Train Epoch: 41 [72/816 (9%)] loss: 0.0308 L_si: 0.0051 L_grad: 0.0257 
Train Epoch: 41 [108/816 (13%)] loss: 0.0247 L_si: 0.0040 L_grad: 0.0207 
Train Epoch: 41 [144/816 (18%)] loss: 0.0303 L_si: 0.0053 L_grad: 0.0250 
Train Epoch: 41 [180/816 (22%)] loss: 0.0151 L_si: 0.0011 L_grad: 0.0140 
Train Epoch: 41 [216/816 (26%)] loss: 0.0235 L_si: 0.0033 L_grad: 0.0202 
Train Epoch: 41 [252/816 (31%)] loss: 0.0271 L_si: 0.0039 L_grad: 0.0232 
Train Epoch: 41 [288/816 (35%)] loss: 0.0257 L_si: 0.0028 L_grad: 0.0228 
Train Epoch: 41 [324/816 (40%)] loss: 0.0205 L_si: 0.0021 L_grad: 0.0185 
Train Epoch: 41 [360/816 (44%)] loss: 0.0264 L_si: 0.0058 L_grad: 0.0206 
Train Epoch: 41 [396/816 (49%)] loss: 0.0205 L_si: 0.0015 L_grad: 0.0190 
Train Epoch: 41 [432/816 (53%)] loss: 0.0251 L_si: 0.0036 L_grad: 0.0214 
Train Epoch: 41 [468/816 (57%)] loss: 0.0273 L_si: 0.0030 L_grad: 0.0243 
Train Epoch: 41 [504/816 (62%)] loss: 0.0188 L_si: 0.0012 L_grad: 0.0177 
Train Epoch: 41 [540/816 (66%)] loss: 0.0246 L_si: 0.0029 L_grad: 0.0216 
Train Epoch: 41 [576/816 (71%)] loss: 0.0256 L_si: 0.0040 L_grad: 0.0217 
Train Epoch: 41 [612/816 (75%)] loss: 0.0346 L_si: 0.0072 L_grad: 0.0273 
Train Epoch: 41 [648/816 (79%)] loss: 0.0238 L_si: 0.0052 L_grad: 0.0186 
Train Epoch: 41 [684/816 (84%)] loss: 0.0233 L_si: 0.0023 L_grad: 0.0211 
Train Epoch: 41 [720/816 (88%)] loss: 0.0186 L_si: 0.0014 L_grad: 0.0172 
Train Epoch: 41 [756/816 (93%)] loss: 0.0228 L_si: 0.0040 L_grad: 0.0188 
Train Epoch: 41 [792/816 (97%)] loss: 0.0223 L_si: 0.0022 L_grad: 0.0201 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.034354861825704575, 0.03594234585762024, 0.03851799666881561, 0.034034568816423416, 0.034459058195352554, 0.03488187491893768, 0.03696940839290619, 0.03871360793709755, 0.043139584362506866, 0.042816512286663055, 0.03617515414953232, 0.03637653961777687, 0.041747063398361206, 0.04211754724383354, 0.039478760212659836, 0.036212753504514694, 0.030654145404696465, 0.03936770558357239, 0.019556457176804543], 'L_si': [0.006039988249540329, 0.005675815045833588, 0.005989722907543182, 0.005111202597618103, 0.005335614085197449, 0.005654837936162949, 0.005892351269721985, 0.006717868149280548, 0.006958127021789551, 0.006393000483512878, 0.005262382328510284, 0.006102677434682846, 0.006270915269851685, 0.007168784737586975, 0.006525963544845581, 0.005375094711780548, 0.003895781934261322, 0.00648016482591629, 0.009917248040437698], 'L_grad': [0.028314873576164246, 0.030266528949141502, 0.03252827376127243, 0.028923366218805313, 0.029123444110155106, 0.029227036982774734, 0.031077057123184204, 0.031995739787817, 0.036181457340717316, 0.03642351180315018, 0.030912771821022034, 0.030273862183094025, 0.03547614812850952, 0.03494876250624657, 0.032952796667814255, 0.030837658792734146, 0.026758363470435143, 0.0328875407576561, 0.009639209136366844]}
Train Epoch: 42 [0/816 (0%)] loss: 0.0315 L_si: 0.0070 L_grad: 0.0244 
Train Epoch: 42 [36/816 (4%)] loss: 0.0232 L_si: 0.0034 L_grad: 0.0198 
Train Epoch: 42 [72/816 (9%)] loss: 0.0205 L_si: 0.0018 L_grad: 0.0188 
Train Epoch: 42 [108/816 (13%)] loss: 0.0379 L_si: 0.0118 L_grad: 0.0261 
Train Epoch: 42 [144/816 (18%)] loss: 0.0244 L_si: 0.0032 L_grad: 0.0211 
Train Epoch: 42 [180/816 (22%)] loss: 0.0160 L_si: 0.0014 L_grad: 0.0146 
Train Epoch: 42 [216/816 (26%)] loss: 0.0356 L_si: 0.0062 L_grad: 0.0294 
Train Epoch: 42 [252/816 (31%)] loss: 0.0270 L_si: 0.0038 L_grad: 0.0231 
Train Epoch: 42 [288/816 (35%)] loss: 0.0292 L_si: 0.0051 L_grad: 0.0242 
Train Epoch: 42 [324/816 (40%)] loss: 0.0171 L_si: 0.0015 L_grad: 0.0156 
Train Epoch: 42 [360/816 (44%)] loss: 0.0276 L_si: 0.0062 L_grad: 0.0213 
Train Epoch: 42 [396/816 (49%)] loss: 0.0246 L_si: 0.0029 L_grad: 0.0217 
Train Epoch: 42 [432/816 (53%)] loss: 0.0288 L_si: 0.0071 L_grad: 0.0217 
Train Epoch: 42 [468/816 (57%)] loss: 0.0222 L_si: 0.0032 L_grad: 0.0190 
Train Epoch: 42 [504/816 (62%)] loss: 0.0463 L_si: 0.0146 L_grad: 0.0317 
Train Epoch: 42 [540/816 (66%)] loss: 0.0227 L_si: 0.0022 L_grad: 0.0205 
Train Epoch: 42 [576/816 (71%)] loss: 0.0257 L_si: 0.0036 L_grad: 0.0222 
Train Epoch: 42 [612/816 (75%)] loss: 0.0332 L_si: 0.0043 L_grad: 0.0289 
Train Epoch: 42 [648/816 (79%)] loss: 0.0229 L_si: 0.0029 L_grad: 0.0200 
Train Epoch: 42 [684/816 (84%)] loss: 0.0267 L_si: 0.0050 L_grad: 0.0217 
Train Epoch: 42 [720/816 (88%)] loss: 0.0303 L_si: 0.0047 L_grad: 0.0256 
Train Epoch: 42 [756/816 (93%)] loss: 0.0193 L_si: 0.0027 L_grad: 0.0166 
Train Epoch: 42 [792/816 (97%)] loss: 0.0178 L_si: 0.0025 L_grad: 0.0153 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.04329198598861694, 0.037525225430727005, 0.03581527993083, 0.03611276298761368, 0.037185221910476685, 0.03457089886069298, 0.03403172269463539, 0.03556801751255989, 0.039615873247385025, 0.0361269973218441, 0.03734706714749336, 0.03802768141031265, 0.03808888792991638, 0.036679498851299286, 0.036524854600429535, 0.036922357976436615, 0.039526358246803284, 0.035615868866443634, 0.012144490145146847], 'L_si': [0.007885165512561798, 0.006844736635684967, 0.006014958024024963, 0.005723729729652405, 0.006882034242153168, 0.005249049514532089, 0.005446668714284897, 0.00586237758398056, 0.006085988134145737, 0.0060445889830589294, 0.006802648305892944, 0.006375454366207123, 0.007304184138774872, 0.006660059094429016, 0.007021471858024597, 0.0056521594524383545, 0.007030166685581207, 0.006514884531497955, 0.004939280450344086], 'L_grad': [0.035406820476055145, 0.030680488795042038, 0.02980032190680504, 0.030389033257961273, 0.030303189530968666, 0.02932184934616089, 0.028585053980350494, 0.02970563992857933, 0.03352988511323929, 0.03008240833878517, 0.030544418841600418, 0.03165222704410553, 0.03078470192849636, 0.03001944161951542, 0.029503384605050087, 0.03127019852399826, 0.032496191561222076, 0.02910098433494568, 0.007205209694802761]}
Train Epoch: 43 [0/816 (0%)] loss: 0.0265 L_si: 0.0043 L_grad: 0.0223 
Train Epoch: 43 [36/816 (4%)] loss: 0.0235 L_si: 0.0030 L_grad: 0.0205 
Train Epoch: 43 [72/816 (9%)] loss: 0.0229 L_si: 0.0021 L_grad: 0.0207 
Train Epoch: 43 [108/816 (13%)] loss: 0.0205 L_si: 0.0017 L_grad: 0.0189 
Train Epoch: 43 [144/816 (18%)] loss: 0.0213 L_si: 0.0021 L_grad: 0.0192 
Train Epoch: 43 [180/816 (22%)] loss: 0.0273 L_si: 0.0042 L_grad: 0.0231 
Train Epoch: 43 [216/816 (26%)] loss: 0.0341 L_si: 0.0056 L_grad: 0.0284 
Train Epoch: 43 [252/816 (31%)] loss: 0.0309 L_si: 0.0062 L_grad: 0.0247 
Train Epoch: 43 [288/816 (35%)] loss: 0.0181 L_si: 0.0017 L_grad: 0.0164 
Train Epoch: 43 [324/816 (40%)] loss: 0.0262 L_si: 0.0042 L_grad: 0.0220 
Train Epoch: 43 [360/816 (44%)] loss: 0.0256 L_si: 0.0043 L_grad: 0.0213 
Train Epoch: 43 [396/816 (49%)] loss: 0.0195 L_si: 0.0016 L_grad: 0.0179 
Train Epoch: 43 [432/816 (53%)] loss: 0.0209 L_si: 0.0024 L_grad: 0.0185 
Train Epoch: 43 [468/816 (57%)] loss: 0.0303 L_si: 0.0061 L_grad: 0.0242 
Train Epoch: 43 [504/816 (62%)] loss: 0.0330 L_si: 0.0076 L_grad: 0.0255 
Train Epoch: 43 [540/816 (66%)] loss: 0.0302 L_si: 0.0051 L_grad: 0.0252 
Train Epoch: 43 [576/816 (71%)] loss: 0.0238 L_si: 0.0028 L_grad: 0.0210 
Train Epoch: 43 [612/816 (75%)] loss: 0.0276 L_si: 0.0045 L_grad: 0.0231 
Train Epoch: 43 [648/816 (79%)] loss: 0.0241 L_si: 0.0026 L_grad: 0.0215 
Train Epoch: 43 [684/816 (84%)] loss: 0.0267 L_si: 0.0039 L_grad: 0.0229 
Train Epoch: 43 [720/816 (88%)] loss: 0.0176 L_si: 0.0015 L_grad: 0.0161 
Train Epoch: 43 [756/816 (93%)] loss: 0.0228 L_si: 0.0031 L_grad: 0.0197 
Train Epoch: 43 [792/816 (97%)] loss: 0.0220 L_si: 0.0027 L_grad: 0.0193 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03826585412025452, 0.038827672600746155, 0.0416501984000206, 0.03527781367301941, 0.03815702348947525, 0.039560429751873016, 0.04363643378019333, 0.03908003121614456, 0.03817889466881752, 0.043673187494277954, 0.03578760102391243, 0.0412411168217659, 0.03684106841683388, 0.032145947217941284, 0.04084053635597229, 0.03949640691280365, 0.03538758307695389, 0.04016629606485367, 0.013851221650838852], 'L_si': [0.006335042417049408, 0.007595933973789215, 0.007309086620807648, 0.005343455821275711, 0.00656794011592865, 0.006794735789299011, 0.007497958838939667, 0.0070242807269096375, 0.006186969578266144, 0.006179474294185638, 0.005322374403476715, 0.007010370492935181, 0.006032422184944153, 0.004371490329504013, 0.006976895034313202, 0.006879366934299469, 0.005968362092971802, 0.007551565766334534, 0.006093017756938934], 'L_grad': [0.03193081170320511, 0.03123173676431179, 0.03434111177921295, 0.029934359714388847, 0.0315890833735466, 0.032765693962574005, 0.03613847494125366, 0.032055750489234924, 0.031991925090551376, 0.037493713200092316, 0.030465226620435715, 0.03423074632883072, 0.030808646231889725, 0.02777445688843727, 0.03386364132165909, 0.03261703997850418, 0.029419220983982086, 0.032614730298519135, 0.00775820342823863]}
Train Epoch: 44 [0/816 (0%)] loss: 0.0245 L_si: 0.0022 L_grad: 0.0223 
Train Epoch: 44 [36/816 (4%)] loss: 0.0200 L_si: 0.0026 L_grad: 0.0174 
Train Epoch: 44 [72/816 (9%)] loss: 0.0257 L_si: 0.0035 L_grad: 0.0222 
Train Epoch: 44 [108/816 (13%)] loss: 0.0262 L_si: 0.0041 L_grad: 0.0221 
Train Epoch: 44 [144/816 (18%)] loss: 0.0192 L_si: 0.0012 L_grad: 0.0181 
Train Epoch: 44 [180/816 (22%)] loss: 0.0206 L_si: 0.0028 L_grad: 0.0178 
Train Epoch: 44 [216/816 (26%)] loss: 0.0251 L_si: 0.0042 L_grad: 0.0209 
Train Epoch: 44 [252/816 (31%)] loss: 0.0310 L_si: 0.0048 L_grad: 0.0262 
Train Epoch: 44 [288/816 (35%)] loss: 0.0273 L_si: 0.0046 L_grad: 0.0227 
Train Epoch: 44 [324/816 (40%)] loss: 0.0259 L_si: 0.0042 L_grad: 0.0217 
Train Epoch: 44 [360/816 (44%)] loss: 0.0292 L_si: 0.0064 L_grad: 0.0228 
Train Epoch: 44 [396/816 (49%)] loss: 0.0218 L_si: 0.0040 L_grad: 0.0178 
Train Epoch: 44 [432/816 (53%)] loss: 0.0214 L_si: 0.0022 L_grad: 0.0191 
Train Epoch: 44 [468/816 (57%)] loss: 0.0203 L_si: 0.0020 L_grad: 0.0183 
Train Epoch: 44 [504/816 (62%)] loss: 0.0196 L_si: 0.0015 L_grad: 0.0180 
Train Epoch: 44 [540/816 (66%)] loss: 0.0294 L_si: 0.0048 L_grad: 0.0246 
Train Epoch: 44 [576/816 (71%)] loss: 0.0226 L_si: 0.0023 L_grad: 0.0204 
Train Epoch: 44 [612/816 (75%)] loss: 0.0263 L_si: 0.0029 L_grad: 0.0234 
Train Epoch: 44 [648/816 (79%)] loss: 0.0250 L_si: 0.0029 L_grad: 0.0221 
Train Epoch: 44 [684/816 (84%)] loss: 0.0229 L_si: 0.0032 L_grad: 0.0197 
Train Epoch: 44 [720/816 (88%)] loss: 0.0269 L_si: 0.0047 L_grad: 0.0222 
Train Epoch: 44 [756/816 (93%)] loss: 0.0230 L_si: 0.0028 L_grad: 0.0202 
Train Epoch: 44 [792/816 (97%)] loss: 0.0212 L_si: 0.0016 L_grad: 0.0196 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving current best: model_best.pth.tar ...
all losses in batch in validation:  {'loss': [0.035850681364536285, 0.03119553253054619, 0.033023301512002945, 0.037754230201244354, 0.033886250108480453, 0.03501833230257034, 0.033755701035261154, 0.033806007355451584, 0.03836555406451225, 0.036637842655181885, 0.03991198539733887, 0.036650486290454865, 0.039485327899456024, 0.03806892782449722, 0.03825199604034424, 0.036784280091524124, 0.036608871072530746, 0.04372173175215721, 0.012251078151166439], 'L_si': [0.005797386169433594, 0.004390489310026169, 0.005038619041442871, 0.006549738347530365, 0.005112834274768829, 0.005010463297367096, 0.005052283406257629, 0.005062602460384369, 0.006152518093585968, 0.005701743066310883, 0.006349295377731323, 0.006582781672477722, 0.00581023097038269, 0.005322948098182678, 0.005045391619205475, 0.006078191101551056, 0.00506320595741272, 0.00566612184047699, 0.0037998557090759277], 'L_grad': [0.03005329519510269, 0.02680504322052002, 0.027984682470560074, 0.03120448999106884, 0.028773415833711624, 0.030007870867848396, 0.028703417629003525, 0.028743404895067215, 0.032213035970926285, 0.030936099588871002, 0.033562690019607544, 0.030067704617977142, 0.033675096929073334, 0.032745979726314545, 0.03320660442113876, 0.030706088989973068, 0.03154566511511803, 0.03805560991168022, 0.008451222442090511]}
Train Epoch: 45 [0/816 (0%)] loss: 0.0288 L_si: 0.0056 L_grad: 0.0233 
Train Epoch: 45 [36/816 (4%)] loss: 0.0202 L_si: 0.0017 L_grad: 0.0185 
Train Epoch: 45 [72/816 (9%)] loss: 0.0222 L_si: 0.0020 L_grad: 0.0203 
Train Epoch: 45 [108/816 (13%)] loss: 0.0327 L_si: 0.0053 L_grad: 0.0274 
Train Epoch: 45 [144/816 (18%)] loss: 0.0301 L_si: 0.0033 L_grad: 0.0268 
Train Epoch: 45 [180/816 (22%)] loss: 0.0342 L_si: 0.0072 L_grad: 0.0270 
Train Epoch: 45 [216/816 (26%)] loss: 0.0282 L_si: 0.0043 L_grad: 0.0239 
Train Epoch: 45 [252/816 (31%)] loss: 0.0205 L_si: 0.0030 L_grad: 0.0176 
Train Epoch: 45 [288/816 (35%)] loss: 0.0230 L_si: 0.0030 L_grad: 0.0200 
Train Epoch: 45 [324/816 (40%)] loss: 0.0235 L_si: 0.0030 L_grad: 0.0206 
Train Epoch: 45 [360/816 (44%)] loss: 0.0284 L_si: 0.0044 L_grad: 0.0240 
Train Epoch: 45 [396/816 (49%)] loss: 0.0224 L_si: 0.0024 L_grad: 0.0200 
Train Epoch: 45 [432/816 (53%)] loss: 0.0248 L_si: 0.0041 L_grad: 0.0207 
Train Epoch: 45 [468/816 (57%)] loss: 0.0193 L_si: 0.0020 L_grad: 0.0173 
Train Epoch: 45 [504/816 (62%)] loss: 0.0230 L_si: 0.0026 L_grad: 0.0204 
Train Epoch: 45 [540/816 (66%)] loss: 0.0257 L_si: 0.0035 L_grad: 0.0222 
Train Epoch: 45 [576/816 (71%)] loss: 0.0238 L_si: 0.0028 L_grad: 0.0210 
Train Epoch: 45 [612/816 (75%)] loss: 0.0178 L_si: 0.0013 L_grad: 0.0166 
Train Epoch: 45 [648/816 (79%)] loss: 0.0286 L_si: 0.0049 L_grad: 0.0237 
Train Epoch: 45 [684/816 (84%)] loss: 0.0244 L_si: 0.0071 L_grad: 0.0173 
Train Epoch: 45 [720/816 (88%)] loss: 0.0263 L_si: 0.0036 L_grad: 0.0228 
Train Epoch: 45 [756/816 (93%)] loss: 0.0283 L_si: 0.0049 L_grad: 0.0234 
Train Epoch: 45 [792/816 (97%)] loss: 0.0237 L_si: 0.0026 L_grad: 0.0211 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04085712879896164, 0.03724481537938118, 0.03269759565591812, 0.04046720638871193, 0.037847936153411865, 0.03902643918991089, 0.03690141439437866, 0.03802229464054108, 0.04100192338228226, 0.03218124806880951, 0.04003636911511421, 0.039170410484075546, 0.03875059634447098, 0.031116344034671783, 0.042249277234077454, 0.03703721612691879, 0.039099447429180145, 0.0377730131149292, 0.013924842700362206], 'L_si': [0.007101923227310181, 0.006346501410007477, 0.005162730813026428, 0.006419293582439423, 0.006275884807109833, 0.006455458700656891, 0.0061872974038124084, 0.006656154990196228, 0.005083627998828888, 0.004505593329668045, 0.006788827478885651, 0.006334118545055389, 0.006057925522327423, 0.004741329699754715, 0.006990209221839905, 0.006195791065692902, 0.006093762814998627, 0.006485246121883392, 0.007030416280031204], 'L_grad': [0.03375520557165146, 0.030898313969373703, 0.027534864842891693, 0.03404791280627251, 0.03157205134630203, 0.032570980489254, 0.030714116990566254, 0.03136613965034485, 0.03591829538345337, 0.027675656601786613, 0.03324754163622856, 0.03283629193902016, 0.032692670822143555, 0.02637501433491707, 0.03525906801223755, 0.03084142506122589, 0.03300568461418152, 0.03128776699304581, 0.006894426885992289]}
Train Epoch: 46 [0/816 (0%)] loss: 0.0217 L_si: 0.0019 L_grad: 0.0198 
Train Epoch: 46 [36/816 (4%)] loss: 0.0263 L_si: 0.0054 L_grad: 0.0209 
Train Epoch: 46 [72/816 (9%)] loss: 0.0263 L_si: 0.0027 L_grad: 0.0236 
Train Epoch: 46 [108/816 (13%)] loss: 0.0237 L_si: 0.0036 L_grad: 0.0200 
Train Epoch: 46 [144/816 (18%)] loss: 0.0173 L_si: 0.0013 L_grad: 0.0159 
Train Epoch: 46 [180/816 (22%)] loss: 0.0216 L_si: 0.0030 L_grad: 0.0186 
Train Epoch: 46 [216/816 (26%)] loss: 0.0182 L_si: 0.0017 L_grad: 0.0165 
Train Epoch: 46 [252/816 (31%)] loss: 0.0198 L_si: 0.0018 L_grad: 0.0180 
Train Epoch: 46 [288/816 (35%)] loss: 0.0233 L_si: 0.0028 L_grad: 0.0205 
Train Epoch: 46 [324/816 (40%)] loss: 0.0252 L_si: 0.0032 L_grad: 0.0221 
Train Epoch: 46 [360/816 (44%)] loss: 0.0283 L_si: 0.0035 L_grad: 0.0247 
Train Epoch: 46 [396/816 (49%)] loss: 0.0178 L_si: 0.0013 L_grad: 0.0165 
Train Epoch: 46 [432/816 (53%)] loss: 0.0230 L_si: 0.0027 L_grad: 0.0203 
Train Epoch: 46 [468/816 (57%)] loss: 0.0220 L_si: 0.0021 L_grad: 0.0199 
Train Epoch: 46 [504/816 (62%)] loss: 0.0251 L_si: 0.0038 L_grad: 0.0213 
Train Epoch: 46 [540/816 (66%)] loss: 0.0212 L_si: 0.0039 L_grad: 0.0173 
Train Epoch: 46 [576/816 (71%)] loss: 0.0216 L_si: 0.0031 L_grad: 0.0185 
Train Epoch: 46 [612/816 (75%)] loss: 0.0275 L_si: 0.0038 L_grad: 0.0237 
Train Epoch: 46 [648/816 (79%)] loss: 0.0289 L_si: 0.0076 L_grad: 0.0213 
Train Epoch: 46 [684/816 (84%)] loss: 0.0275 L_si: 0.0062 L_grad: 0.0213 
Train Epoch: 46 [720/816 (88%)] loss: 0.0186 L_si: 0.0017 L_grad: 0.0169 
Train Epoch: 46 [756/816 (93%)] loss: 0.0225 L_si: 0.0027 L_grad: 0.0199 
Train Epoch: 46 [792/816 (97%)] loss: 0.0253 L_si: 0.0041 L_grad: 0.0212 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03709537535905838, 0.03737886622548103, 0.04281830042600632, 0.03915954753756523, 0.04054630547761917, 0.037087563425302505, 0.0399320088326931, 0.03729625046253204, 0.04518873617053032, 0.03403298556804657, 0.034672971814870834, 0.041094861924648285, 0.03681434318423271, 0.03415834531188011, 0.03913338482379913, 0.03863302618265152, 0.04165247827768326, 0.041915684938430786, 0.014373738318681717], 'L_si': [0.007205657660961151, 0.005450747907161713, 0.006541527807712555, 0.006621144711971283, 0.0067815110087394714, 0.0059722959995269775, 0.005850240588188171, 0.005919292569160461, 0.007328018546104431, 0.004717469215393066, 0.005281522870063782, 0.0064378902316093445, 0.006275177001953125, 0.005236305296421051, 0.006501063704490662, 0.005663678050041199, 0.007420085370540619, 0.006908528506755829, 0.005889177322387695], 'L_grad': [0.02988971769809723, 0.03192811831831932, 0.03627677261829376, 0.03253840282559395, 0.0337647944688797, 0.031115267425775528, 0.03408176824450493, 0.03137695789337158, 0.03786071762442589, 0.029315518215298653, 0.029391448944807053, 0.03465697169303894, 0.030539166182279587, 0.02892204001545906, 0.03263232111930847, 0.03296934813261032, 0.03423239290714264, 0.03500715643167496, 0.008484560996294022]}
Train Epoch: 47 [0/816 (0%)] loss: 0.0325 L_si: 0.0067 L_grad: 0.0258 
Train Epoch: 47 [36/816 (4%)] loss: 0.0294 L_si: 0.0082 L_grad: 0.0211 
Train Epoch: 47 [72/816 (9%)] loss: 0.0205 L_si: 0.0028 L_grad: 0.0177 
Train Epoch: 47 [108/816 (13%)] loss: 0.0241 L_si: 0.0034 L_grad: 0.0206 
Train Epoch: 47 [144/816 (18%)] loss: 0.0226 L_si: 0.0020 L_grad: 0.0206 
Train Epoch: 47 [180/816 (22%)] loss: 0.0205 L_si: 0.0019 L_grad: 0.0186 
Train Epoch: 47 [216/816 (26%)] loss: 0.0254 L_si: 0.0040 L_grad: 0.0214 
Train Epoch: 47 [252/816 (31%)] loss: 0.0300 L_si: 0.0052 L_grad: 0.0249 
Train Epoch: 47 [288/816 (35%)] loss: 0.0270 L_si: 0.0046 L_grad: 0.0224 
Train Epoch: 47 [324/816 (40%)] loss: 0.0237 L_si: 0.0028 L_grad: 0.0209 
Train Epoch: 47 [360/816 (44%)] loss: 0.0213 L_si: 0.0021 L_grad: 0.0192 
Train Epoch: 47 [396/816 (49%)] loss: 0.0171 L_si: 0.0012 L_grad: 0.0159 
Train Epoch: 47 [432/816 (53%)] loss: 0.0213 L_si: 0.0021 L_grad: 0.0192 
Train Epoch: 47 [468/816 (57%)] loss: 0.0208 L_si: 0.0021 L_grad: 0.0187 
Train Epoch: 47 [504/816 (62%)] loss: 0.0146 L_si: 0.0009 L_grad: 0.0137 
Train Epoch: 47 [540/816 (66%)] loss: 0.0171 L_si: 0.0016 L_grad: 0.0155 
Train Epoch: 47 [576/816 (71%)] loss: 0.0276 L_si: 0.0052 L_grad: 0.0224 
Train Epoch: 47 [612/816 (75%)] loss: 0.0227 L_si: 0.0032 L_grad: 0.0195 
Train Epoch: 47 [648/816 (79%)] loss: 0.0245 L_si: 0.0030 L_grad: 0.0215 
Train Epoch: 47 [684/816 (84%)] loss: 0.0202 L_si: 0.0025 L_grad: 0.0177 
Train Epoch: 47 [720/816 (88%)] loss: 0.0247 L_si: 0.0039 L_grad: 0.0208 
Train Epoch: 47 [756/816 (93%)] loss: 0.0227 L_si: 0.0037 L_grad: 0.0190 
Train Epoch: 47 [792/816 (97%)] loss: 0.0230 L_si: 0.0025 L_grad: 0.0205 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03672192618250847, 0.03758484125137329, 0.03944503515958786, 0.0406140573322773, 0.03667527437210083, 0.036325134336948395, 0.03576840087771416, 0.03748420625925064, 0.03922836855053902, 0.03556289151310921, 0.03387443348765373, 0.04047160595655441, 0.0319654606282711, 0.03656357526779175, 0.039716318249702454, 0.03959193453192711, 0.03177853673696518, 0.037138454616069794, 0.013419483788311481], 'L_si': [0.005092456936836243, 0.006631933152675629, 0.00641709566116333, 0.006046511232852936, 0.005254484713077545, 0.004709027707576752, 0.006133250892162323, 0.005324825644493103, 0.006309863179922104, 0.005845971405506134, 0.005136851221323013, 0.006124816834926605, 0.004393342882394791, 0.005703743547201157, 0.00573025643825531, 0.006601490080356598, 0.0034393779933452606, 0.006206993013620377, 0.0058961063623428345], 'L_grad': [0.031629469245672226, 0.03095290996134281, 0.03302793949842453, 0.03456754609942436, 0.031420789659023285, 0.03161610662937164, 0.029635149985551834, 0.03215938061475754, 0.03291850537061691, 0.029716920107603073, 0.02873758226633072, 0.03434678912162781, 0.027572117745876312, 0.03085983172059059, 0.033986061811447144, 0.03299044445157051, 0.02833915874361992, 0.030931461602449417, 0.007523377425968647]}
Train Epoch: 48 [0/816 (0%)] loss: 0.0225 L_si: 0.0022 L_grad: 0.0203 
Train Epoch: 48 [36/816 (4%)] loss: 0.0234 L_si: 0.0025 L_grad: 0.0209 
Train Epoch: 48 [72/816 (9%)] loss: 0.0213 L_si: 0.0017 L_grad: 0.0196 
Train Epoch: 48 [108/816 (13%)] loss: 0.0196 L_si: 0.0020 L_grad: 0.0176 
Train Epoch: 48 [144/816 (18%)] loss: 0.0225 L_si: 0.0038 L_grad: 0.0187 
Train Epoch: 48 [180/816 (22%)] loss: 0.0169 L_si: 0.0010 L_grad: 0.0159 
Train Epoch: 48 [216/816 (26%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0158 
Train Epoch: 48 [252/816 (31%)] loss: 0.0215 L_si: 0.0020 L_grad: 0.0195 
Train Epoch: 48 [288/816 (35%)] loss: 0.0274 L_si: 0.0044 L_grad: 0.0230 
Train Epoch: 48 [324/816 (40%)] loss: 0.0218 L_si: 0.0022 L_grad: 0.0196 
Train Epoch: 48 [360/816 (44%)] loss: 0.0278 L_si: 0.0034 L_grad: 0.0243 
Train Epoch: 48 [396/816 (49%)] loss: 0.0281 L_si: 0.0033 L_grad: 0.0248 
Train Epoch: 48 [432/816 (53%)] loss: 0.0238 L_si: 0.0042 L_grad: 0.0196 
Train Epoch: 48 [468/816 (57%)] loss: 0.0274 L_si: 0.0052 L_grad: 0.0222 
Train Epoch: 48 [504/816 (62%)] loss: 0.0272 L_si: 0.0042 L_grad: 0.0230 
Train Epoch: 48 [540/816 (66%)] loss: 0.0187 L_si: 0.0015 L_grad: 0.0172 
Train Epoch: 48 [576/816 (71%)] loss: 0.0216 L_si: 0.0032 L_grad: 0.0184 
Train Epoch: 48 [612/816 (75%)] loss: 0.0333 L_si: 0.0059 L_grad: 0.0274 
Train Epoch: 48 [648/816 (79%)] loss: 0.0181 L_si: 0.0017 L_grad: 0.0164 
Train Epoch: 48 [684/816 (84%)] loss: 0.0247 L_si: 0.0028 L_grad: 0.0220 
Train Epoch: 48 [720/816 (88%)] loss: 0.0241 L_si: 0.0028 L_grad: 0.0212 
Train Epoch: 48 [756/816 (93%)] loss: 0.0248 L_si: 0.0045 L_grad: 0.0203 
Train Epoch: 48 [792/816 (97%)] loss: 0.0265 L_si: 0.0029 L_grad: 0.0236 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03765208274126053, 0.03582997992634773, 0.042847756296396255, 0.040069736540317535, 0.03629695624113083, 0.04052947461605072, 0.04284445196390152, 0.041634343564510345, 0.03941858932375908, 0.04279835894703865, 0.04091854393482208, 0.04207805544137955, 0.03503449261188507, 0.03299955278635025, 0.03715096041560173, 0.04070419445633888, 0.04090651124715805, 0.028246641159057617, 0.012695500627160072], 'L_si': [0.00783459097146988, 0.005667898803949356, 0.008674874901771545, 0.007908500730991364, 0.007504716515541077, 0.007958143949508667, 0.007968224585056305, 0.007109396159648895, 0.007629796862602234, 0.007632061839103699, 0.0064167603850364685, 0.007261939346790314, 0.006630178540945053, 0.005530692636966705, 0.006609588861465454, 0.007823020219802856, 0.007994823157787323, 0.003857087343931198, 0.0036386996507644653], 'L_grad': [0.02981749176979065, 0.030162081122398376, 0.03417288139462471, 0.03216123580932617, 0.028792239725589752, 0.03257133066654205, 0.034876227378845215, 0.03452494740486145, 0.031788792461156845, 0.03516629710793495, 0.034501783549785614, 0.03481611609458923, 0.028404315933585167, 0.027468860149383545, 0.030541371554136276, 0.032881174236536026, 0.03291168808937073, 0.02438955381512642, 0.009056800976395607]}
Train Epoch: 49 [0/816 (0%)] loss: 0.0196 L_si: 0.0018 L_grad: 0.0178 
Train Epoch: 49 [36/816 (4%)] loss: 0.0212 L_si: 0.0025 L_grad: 0.0188 
Train Epoch: 49 [72/816 (9%)] loss: 0.0301 L_si: 0.0079 L_grad: 0.0222 
Train Epoch: 49 [108/816 (13%)] loss: 0.0220 L_si: 0.0023 L_grad: 0.0198 
Train Epoch: 49 [144/816 (18%)] loss: 0.0235 L_si: 0.0027 L_grad: 0.0208 
Train Epoch: 49 [180/816 (22%)] loss: 0.0268 L_si: 0.0037 L_grad: 0.0231 
Train Epoch: 49 [216/816 (26%)] loss: 0.0235 L_si: 0.0025 L_grad: 0.0210 
Train Epoch: 49 [252/816 (31%)] loss: 0.0156 L_si: 0.0024 L_grad: 0.0133 
Train Epoch: 49 [288/816 (35%)] loss: 0.0277 L_si: 0.0040 L_grad: 0.0238 
Train Epoch: 49 [324/816 (40%)] loss: 0.0291 L_si: 0.0063 L_grad: 0.0228 
Train Epoch: 49 [360/816 (44%)] loss: 0.0256 L_si: 0.0038 L_grad: 0.0218 
Train Epoch: 49 [396/816 (49%)] loss: 0.0278 L_si: 0.0037 L_grad: 0.0242 
Train Epoch: 49 [432/816 (53%)] loss: 0.0271 L_si: 0.0035 L_grad: 0.0236 
Train Epoch: 49 [468/816 (57%)] loss: 0.0240 L_si: 0.0021 L_grad: 0.0219 
Train Epoch: 49 [504/816 (62%)] loss: 0.0173 L_si: 0.0012 L_grad: 0.0161 
Train Epoch: 49 [540/816 (66%)] loss: 0.0319 L_si: 0.0062 L_grad: 0.0258 
Train Epoch: 49 [576/816 (71%)] loss: 0.0233 L_si: 0.0027 L_grad: 0.0206 
Train Epoch: 49 [612/816 (75%)] loss: 0.0188 L_si: 0.0018 L_grad: 0.0170 
Train Epoch: 49 [648/816 (79%)] loss: 0.0202 L_si: 0.0017 L_grad: 0.0185 
Train Epoch: 49 [684/816 (84%)] loss: 0.0299 L_si: 0.0063 L_grad: 0.0236 
Train Epoch: 49 [720/816 (88%)] loss: 0.0230 L_si: 0.0027 L_grad: 0.0204 
Train Epoch: 49 [756/816 (93%)] loss: 0.0199 L_si: 0.0026 L_grad: 0.0173 
Train Epoch: 49 [792/816 (97%)] loss: 0.0264 L_si: 0.0032 L_grad: 0.0232 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03863387554883957, 0.04054958373308182, 0.03803681209683418, 0.03921342268586159, 0.03666169196367264, 0.03622061014175415, 0.03548907861113548, 0.03785926476120949, 0.03757162764668465, 0.04007873684167862, 0.03656288981437683, 0.04101065546274185, 0.03828267753124237, 0.03312193229794502, 0.03984735161066055, 0.043407365679740906, 0.039187200367450714, 0.04253966361284256, 0.01598321460187435], 'L_si': [0.00633404403924942, 0.007754631340503693, 0.006396830081939697, 0.008241772651672363, 0.0067679136991500854, 0.006728462874889374, 0.0066807568073272705, 0.006707273423671722, 0.0073834434151649475, 0.006835676729679108, 0.00613769143819809, 0.008031800389289856, 0.007235996425151825, 0.0047643110156059265, 0.007034383714199066, 0.007942907512187958, 0.007106609642505646, 0.007867537438869476, 0.007990457117557526], 'L_grad': [0.03229983150959015, 0.032794952392578125, 0.031639982014894485, 0.030971650034189224, 0.029893776401877403, 0.029492147266864777, 0.028808321803808212, 0.031151991337537766, 0.0301881842315197, 0.03324306011199951, 0.030425196513533592, 0.032978855073451996, 0.031046679243445396, 0.028357621282339096, 0.03281296789646149, 0.03546445816755295, 0.03208059072494507, 0.034672126173973083, 0.007992757484316826]}
Train Epoch: 50 [0/816 (0%)] loss: 0.0266 L_si: 0.0036 L_grad: 0.0230 
Train Epoch: 50 [36/816 (4%)] loss: 0.0301 L_si: 0.0057 L_grad: 0.0244 
Train Epoch: 50 [72/816 (9%)] loss: 0.0258 L_si: 0.0029 L_grad: 0.0229 
Train Epoch: 50 [108/816 (13%)] loss: 0.0206 L_si: 0.0020 L_grad: 0.0186 
Train Epoch: 50 [144/816 (18%)] loss: 0.0323 L_si: 0.0069 L_grad: 0.0255 
Train Epoch: 50 [180/816 (22%)] loss: 0.0231 L_si: 0.0022 L_grad: 0.0209 
Train Epoch: 50 [216/816 (26%)] loss: 0.0251 L_si: 0.0029 L_grad: 0.0222 
Train Epoch: 50 [252/816 (31%)] loss: 0.0239 L_si: 0.0022 L_grad: 0.0216 
Train Epoch: 50 [288/816 (35%)] loss: 0.0279 L_si: 0.0041 L_grad: 0.0238 
Train Epoch: 50 [324/816 (40%)] loss: 0.0244 L_si: 0.0033 L_grad: 0.0212 
Train Epoch: 50 [360/816 (44%)] loss: 0.0211 L_si: 0.0027 L_grad: 0.0184 
Train Epoch: 50 [396/816 (49%)] loss: 0.0228 L_si: 0.0034 L_grad: 0.0194 
Train Epoch: 50 [432/816 (53%)] loss: 0.0172 L_si: 0.0015 L_grad: 0.0157 
Train Epoch: 50 [468/816 (57%)] loss: 0.0195 L_si: 0.0017 L_grad: 0.0178 
Train Epoch: 50 [504/816 (62%)] loss: 0.0203 L_si: 0.0015 L_grad: 0.0188 
Train Epoch: 50 [540/816 (66%)] loss: 0.0276 L_si: 0.0043 L_grad: 0.0233 
Train Epoch: 50 [576/816 (71%)] loss: 0.0176 L_si: 0.0014 L_grad: 0.0162 
Train Epoch: 50 [612/816 (75%)] loss: 0.0184 L_si: 0.0019 L_grad: 0.0164 
Train Epoch: 50 [648/816 (79%)] loss: 0.0172 L_si: 0.0012 L_grad: 0.0160 
Train Epoch: 50 [684/816 (84%)] loss: 0.0234 L_si: 0.0027 L_grad: 0.0207 
Train Epoch: 50 [720/816 (88%)] loss: 0.0221 L_si: 0.0028 L_grad: 0.0193 
Train Epoch: 50 [756/816 (93%)] loss: 0.0175 L_si: 0.0011 L_grad: 0.0164 
Train Epoch: 50 [792/816 (97%)] loss: 0.0147 L_si: 0.0008 L_grad: 0.0140 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch050-loss-0.0224.pth.tar ...
New Learning Rate: 0.000150
all losses in batch in validation:  {'loss': [0.03398687392473221, 0.03592938929796219, 0.03434191644191742, 0.04055136442184448, 0.04096875339746475, 0.040121570229530334, 0.03718917444348335, 0.036886170506477356, 0.03765059635043144, 0.039582058787345886, 0.035609494894742966, 0.03744090721011162, 0.03569269925355911, 0.038896966725587845, 0.04195918142795563, 0.0427497923374176, 0.03947940468788147, 0.04207153245806694, 0.013952680863440037], 'L_si': [0.0064694806933403015, 0.0064597055315971375, 0.00626799464225769, 0.007182799279689789, 0.0062543973326683044, 0.007070109248161316, 0.006579108536243439, 0.007046714425086975, 0.007825598120689392, 0.00653945654630661, 0.006918206810951233, 0.00640510767698288, 0.006164036691188812, 0.007565528154373169, 0.007450111210346222, 0.007636047899723053, 0.00730537623167038, 0.0077383145689964294, 0.0043236613273620605], 'L_grad': [0.027517393231391907, 0.029469681903719902, 0.028073923662304878, 0.033368565142154694, 0.03471435606479645, 0.03305146098136902, 0.030610065907239914, 0.02983945794403553, 0.02982499822974205, 0.033042602241039276, 0.028691288083791733, 0.03103579953312874, 0.0295286625623703, 0.031331438571214676, 0.034509070217609406, 0.03511374443769455, 0.03217402845621109, 0.03433321788907051, 0.009629019536077976]}
Train Epoch: 51 [0/816 (0%)] loss: 0.0210 L_si: 0.0020 L_grad: 0.0190 
Train Epoch: 51 [36/816 (4%)] loss: 0.0268 L_si: 0.0046 L_grad: 0.0222 
Train Epoch: 51 [72/816 (9%)] loss: 0.0182 L_si: 0.0015 L_grad: 0.0167 
Train Epoch: 51 [108/816 (13%)] loss: 0.0218 L_si: 0.0023 L_grad: 0.0195 
Train Epoch: 51 [144/816 (18%)] loss: 0.0259 L_si: 0.0037 L_grad: 0.0222 
Train Epoch: 51 [180/816 (22%)] loss: 0.0237 L_si: 0.0031 L_grad: 0.0206 
Train Epoch: 51 [216/816 (26%)] loss: 0.0137 L_si: 0.0009 L_grad: 0.0127 
Train Epoch: 51 [252/816 (31%)] loss: 0.0237 L_si: 0.0036 L_grad: 0.0202 
Train Epoch: 51 [288/816 (35%)] loss: 0.0214 L_si: 0.0048 L_grad: 0.0166 
Train Epoch: 51 [324/816 (40%)] loss: 0.0260 L_si: 0.0030 L_grad: 0.0230 
Train Epoch: 51 [360/816 (44%)] loss: 0.0260 L_si: 0.0063 L_grad: 0.0197 
Train Epoch: 51 [396/816 (49%)] loss: 0.0209 L_si: 0.0020 L_grad: 0.0190 
Train Epoch: 51 [432/816 (53%)] loss: 0.0160 L_si: 0.0021 L_grad: 0.0139 
Train Epoch: 51 [468/816 (57%)] loss: 0.0173 L_si: 0.0012 L_grad: 0.0161 
Train Epoch: 51 [504/816 (62%)] loss: 0.0189 L_si: 0.0016 L_grad: 0.0174 
Train Epoch: 51 [540/816 (66%)] loss: 0.0250 L_si: 0.0060 L_grad: 0.0191 
Train Epoch: 51 [576/816 (71%)] loss: 0.0181 L_si: 0.0018 L_grad: 0.0163 
Train Epoch: 51 [612/816 (75%)] loss: 0.0232 L_si: 0.0024 L_grad: 0.0208 
Train Epoch: 51 [648/816 (79%)] loss: 0.0362 L_si: 0.0105 L_grad: 0.0258 
Train Epoch: 51 [684/816 (84%)] loss: 0.0229 L_si: 0.0033 L_grad: 0.0196 
Train Epoch: 51 [720/816 (88%)] loss: 0.0265 L_si: 0.0045 L_grad: 0.0220 
Train Epoch: 51 [756/816 (93%)] loss: 0.0200 L_si: 0.0015 L_grad: 0.0185 
Train Epoch: 51 [792/816 (97%)] loss: 0.0222 L_si: 0.0032 L_grad: 0.0190 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.035271868109703064, 0.037751805037260056, 0.042364105582237244, 0.03571534529328346, 0.03829130157828331, 0.039679765701293945, 0.036568351089954376, 0.03744998201727867, 0.038743551820516586, 0.03631442412734032, 0.03907671198248863, 0.03535853326320648, 0.0367242656648159, 0.03868367522954941, 0.03779122233390808, 0.0359904021024704, 0.034783683717250824, 0.04075496271252632, 0.015132193453609943], 'L_si': [0.006187170743942261, 0.007082328200340271, 0.0075485557317733765, 0.005357474088668823, 0.00747072696685791, 0.006624683737754822, 0.006617195904254913, 0.007003284990787506, 0.00687948614358902, 0.006574064493179321, 0.006857432425022125, 0.0059125348925590515, 0.0061913058161735535, 0.008482038974761963, 0.00704193115234375, 0.00667109340429306, 0.006482869386672974, 0.006667084991931915, 0.007036440074443817], 'L_grad': [0.029084697365760803, 0.030669476836919785, 0.03481554985046387, 0.03035787120461464, 0.0308205746114254, 0.033055081963539124, 0.029951153323054314, 0.030446697026491165, 0.031864065676927567, 0.029740359634160995, 0.03221927955746651, 0.02944599650800228, 0.03053295984864235, 0.030201636254787445, 0.03074929304420948, 0.029319310560822487, 0.02830081433057785, 0.034087877720594406, 0.008095753379166126]}
Train Epoch: 52 [0/816 (0%)] loss: 0.0180 L_si: 0.0020 L_grad: 0.0159 
Train Epoch: 52 [36/816 (4%)] loss: 0.0193 L_si: 0.0017 L_grad: 0.0175 
Train Epoch: 52 [72/816 (9%)] loss: 0.0316 L_si: 0.0044 L_grad: 0.0273 
Train Epoch: 52 [108/816 (13%)] loss: 0.0251 L_si: 0.0038 L_grad: 0.0213 
Train Epoch: 52 [144/816 (18%)] loss: 0.0229 L_si: 0.0026 L_grad: 0.0203 
Train Epoch: 52 [180/816 (22%)] loss: 0.0175 L_si: 0.0018 L_grad: 0.0157 
Train Epoch: 52 [216/816 (26%)] loss: 0.0265 L_si: 0.0039 L_grad: 0.0226 
Train Epoch: 52 [252/816 (31%)] loss: 0.0231 L_si: 0.0035 L_grad: 0.0196 
Train Epoch: 52 [288/816 (35%)] loss: 0.0221 L_si: 0.0027 L_grad: 0.0194 
Train Epoch: 52 [324/816 (40%)] loss: 0.0228 L_si: 0.0027 L_grad: 0.0201 
Train Epoch: 52 [360/816 (44%)] loss: 0.0189 L_si: 0.0013 L_grad: 0.0176 
Train Epoch: 52 [396/816 (49%)] loss: 0.0185 L_si: 0.0026 L_grad: 0.0159 
Train Epoch: 52 [432/816 (53%)] loss: 0.0195 L_si: 0.0015 L_grad: 0.0180 
Train Epoch: 52 [468/816 (57%)] loss: 0.0196 L_si: 0.0019 L_grad: 0.0177 
Train Epoch: 52 [504/816 (62%)] loss: 0.0206 L_si: 0.0020 L_grad: 0.0187 
Train Epoch: 52 [540/816 (66%)] loss: 0.0161 L_si: 0.0014 L_grad: 0.0147 
Train Epoch: 52 [576/816 (71%)] loss: 0.0249 L_si: 0.0037 L_grad: 0.0212 
Train Epoch: 52 [612/816 (75%)] loss: 0.0214 L_si: 0.0029 L_grad: 0.0185 
Train Epoch: 52 [648/816 (79%)] loss: 0.0282 L_si: 0.0049 L_grad: 0.0234 
Train Epoch: 52 [684/816 (84%)] loss: 0.0215 L_si: 0.0026 L_grad: 0.0189 
Train Epoch: 52 [720/816 (88%)] loss: 0.0166 L_si: 0.0012 L_grad: 0.0154 
Train Epoch: 52 [756/816 (93%)] loss: 0.0183 L_si: 0.0020 L_grad: 0.0163 
Train Epoch: 52 [792/816 (97%)] loss: 0.0213 L_si: 0.0028 L_grad: 0.0185 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040737513452768326, 0.04145461320877075, 0.03768616542220116, 0.03991039842367172, 0.03957754373550415, 0.041398242115974426, 0.0352645218372345, 0.03887443616986275, 0.039933666586875916, 0.036757148802280426, 0.03921760618686676, 0.03950316086411476, 0.03821948915719986, 0.040649522095918655, 0.042514801025390625, 0.03784238547086716, 0.04032488912343979, 0.040118031203746796, 0.016362685710191727], 'L_si': [0.007397182285785675, 0.008462965488433838, 0.007119998335838318, 0.007320299744606018, 0.00764445960521698, 0.006194479763507843, 0.007508322596549988, 0.0071858689188957214, 0.0076478272676467896, 0.006865069270133972, 0.007040686905384064, 0.00686868280172348, 0.006731711328029633, 0.008693195879459381, 0.006996721029281616, 0.007399603724479675, 0.0077547356486320496, 0.007446996867656708, 0.007745891809463501], 'L_grad': [0.03334033116698265, 0.032991647720336914, 0.03056616708636284, 0.032590098679065704, 0.03193308413028717, 0.03520376235246658, 0.02775619737803936, 0.031688567250967026, 0.032285839319229126, 0.029892079532146454, 0.0321769192814827, 0.03263447806239128, 0.03148777782917023, 0.031956326216459274, 0.03551807999610901, 0.03044278360903263, 0.03257015347480774, 0.03267103433609009, 0.008616793900728226]}
Train Epoch: 53 [0/816 (0%)] loss: 0.0201 L_si: 0.0021 L_grad: 0.0180 
Train Epoch: 53 [36/816 (4%)] loss: 0.0161 L_si: 0.0014 L_grad: 0.0147 
Train Epoch: 53 [72/816 (9%)] loss: 0.0206 L_si: 0.0016 L_grad: 0.0190 
Train Epoch: 53 [108/816 (13%)] loss: 0.0184 L_si: 0.0030 L_grad: 0.0154 
Train Epoch: 53 [144/816 (18%)] loss: 0.0251 L_si: 0.0036 L_grad: 0.0215 
Train Epoch: 53 [180/816 (22%)] loss: 0.0236 L_si: 0.0032 L_grad: 0.0205 
Train Epoch: 53 [216/816 (26%)] loss: 0.0237 L_si: 0.0023 L_grad: 0.0214 
Train Epoch: 53 [252/816 (31%)] loss: 0.0206 L_si: 0.0023 L_grad: 0.0183 
Train Epoch: 53 [288/816 (35%)] loss: 0.0150 L_si: 0.0012 L_grad: 0.0139 
Train Epoch: 53 [324/816 (40%)] loss: 0.0226 L_si: 0.0029 L_grad: 0.0197 
Train Epoch: 53 [360/816 (44%)] loss: 0.0218 L_si: 0.0022 L_grad: 0.0196 
Train Epoch: 53 [396/816 (49%)] loss: 0.0193 L_si: 0.0019 L_grad: 0.0175 
Train Epoch: 53 [432/816 (53%)] loss: 0.0252 L_si: 0.0032 L_grad: 0.0219 
Train Epoch: 53 [468/816 (57%)] loss: 0.0157 L_si: 0.0011 L_grad: 0.0145 
Train Epoch: 53 [504/816 (62%)] loss: 0.0136 L_si: 0.0007 L_grad: 0.0129 
Train Epoch: 53 [540/816 (66%)] loss: 0.0226 L_si: 0.0027 L_grad: 0.0199 
Train Epoch: 53 [576/816 (71%)] loss: 0.0234 L_si: 0.0020 L_grad: 0.0214 
Train Epoch: 53 [612/816 (75%)] loss: 0.0172 L_si: 0.0027 L_grad: 0.0145 
Train Epoch: 53 [648/816 (79%)] loss: 0.0201 L_si: 0.0017 L_grad: 0.0184 
Train Epoch: 53 [684/816 (84%)] loss: 0.0303 L_si: 0.0040 L_grad: 0.0263 
Train Epoch: 53 [720/816 (88%)] loss: 0.0243 L_si: 0.0045 L_grad: 0.0198 
Train Epoch: 53 [756/816 (93%)] loss: 0.0180 L_si: 0.0013 L_grad: 0.0167 
Train Epoch: 53 [792/816 (97%)] loss: 0.0215 L_si: 0.0020 L_grad: 0.0195 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.037103693932294846, 0.037804193794727325, 0.03607265651226044, 0.0417301170527935, 0.03571870177984238, 0.037759482860565186, 0.03048878163099289, 0.04110685735940933, 0.03457018733024597, 0.03626544401049614, 0.04625323414802551, 0.036450255662202835, 0.03848131000995636, 0.03998509421944618, 0.03779039531946182, 0.0317160040140152, 0.03849533945322037, 0.0375748872756958, 0.01280202902853489], 'L_si': [0.006501130759716034, 0.00599563866853714, 0.006369605660438538, 0.006440669298171997, 0.005842335522174835, 0.006025724112987518, 0.004411861300468445, 0.006835505366325378, 0.006650760769844055, 0.006077408790588379, 0.008746914565563202, 0.005893014371395111, 0.005931347608566284, 0.0067793577909469604, 0.007069095969200134, 0.005147747695446014, 0.0070791468024253845, 0.006197944283485413, 0.004728421568870544], 'L_grad': [0.03060256317257881, 0.031808555126190186, 0.02970305271446705, 0.035289447754621506, 0.029876364395022392, 0.03173375874757767, 0.026076920330524445, 0.034271351993083954, 0.027919428423047066, 0.03018803521990776, 0.03750631958246231, 0.030557241290807724, 0.032549962401390076, 0.03320573642849922, 0.030721301212906837, 0.026568254455924034, 0.03141619265079498, 0.03137694299221039, 0.008073607459664345]}
Train Epoch: 54 [0/816 (0%)] loss: 0.0152 L_si: 0.0014 L_grad: 0.0138 
Train Epoch: 54 [36/816 (4%)] loss: 0.0217 L_si: 0.0030 L_grad: 0.0188 
Train Epoch: 54 [72/816 (9%)] loss: 0.0260 L_si: 0.0034 L_grad: 0.0226 
Train Epoch: 54 [108/816 (13%)] loss: 0.0206 L_si: 0.0021 L_grad: 0.0186 
Train Epoch: 54 [144/816 (18%)] loss: 0.0256 L_si: 0.0025 L_grad: 0.0231 
Train Epoch: 54 [180/816 (22%)] loss: 0.0303 L_si: 0.0041 L_grad: 0.0262 
Train Epoch: 54 [216/816 (26%)] loss: 0.0165 L_si: 0.0009 L_grad: 0.0155 
Train Epoch: 54 [252/816 (31%)] loss: 0.0220 L_si: 0.0051 L_grad: 0.0169 
Train Epoch: 54 [288/816 (35%)] loss: 0.0160 L_si: 0.0014 L_grad: 0.0146 
Train Epoch: 54 [324/816 (40%)] loss: 0.0141 L_si: 0.0007 L_grad: 0.0135 
Train Epoch: 54 [360/816 (44%)] loss: 0.0194 L_si: 0.0017 L_grad: 0.0177 
Train Epoch: 54 [396/816 (49%)] loss: 0.0193 L_si: 0.0018 L_grad: 0.0175 
Train Epoch: 54 [432/816 (53%)] loss: 0.0264 L_si: 0.0033 L_grad: 0.0231 
Train Epoch: 54 [468/816 (57%)] loss: 0.0198 L_si: 0.0026 L_grad: 0.0172 
Train Epoch: 54 [504/816 (62%)] loss: 0.0181 L_si: 0.0016 L_grad: 0.0165 
Train Epoch: 54 [540/816 (66%)] loss: 0.0172 L_si: 0.0019 L_grad: 0.0153 
Train Epoch: 54 [576/816 (71%)] loss: 0.0236 L_si: 0.0024 L_grad: 0.0212 
Train Epoch: 54 [612/816 (75%)] loss: 0.0207 L_si: 0.0023 L_grad: 0.0183 
Train Epoch: 54 [648/816 (79%)] loss: 0.0178 L_si: 0.0015 L_grad: 0.0163 
Train Epoch: 54 [684/816 (84%)] loss: 0.0206 L_si: 0.0022 L_grad: 0.0184 
Train Epoch: 54 [720/816 (88%)] loss: 0.0200 L_si: 0.0027 L_grad: 0.0173 
Train Epoch: 54 [756/816 (93%)] loss: 0.0314 L_si: 0.0052 L_grad: 0.0262 
Train Epoch: 54 [792/816 (97%)] loss: 0.0213 L_si: 0.0022 L_grad: 0.0191 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03550481051206589, 0.04068787395954132, 0.04256576672196388, 0.03723304718732834, 0.039404354989528656, 0.0402522087097168, 0.04146897792816162, 0.03668340668082237, 0.03985228016972542, 0.03942535072565079, 0.03679855912923813, 0.03526083007454872, 0.03648011013865471, 0.03546546772122383, 0.03587969392538071, 0.03829813376069069, 0.036401182413101196, 0.039524320513010025, 0.015357931144535542], 'L_si': [0.006263740360736847, 0.007375694811344147, 0.008425801992416382, 0.006832905113697052, 0.005928926169872284, 0.0072624534368515015, 0.006890319287776947, 0.006956204771995544, 0.007817916572093964, 0.0070123374462127686, 0.007361523807048798, 0.006431370973587036, 0.0067043304443359375, 0.006287001073360443, 0.0061311498284339905, 0.006745345890522003, 0.006603077054023743, 0.007522284984588623, 0.007848910987377167], 'L_grad': [0.02924107201397419, 0.033312179148197174, 0.0341399647295475, 0.030400143936276436, 0.03347542881965637, 0.032989755272865295, 0.034578658640384674, 0.029727201908826828, 0.032034363597631454, 0.03241301327943802, 0.02943703532218933, 0.028829459100961685, 0.02977577969431877, 0.029178466647863388, 0.029748544096946716, 0.031552787870168686, 0.029798103496432304, 0.0320020355284214, 0.007509020157158375]}
Train Epoch: 55 [0/816 (0%)] loss: 0.0299 L_si: 0.0040 L_grad: 0.0259 
Train Epoch: 55 [36/816 (4%)] loss: 0.0159 L_si: 0.0011 L_grad: 0.0149 
Train Epoch: 55 [72/816 (9%)] loss: 0.0201 L_si: 0.0024 L_grad: 0.0177 
Train Epoch: 55 [108/816 (13%)] loss: 0.0174 L_si: 0.0014 L_grad: 0.0159 
Train Epoch: 55 [144/816 (18%)] loss: 0.0176 L_si: 0.0017 L_grad: 0.0159 
Train Epoch: 55 [180/816 (22%)] loss: 0.0229 L_si: 0.0033 L_grad: 0.0197 
Train Epoch: 55 [216/816 (26%)] loss: 0.0179 L_si: 0.0015 L_grad: 0.0164 
Train Epoch: 55 [252/816 (31%)] loss: 0.0208 L_si: 0.0026 L_grad: 0.0182 
Train Epoch: 55 [288/816 (35%)] loss: 0.0189 L_si: 0.0021 L_grad: 0.0167 
Train Epoch: 55 [324/816 (40%)] loss: 0.0187 L_si: 0.0017 L_grad: 0.0170 
Train Epoch: 55 [360/816 (44%)] loss: 0.0268 L_si: 0.0080 L_grad: 0.0188 
Train Epoch: 55 [396/816 (49%)] loss: 0.0210 L_si: 0.0028 L_grad: 0.0182 
Train Epoch: 55 [432/816 (53%)] loss: 0.0188 L_si: 0.0023 L_grad: 0.0165 
Train Epoch: 55 [468/816 (57%)] loss: 0.0226 L_si: 0.0023 L_grad: 0.0203 
Train Epoch: 55 [504/816 (62%)] loss: 0.0309 L_si: 0.0041 L_grad: 0.0268 
Train Epoch: 55 [540/816 (66%)] loss: 0.0170 L_si: 0.0012 L_grad: 0.0158 
Train Epoch: 55 [576/816 (71%)] loss: 0.0194 L_si: 0.0017 L_grad: 0.0177 
Train Epoch: 55 [612/816 (75%)] loss: 0.0237 L_si: 0.0023 L_grad: 0.0214 
Train Epoch: 55 [648/816 (79%)] loss: 0.0220 L_si: 0.0029 L_grad: 0.0191 
Train Epoch: 55 [684/816 (84%)] loss: 0.0275 L_si: 0.0054 L_grad: 0.0221 
Train Epoch: 55 [720/816 (88%)] loss: 0.0227 L_si: 0.0028 L_grad: 0.0199 
Train Epoch: 55 [756/816 (93%)] loss: 0.0226 L_si: 0.0029 L_grad: 0.0197 
Train Epoch: 55 [792/816 (97%)] loss: 0.0230 L_si: 0.0044 L_grad: 0.0186 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04063878208398819, 0.03602834418416023, 0.039706919342279434, 0.03584025055170059, 0.037427570670843124, 0.03887137025594711, 0.04021783918142319, 0.0349678136408329, 0.03675984963774681, 0.03733556717634201, 0.03734983503818512, 0.04155538231134415, 0.03521936014294624, 0.0389542281627655, 0.03880877047777176, 0.037861183285713196, 0.037148863077163696, 0.03742753714323044, 0.01541478093713522], 'L_si': [0.007454469799995422, 0.0063688382506370544, 0.006782427430152893, 0.006434425711631775, 0.00676320493221283, 0.0071189627051353455, 0.007674649357795715, 0.005996488034725189, 0.006240040063858032, 0.006810002028942108, 0.006995365023612976, 0.006453372538089752, 0.006000444293022156, 0.006587818264961243, 0.006959646940231323, 0.007760301232337952, 0.007030867040157318, 0.0070070624351501465, 0.0077925026416778564], 'L_grad': [0.03318431228399277, 0.029659505933523178, 0.03292449191212654, 0.029405824840068817, 0.030664365738630295, 0.03175240755081177, 0.03254318982362747, 0.028971325606107712, 0.03051980957388878, 0.03052556701004505, 0.030354470014572144, 0.035102009773254395, 0.029218915849924088, 0.03236640989780426, 0.031849123537540436, 0.030100882053375244, 0.030117996037006378, 0.03042047657072544, 0.007622278295457363]}
Train Epoch: 56 [0/816 (0%)] loss: 0.0234 L_si: 0.0029 L_grad: 0.0205 
Train Epoch: 56 [36/816 (4%)] loss: 0.0235 L_si: 0.0044 L_grad: 0.0191 
Train Epoch: 56 [72/816 (9%)] loss: 0.0162 L_si: 0.0016 L_grad: 0.0146 
Train Epoch: 56 [108/816 (13%)] loss: 0.0230 L_si: 0.0031 L_grad: 0.0199 
Train Epoch: 56 [144/816 (18%)] loss: 0.0211 L_si: 0.0038 L_grad: 0.0173 
Train Epoch: 56 [180/816 (22%)] loss: 0.0180 L_si: 0.0014 L_grad: 0.0167 
Train Epoch: 56 [216/816 (26%)] loss: 0.0157 L_si: 0.0008 L_grad: 0.0149 
Train Epoch: 56 [252/816 (31%)] loss: 0.0225 L_si: 0.0026 L_grad: 0.0199 
Train Epoch: 56 [288/816 (35%)] loss: 0.0166 L_si: 0.0015 L_grad: 0.0151 
Train Epoch: 56 [324/816 (40%)] loss: 0.0179 L_si: 0.0014 L_grad: 0.0165 
Train Epoch: 56 [360/816 (44%)] loss: 0.0167 L_si: 0.0010 L_grad: 0.0157 
Train Epoch: 56 [396/816 (49%)] loss: 0.0225 L_si: 0.0027 L_grad: 0.0198 
Train Epoch: 56 [432/816 (53%)] loss: 0.0155 L_si: 0.0010 L_grad: 0.0144 
Train Epoch: 56 [468/816 (57%)] loss: 0.0192 L_si: 0.0011 L_grad: 0.0181 
Train Epoch: 56 [504/816 (62%)] loss: 0.0223 L_si: 0.0020 L_grad: 0.0203 
Train Epoch: 56 [540/816 (66%)] loss: 0.0211 L_si: 0.0028 L_grad: 0.0183 
Train Epoch: 56 [576/816 (71%)] loss: 0.0220 L_si: 0.0034 L_grad: 0.0187 
Train Epoch: 56 [612/816 (75%)] loss: 0.0173 L_si: 0.0016 L_grad: 0.0157 
Train Epoch: 56 [648/816 (79%)] loss: 0.0130 L_si: 0.0009 L_grad: 0.0121 
Train Epoch: 56 [684/816 (84%)] loss: 0.0195 L_si: 0.0021 L_grad: 0.0174 
Train Epoch: 56 [720/816 (88%)] loss: 0.0169 L_si: 0.0011 L_grad: 0.0158 
Train Epoch: 56 [756/816 (93%)] loss: 0.0230 L_si: 0.0029 L_grad: 0.0201 
Train Epoch: 56 [792/816 (97%)] loss: 0.0166 L_si: 0.0022 L_grad: 0.0145 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04112072288990021, 0.04011109471321106, 0.04101515933871269, 0.03635963052511215, 0.033204130828380585, 0.0377645418047905, 0.034127067774534225, 0.04090311378240585, 0.035156335681676865, 0.040083736181259155, 0.03331039100885391, 0.03902386128902435, 0.03750722110271454, 0.038382139056921005, 0.03652738407254219, 0.039318013936281204, 0.041390277445316315, 0.04142431914806366, 0.013347897678613663], 'L_si': [0.007261887192726135, 0.006863430142402649, 0.007676035165786743, 0.006322324275970459, 0.005057528614997864, 0.007609114050865173, 0.006231203675270081, 0.007263399660587311, 0.006110206246376038, 0.0068998560309410095, 0.004803180694580078, 0.007257841527462006, 0.006515093147754669, 0.006229229271411896, 0.0064948126673698425, 0.006860017776489258, 0.007193326950073242, 0.008150830864906311, 0.005928665399551392], 'L_grad': [0.03385883569717407, 0.03324766457080841, 0.03333912417292595, 0.030037304386496544, 0.02814660221338272, 0.030155427753925323, 0.027895864099264145, 0.03363971412181854, 0.029046129435300827, 0.033183880150318146, 0.028507208451628685, 0.03176601976156235, 0.03099212795495987, 0.03215290978550911, 0.030032571405172348, 0.032457996159791946, 0.03419695049524307, 0.03327348828315735, 0.007419232279062271]}
Train Epoch: 57 [0/816 (0%)] loss: 0.0228 L_si: 0.0035 L_grad: 0.0193 
Train Epoch: 57 [36/816 (4%)] loss: 0.0173 L_si: 0.0020 L_grad: 0.0153 
Train Epoch: 57 [72/816 (9%)] loss: 0.0222 L_si: 0.0022 L_grad: 0.0200 
Train Epoch: 57 [108/816 (13%)] loss: 0.0187 L_si: 0.0017 L_grad: 0.0170 
Train Epoch: 57 [144/816 (18%)] loss: 0.0200 L_si: 0.0020 L_grad: 0.0180 
Train Epoch: 57 [180/816 (22%)] loss: 0.0230 L_si: 0.0031 L_grad: 0.0199 
Train Epoch: 57 [216/816 (26%)] loss: 0.0161 L_si: 0.0012 L_grad: 0.0149 
Train Epoch: 57 [252/816 (31%)] loss: 0.0189 L_si: 0.0022 L_grad: 0.0167 
Train Epoch: 57 [288/816 (35%)] loss: 0.0204 L_si: 0.0023 L_grad: 0.0181 
Train Epoch: 57 [324/816 (40%)] loss: 0.0199 L_si: 0.0018 L_grad: 0.0181 
Train Epoch: 57 [360/816 (44%)] loss: 0.0164 L_si: 0.0012 L_grad: 0.0152 
Train Epoch: 57 [396/816 (49%)] loss: 0.0218 L_si: 0.0021 L_grad: 0.0197 
Train Epoch: 57 [432/816 (53%)] loss: 0.0194 L_si: 0.0031 L_grad: 0.0163 
Train Epoch: 57 [468/816 (57%)] loss: 0.0308 L_si: 0.0056 L_grad: 0.0252 
Train Epoch: 57 [504/816 (62%)] loss: 0.0204 L_si: 0.0021 L_grad: 0.0182 
Train Epoch: 57 [540/816 (66%)] loss: 0.0148 L_si: 0.0012 L_grad: 0.0136 
Train Epoch: 57 [576/816 (71%)] loss: 0.0175 L_si: 0.0013 L_grad: 0.0162 
Train Epoch: 57 [612/816 (75%)] loss: 0.0256 L_si: 0.0040 L_grad: 0.0216 
Train Epoch: 57 [648/816 (79%)] loss: 0.0159 L_si: 0.0014 L_grad: 0.0145 
Train Epoch: 57 [684/816 (84%)] loss: 0.0201 L_si: 0.0017 L_grad: 0.0184 
Train Epoch: 57 [720/816 (88%)] loss: 0.0183 L_si: 0.0016 L_grad: 0.0167 
Train Epoch: 57 [756/816 (93%)] loss: 0.0209 L_si: 0.0022 L_grad: 0.0187 
Train Epoch: 57 [792/816 (97%)] loss: 0.0181 L_si: 0.0012 L_grad: 0.0169 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03450264409184456, 0.04053139314055443, 0.04472360014915466, 0.03444179892539978, 0.04098675400018692, 0.03589774668216705, 0.04265255481004715, 0.03287414088845253, 0.041415371000766754, 0.03671771660447121, 0.03895566612482071, 0.0390055775642395, 0.038139939308166504, 0.03753088414669037, 0.03692609816789627, 0.03909928351640701, 0.0393797792494297, 0.03425010293722153, 0.013742197304964066], 'L_si': [0.0064131468534469604, 0.006869025528430939, 0.008825473487377167, 0.006326325237751007, 0.007693931460380554, 0.005917392671108246, 0.008035875856876373, 0.00591094046831131, 0.007610604166984558, 0.00624663382768631, 0.006598040461540222, 0.006244748830795288, 0.00672873854637146, 0.006358698010444641, 0.007345862686634064, 0.007434166967868805, 0.007281653583049774, 0.005812041461467743, 0.00595749169588089], 'L_grad': [0.0280894972383976, 0.03366236761212349, 0.035898126661777496, 0.028115473687648773, 0.033292822539806366, 0.029980352148413658, 0.034616678953170776, 0.02696320042014122, 0.033804766833782196, 0.030471082776784897, 0.03235762566328049, 0.032760828733444214, 0.031411200761795044, 0.031172187998890877, 0.029580235481262207, 0.03166511654853821, 0.03209812566637993, 0.028438063338398933, 0.007784705609083176]}
Train Epoch: 58 [0/816 (0%)] loss: 0.0166 L_si: 0.0009 L_grad: 0.0157 
Train Epoch: 58 [36/816 (4%)] loss: 0.0205 L_si: 0.0020 L_grad: 0.0185 
Train Epoch: 58 [72/816 (9%)] loss: 0.0189 L_si: 0.0018 L_grad: 0.0170 
Train Epoch: 58 [108/816 (13%)] loss: 0.0190 L_si: 0.0022 L_grad: 0.0168 
Train Epoch: 58 [144/816 (18%)] loss: 0.0184 L_si: 0.0027 L_grad: 0.0157 
Train Epoch: 58 [180/816 (22%)] loss: 0.0190 L_si: 0.0017 L_grad: 0.0173 
Train Epoch: 58 [216/816 (26%)] loss: 0.0182 L_si: 0.0013 L_grad: 0.0169 
Train Epoch: 58 [252/816 (31%)] loss: 0.0178 L_si: 0.0019 L_grad: 0.0159 
Train Epoch: 58 [288/816 (35%)] loss: 0.0149 L_si: 0.0009 L_grad: 0.0140 
Train Epoch: 58 [324/816 (40%)] loss: 0.0233 L_si: 0.0032 L_grad: 0.0201 
Train Epoch: 58 [360/816 (44%)] loss: 0.0232 L_si: 0.0025 L_grad: 0.0208 
Train Epoch: 58 [396/816 (49%)] loss: 0.0237 L_si: 0.0028 L_grad: 0.0209 
Train Epoch: 58 [432/816 (53%)] loss: 0.0211 L_si: 0.0032 L_grad: 0.0178 
Train Epoch: 58 [468/816 (57%)] loss: 0.0263 L_si: 0.0028 L_grad: 0.0235 
Train Epoch: 58 [504/816 (62%)] loss: 0.0200 L_si: 0.0027 L_grad: 0.0173 
Train Epoch: 58 [540/816 (66%)] loss: 0.0199 L_si: 0.0015 L_grad: 0.0185 
Train Epoch: 58 [576/816 (71%)] loss: 0.0179 L_si: 0.0021 L_grad: 0.0158 
Train Epoch: 58 [612/816 (75%)] loss: 0.0230 L_si: 0.0021 L_grad: 0.0209 
Train Epoch: 58 [648/816 (79%)] loss: 0.0138 L_si: 0.0007 L_grad: 0.0131 
Train Epoch: 58 [684/816 (84%)] loss: 0.0135 L_si: 0.0007 L_grad: 0.0128 
Train Epoch: 58 [720/816 (88%)] loss: 0.0191 L_si: 0.0014 L_grad: 0.0178 
Train Epoch: 58 [756/816 (93%)] loss: 0.0266 L_si: 0.0035 L_grad: 0.0231 
Train Epoch: 58 [792/816 (97%)] loss: 0.0174 L_si: 0.0014 L_grad: 0.0160 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.041516903787851334, 0.03913496434688568, 0.03706415742635727, 0.04083149880170822, 0.03992787003517151, 0.0382845401763916, 0.039982229471206665, 0.040325384587049484, 0.04099646210670471, 0.032350167632102966, 0.03509248420596123, 0.040113914757966995, 0.039155952632427216, 0.04261021316051483, 0.03764438256621361, 0.041349146515131, 0.035545311868190765, 0.030454926192760468, 0.01103328075259924], 'L_si': [0.006666786968708038, 0.007762730121612549, 0.007310457527637482, 0.006704777479171753, 0.007100619375705719, 0.00624963641166687, 0.006497666239738464, 0.005963489413261414, 0.006614819169044495, 0.004693035036325455, 0.006199926137924194, 0.008324429392814636, 0.005887866020202637, 0.006933718919754028, 0.005869314074516296, 0.0067667290568351746, 0.0055089071393013, 0.005185738205909729, 0.004432544112205505], 'L_grad': [0.034850116819143295, 0.03137223422527313, 0.029753701761364937, 0.03412672132253647, 0.03282725065946579, 0.03203490376472473, 0.0334845632314682, 0.03436189517378807, 0.03438164293766022, 0.02765713445842266, 0.028892558068037033, 0.03178948536515236, 0.03326808661222458, 0.0356764942407608, 0.03177506849169731, 0.03458241745829582, 0.030036406591534615, 0.02526918798685074, 0.006600736640393734]}
Train Epoch: 59 [0/816 (0%)] loss: 0.0199 L_si: 0.0023 L_grad: 0.0176 
Train Epoch: 59 [36/816 (4%)] loss: 0.0207 L_si: 0.0028 L_grad: 0.0178 
Train Epoch: 59 [72/816 (9%)] loss: 0.0165 L_si: 0.0011 L_grad: 0.0154 
Train Epoch: 59 [108/816 (13%)] loss: 0.0229 L_si: 0.0041 L_grad: 0.0189 
Train Epoch: 59 [144/816 (18%)] loss: 0.0229 L_si: 0.0024 L_grad: 0.0205 
Train Epoch: 59 [180/816 (22%)] loss: 0.0205 L_si: 0.0026 L_grad: 0.0178 
Train Epoch: 59 [216/816 (26%)] loss: 0.0220 L_si: 0.0023 L_grad: 0.0198 
Train Epoch: 59 [252/816 (31%)] loss: 0.0198 L_si: 0.0020 L_grad: 0.0178 
Train Epoch: 59 [288/816 (35%)] loss: 0.0250 L_si: 0.0025 L_grad: 0.0224 
Train Epoch: 59 [324/816 (40%)] loss: 0.0196 L_si: 0.0015 L_grad: 0.0180 
Train Epoch: 59 [360/816 (44%)] loss: 0.0200 L_si: 0.0021 L_grad: 0.0178 
Train Epoch: 59 [396/816 (49%)] loss: 0.0194 L_si: 0.0031 L_grad: 0.0163 
Train Epoch: 59 [432/816 (53%)] loss: 0.0170 L_si: 0.0015 L_grad: 0.0155 
Train Epoch: 59 [468/816 (57%)] loss: 0.0167 L_si: 0.0012 L_grad: 0.0155 
Train Epoch: 59 [504/816 (62%)] loss: 0.0210 L_si: 0.0018 L_grad: 0.0193 
Train Epoch: 59 [540/816 (66%)] loss: 0.0161 L_si: 0.0014 L_grad: 0.0148 
Train Epoch: 59 [576/816 (71%)] loss: 0.0170 L_si: 0.0014 L_grad: 0.0157 
Train Epoch: 59 [612/816 (75%)] loss: 0.0123 L_si: 0.0006 L_grad: 0.0117 
Train Epoch: 59 [648/816 (79%)] loss: 0.0229 L_si: 0.0038 L_grad: 0.0191 
Train Epoch: 59 [684/816 (84%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0143 
Train Epoch: 59 [720/816 (88%)] loss: 0.0221 L_si: 0.0033 L_grad: 0.0188 
Train Epoch: 59 [756/816 (93%)] loss: 0.0175 L_si: 0.0018 L_grad: 0.0158 
Train Epoch: 59 [792/816 (97%)] loss: 0.0252 L_si: 0.0035 L_grad: 0.0217 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03940385580062866, 0.03785710781812668, 0.03887448087334633, 0.040081799030303955, 0.03802378103137016, 0.03548102825880051, 0.038535166531801224, 0.03595411032438278, 0.04000129923224449, 0.036642130464315414, 0.04087913781404495, 0.038243040442466736, 0.042141471058130264, 0.039315126836299896, 0.03509101644158363, 0.03709324076771736, 0.039331208914518356, 0.03689860552549362, 0.010996848344802856], 'L_si': [0.0066199153661727905, 0.006726130843162537, 0.006752334535121918, 0.006386406719684601, 0.0063604190945625305, 0.007744528353214264, 0.005719318985939026, 0.006630688905715942, 0.006279692053794861, 0.005907215178012848, 0.006810642778873444, 0.005895435810089111, 0.0067385658621788025, 0.007250964641571045, 0.005872577428817749, 0.007178112864494324, 0.007153414189815521, 0.005772054195404053, 0.004646178334951401], 'L_grad': [0.03278394043445587, 0.03113097883760929, 0.03212214633822441, 0.033695392310619354, 0.03166336193680763, 0.027736501768231392, 0.0328158475458622, 0.02932341955602169, 0.03372160717844963, 0.030734915286302567, 0.03406849503517151, 0.032347604632377625, 0.03540290519595146, 0.03206416219472885, 0.029218439012765884, 0.029915127903223038, 0.032177794724702835, 0.03112655319273472, 0.006350670009851456]}
Train Epoch: 60 [0/816 (0%)] loss: 0.0170 L_si: 0.0012 L_grad: 0.0158 
Train Epoch: 60 [36/816 (4%)] loss: 0.0232 L_si: 0.0025 L_grad: 0.0207 
Train Epoch: 60 [72/816 (9%)] loss: 0.0228 L_si: 0.0029 L_grad: 0.0199 
Train Epoch: 60 [108/816 (13%)] loss: 0.0206 L_si: 0.0016 L_grad: 0.0190 
Train Epoch: 60 [144/816 (18%)] loss: 0.0257 L_si: 0.0038 L_grad: 0.0219 
Train Epoch: 60 [180/816 (22%)] loss: 0.0208 L_si: 0.0022 L_grad: 0.0187 
Train Epoch: 60 [216/816 (26%)] loss: 0.0196 L_si: 0.0020 L_grad: 0.0176 
Train Epoch: 60 [252/816 (31%)] loss: 0.0159 L_si: 0.0009 L_grad: 0.0150 
Train Epoch: 60 [288/816 (35%)] loss: 0.0224 L_si: 0.0025 L_grad: 0.0199 
Train Epoch: 60 [324/816 (40%)] loss: 0.0188 L_si: 0.0017 L_grad: 0.0171 
Train Epoch: 60 [360/816 (44%)] loss: 0.0183 L_si: 0.0018 L_grad: 0.0165 
Train Epoch: 60 [396/816 (49%)] loss: 0.0169 L_si: 0.0013 L_grad: 0.0156 
Train Epoch: 60 [432/816 (53%)] loss: 0.0182 L_si: 0.0014 L_grad: 0.0167 
Train Epoch: 60 [468/816 (57%)] loss: 0.0205 L_si: 0.0029 L_grad: 0.0176 
Train Epoch: 60 [504/816 (62%)] loss: 0.0180 L_si: 0.0011 L_grad: 0.0169 
Train Epoch: 60 [540/816 (66%)] loss: 0.0152 L_si: 0.0011 L_grad: 0.0140 
Train Epoch: 60 [576/816 (71%)] loss: 0.0177 L_si: 0.0024 L_grad: 0.0153 
Train Epoch: 60 [612/816 (75%)] loss: 0.0253 L_si: 0.0030 L_grad: 0.0223 
Train Epoch: 60 [648/816 (79%)] loss: 0.0295 L_si: 0.0084 L_grad: 0.0212 
Train Epoch: 60 [684/816 (84%)] loss: 0.0255 L_si: 0.0044 L_grad: 0.0211 
Train Epoch: 60 [720/816 (88%)] loss: 0.0159 L_si: 0.0012 L_grad: 0.0147 
Train Epoch: 60 [756/816 (93%)] loss: 0.0214 L_si: 0.0022 L_grad: 0.0191 
Train Epoch: 60 [792/816 (97%)] loss: 0.0239 L_si: 0.0024 L_grad: 0.0215 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch060-loss-0.0199.pth.tar ...
all losses in batch in validation:  {'loss': [0.03343915566802025, 0.03671515733003616, 0.03865380212664604, 0.035906627774238586, 0.03464629501104355, 0.0354733020067215, 0.03865291178226471, 0.03969131410121918, 0.04052946716547012, 0.03751245141029358, 0.0422172024846077, 0.028719555586576462, 0.03627417981624603, 0.03810732439160347, 0.03276566043496132, 0.03745642304420471, 0.04125359654426575, 0.04158438742160797, 0.012022155337035656], 'L_si': [0.005092740058898926, 0.0060310885310173035, 0.006009131669998169, 0.006128974258899689, 0.005692213773727417, 0.005841977894306183, 0.005544736981391907, 0.005812987685203552, 0.005788445472717285, 0.0060203224420547485, 0.007439121603965759, 0.004319466650485992, 0.0065515488386154175, 0.005956120789051056, 0.004708528518676758, 0.0051857829093933105, 0.006522126495838165, 0.006577529013156891, 0.005391635000705719], 'L_grad': [0.028346415609121323, 0.03068406879901886, 0.03264467045664787, 0.029777655377984047, 0.02895408309996128, 0.029631324112415314, 0.0331081748008728, 0.033878326416015625, 0.03474102169275284, 0.03149212896823883, 0.03477808088064194, 0.02440008893609047, 0.029722630977630615, 0.032151203602552414, 0.02805713191628456, 0.0322706401348114, 0.03473147004842758, 0.03500685840845108, 0.006630520336329937]}
Train Epoch: 61 [0/816 (0%)] loss: 0.0212 L_si: 0.0021 L_grad: 0.0191 
Train Epoch: 61 [36/816 (4%)] loss: 0.0298 L_si: 0.0035 L_grad: 0.0263 
Train Epoch: 61 [72/816 (9%)] loss: 0.0183 L_si: 0.0013 L_grad: 0.0169 
Train Epoch: 61 [108/816 (13%)] loss: 0.0208 L_si: 0.0027 L_grad: 0.0181 
Train Epoch: 61 [144/816 (18%)] loss: 0.0202 L_si: 0.0037 L_grad: 0.0165 
Train Epoch: 61 [180/816 (22%)] loss: 0.0170 L_si: 0.0021 L_grad: 0.0149 
Train Epoch: 61 [216/816 (26%)] loss: 0.0321 L_si: 0.0057 L_grad: 0.0265 
Train Epoch: 61 [252/816 (31%)] loss: 0.0149 L_si: 0.0009 L_grad: 0.0140 
Train Epoch: 61 [288/816 (35%)] loss: 0.0197 L_si: 0.0019 L_grad: 0.0177 
Train Epoch: 61 [324/816 (40%)] loss: 0.0216 L_si: 0.0018 L_grad: 0.0198 
Train Epoch: 61 [360/816 (44%)] loss: 0.0201 L_si: 0.0014 L_grad: 0.0187 
Train Epoch: 61 [396/816 (49%)] loss: 0.0169 L_si: 0.0017 L_grad: 0.0152 
Train Epoch: 61 [432/816 (53%)] loss: 0.0150 L_si: 0.0008 L_grad: 0.0142 
Train Epoch: 61 [468/816 (57%)] loss: 0.0227 L_si: 0.0027 L_grad: 0.0200 
Train Epoch: 61 [504/816 (62%)] loss: 0.0129 L_si: 0.0007 L_grad: 0.0122 
Train Epoch: 61 [540/816 (66%)] loss: 0.0184 L_si: 0.0013 L_grad: 0.0171 
Train Epoch: 61 [576/816 (71%)] loss: 0.0148 L_si: 0.0013 L_grad: 0.0135 
Train Epoch: 61 [612/816 (75%)] loss: 0.0197 L_si: 0.0016 L_grad: 0.0181 
Train Epoch: 61 [648/816 (79%)] loss: 0.0198 L_si: 0.0019 L_grad: 0.0179 
Train Epoch: 61 [684/816 (84%)] loss: 0.0171 L_si: 0.0017 L_grad: 0.0154 
Train Epoch: 61 [720/816 (88%)] loss: 0.0163 L_si: 0.0014 L_grad: 0.0149 
Train Epoch: 61 [756/816 (93%)] loss: 0.0197 L_si: 0.0018 L_grad: 0.0179 
Train Epoch: 61 [792/816 (97%)] loss: 0.0196 L_si: 0.0014 L_grad: 0.0182 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.035633742809295654, 0.032735675573349, 0.03834718465805054, 0.044225506484508514, 0.03901281580328941, 0.04132820665836334, 0.038506101816892624, 0.039932217448949814, 0.04183132201433182, 0.03590632975101471, 0.03806741163134575, 0.03731175512075424, 0.03812576085329056, 0.025212135165929794, 0.03306366875767708, 0.033847659826278687, 0.03555838763713837, 0.03723665326833725, 0.014513721689581871], 'L_si': [0.005430661141872406, 0.004393965005874634, 0.006357729434967041, 0.0067632198333740234, 0.0063664838671684265, 0.006108596920967102, 0.005989491939544678, 0.006143644452095032, 0.00716891884803772, 0.006134212017059326, 0.0067092254757881165, 0.005584880709648132, 0.005731634795665741, 0.002032354474067688, 0.005094282329082489, 0.005575120449066162, 0.0050234124064445496, 0.005612529814243317, 0.006480894982814789], 'L_grad': [0.0302030798047781, 0.028341708704829216, 0.031989455223083496, 0.03746228665113449, 0.03264633193612099, 0.03521960973739624, 0.032516609877347946, 0.03378857299685478, 0.0346624031662941, 0.029772117733955383, 0.03135818615555763, 0.03172687441110611, 0.03239412605762482, 0.023179780691862106, 0.02796938642859459, 0.028272541239857674, 0.030534977093338966, 0.03162412345409393, 0.008032826706767082]}
Train Epoch: 62 [0/816 (0%)] loss: 0.0158 L_si: 0.0009 L_grad: 0.0149 
Train Epoch: 62 [36/816 (4%)] loss: 0.0141 L_si: 0.0009 L_grad: 0.0131 
Train Epoch: 62 [72/816 (9%)] loss: 0.0269 L_si: 0.0024 L_grad: 0.0245 
Train Epoch: 62 [108/816 (13%)] loss: 0.0216 L_si: 0.0037 L_grad: 0.0179 
Train Epoch: 62 [144/816 (18%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 62 [180/816 (22%)] loss: 0.0214 L_si: 0.0031 L_grad: 0.0182 
Train Epoch: 62 [216/816 (26%)] loss: 0.0155 L_si: 0.0010 L_grad: 0.0146 
Train Epoch: 62 [252/816 (31%)] loss: 0.0242 L_si: 0.0030 L_grad: 0.0212 
Train Epoch: 62 [288/816 (35%)] loss: 0.0215 L_si: 0.0034 L_grad: 0.0181 
Train Epoch: 62 [324/816 (40%)] loss: 0.0196 L_si: 0.0016 L_grad: 0.0180 
Train Epoch: 62 [360/816 (44%)] loss: 0.0204 L_si: 0.0014 L_grad: 0.0190 
Train Epoch: 62 [396/816 (49%)] loss: 0.0152 L_si: 0.0013 L_grad: 0.0139 
Train Epoch: 62 [432/816 (53%)] loss: 0.0146 L_si: 0.0008 L_grad: 0.0138 
Train Epoch: 62 [468/816 (57%)] loss: 0.0199 L_si: 0.0020 L_grad: 0.0179 
Train Epoch: 62 [504/816 (62%)] loss: 0.0163 L_si: 0.0013 L_grad: 0.0150 
Train Epoch: 62 [540/816 (66%)] loss: 0.0217 L_si: 0.0021 L_grad: 0.0196 
Train Epoch: 62 [576/816 (71%)] loss: 0.0195 L_si: 0.0015 L_grad: 0.0180 
Train Epoch: 62 [612/816 (75%)] loss: 0.0222 L_si: 0.0040 L_grad: 0.0182 
Train Epoch: 62 [648/816 (79%)] loss: 0.0197 L_si: 0.0015 L_grad: 0.0182 
Train Epoch: 62 [684/816 (84%)] loss: 0.0195 L_si: 0.0025 L_grad: 0.0170 
Train Epoch: 62 [720/816 (88%)] loss: 0.0168 L_si: 0.0013 L_grad: 0.0155 
Train Epoch: 62 [756/816 (93%)] loss: 0.0282 L_si: 0.0051 L_grad: 0.0230 
Train Epoch: 62 [792/816 (97%)] loss: 0.0160 L_si: 0.0010 L_grad: 0.0150 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03689539059996605, 0.04478126019239426, 0.04308213293552399, 0.03767827898263931, 0.04024004191160202, 0.037559397518634796, 0.04290197789669037, 0.03797490894794464, 0.03992635756731033, 0.03918209299445152, 0.04228527098894119, 0.03695955127477646, 0.03653891757130623, 0.038791730999946594, 0.03947509080171585, 0.03810518980026245, 0.04295385628938675, 0.040644098073244095, 0.011996147222816944], 'L_si': [0.005674801766872406, 0.008939094841480255, 0.0077571868896484375, 0.0079207643866539, 0.007468268275260925, 0.006471104919910431, 0.007986009120941162, 0.006789661943912506, 0.0074315741658210754, 0.006804719567298889, 0.00796671211719513, 0.006356246769428253, 0.005626320838928223, 0.006167404353618622, 0.007171005010604858, 0.006472684442996979, 0.007094323635101318, 0.006700620055198669, 0.004744529724121094], 'L_grad': [0.031220588833093643, 0.035842165350914, 0.03532494604587555, 0.029757514595985413, 0.032771773636341095, 0.031088290736079216, 0.03491596877574921, 0.031185247004032135, 0.03249478340148926, 0.032377373427152634, 0.03431855887174606, 0.030603302642703056, 0.030912596732378006, 0.03262432664632797, 0.03230408579111099, 0.03163250535726547, 0.03585953265428543, 0.033943478018045425, 0.00725161749869585]}
Train Epoch: 63 [0/816 (0%)] loss: 0.0253 L_si: 0.0044 L_grad: 0.0209 
Train Epoch: 63 [36/816 (4%)] loss: 0.0195 L_si: 0.0017 L_grad: 0.0177 
Train Epoch: 63 [72/816 (9%)] loss: 0.0219 L_si: 0.0033 L_grad: 0.0186 
Train Epoch: 63 [108/816 (13%)] loss: 0.0172 L_si: 0.0015 L_grad: 0.0157 
Train Epoch: 63 [144/816 (18%)] loss: 0.0178 L_si: 0.0015 L_grad: 0.0163 
Train Epoch: 63 [180/816 (22%)] loss: 0.0255 L_si: 0.0030 L_grad: 0.0225 
Train Epoch: 63 [216/816 (26%)] loss: 0.0224 L_si: 0.0042 L_grad: 0.0182 
Train Epoch: 63 [252/816 (31%)] loss: 0.0191 L_si: 0.0018 L_grad: 0.0173 
Train Epoch: 63 [288/816 (35%)] loss: 0.0197 L_si: 0.0017 L_grad: 0.0180 
Train Epoch: 63 [324/816 (40%)] loss: 0.0192 L_si: 0.0018 L_grad: 0.0174 
Train Epoch: 63 [360/816 (44%)] loss: 0.0209 L_si: 0.0016 L_grad: 0.0193 
Train Epoch: 63 [396/816 (49%)] loss: 0.0169 L_si: 0.0015 L_grad: 0.0154 
Train Epoch: 63 [432/816 (53%)] loss: 0.0198 L_si: 0.0014 L_grad: 0.0184 
Train Epoch: 63 [468/816 (57%)] loss: 0.0216 L_si: 0.0015 L_grad: 0.0201 
Train Epoch: 63 [504/816 (62%)] loss: 0.0164 L_si: 0.0015 L_grad: 0.0149 
Train Epoch: 63 [540/816 (66%)] loss: 0.0151 L_si: 0.0012 L_grad: 0.0139 
Train Epoch: 63 [576/816 (71%)] loss: 0.0151 L_si: 0.0007 L_grad: 0.0143 
Train Epoch: 63 [612/816 (75%)] loss: 0.0232 L_si: 0.0049 L_grad: 0.0183 
Train Epoch: 63 [648/816 (79%)] loss: 0.0154 L_si: 0.0010 L_grad: 0.0144 
Train Epoch: 63 [684/816 (84%)] loss: 0.0196 L_si: 0.0023 L_grad: 0.0174 
Train Epoch: 63 [720/816 (88%)] loss: 0.0246 L_si: 0.0035 L_grad: 0.0211 
Train Epoch: 63 [756/816 (93%)] loss: 0.0228 L_si: 0.0022 L_grad: 0.0206 
Train Epoch: 63 [792/816 (97%)] loss: 0.0148 L_si: 0.0010 L_grad: 0.0138 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.038106635212898254, 0.03792569413781166, 0.038342393934726715, 0.03062170371413231, 0.03760407119989395, 0.04070732742547989, 0.03741680085659027, 0.035288162529468536, 0.03997442126274109, 0.03463000804185867, 0.03935464099049568, 0.03295767679810524, 0.038454607129096985, 0.03904375433921814, 0.0371720977127552, 0.03705885633826256, 0.04084441438317299, 0.041086480021476746, 0.013537833467125893], 'L_si': [0.006084375083446503, 0.006597079336643219, 0.006266199052333832, 0.004384227097034454, 0.0065964460372924805, 0.0056360214948654175, 0.005890712141990662, 0.004768349230289459, 0.006265915930271149, 0.004843413829803467, 0.005956001579761505, 0.005490995943546295, 0.005720734596252441, 0.006122469902038574, 0.006828472018241882, 0.006683379411697388, 0.006083749234676361, 0.0064536333084106445, 0.005006544291973114], 'L_grad': [0.03202226012945175, 0.03132861480116844, 0.03207619488239288, 0.026237476617097855, 0.03100762516260147, 0.03507130593061447, 0.03152608871459961, 0.030519813299179077, 0.03370850533246994, 0.029786592349410057, 0.03339863941073418, 0.027466680854558945, 0.03273387253284454, 0.032921284437179565, 0.03034362569451332, 0.03037547692656517, 0.03476066514849663, 0.0346328467130661, 0.008531289175152779]}
Train Epoch: 64 [0/816 (0%)] loss: 0.0247 L_si: 0.0039 L_grad: 0.0208 
Train Epoch: 64 [36/816 (4%)] loss: 0.0195 L_si: 0.0018 L_grad: 0.0177 
Train Epoch: 64 [72/816 (9%)] loss: 0.0180 L_si: 0.0014 L_grad: 0.0166 
Train Epoch: 64 [108/816 (13%)] loss: 0.0219 L_si: 0.0019 L_grad: 0.0200 
Train Epoch: 64 [144/816 (18%)] loss: 0.0194 L_si: 0.0015 L_grad: 0.0179 
Train Epoch: 64 [180/816 (22%)] loss: 0.0235 L_si: 0.0032 L_grad: 0.0203 
Train Epoch: 64 [216/816 (26%)] loss: 0.0246 L_si: 0.0034 L_grad: 0.0212 
Train Epoch: 64 [252/816 (31%)] loss: 0.0143 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 64 [288/816 (35%)] loss: 0.0193 L_si: 0.0013 L_grad: 0.0180 
Train Epoch: 64 [324/816 (40%)] loss: 0.0205 L_si: 0.0020 L_grad: 0.0185 
Train Epoch: 64 [360/816 (44%)] loss: 0.0187 L_si: 0.0016 L_grad: 0.0171 
Train Epoch: 64 [396/816 (49%)] loss: 0.0219 L_si: 0.0029 L_grad: 0.0190 
Train Epoch: 64 [432/816 (53%)] loss: 0.0227 L_si: 0.0025 L_grad: 0.0202 
Train Epoch: 64 [468/816 (57%)] loss: 0.0175 L_si: 0.0011 L_grad: 0.0164 
Train Epoch: 64 [504/816 (62%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 64 [540/816 (66%)] loss: 0.0188 L_si: 0.0018 L_grad: 0.0169 
Train Epoch: 64 [576/816 (71%)] loss: 0.0274 L_si: 0.0049 L_grad: 0.0225 
Train Epoch: 64 [612/816 (75%)] loss: 0.0174 L_si: 0.0015 L_grad: 0.0160 
Train Epoch: 64 [648/816 (79%)] loss: 0.0153 L_si: 0.0013 L_grad: 0.0140 
Train Epoch: 64 [684/816 (84%)] loss: 0.0169 L_si: 0.0009 L_grad: 0.0160 
Train Epoch: 64 [720/816 (88%)] loss: 0.0247 L_si: 0.0029 L_grad: 0.0218 
Train Epoch: 64 [756/816 (93%)] loss: 0.0180 L_si: 0.0016 L_grad: 0.0164 
Train Epoch: 64 [792/816 (97%)] loss: 0.0194 L_si: 0.0019 L_grad: 0.0174 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03404461219906807, 0.036339737474918365, 0.04045315831899643, 0.04001643508672714, 0.032817523926496506, 0.03904136270284653, 0.03894427418708801, 0.03750770166516304, 0.03703403100371361, 0.03595944494009018, 0.03883109986782074, 0.03909382224082947, 0.03884153440594673, 0.04104537144303322, 0.03773447126150131, 0.03523113206028938, 0.04372861981391907, 0.035926979035139084, 0.013763722032308578], 'L_si': [0.004942178726196289, 0.006105989217758179, 0.005998685956001282, 0.006366066634654999, 0.005139298737049103, 0.006841912865638733, 0.006161309778690338, 0.005691066384315491, 0.0066403597593307495, 0.005693003535270691, 0.006286174058914185, 0.005962558090686798, 0.006719015538692474, 0.006856933236122131, 0.0070914700627326965, 0.006026327610015869, 0.007685326039791107, 0.0051529258489608765, 0.006232075393199921], 'L_grad': [0.02910243347287178, 0.030233748257160187, 0.03445447236299515, 0.033650368452072144, 0.027678225189447403, 0.032199449837207794, 0.032782964408397675, 0.03181663528084755, 0.03039367124438286, 0.03026644140481949, 0.032544925808906555, 0.03313126415014267, 0.03212251886725426, 0.03418843820691109, 0.030642999336123466, 0.029204804450273514, 0.03604329377412796, 0.030774053186178207, 0.0075316461734473705]}
Train Epoch: 65 [0/816 (0%)] loss: 0.0198 L_si: 0.0019 L_grad: 0.0179 
Train Epoch: 65 [36/816 (4%)] loss: 0.0212 L_si: 0.0021 L_grad: 0.0191 
Train Epoch: 65 [72/816 (9%)] loss: 0.0196 L_si: 0.0018 L_grad: 0.0178 
Train Epoch: 65 [108/816 (13%)] loss: 0.0216 L_si: 0.0029 L_grad: 0.0187 
Train Epoch: 65 [144/816 (18%)] loss: 0.0175 L_si: 0.0014 L_grad: 0.0161 
Train Epoch: 65 [180/816 (22%)] loss: 0.0259 L_si: 0.0042 L_grad: 0.0217 
Train Epoch: 65 [216/816 (26%)] loss: 0.0276 L_si: 0.0032 L_grad: 0.0244 
Train Epoch: 65 [252/816 (31%)] loss: 0.0201 L_si: 0.0019 L_grad: 0.0181 
Train Epoch: 65 [288/816 (35%)] loss: 0.0181 L_si: 0.0014 L_grad: 0.0167 
Train Epoch: 65 [324/816 (40%)] loss: 0.0230 L_si: 0.0023 L_grad: 0.0207 
Train Epoch: 65 [360/816 (44%)] loss: 0.0210 L_si: 0.0024 L_grad: 0.0187 
Train Epoch: 65 [396/816 (49%)] loss: 0.0165 L_si: 0.0015 L_grad: 0.0150 
Train Epoch: 65 [432/816 (53%)] loss: 0.0185 L_si: 0.0028 L_grad: 0.0157 
Train Epoch: 65 [468/816 (57%)] loss: 0.0154 L_si: 0.0012 L_grad: 0.0142 
Train Epoch: 65 [504/816 (62%)] loss: 0.0185 L_si: 0.0017 L_grad: 0.0168 
Train Epoch: 65 [540/816 (66%)] loss: 0.0225 L_si: 0.0037 L_grad: 0.0187 
Train Epoch: 65 [576/816 (71%)] loss: 0.0192 L_si: 0.0020 L_grad: 0.0173 
Train Epoch: 65 [612/816 (75%)] loss: 0.0200 L_si: 0.0016 L_grad: 0.0184 
Train Epoch: 65 [648/816 (79%)] loss: 0.0203 L_si: 0.0025 L_grad: 0.0179 
Train Epoch: 65 [684/816 (84%)] loss: 0.0231 L_si: 0.0032 L_grad: 0.0199 
Train Epoch: 65 [720/816 (88%)] loss: 0.0213 L_si: 0.0026 L_grad: 0.0187 
Train Epoch: 65 [756/816 (93%)] loss: 0.0151 L_si: 0.0011 L_grad: 0.0140 
Train Epoch: 65 [792/816 (97%)] loss: 0.0192 L_si: 0.0018 L_grad: 0.0175 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.036667510867118835, 0.04049680382013321, 0.03859126940369606, 0.030391313135623932, 0.03567931056022644, 0.040212638676166534, 0.03880566358566284, 0.03555547446012497, 0.041548579931259155, 0.03828924149274826, 0.036858923733234406, 0.03688591718673706, 0.03661787137389183, 0.03260139748454094, 0.03633832558989525, 0.03850717470049858, 0.03746110945940018, 0.03844337910413742, 0.0065918429754674435], 'L_si': [0.006020955741405487, 0.007553949952125549, 0.005206063389778137, 0.005125582218170166, 0.005999520421028137, 0.005216591060161591, 0.0069227442145347595, 0.005251072347164154, 0.007521763443946838, 0.005840092897415161, 0.006279744207859039, 0.005446590483188629, 0.006215028464794159, 0.005352519452571869, 0.005804084241390228, 0.006479524075984955, 0.005692586302757263, 0.0063216909766197205, 0.0011503174901008606], 'L_grad': [0.030646556988358498, 0.03294285386800766, 0.03338520601391792, 0.025265730917453766, 0.029679788276553154, 0.034996047616004944, 0.03188291937112808, 0.030304402112960815, 0.03402681648731232, 0.0324491485953331, 0.030579177662730217, 0.03143932670354843, 0.03040284290909767, 0.02724887803196907, 0.03053424134850502, 0.032027650624513626, 0.031768523156642914, 0.0321216881275177, 0.005441525485366583]}
Train Epoch: 66 [0/816 (0%)] loss: 0.0285 L_si: 0.0038 L_grad: 0.0247 
Train Epoch: 66 [36/816 (4%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0158 
Train Epoch: 66 [72/816 (9%)] loss: 0.0188 L_si: 0.0025 L_grad: 0.0163 
Train Epoch: 66 [108/816 (13%)] loss: 0.0149 L_si: 0.0009 L_grad: 0.0140 
Train Epoch: 66 [144/816 (18%)] loss: 0.0222 L_si: 0.0027 L_grad: 0.0195 
Train Epoch: 66 [180/816 (22%)] loss: 0.0204 L_si: 0.0019 L_grad: 0.0185 
Train Epoch: 66 [216/816 (26%)] loss: 0.0179 L_si: 0.0015 L_grad: 0.0164 
Train Epoch: 66 [252/816 (31%)] loss: 0.0274 L_si: 0.0036 L_grad: 0.0238 
Train Epoch: 66 [288/816 (35%)] loss: 0.0183 L_si: 0.0013 L_grad: 0.0170 
Train Epoch: 66 [324/816 (40%)] loss: 0.0238 L_si: 0.0034 L_grad: 0.0204 
Train Epoch: 66 [360/816 (44%)] loss: 0.0224 L_si: 0.0024 L_grad: 0.0200 
Train Epoch: 66 [396/816 (49%)] loss: 0.0203 L_si: 0.0017 L_grad: 0.0186 
Train Epoch: 66 [432/816 (53%)] loss: 0.0176 L_si: 0.0014 L_grad: 0.0163 
Train Epoch: 66 [468/816 (57%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0161 
Train Epoch: 66 [504/816 (62%)] loss: 0.0188 L_si: 0.0014 L_grad: 0.0174 
Train Epoch: 66 [540/816 (66%)] loss: 0.0149 L_si: 0.0010 L_grad: 0.0139 
Train Epoch: 66 [576/816 (71%)] loss: 0.0204 L_si: 0.0022 L_grad: 0.0182 
Train Epoch: 66 [612/816 (75%)] loss: 0.0179 L_si: 0.0014 L_grad: 0.0165 
Train Epoch: 66 [648/816 (79%)] loss: 0.0181 L_si: 0.0020 L_grad: 0.0161 
Train Epoch: 66 [684/816 (84%)] loss: 0.0204 L_si: 0.0030 L_grad: 0.0173 
Train Epoch: 66 [720/816 (88%)] loss: 0.0204 L_si: 0.0029 L_grad: 0.0175 
Train Epoch: 66 [756/816 (93%)] loss: 0.0198 L_si: 0.0022 L_grad: 0.0176 
Train Epoch: 66 [792/816 (97%)] loss: 0.0275 L_si: 0.0035 L_grad: 0.0240 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04069649055600166, 0.03746230900287628, 0.03674381226301193, 0.04655260592699051, 0.03635486215353012, 0.041000060737133026, 0.03410692885518074, 0.04193335771560669, 0.037959009408950806, 0.038685280829668045, 0.04418127238750458, 0.0336608961224556, 0.03832177072763443, 0.045947831124067307, 0.04049576446413994, 0.03808475285768509, 0.0397447794675827, 0.037968166172504425, 0.019295044243335724], 'L_si': [0.007075019180774689, 0.006719626486301422, 0.006502315402030945, 0.008392028510570526, 0.006575532257556915, 0.00727466493844986, 0.006769917905330658, 0.008064709603786469, 0.00752982497215271, 0.007810458540916443, 0.008236445486545563, 0.005527958273887634, 0.006755620241165161, 0.008308663964271545, 0.005581483244895935, 0.007267408072948456, 0.007005877792835236, 0.007169075310230255, 0.009305350482463837], 'L_grad': [0.033621471375226974, 0.03074268065392971, 0.03024149499833584, 0.03816057741641998, 0.029779329895973206, 0.033725395798683167, 0.027337010949850082, 0.03386864811182022, 0.030429186299443245, 0.030874822288751602, 0.035944826900959015, 0.028132935985922813, 0.03156615048646927, 0.03763916715979576, 0.034914281219244, 0.030817346647381783, 0.03273890167474747, 0.03079908899962902, 0.009989693760871887]}
Train Epoch: 67 [0/816 (0%)] loss: 0.0195 L_si: 0.0022 L_grad: 0.0173 
Train Epoch: 67 [36/816 (4%)] loss: 0.0261 L_si: 0.0051 L_grad: 0.0210 
Train Epoch: 67 [72/816 (9%)] loss: 0.0276 L_si: 0.0043 L_grad: 0.0233 
Train Epoch: 67 [108/816 (13%)] loss: 0.0240 L_si: 0.0029 L_grad: 0.0211 
Train Epoch: 67 [144/816 (18%)] loss: 0.0178 L_si: 0.0013 L_grad: 0.0165 
Train Epoch: 67 [180/816 (22%)] loss: 0.0154 L_si: 0.0010 L_grad: 0.0144 
Train Epoch: 67 [216/816 (26%)] loss: 0.0138 L_si: 0.0014 L_grad: 0.0124 
Train Epoch: 67 [252/816 (31%)] loss: 0.0228 L_si: 0.0028 L_grad: 0.0199 
Train Epoch: 67 [288/816 (35%)] loss: 0.0150 L_si: 0.0007 L_grad: 0.0143 
Train Epoch: 67 [324/816 (40%)] loss: 0.0225 L_si: 0.0019 L_grad: 0.0206 
Train Epoch: 67 [360/816 (44%)] loss: 0.0166 L_si: 0.0013 L_grad: 0.0153 
Train Epoch: 67 [396/816 (49%)] loss: 0.0181 L_si: 0.0016 L_grad: 0.0165 
Train Epoch: 67 [432/816 (53%)] loss: 0.0202 L_si: 0.0021 L_grad: 0.0181 
Train Epoch: 67 [468/816 (57%)] loss: 0.0178 L_si: 0.0016 L_grad: 0.0161 
Train Epoch: 67 [504/816 (62%)] loss: 0.0210 L_si: 0.0017 L_grad: 0.0194 
Train Epoch: 67 [540/816 (66%)] loss: 0.0215 L_si: 0.0020 L_grad: 0.0195 
Train Epoch: 67 [576/816 (71%)] loss: 0.0141 L_si: 0.0007 L_grad: 0.0134 
Train Epoch: 67 [612/816 (75%)] loss: 0.0218 L_si: 0.0027 L_grad: 0.0190 
Train Epoch: 67 [648/816 (79%)] loss: 0.0170 L_si: 0.0015 L_grad: 0.0155 
Train Epoch: 67 [684/816 (84%)] loss: 0.0217 L_si: 0.0029 L_grad: 0.0188 
Train Epoch: 67 [720/816 (88%)] loss: 0.0174 L_si: 0.0014 L_grad: 0.0160 
Train Epoch: 67 [756/816 (93%)] loss: 0.0228 L_si: 0.0028 L_grad: 0.0200 
Train Epoch: 67 [792/816 (97%)] loss: 0.0225 L_si: 0.0035 L_grad: 0.0190 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040278855711221695, 0.03679809346795082, 0.03747190162539482, 0.040285706520080566, 0.037407178431749344, 0.03787293657660484, 0.03598818928003311, 0.036933258175849915, 0.032283760607242584, 0.03579907491803169, 0.04428505897521973, 0.03805316984653473, 0.04015578329563141, 0.04096406325697899, 0.03528233990073204, 0.037648580968379974, 0.040213219821453094, 0.03207012638449669, 0.013338685035705566], 'L_si': [0.004994891583919525, 0.005776919424533844, 0.0068846195936203, 0.0056975483894348145, 0.006305590271949768, 0.006351955235004425, 0.0060503482818603516, 0.0061988383531570435, 0.00530657172203064, 0.006540954113006592, 0.007183775305747986, 0.006022162735462189, 0.0063850730657577515, 0.005941033363342285, 0.0060822442173957825, 0.006317473948001862, 0.007348902523517609, 0.0055427998304367065, 0.005738668143749237], 'L_grad': [0.03528396412730217, 0.031021174043416977, 0.03058728203177452, 0.03458815813064575, 0.031101588159799576, 0.03152098134160042, 0.02993784099817276, 0.03073441982269287, 0.026977190747857094, 0.0292581208050251, 0.03710128366947174, 0.03203100711107254, 0.03377071022987366, 0.035023029893636703, 0.029200095683336258, 0.03133110702037811, 0.032864317297935486, 0.026527326554059982, 0.007600016891956329]}
Train Epoch: 68 [0/816 (0%)] loss: 0.0161 L_si: 0.0014 L_grad: 0.0147 
Train Epoch: 68 [36/816 (4%)] loss: 0.0186 L_si: 0.0019 L_grad: 0.0167 
Train Epoch: 68 [72/816 (9%)] loss: 0.0143 L_si: 0.0007 L_grad: 0.0136 
Train Epoch: 68 [108/816 (13%)] loss: 0.0143 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 68 [144/816 (18%)] loss: 0.0180 L_si: 0.0017 L_grad: 0.0163 
Train Epoch: 68 [180/816 (22%)] loss: 0.0220 L_si: 0.0027 L_grad: 0.0193 
Train Epoch: 68 [216/816 (26%)] loss: 0.0157 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 68 [252/816 (31%)] loss: 0.0167 L_si: 0.0011 L_grad: 0.0156 
Train Epoch: 68 [288/816 (35%)] loss: 0.0189 L_si: 0.0015 L_grad: 0.0174 
Train Epoch: 68 [324/816 (40%)] loss: 0.0131 L_si: 0.0006 L_grad: 0.0125 
Train Epoch: 68 [360/816 (44%)] loss: 0.0197 L_si: 0.0017 L_grad: 0.0180 
Train Epoch: 68 [396/816 (49%)] loss: 0.0184 L_si: 0.0018 L_grad: 0.0165 
Train Epoch: 68 [432/816 (53%)] loss: 0.0200 L_si: 0.0018 L_grad: 0.0183 
Train Epoch: 68 [468/816 (57%)] loss: 0.0205 L_si: 0.0020 L_grad: 0.0185 
Train Epoch: 68 [504/816 (62%)] loss: 0.0310 L_si: 0.0044 L_grad: 0.0266 
Train Epoch: 68 [540/816 (66%)] loss: 0.0191 L_si: 0.0020 L_grad: 0.0171 
Train Epoch: 68 [576/816 (71%)] loss: 0.0204 L_si: 0.0016 L_grad: 0.0188 
Train Epoch: 68 [612/816 (75%)] loss: 0.0212 L_si: 0.0031 L_grad: 0.0180 
Train Epoch: 68 [648/816 (79%)] loss: 0.0167 L_si: 0.0010 L_grad: 0.0157 
Train Epoch: 68 [684/816 (84%)] loss: 0.0180 L_si: 0.0022 L_grad: 0.0158 
Train Epoch: 68 [720/816 (88%)] loss: 0.0189 L_si: 0.0012 L_grad: 0.0177 
Train Epoch: 68 [756/816 (93%)] loss: 0.0157 L_si: 0.0013 L_grad: 0.0144 
Train Epoch: 68 [792/816 (97%)] loss: 0.0165 L_si: 0.0016 L_grad: 0.0149 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03453212231397629, 0.04389907419681549, 0.0372530072927475, 0.03653417527675629, 0.037506621330976486, 0.03699056804180145, 0.03851038217544556, 0.030382905155420303, 0.03446640446782112, 0.03790360689163208, 0.03731768950819969, 0.03865706920623779, 0.040447644889354706, 0.038191620260477066, 0.040757447481155396, 0.034754328429698944, 0.03258422017097473, 0.03473992645740509, 0.01121936272829771], 'L_si': [0.004882737994194031, 0.006104357540607452, 0.004871860146522522, 0.005873784422874451, 0.005291394889354706, 0.0062708184123039246, 0.005610719323158264, 0.0036732107400894165, 0.004701778292655945, 0.005626074969768524, 0.005057193338871002, 0.006047531962394714, 0.0070148855447769165, 0.006677865982055664, 0.00620008260011673, 0.005962677299976349, 0.004604868590831757, 0.0054425522685050964, 0.004335612058639526], 'L_grad': [0.029649382457137108, 0.03779471665620804, 0.032381147146224976, 0.030660390853881836, 0.03221522644162178, 0.030719751492142677, 0.03289966285228729, 0.026709694415330887, 0.029764626175165176, 0.032277531921863556, 0.03226049616932869, 0.03260953724384308, 0.03343275934457779, 0.0315137542784214, 0.034557364881038666, 0.028791649267077446, 0.027979349717497826, 0.029297372326254845, 0.006883750669658184]}
Train Epoch: 69 [0/816 (0%)] loss: 0.0212 L_si: 0.0026 L_grad: 0.0185 
Train Epoch: 69 [36/816 (4%)] loss: 0.0203 L_si: 0.0019 L_grad: 0.0184 
Train Epoch: 69 [72/816 (9%)] loss: 0.0237 L_si: 0.0022 L_grad: 0.0215 
Train Epoch: 69 [108/816 (13%)] loss: 0.0197 L_si: 0.0019 L_grad: 0.0178 
Train Epoch: 69 [144/816 (18%)] loss: 0.0176 L_si: 0.0016 L_grad: 0.0160 
Train Epoch: 69 [180/816 (22%)] loss: 0.0214 L_si: 0.0045 L_grad: 0.0169 
Train Epoch: 69 [216/816 (26%)] loss: 0.0215 L_si: 0.0031 L_grad: 0.0184 
Train Epoch: 69 [252/816 (31%)] loss: 0.0192 L_si: 0.0025 L_grad: 0.0167 
Train Epoch: 69 [288/816 (35%)] loss: 0.0209 L_si: 0.0018 L_grad: 0.0191 
Train Epoch: 69 [324/816 (40%)] loss: 0.0330 L_si: 0.0060 L_grad: 0.0271 
Train Epoch: 69 [360/816 (44%)] loss: 0.0150 L_si: 0.0011 L_grad: 0.0139 
Train Epoch: 69 [396/816 (49%)] loss: 0.0220 L_si: 0.0040 L_grad: 0.0180 
Train Epoch: 69 [432/816 (53%)] loss: 0.0152 L_si: 0.0012 L_grad: 0.0140 
Train Epoch: 69 [468/816 (57%)] loss: 0.0153 L_si: 0.0012 L_grad: 0.0141 
Train Epoch: 69 [504/816 (62%)] loss: 0.0167 L_si: 0.0015 L_grad: 0.0152 
Train Epoch: 69 [540/816 (66%)] loss: 0.0202 L_si: 0.0016 L_grad: 0.0186 
Train Epoch: 69 [576/816 (71%)] loss: 0.0166 L_si: 0.0014 L_grad: 0.0152 
Train Epoch: 69 [612/816 (75%)] loss: 0.0142 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 69 [648/816 (79%)] loss: 0.0226 L_si: 0.0033 L_grad: 0.0192 
Train Epoch: 69 [684/816 (84%)] loss: 0.0131 L_si: 0.0007 L_grad: 0.0124 
Train Epoch: 69 [720/816 (88%)] loss: 0.0163 L_si: 0.0009 L_grad: 0.0153 
Train Epoch: 69 [756/816 (93%)] loss: 0.0164 L_si: 0.0016 L_grad: 0.0148 
Train Epoch: 69 [792/816 (97%)] loss: 0.0155 L_si: 0.0009 L_grad: 0.0145 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03947613388299942, 0.035048604011535645, 0.034308865666389465, 0.04124211519956589, 0.038380082696676254, 0.03701087832450867, 0.0396365150809288, 0.03655971586704254, 0.0376567468047142, 0.03380165249109268, 0.03667997941374779, 0.039201442152261734, 0.03711812198162079, 0.03990602120757103, 0.04545293748378754, 0.03798568248748779, 0.036900363862514496, 0.038638804107904434, 0.014531737193465233], 'L_si': [0.006714388728141785, 0.0056266337633132935, 0.004967071115970612, 0.006477706134319305, 0.006977565586566925, 0.006683178246021271, 0.006854787468910217, 0.007079280912876129, 0.007109880447387695, 0.0053823962807655334, 0.006187751889228821, 0.0065463632345199585, 0.005896024405956268, 0.006629742681980133, 0.0080905482172966, 0.006681911647319794, 0.005803465843200684, 0.0062909796833992004, 0.006175018846988678], 'L_grad': [0.032761745154857635, 0.029421968385577202, 0.029341796413064003, 0.03476440906524658, 0.03140251711010933, 0.030327700078487396, 0.032781727612018585, 0.029480433091521263, 0.03054686449468136, 0.028419254347682, 0.030492227524518967, 0.032655078917741776, 0.03122209757566452, 0.0332762785255909, 0.037362389266490936, 0.031303770840168, 0.031096896156668663, 0.032347824424505234, 0.008356718346476555]}
Train Epoch: 70 [0/816 (0%)] loss: 0.0230 L_si: 0.0017 L_grad: 0.0213 
Train Epoch: 70 [36/816 (4%)] loss: 0.0187 L_si: 0.0014 L_grad: 0.0173 
Train Epoch: 70 [72/816 (9%)] loss: 0.0155 L_si: 0.0008 L_grad: 0.0147 
Train Epoch: 70 [108/816 (13%)] loss: 0.0188 L_si: 0.0012 L_grad: 0.0177 
Train Epoch: 70 [144/816 (18%)] loss: 0.0162 L_si: 0.0015 L_grad: 0.0147 
Train Epoch: 70 [180/816 (22%)] loss: 0.0181 L_si: 0.0012 L_grad: 0.0168 
Train Epoch: 70 [216/816 (26%)] loss: 0.0209 L_si: 0.0034 L_grad: 0.0175 
Train Epoch: 70 [252/816 (31%)] loss: 0.0185 L_si: 0.0013 L_grad: 0.0172 
Train Epoch: 70 [288/816 (35%)] loss: 0.0149 L_si: 0.0011 L_grad: 0.0138 
Train Epoch: 70 [324/816 (40%)] loss: 0.0147 L_si: 0.0007 L_grad: 0.0139 
Train Epoch: 70 [360/816 (44%)] loss: 0.0247 L_si: 0.0031 L_grad: 0.0216 
Train Epoch: 70 [396/816 (49%)] loss: 0.0212 L_si: 0.0025 L_grad: 0.0186 
Train Epoch: 70 [432/816 (53%)] loss: 0.0181 L_si: 0.0022 L_grad: 0.0159 
Train Epoch: 70 [468/816 (57%)] loss: 0.0257 L_si: 0.0028 L_grad: 0.0229 
Train Epoch: 70 [504/816 (62%)] loss: 0.0219 L_si: 0.0020 L_grad: 0.0199 
Train Epoch: 70 [540/816 (66%)] loss: 0.0188 L_si: 0.0031 L_grad: 0.0157 
Train Epoch: 70 [576/816 (71%)] loss: 0.0154 L_si: 0.0010 L_grad: 0.0144 
Train Epoch: 70 [612/816 (75%)] loss: 0.0301 L_si: 0.0036 L_grad: 0.0265 
Train Epoch: 70 [648/816 (79%)] loss: 0.0201 L_si: 0.0021 L_grad: 0.0181 
Train Epoch: 70 [684/816 (84%)] loss: 0.0146 L_si: 0.0009 L_grad: 0.0137 
Train Epoch: 70 [720/816 (88%)] loss: 0.0226 L_si: 0.0029 L_grad: 0.0196 
Train Epoch: 70 [756/816 (93%)] loss: 0.0172 L_si: 0.0018 L_grad: 0.0154 
Train Epoch: 70 [792/816 (97%)] loss: 0.0189 L_si: 0.0019 L_grad: 0.0170 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch070-loss-0.0190.pth.tar ...
all losses in batch in validation:  {'loss': [0.03662342578172684, 0.037411317229270935, 0.03332819789648056, 0.03529610112309456, 0.04070501774549484, 0.038733404129743576, 0.03177572041749954, 0.03604551777243614, 0.03986363857984543, 0.044130727648735046, 0.03775976598262787, 0.04124641418457031, 0.038200609385967255, 0.036796048283576965, 0.03729171305894852, 0.03776245564222336, 0.042278025299310684, 0.03833388537168503, 0.014006592333316803], 'L_si': [0.006522282958030701, 0.006380908191204071, 0.00478922575712204, 0.005912028253078461, 0.0069986432790756226, 0.006152525544166565, 0.005487628281116486, 0.00628700852394104, 0.0065901875495910645, 0.0074432045221328735, 0.006904713809490204, 0.005416251718997955, 0.00653771311044693, 0.006740666925907135, 0.006395839154720306, 0.00657770037651062, 0.006471753120422363, 0.006462104618549347, 0.00448048859834671], 'L_grad': [0.030101144686341286, 0.031030410900712013, 0.02853897213935852, 0.029384072870016098, 0.03370637446641922, 0.03258087858557701, 0.026288092136383057, 0.029758509248495102, 0.033273451030254364, 0.03668752312660217, 0.030855050310492516, 0.03583016246557236, 0.031662896275520325, 0.03005538322031498, 0.03089587390422821, 0.03118475340306759, 0.03580627217888832, 0.03187178075313568, 0.009526103734970093]}
Train Epoch: 71 [0/816 (0%)] loss: 0.0164 L_si: 0.0011 L_grad: 0.0153 
Train Epoch: 71 [36/816 (4%)] loss: 0.0185 L_si: 0.0016 L_grad: 0.0169 
Train Epoch: 71 [72/816 (9%)] loss: 0.0162 L_si: 0.0012 L_grad: 0.0151 
Train Epoch: 71 [108/816 (13%)] loss: 0.0256 L_si: 0.0030 L_grad: 0.0225 
Train Epoch: 71 [144/816 (18%)] loss: 0.0168 L_si: 0.0016 L_grad: 0.0152 
Train Epoch: 71 [180/816 (22%)] loss: 0.0272 L_si: 0.0038 L_grad: 0.0235 
Train Epoch: 71 [216/816 (26%)] loss: 0.0143 L_si: 0.0009 L_grad: 0.0135 
Train Epoch: 71 [252/816 (31%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0157 
Train Epoch: 71 [288/816 (35%)] loss: 0.0152 L_si: 0.0015 L_grad: 0.0137 
Train Epoch: 71 [324/816 (40%)] loss: 0.0236 L_si: 0.0022 L_grad: 0.0214 
Train Epoch: 71 [360/816 (44%)] loss: 0.0236 L_si: 0.0023 L_grad: 0.0214 
Train Epoch: 71 [396/816 (49%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0142 
Train Epoch: 71 [432/816 (53%)] loss: 0.0202 L_si: 0.0017 L_grad: 0.0185 
Train Epoch: 71 [468/816 (57%)] loss: 0.0143 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 71 [504/816 (62%)] loss: 0.0201 L_si: 0.0023 L_grad: 0.0178 
Train Epoch: 71 [540/816 (66%)] loss: 0.0211 L_si: 0.0033 L_grad: 0.0178 
Train Epoch: 71 [576/816 (71%)] loss: 0.0185 L_si: 0.0014 L_grad: 0.0171 
Train Epoch: 71 [612/816 (75%)] loss: 0.0173 L_si: 0.0014 L_grad: 0.0159 
Train Epoch: 71 [648/816 (79%)] loss: 0.0203 L_si: 0.0027 L_grad: 0.0176 
Train Epoch: 71 [684/816 (84%)] loss: 0.0149 L_si: 0.0008 L_grad: 0.0140 
Train Epoch: 71 [720/816 (88%)] loss: 0.0176 L_si: 0.0019 L_grad: 0.0157 
Train Epoch: 71 [756/816 (93%)] loss: 0.0188 L_si: 0.0012 L_grad: 0.0177 
Train Epoch: 71 [792/816 (97%)] loss: 0.0227 L_si: 0.0030 L_grad: 0.0196 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03530443459749222, 0.04401463642716408, 0.03547278046607971, 0.03499418497085571, 0.039554644376039505, 0.041087839752435684, 0.04052058979868889, 0.030804699286818504, 0.03800966218113899, 0.0400778129696846, 0.041502878069877625, 0.03866732865571976, 0.04256092756986618, 0.04533608257770538, 0.033708006143569946, 0.038688283413648605, 0.03664889931678772, 0.042374394834041595, 0.01609235629439354], 'L_si': [0.006213396787643433, 0.008429810404777527, 0.006495565176010132, 0.006218522787094116, 0.006572529673576355, 0.00681576132774353, 0.007146552205085754, 0.005411744117736816, 0.007046565413475037, 0.006806850433349609, 0.008621089160442352, 0.007894270122051239, 0.006823383271694183, 0.009122423827648163, 0.005660109221935272, 0.00676562637090683, 0.005938529968261719, 0.008165910840034485, 0.006892025470733643], 'L_grad': [0.029091037809848785, 0.03558482602238655, 0.02897721529006958, 0.028775662183761597, 0.03298211470246315, 0.034272078424692154, 0.033374037593603134, 0.025392955169081688, 0.030963096767663956, 0.03327096253633499, 0.03288178890943527, 0.030773058533668518, 0.035737544298172, 0.03621365875005722, 0.028047898784279823, 0.031922657042741776, 0.030710369348526, 0.03420848399400711, 0.009200329892337322]}
Train Epoch: 72 [0/816 (0%)] loss: 0.0162 L_si: 0.0016 L_grad: 0.0147 
Train Epoch: 72 [36/816 (4%)] loss: 0.0146 L_si: 0.0010 L_grad: 0.0136 
Train Epoch: 72 [72/816 (9%)] loss: 0.0105 L_si: 0.0004 L_grad: 0.0101 
Train Epoch: 72 [108/816 (13%)] loss: 0.0119 L_si: 0.0005 L_grad: 0.0114 
Train Epoch: 72 [144/816 (18%)] loss: 0.0122 L_si: 0.0007 L_grad: 0.0115 
Train Epoch: 72 [180/816 (22%)] loss: 0.0174 L_si: 0.0012 L_grad: 0.0162 
Train Epoch: 72 [216/816 (26%)] loss: 0.0197 L_si: 0.0030 L_grad: 0.0167 
Train Epoch: 72 [252/816 (31%)] loss: 0.0240 L_si: 0.0023 L_grad: 0.0217 
Train Epoch: 72 [288/816 (35%)] loss: 0.0173 L_si: 0.0020 L_grad: 0.0154 
Train Epoch: 72 [324/816 (40%)] loss: 0.0158 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 72 [360/816 (44%)] loss: 0.0150 L_si: 0.0011 L_grad: 0.0139 
Train Epoch: 72 [396/816 (49%)] loss: 0.0217 L_si: 0.0031 L_grad: 0.0186 
Train Epoch: 72 [432/816 (53%)] loss: 0.0184 L_si: 0.0015 L_grad: 0.0169 
Train Epoch: 72 [468/816 (57%)] loss: 0.0250 L_si: 0.0041 L_grad: 0.0209 
Train Epoch: 72 [504/816 (62%)] loss: 0.0202 L_si: 0.0022 L_grad: 0.0180 
Train Epoch: 72 [540/816 (66%)] loss: 0.0177 L_si: 0.0016 L_grad: 0.0161 
Train Epoch: 72 [576/816 (71%)] loss: 0.0140 L_si: 0.0011 L_grad: 0.0129 
Train Epoch: 72 [612/816 (75%)] loss: 0.0161 L_si: 0.0016 L_grad: 0.0145 
Train Epoch: 72 [648/816 (79%)] loss: 0.0150 L_si: 0.0008 L_grad: 0.0142 
Train Epoch: 72 [684/816 (84%)] loss: 0.0154 L_si: 0.0015 L_grad: 0.0139 
Train Epoch: 72 [720/816 (88%)] loss: 0.0176 L_si: 0.0015 L_grad: 0.0161 
Train Epoch: 72 [756/816 (93%)] loss: 0.0169 L_si: 0.0013 L_grad: 0.0156 
Train Epoch: 72 [792/816 (97%)] loss: 0.0134 L_si: 0.0015 L_grad: 0.0118 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03588687628507614, 0.043779157102108, 0.037350475788116455, 0.037650253623723984, 0.039183929562568665, 0.03697727993130684, 0.04133405536413193, 0.04085470736026764, 0.039518631994724274, 0.03196334093809128, 0.039622824639081955, 0.041574109345674515, 0.04050059616565704, 0.03641842305660248, 0.0392431803047657, 0.03766466677188873, 0.03783518075942993, 0.04005911946296692, 0.012393921613693237], 'L_si': [0.006509110331535339, 0.008036985993385315, 0.006671153008937836, 0.006576366722583771, 0.00662606954574585, 0.00618155300617218, 0.007377289235591888, 0.008349865674972534, 0.007760457694530487, 0.004084371030330658, 0.007144026458263397, 0.0072785913944244385, 0.005735024809837341, 0.0066271498799324036, 0.007686540484428406, 0.007329680025577545, 0.006447039544582367, 0.0067101940512657166, 0.00500711053609848], 'L_grad': [0.02937776781618595, 0.03574217110872269, 0.03067932091653347, 0.031073886901140213, 0.032557860016822815, 0.03079572692513466, 0.03395676612854004, 0.032504841685295105, 0.03175817430019379, 0.02787896990776062, 0.03247879818081856, 0.034295517951250076, 0.0347655713558197, 0.029791273176670074, 0.031556639820337296, 0.030334988608956337, 0.031388141214847565, 0.0333489254117012, 0.007386811077594757]}
Train Epoch: 73 [0/816 (0%)] loss: 0.0166 L_si: 0.0013 L_grad: 0.0152 
Train Epoch: 73 [36/816 (4%)] loss: 0.0236 L_si: 0.0028 L_grad: 0.0208 
Train Epoch: 73 [72/816 (9%)] loss: 0.0146 L_si: 0.0009 L_grad: 0.0138 
Train Epoch: 73 [108/816 (13%)] loss: 0.0192 L_si: 0.0015 L_grad: 0.0176 
Train Epoch: 73 [144/816 (18%)] loss: 0.0127 L_si: 0.0008 L_grad: 0.0118 
Train Epoch: 73 [180/816 (22%)] loss: 0.0262 L_si: 0.0035 L_grad: 0.0227 
Train Epoch: 73 [216/816 (26%)] loss: 0.0235 L_si: 0.0036 L_grad: 0.0199 
Train Epoch: 73 [252/816 (31%)] loss: 0.0181 L_si: 0.0022 L_grad: 0.0159 
Train Epoch: 73 [288/816 (35%)] loss: 0.0240 L_si: 0.0034 L_grad: 0.0207 
Train Epoch: 73 [324/816 (40%)] loss: 0.0139 L_si: 0.0008 L_grad: 0.0131 
Train Epoch: 73 [360/816 (44%)] loss: 0.0220 L_si: 0.0027 L_grad: 0.0192 
Train Epoch: 73 [396/816 (49%)] loss: 0.0168 L_si: 0.0011 L_grad: 0.0157 
Train Epoch: 73 [432/816 (53%)] loss: 0.0158 L_si: 0.0013 L_grad: 0.0146 
Train Epoch: 73 [468/816 (57%)] loss: 0.0193 L_si: 0.0028 L_grad: 0.0165 
Train Epoch: 73 [504/816 (62%)] loss: 0.0186 L_si: 0.0021 L_grad: 0.0165 
Train Epoch: 73 [540/816 (66%)] loss: 0.0187 L_si: 0.0014 L_grad: 0.0173 
Train Epoch: 73 [576/816 (71%)] loss: 0.0173 L_si: 0.0015 L_grad: 0.0158 
Train Epoch: 73 [612/816 (75%)] loss: 0.0163 L_si: 0.0013 L_grad: 0.0150 
Train Epoch: 73 [648/816 (79%)] loss: 0.0222 L_si: 0.0022 L_grad: 0.0200 
Train Epoch: 73 [684/816 (84%)] loss: 0.0233 L_si: 0.0022 L_grad: 0.0211 
Train Epoch: 73 [720/816 (88%)] loss: 0.0160 L_si: 0.0025 L_grad: 0.0135 
Train Epoch: 73 [756/816 (93%)] loss: 0.0245 L_si: 0.0038 L_grad: 0.0207 
Train Epoch: 73 [792/816 (97%)] loss: 0.0162 L_si: 0.0019 L_grad: 0.0143 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.039576414972543716, 0.03867383301258087, 0.045573920011520386, 0.034321803599596024, 0.04027767851948738, 0.037556760013103485, 0.03436611592769623, 0.036169517785310745, 0.034918852150440216, 0.040832728147506714, 0.040318116545677185, 0.040378548204898834, 0.03751053661108017, 0.041844286024570465, 0.040266744792461395, 0.032165784388780594, 0.03853055089712143, 0.038942284882068634, 0.01495498139411211], 'L_si': [0.0067752450704574585, 0.00611509382724762, 0.007864676415920258, 0.005537629127502441, 0.006761513650417328, 0.006068103015422821, 0.00563386082649231, 0.006345406174659729, 0.005732454359531403, 0.004703804850578308, 0.007279746234416962, 0.007409572601318359, 0.006407417356967926, 0.0075214579701423645, 0.006228700280189514, 0.005042478442192078, 0.00670161098241806, 0.006618380546569824, 0.006850548088550568], 'L_grad': [0.03280116990208626, 0.03255873918533325, 0.03770924359560013, 0.028784174472093582, 0.03351616486907005, 0.031488656997680664, 0.02873225510120392, 0.029824111610651016, 0.029186397790908813, 0.036128923296928406, 0.03303837031126022, 0.032968975603580475, 0.031103121116757393, 0.0343228280544281, 0.03403804451227188, 0.027123305946588516, 0.03182893991470337, 0.03232390433549881, 0.008104433305561543]}
Train Epoch: 74 [0/816 (0%)] loss: 0.0160 L_si: 0.0010 L_grad: 0.0150 
Train Epoch: 74 [36/816 (4%)] loss: 0.0262 L_si: 0.0054 L_grad: 0.0208 
Train Epoch: 74 [72/816 (9%)] loss: 0.0194 L_si: 0.0017 L_grad: 0.0177 
Train Epoch: 74 [108/816 (13%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0143 
Train Epoch: 74 [144/816 (18%)] loss: 0.0209 L_si: 0.0033 L_grad: 0.0176 
Train Epoch: 74 [180/816 (22%)] loss: 0.0145 L_si: 0.0007 L_grad: 0.0138 
Train Epoch: 74 [216/816 (26%)] loss: 0.0189 L_si: 0.0017 L_grad: 0.0172 
Train Epoch: 74 [252/816 (31%)] loss: 0.0307 L_si: 0.0052 L_grad: 0.0255 
Train Epoch: 74 [288/816 (35%)] loss: 0.0182 L_si: 0.0021 L_grad: 0.0160 
Train Epoch: 74 [324/816 (40%)] loss: 0.0175 L_si: 0.0016 L_grad: 0.0159 
Train Epoch: 74 [360/816 (44%)] loss: 0.0154 L_si: 0.0011 L_grad: 0.0142 
Train Epoch: 74 [396/816 (49%)] loss: 0.0208 L_si: 0.0016 L_grad: 0.0192 
Train Epoch: 74 [432/816 (53%)] loss: 0.0154 L_si: 0.0010 L_grad: 0.0144 
Train Epoch: 74 [468/816 (57%)] loss: 0.0191 L_si: 0.0017 L_grad: 0.0174 
Train Epoch: 74 [504/816 (62%)] loss: 0.0203 L_si: 0.0020 L_grad: 0.0183 
Train Epoch: 74 [540/816 (66%)] loss: 0.0200 L_si: 0.0023 L_grad: 0.0177 
Train Epoch: 74 [576/816 (71%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0143 
Train Epoch: 74 [612/816 (75%)] loss: 0.0157 L_si: 0.0011 L_grad: 0.0145 
Train Epoch: 74 [648/816 (79%)] loss: 0.0168 L_si: 0.0011 L_grad: 0.0157 
Train Epoch: 74 [684/816 (84%)] loss: 0.0181 L_si: 0.0046 L_grad: 0.0135 
Train Epoch: 74 [720/816 (88%)] loss: 0.0260 L_si: 0.0045 L_grad: 0.0215 
Train Epoch: 74 [756/816 (93%)] loss: 0.0165 L_si: 0.0009 L_grad: 0.0157 
Train Epoch: 74 [792/816 (97%)] loss: 0.0173 L_si: 0.0011 L_grad: 0.0162 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04205554351210594, 0.03345378115773201, 0.04134714975953102, 0.038596756756305695, 0.03990209102630615, 0.03836588189005852, 0.03998180478811264, 0.03971206769347191, 0.043418653309345245, 0.03871039301156998, 0.03953070193529129, 0.03461996838450432, 0.04283750802278519, 0.033140622079372406, 0.0392908900976181, 0.03771442919969559, 0.041494354605674744, 0.0366973802447319, 0.016278548166155815], 'L_si': [0.00655771791934967, 0.005315668880939484, 0.0070954859256744385, 0.006549760699272156, 0.006667859852313995, 0.006780281662940979, 0.006233520805835724, 0.00707215815782547, 0.006902754306793213, 0.00635499507188797, 0.006623119115829468, 0.005231603980064392, 0.007581993937492371, 0.005501016974449158, 0.00579872727394104, 0.006139092147350311, 0.00704684853553772, 0.006151124835014343, 0.006868794560432434], 'L_grad': [0.03549782559275627, 0.028138112276792526, 0.03425166383385658, 0.03204699605703354, 0.03323423117399216, 0.03158560022711754, 0.033748283982276917, 0.03263990953564644, 0.03651589900255203, 0.03235539793968201, 0.03290758281946182, 0.029388364404439926, 0.035255514085292816, 0.02763960510492325, 0.03349216282367706, 0.031575337052345276, 0.034447506070137024, 0.03054625540971756, 0.009409753605723381]}
Train Epoch: 75 [0/816 (0%)] loss: 0.0173 L_si: 0.0014 L_grad: 0.0159 
Train Epoch: 75 [36/816 (4%)] loss: 0.0166 L_si: 0.0024 L_grad: 0.0142 
Train Epoch: 75 [72/816 (9%)] loss: 0.0252 L_si: 0.0051 L_grad: 0.0201 
Train Epoch: 75 [108/816 (13%)] loss: 0.0159 L_si: 0.0011 L_grad: 0.0148 
Train Epoch: 75 [144/816 (18%)] loss: 0.0143 L_si: 0.0008 L_grad: 0.0135 
Train Epoch: 75 [180/816 (22%)] loss: 0.0227 L_si: 0.0052 L_grad: 0.0175 
Train Epoch: 75 [216/816 (26%)] loss: 0.0213 L_si: 0.0021 L_grad: 0.0192 
Train Epoch: 75 [252/816 (31%)] loss: 0.0219 L_si: 0.0018 L_grad: 0.0201 
Train Epoch: 75 [288/816 (35%)] loss: 0.0192 L_si: 0.0017 L_grad: 0.0175 
Train Epoch: 75 [324/816 (40%)] loss: 0.0250 L_si: 0.0031 L_grad: 0.0219 
Train Epoch: 75 [360/816 (44%)] loss: 0.0167 L_si: 0.0010 L_grad: 0.0157 
Train Epoch: 75 [396/816 (49%)] loss: 0.0152 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 75 [432/816 (53%)] loss: 0.0232 L_si: 0.0025 L_grad: 0.0207 
Train Epoch: 75 [468/816 (57%)] loss: 0.0175 L_si: 0.0012 L_grad: 0.0163 
Train Epoch: 75 [504/816 (62%)] loss: 0.0210 L_si: 0.0042 L_grad: 0.0168 
Train Epoch: 75 [540/816 (66%)] loss: 0.0193 L_si: 0.0017 L_grad: 0.0176 
Train Epoch: 75 [576/816 (71%)] loss: 0.0206 L_si: 0.0026 L_grad: 0.0180 
Train Epoch: 75 [612/816 (75%)] loss: 0.0153 L_si: 0.0011 L_grad: 0.0142 
Train Epoch: 75 [648/816 (79%)] loss: 0.0186 L_si: 0.0019 L_grad: 0.0167 
Train Epoch: 75 [684/816 (84%)] loss: 0.0170 L_si: 0.0016 L_grad: 0.0154 
Train Epoch: 75 [720/816 (88%)] loss: 0.0221 L_si: 0.0033 L_grad: 0.0188 
Train Epoch: 75 [756/816 (93%)] loss: 0.0190 L_si: 0.0016 L_grad: 0.0173 
Train Epoch: 75 [792/816 (97%)] loss: 0.0165 L_si: 0.0012 L_grad: 0.0153 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04475393891334534, 0.03428647667169571, 0.04195622354745865, 0.03583879768848419, 0.04118810221552849, 0.03485824912786484, 0.040051914751529694, 0.03823762387037277, 0.04270434379577637, 0.038696661591529846, 0.04449354112148285, 0.03896070271730423, 0.03755496069788933, 0.0333552248775959, 0.033170945942401886, 0.0385216660797596, 0.03230889141559601, 0.03797993063926697, 0.016772041097283363], 'L_si': [0.007983677089214325, 0.005367845296859741, 0.007099635899066925, 0.0054635778069496155, 0.006667099893093109, 0.0046388134360313416, 0.006950244307518005, 0.006496697664260864, 0.007198818027973175, 0.006310604512691498, 0.007632359862327576, 0.005591392517089844, 0.00564160943031311, 0.0043291375041007996, 0.005537055432796478, 0.006442427635192871, 0.004575669765472412, 0.005950219929218292, 0.007845737040042877], 'L_grad': [0.03677026182413101, 0.028918631374835968, 0.034856587648391724, 0.030375218018889427, 0.03452100232243538, 0.030219433829188347, 0.03310167044401169, 0.03174092620611191, 0.03550552576780319, 0.03238605707883835, 0.03686118125915527, 0.033369310200214386, 0.03191335126757622, 0.029026087373495102, 0.027633892372250557, 0.03207923844456673, 0.027733221650123596, 0.032029710710048676, 0.008926304057240486]}
Train Epoch: 76 [0/816 (0%)] loss: 0.0154 L_si: 0.0009 L_grad: 0.0145 
Train Epoch: 76 [36/816 (4%)] loss: 0.0243 L_si: 0.0025 L_grad: 0.0218 
Train Epoch: 76 [72/816 (9%)] loss: 0.0198 L_si: 0.0016 L_grad: 0.0183 
Train Epoch: 76 [108/816 (13%)] loss: 0.0148 L_si: 0.0009 L_grad: 0.0140 
Train Epoch: 76 [144/816 (18%)] loss: 0.0202 L_si: 0.0025 L_grad: 0.0177 
Train Epoch: 76 [180/816 (22%)] loss: 0.0170 L_si: 0.0010 L_grad: 0.0161 
Train Epoch: 76 [216/816 (26%)] loss: 0.0151 L_si: 0.0010 L_grad: 0.0141 
Train Epoch: 76 [252/816 (31%)] loss: 0.0235 L_si: 0.0020 L_grad: 0.0214 
Train Epoch: 76 [288/816 (35%)] loss: 0.0162 L_si: 0.0010 L_grad: 0.0152 
Train Epoch: 76 [324/816 (40%)] loss: 0.0151 L_si: 0.0007 L_grad: 0.0143 
Train Epoch: 76 [360/816 (44%)] loss: 0.0225 L_si: 0.0031 L_grad: 0.0194 
Train Epoch: 76 [396/816 (49%)] loss: 0.0213 L_si: 0.0020 L_grad: 0.0192 
Train Epoch: 76 [432/816 (53%)] loss: 0.0153 L_si: 0.0017 L_grad: 0.0136 
Train Epoch: 76 [468/816 (57%)] loss: 0.0152 L_si: 0.0010 L_grad: 0.0142 
Train Epoch: 76 [504/816 (62%)] loss: 0.0171 L_si: 0.0010 L_grad: 0.0160 
Train Epoch: 76 [540/816 (66%)] loss: 0.0184 L_si: 0.0022 L_grad: 0.0163 
Train Epoch: 76 [576/816 (71%)] loss: 0.0159 L_si: 0.0011 L_grad: 0.0148 
Train Epoch: 76 [612/816 (75%)] loss: 0.0174 L_si: 0.0011 L_grad: 0.0163 
Train Epoch: 76 [648/816 (79%)] loss: 0.0197 L_si: 0.0023 L_grad: 0.0173 
Train Epoch: 76 [684/816 (84%)] loss: 0.0189 L_si: 0.0030 L_grad: 0.0159 
Train Epoch: 76 [720/816 (88%)] loss: 0.0164 L_si: 0.0012 L_grad: 0.0152 
Train Epoch: 76 [756/816 (93%)] loss: 0.0151 L_si: 0.0010 L_grad: 0.0141 
Train Epoch: 76 [792/816 (97%)] loss: 0.0158 L_si: 0.0011 L_grad: 0.0147 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03386354818940163, 0.03811563551425934, 0.041709959506988525, 0.0390593595802784, 0.03874225169420242, 0.03728410601615906, 0.04022539407014847, 0.03894144296646118, 0.0405801460146904, 0.03650312125682831, 0.03998707979917526, 0.03923580050468445, 0.03775196522474289, 0.03882173076272011, 0.03945361450314522, 0.03706567361950874, 0.04227502644062042, 0.03956998884677887, 0.014082223176956177], 'L_si': [0.00584758073091507, 0.006743624806404114, 0.007869362831115723, 0.007171966135501862, 0.006453387439250946, 0.007169567048549652, 0.007217831909656525, 0.006654322147369385, 0.007039546966552734, 0.006048485636711121, 0.006267055869102478, 0.00736699253320694, 0.0061595141887664795, 0.006417661905288696, 0.007176883518695831, 0.006304830312728882, 0.007577754557132721, 0.00680919736623764, 0.005675576627254486], 'L_grad': [0.028015967458486557, 0.031372010707855225, 0.0338405966758728, 0.031887393444776535, 0.03228886425495148, 0.030114540830254555, 0.03300756216049194, 0.0322871208190918, 0.033540599048137665, 0.030454635620117188, 0.033720023930072784, 0.03186880797147751, 0.03159245103597641, 0.03240406885743141, 0.03227673098444939, 0.03076084330677986, 0.0346972718834877, 0.03276079148054123, 0.00840664654970169]}
Train Epoch: 77 [0/816 (0%)] loss: 0.0122 L_si: 0.0005 L_grad: 0.0117 
Train Epoch: 77 [36/816 (4%)] loss: 0.0163 L_si: 0.0010 L_grad: 0.0153 
Train Epoch: 77 [72/816 (9%)] loss: 0.0150 L_si: 0.0024 L_grad: 0.0125 
Train Epoch: 77 [108/816 (13%)] loss: 0.0146 L_si: 0.0013 L_grad: 0.0133 
Train Epoch: 77 [144/816 (18%)] loss: 0.0151 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 77 [180/816 (22%)] loss: 0.0217 L_si: 0.0029 L_grad: 0.0188 
Train Epoch: 77 [216/816 (26%)] loss: 0.0233 L_si: 0.0027 L_grad: 0.0206 
Train Epoch: 77 [252/816 (31%)] loss: 0.0200 L_si: 0.0010 L_grad: 0.0189 
Train Epoch: 77 [288/816 (35%)] loss: 0.0143 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 77 [324/816 (40%)] loss: 0.0168 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 77 [360/816 (44%)] loss: 0.0114 L_si: 0.0005 L_grad: 0.0110 
Train Epoch: 77 [396/816 (49%)] loss: 0.0136 L_si: 0.0007 L_grad: 0.0130 
Train Epoch: 77 [432/816 (53%)] loss: 0.0152 L_si: 0.0008 L_grad: 0.0144 
Train Epoch: 77 [468/816 (57%)] loss: 0.0167 L_si: 0.0011 L_grad: 0.0156 
Train Epoch: 77 [504/816 (62%)] loss: 0.0156 L_si: 0.0011 L_grad: 0.0145 
Train Epoch: 77 [540/816 (66%)] loss: 0.0155 L_si: 0.0008 L_grad: 0.0147 
Train Epoch: 77 [576/816 (71%)] loss: 0.0220 L_si: 0.0034 L_grad: 0.0186 
Train Epoch: 77 [612/816 (75%)] loss: 0.0218 L_si: 0.0033 L_grad: 0.0185 
Train Epoch: 77 [648/816 (79%)] loss: 0.0205 L_si: 0.0018 L_grad: 0.0187 
Train Epoch: 77 [684/816 (84%)] loss: 0.0179 L_si: 0.0012 L_grad: 0.0167 
Train Epoch: 77 [720/816 (88%)] loss: 0.0264 L_si: 0.0050 L_grad: 0.0214 
Train Epoch: 77 [756/816 (93%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0145 
Train Epoch: 77 [792/816 (97%)] loss: 0.0163 L_si: 0.0013 L_grad: 0.0150 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03996562212705612, 0.03298710286617279, 0.03542669862508774, 0.041419629007577896, 0.039637356996536255, 0.042354293167591095, 0.038596704602241516, 0.03624716028571129, 0.041264284402132034, 0.040461376309394836, 0.040407635271549225, 0.030364159494638443, 0.038921862840652466, 0.039724256843328476, 0.04037148505449295, 0.043195560574531555, 0.04141949117183685, 0.03809354454278946, 0.012868041172623634], 'L_si': [0.006854593753814697, 0.005028560757637024, 0.006533302366733551, 0.008018538355827332, 0.00486399233341217, 0.007250048220157623, 0.0063882023096084595, 0.006057329475879669, 0.005949854850769043, 0.006760507822036743, 0.00627300888299942, 0.004249207675457001, 0.006398938596248627, 0.007666848599910736, 0.006584957242012024, 0.0066892728209495544, 0.0067804232239723206, 0.0064234137535095215, 0.005923822522163391], 'L_grad': [0.033111028373241425, 0.027958542108535767, 0.028893396258354187, 0.033401090651750565, 0.034773364663124084, 0.03510424494743347, 0.03220850229263306, 0.03018983080983162, 0.03531442955136299, 0.03370086848735809, 0.034134626388549805, 0.026114951819181442, 0.03252292424440384, 0.03205740824341774, 0.033786527812480927, 0.036506287753582, 0.03463906794786453, 0.03167013078927994, 0.006944218650460243]}
Train Epoch: 78 [0/816 (0%)] loss: 0.0179 L_si: 0.0017 L_grad: 0.0163 
Train Epoch: 78 [36/816 (4%)] loss: 0.0246 L_si: 0.0049 L_grad: 0.0197 
Train Epoch: 78 [72/816 (9%)] loss: 0.0152 L_si: 0.0012 L_grad: 0.0140 
Train Epoch: 78 [108/816 (13%)] loss: 0.0262 L_si: 0.0029 L_grad: 0.0234 
Train Epoch: 78 [144/816 (18%)] loss: 0.0173 L_si: 0.0019 L_grad: 0.0154 
Train Epoch: 78 [180/816 (22%)] loss: 0.0262 L_si: 0.0029 L_grad: 0.0233 
Train Epoch: 78 [216/816 (26%)] loss: 0.0195 L_si: 0.0029 L_grad: 0.0166 
Train Epoch: 78 [252/816 (31%)] loss: 0.0175 L_si: 0.0018 L_grad: 0.0157 
Train Epoch: 78 [288/816 (35%)] loss: 0.0252 L_si: 0.0036 L_grad: 0.0217 
Train Epoch: 78 [324/816 (40%)] loss: 0.0167 L_si: 0.0013 L_grad: 0.0154 
Train Epoch: 78 [360/816 (44%)] loss: 0.0158 L_si: 0.0009 L_grad: 0.0148 
Train Epoch: 78 [396/816 (49%)] loss: 0.0216 L_si: 0.0066 L_grad: 0.0150 
Train Epoch: 78 [432/816 (53%)] loss: 0.0225 L_si: 0.0026 L_grad: 0.0199 
Train Epoch: 78 [468/816 (57%)] loss: 0.0187 L_si: 0.0024 L_grad: 0.0162 
Train Epoch: 78 [504/816 (62%)] loss: 0.0239 L_si: 0.0025 L_grad: 0.0214 
Train Epoch: 78 [540/816 (66%)] loss: 0.0210 L_si: 0.0019 L_grad: 0.0190 
Train Epoch: 78 [576/816 (71%)] loss: 0.0151 L_si: 0.0011 L_grad: 0.0140 
Train Epoch: 78 [612/816 (75%)] loss: 0.0213 L_si: 0.0022 L_grad: 0.0191 
Train Epoch: 78 [648/816 (79%)] loss: 0.0155 L_si: 0.0014 L_grad: 0.0141 
Train Epoch: 78 [684/816 (84%)] loss: 0.0181 L_si: 0.0016 L_grad: 0.0165 
Train Epoch: 78 [720/816 (88%)] loss: 0.0197 L_si: 0.0017 L_grad: 0.0179 
Train Epoch: 78 [756/816 (93%)] loss: 0.0112 L_si: 0.0004 L_grad: 0.0108 
Train Epoch: 78 [792/816 (97%)] loss: 0.0162 L_si: 0.0011 L_grad: 0.0151 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04249121993780136, 0.03992699086666107, 0.03992705047130585, 0.041537269949913025, 0.03462111949920654, 0.041201405227184296, 0.0405428521335125, 0.039799436926841736, 0.03377695009112358, 0.037639155983924866, 0.04048533737659454, 0.03075168840587139, 0.03830275684595108, 0.03968732804059982, 0.035698581486940384, 0.037964556366205215, 0.03638619929552078, 0.038102734833955765, 0.012550493702292442], 'L_si': [0.007212474942207336, 0.007452748715877533, 0.006779953837394714, 0.006397321820259094, 0.006021648645401001, 0.007164627313613892, 0.006197594106197357, 0.006032228469848633, 0.006102956831455231, 0.007414400577545166, 0.0067668333649635315, 0.004048630595207214, 0.007043659687042236, 0.007108874619007111, 0.005638480186462402, 0.0071070194244384766, 0.005933448672294617, 0.0059922486543655396, 0.0050148069858551025], 'L_grad': [0.035278744995594025, 0.03247424215078354, 0.03314709663391113, 0.03513994812965393, 0.028599470853805542, 0.034036777913570404, 0.03434525802731514, 0.0337672084569931, 0.02767399325966835, 0.03022475354373455, 0.03371850401163101, 0.026703057810664177, 0.031259097158908844, 0.03257845342159271, 0.03006010130047798, 0.03085753694176674, 0.030452748760581017, 0.032110486179590225, 0.007535687182098627]}
Train Epoch: 79 [0/816 (0%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0161 
Train Epoch: 79 [36/816 (4%)] loss: 0.0178 L_si: 0.0015 L_grad: 0.0163 
Train Epoch: 79 [72/816 (9%)] loss: 0.0199 L_si: 0.0024 L_grad: 0.0175 
Train Epoch: 79 [108/816 (13%)] loss: 0.0255 L_si: 0.0023 L_grad: 0.0233 
Train Epoch: 79 [144/816 (18%)] loss: 0.0247 L_si: 0.0044 L_grad: 0.0203 
Train Epoch: 79 [180/816 (22%)] loss: 0.0216 L_si: 0.0030 L_grad: 0.0186 
Train Epoch: 79 [216/816 (26%)] loss: 0.0199 L_si: 0.0019 L_grad: 0.0180 
Train Epoch: 79 [252/816 (31%)] loss: 0.0188 L_si: 0.0026 L_grad: 0.0162 
Train Epoch: 79 [288/816 (35%)] loss: 0.0191 L_si: 0.0020 L_grad: 0.0170 
Train Epoch: 79 [324/816 (40%)] loss: 0.0136 L_si: 0.0008 L_grad: 0.0128 
Train Epoch: 79 [360/816 (44%)] loss: 0.0142 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 79 [396/816 (49%)] loss: 0.0181 L_si: 0.0011 L_grad: 0.0171 
Train Epoch: 79 [432/816 (53%)] loss: 0.0204 L_si: 0.0019 L_grad: 0.0185 
Train Epoch: 79 [468/816 (57%)] loss: 0.0211 L_si: 0.0027 L_grad: 0.0184 
Train Epoch: 79 [504/816 (62%)] loss: 0.0163 L_si: 0.0009 L_grad: 0.0154 
Train Epoch: 79 [540/816 (66%)] loss: 0.0155 L_si: 0.0010 L_grad: 0.0145 
Train Epoch: 79 [576/816 (71%)] loss: 0.0126 L_si: 0.0007 L_grad: 0.0119 
Train Epoch: 79 [612/816 (75%)] loss: 0.0122 L_si: 0.0011 L_grad: 0.0111 
Train Epoch: 79 [648/816 (79%)] loss: 0.0118 L_si: 0.0005 L_grad: 0.0113 
Train Epoch: 79 [684/816 (84%)] loss: 0.0206 L_si: 0.0014 L_grad: 0.0192 
Train Epoch: 79 [720/816 (88%)] loss: 0.0210 L_si: 0.0020 L_grad: 0.0190 
Train Epoch: 79 [756/816 (93%)] loss: 0.0196 L_si: 0.0023 L_grad: 0.0173 
Train Epoch: 79 [792/816 (97%)] loss: 0.0209 L_si: 0.0019 L_grad: 0.0190 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04338311031460762, 0.03019103966653347, 0.040542569011449814, 0.03791360184550285, 0.03530503064393997, 0.03560392186045647, 0.03805382177233696, 0.03528617322444916, 0.03415597230195999, 0.04005013778805733, 0.03713947534561157, 0.03764183074235916, 0.04051860421895981, 0.03884690999984741, 0.04420951381325722, 0.03362150490283966, 0.04038466513156891, 0.03423185274004936, 0.01718130148947239], 'L_si': [0.00732421875, 0.004061795771121979, 0.007154829800128937, 0.0070427656173706055, 0.004946097731590271, 0.006706595420837402, 0.005434982478618622, 0.005351357161998749, 0.005805030465126038, 0.0063098520040512085, 0.00598454475402832, 0.005895107984542847, 0.007508695125579834, 0.006321251392364502, 0.0069208890199661255, 0.005492255091667175, 0.005218565464019775, 0.005398780107498169, 0.008070416748523712], 'L_grad': [0.03605889156460762, 0.02612924389541149, 0.03338773921132088, 0.030870836228132248, 0.03035893477499485, 0.028897326439619064, 0.03261883929371834, 0.02993481419980526, 0.028350941836833954, 0.03374028578400612, 0.031154930591583252, 0.031746722757816315, 0.033009909093379974, 0.03252565860748291, 0.03728862479329109, 0.028129247948527336, 0.03516609966754913, 0.028833072632551193, 0.009110884740948677]}
Train Epoch: 80 [0/816 (0%)] loss: 0.0147 L_si: 0.0010 L_grad: 0.0137 
Train Epoch: 80 [36/816 (4%)] loss: 0.0210 L_si: 0.0019 L_grad: 0.0192 
Train Epoch: 80 [72/816 (9%)] loss: 0.0246 L_si: 0.0025 L_grad: 0.0221 
Train Epoch: 80 [108/816 (13%)] loss: 0.0144 L_si: 0.0008 L_grad: 0.0136 
Train Epoch: 80 [144/816 (18%)] loss: 0.0244 L_si: 0.0033 L_grad: 0.0212 
Train Epoch: 80 [180/816 (22%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 80 [216/816 (26%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 80 [252/816 (31%)] loss: 0.0183 L_si: 0.0015 L_grad: 0.0167 
Train Epoch: 80 [288/816 (35%)] loss: 0.0187 L_si: 0.0011 L_grad: 0.0175 
Train Epoch: 80 [324/816 (40%)] loss: 0.0173 L_si: 0.0016 L_grad: 0.0157 
Train Epoch: 80 [360/816 (44%)] loss: 0.0187 L_si: 0.0025 L_grad: 0.0162 
Train Epoch: 80 [396/816 (49%)] loss: 0.0156 L_si: 0.0010 L_grad: 0.0146 
Train Epoch: 80 [432/816 (53%)] loss: 0.0192 L_si: 0.0020 L_grad: 0.0172 
Train Epoch: 80 [468/816 (57%)] loss: 0.0232 L_si: 0.0023 L_grad: 0.0209 
Train Epoch: 80 [504/816 (62%)] loss: 0.0231 L_si: 0.0036 L_grad: 0.0195 
Train Epoch: 80 [540/816 (66%)] loss: 0.0149 L_si: 0.0012 L_grad: 0.0138 
Train Epoch: 80 [576/816 (71%)] loss: 0.0217 L_si: 0.0018 L_grad: 0.0200 
Train Epoch: 80 [612/816 (75%)] loss: 0.0210 L_si: 0.0022 L_grad: 0.0188 
Train Epoch: 80 [648/816 (79%)] loss: 0.0172 L_si: 0.0011 L_grad: 0.0161 
Train Epoch: 80 [684/816 (84%)] loss: 0.0248 L_si: 0.0028 L_grad: 0.0221 
Train Epoch: 80 [720/816 (88%)] loss: 0.0188 L_si: 0.0017 L_grad: 0.0170 
Train Epoch: 80 [756/816 (93%)] loss: 0.0204 L_si: 0.0024 L_grad: 0.0180 
Train Epoch: 80 [792/816 (97%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0144 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch080-loss-0.0183.pth.tar ...
all losses in batch in validation:  {'loss': [0.038761336356401443, 0.042568180710077286, 0.039563339203596115, 0.039741598069667816, 0.0367288663983345, 0.04038789123296738, 0.036176759749650955, 0.03580157458782196, 0.031667280942201614, 0.04420369863510132, 0.03788328543305397, 0.04033931344747543, 0.04168947786092758, 0.04207571968436241, 0.036834828555583954, 0.03930431604385376, 0.03654039651155472, 0.04264433681964874, 0.015551146119832993], 'L_si': [0.006850376725196838, 0.006688624620437622, 0.006317935883998871, 0.006881825625896454, 0.006999582052230835, 0.007650256156921387, 0.005347125232219696, 0.006676733493804932, 0.005864046514034271, 0.007278703153133392, 0.006819911301136017, 0.006939463317394257, 0.007143743336200714, 0.0068220049142837524, 0.006057851016521454, 0.005342237651348114, 0.0056329816579818726, 0.00587492436170578, 0.006311915814876556], 'L_grad': [0.031910959631204605, 0.035879556089639664, 0.033245403319597244, 0.03285977244377136, 0.02972928248345852, 0.03273763507604599, 0.03082963451743126, 0.029124842956662178, 0.025803234428167343, 0.036924995481967926, 0.031063374131917953, 0.03339985013008118, 0.03454573452472687, 0.03525371477007866, 0.03077697567641735, 0.033962078392505646, 0.030907416716217995, 0.03676941245794296, 0.009239230304956436]}
Train Epoch: 81 [0/816 (0%)] loss: 0.0184 L_si: 0.0011 L_grad: 0.0174 
Train Epoch: 81 [36/816 (4%)] loss: 0.0150 L_si: 0.0009 L_grad: 0.0141 
Train Epoch: 81 [72/816 (9%)] loss: 0.0203 L_si: 0.0018 L_grad: 0.0185 
Train Epoch: 81 [108/816 (13%)] loss: 0.0198 L_si: 0.0018 L_grad: 0.0181 
Train Epoch: 81 [144/816 (18%)] loss: 0.0167 L_si: 0.0012 L_grad: 0.0155 
Train Epoch: 81 [180/816 (22%)] loss: 0.0258 L_si: 0.0044 L_grad: 0.0214 
Train Epoch: 81 [216/816 (26%)] loss: 0.0197 L_si: 0.0016 L_grad: 0.0180 
Train Epoch: 81 [252/816 (31%)] loss: 0.0139 L_si: 0.0007 L_grad: 0.0132 
Train Epoch: 81 [288/816 (35%)] loss: 0.0185 L_si: 0.0012 L_grad: 0.0172 
Train Epoch: 81 [324/816 (40%)] loss: 0.0195 L_si: 0.0016 L_grad: 0.0179 
Train Epoch: 81 [360/816 (44%)] loss: 0.0173 L_si: 0.0013 L_grad: 0.0160 
Train Epoch: 81 [396/816 (49%)] loss: 0.0148 L_si: 0.0010 L_grad: 0.0138 
Train Epoch: 81 [432/816 (53%)] loss: 0.0217 L_si: 0.0018 L_grad: 0.0199 
Train Epoch: 81 [468/816 (57%)] loss: 0.0202 L_si: 0.0023 L_grad: 0.0179 
Train Epoch: 81 [504/816 (62%)] loss: 0.0219 L_si: 0.0027 L_grad: 0.0192 
Train Epoch: 81 [540/816 (66%)] loss: 0.0177 L_si: 0.0011 L_grad: 0.0165 
Train Epoch: 81 [576/816 (71%)] loss: 0.0121 L_si: 0.0008 L_grad: 0.0114 
Train Epoch: 81 [612/816 (75%)] loss: 0.0130 L_si: 0.0007 L_grad: 0.0123 
Train Epoch: 81 [648/816 (79%)] loss: 0.0208 L_si: 0.0034 L_grad: 0.0174 
Train Epoch: 81 [684/816 (84%)] loss: 0.0198 L_si: 0.0023 L_grad: 0.0175 
Train Epoch: 81 [720/816 (88%)] loss: 0.0204 L_si: 0.0036 L_grad: 0.0168 
Train Epoch: 81 [756/816 (93%)] loss: 0.0157 L_si: 0.0013 L_grad: 0.0144 
Train Epoch: 81 [792/816 (97%)] loss: 0.0242 L_si: 0.0028 L_grad: 0.0214 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.0419018417596817, 0.03950205445289612, 0.037545062601566315, 0.036786824464797974, 0.040484681725502014, 0.03394833207130432, 0.042816389352083206, 0.04630725085735321, 0.0443243682384491, 0.03372759371995926, 0.04073821008205414, 0.03465758264064789, 0.038110312074422836, 0.040909282863140106, 0.03627388924360275, 0.03923405706882477, 0.04049001261591911, 0.04278464615345001, 0.012770134955644608], 'L_si': [0.006993889808654785, 0.007102206349372864, 0.007049195468425751, 0.006038457155227661, 0.006569467484951019, 0.006100989878177643, 0.008222982287406921, 0.008539117872714996, 0.008193187415599823, 0.007038123905658722, 0.0066713616251945496, 0.005628526210784912, 0.006983153522014618, 0.007492102682590485, 0.00613056868314743, 0.006888560950756073, 0.007628031075000763, 0.007102452218532562, 0.00562325119972229], 'L_grad': [0.034907951951026917, 0.032399848103523254, 0.030495865270495415, 0.03074836917221546, 0.033915214240550995, 0.02784734033048153, 0.034593407064676285, 0.037768132984638214, 0.036131180822849274, 0.026689467951655388, 0.03406684845685959, 0.029029056429862976, 0.03112715855240822, 0.03341718018054962, 0.030143320560455322, 0.032345496118068695, 0.03286198154091835, 0.03568219393491745, 0.00714688329026103]}
Train Epoch: 82 [0/816 (0%)] loss: 0.0135 L_si: 0.0009 L_grad: 0.0126 
Train Epoch: 82 [36/816 (4%)] loss: 0.0206 L_si: 0.0017 L_grad: 0.0189 
Train Epoch: 82 [72/816 (9%)] loss: 0.0163 L_si: 0.0014 L_grad: 0.0149 
Train Epoch: 82 [108/816 (13%)] loss: 0.0221 L_si: 0.0034 L_grad: 0.0187 
Train Epoch: 82 [144/816 (18%)] loss: 0.0193 L_si: 0.0013 L_grad: 0.0181 
Train Epoch: 82 [180/816 (22%)] loss: 0.0143 L_si: 0.0006 L_grad: 0.0137 
Train Epoch: 82 [216/816 (26%)] loss: 0.0208 L_si: 0.0035 L_grad: 0.0173 
Train Epoch: 82 [252/816 (31%)] loss: 0.0221 L_si: 0.0025 L_grad: 0.0196 
Train Epoch: 82 [288/816 (35%)] loss: 0.0180 L_si: 0.0014 L_grad: 0.0166 
Train Epoch: 82 [324/816 (40%)] loss: 0.0198 L_si: 0.0016 L_grad: 0.0182 
Train Epoch: 82 [360/816 (44%)] loss: 0.0143 L_si: 0.0010 L_grad: 0.0133 
Train Epoch: 82 [396/816 (49%)] loss: 0.0149 L_si: 0.0008 L_grad: 0.0141 
Train Epoch: 82 [432/816 (53%)] loss: 0.0186 L_si: 0.0013 L_grad: 0.0173 
Train Epoch: 82 [468/816 (57%)] loss: 0.0151 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 82 [504/816 (62%)] loss: 0.0135 L_si: 0.0009 L_grad: 0.0126 
Train Epoch: 82 [540/816 (66%)] loss: 0.0175 L_si: 0.0018 L_grad: 0.0157 
Train Epoch: 82 [576/816 (71%)] loss: 0.0125 L_si: 0.0007 L_grad: 0.0118 
Train Epoch: 82 [612/816 (75%)] loss: 0.0151 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 82 [648/816 (79%)] loss: 0.0191 L_si: 0.0026 L_grad: 0.0164 
Train Epoch: 82 [684/816 (84%)] loss: 0.0194 L_si: 0.0022 L_grad: 0.0172 
Train Epoch: 82 [720/816 (88%)] loss: 0.0194 L_si: 0.0018 L_grad: 0.0176 
Train Epoch: 82 [756/816 (93%)] loss: 0.0190 L_si: 0.0012 L_grad: 0.0178 
Train Epoch: 82 [792/816 (97%)] loss: 0.0202 L_si: 0.0019 L_grad: 0.0183 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03659791499376297, 0.039543069899082184, 0.037460535764694214, 0.03605422377586365, 0.03632807359099388, 0.0339747779071331, 0.03560236468911171, 0.0382201112806797, 0.04135482385754585, 0.03574834018945694, 0.03540746867656708, 0.03886179253458977, 0.03902418166399002, 0.03697887435555458, 0.03525456041097641, 0.03920202702283859, 0.03832650184631348, 0.04425320029258728, 0.014529265463352203], 'L_si': [0.005946420133113861, 0.006068341434001923, 0.006912633776664734, 0.0057906657457351685, 0.006148159503936768, 0.005599416792392731, 0.006136849522590637, 0.00696825236082077, 0.007266029715538025, 0.005876332521438599, 0.0064990222454071045, 0.006307065486907959, 0.007187359035015106, 0.005533352494239807, 0.005769491195678711, 0.007627792656421661, 0.006452329456806183, 0.0074252113699913025, 0.00656341016292572], 'L_grad': [0.03065149299800396, 0.03347472846508026, 0.03054790012538433, 0.030263559892773628, 0.030179914087057114, 0.02837536111474037, 0.029465515166521072, 0.03125185891985893, 0.03408879414200783, 0.02987200766801834, 0.028908448293805122, 0.03255472704768181, 0.031836822628974915, 0.031445521861314774, 0.0294850692152977, 0.03157423436641693, 0.031874172389507294, 0.03682798892259598, 0.007965855300426483]}
Train Epoch: 83 [0/816 (0%)] loss: 0.0180 L_si: 0.0015 L_grad: 0.0164 
Train Epoch: 83 [36/816 (4%)] loss: 0.0199 L_si: 0.0027 L_grad: 0.0171 
Train Epoch: 83 [72/816 (9%)] loss: 0.0123 L_si: 0.0007 L_grad: 0.0116 
Train Epoch: 83 [108/816 (13%)] loss: 0.0207 L_si: 0.0027 L_grad: 0.0180 
Train Epoch: 83 [144/816 (18%)] loss: 0.0122 L_si: 0.0007 L_grad: 0.0115 
Train Epoch: 83 [180/816 (22%)] loss: 0.0174 L_si: 0.0015 L_grad: 0.0159 
Train Epoch: 83 [216/816 (26%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0161 
Train Epoch: 83 [252/816 (31%)] loss: 0.0198 L_si: 0.0025 L_grad: 0.0173 
Train Epoch: 83 [288/816 (35%)] loss: 0.0161 L_si: 0.0011 L_grad: 0.0150 
Train Epoch: 83 [324/816 (40%)] loss: 0.0274 L_si: 0.0049 L_grad: 0.0225 
Train Epoch: 83 [360/816 (44%)] loss: 0.0201 L_si: 0.0015 L_grad: 0.0186 
Train Epoch: 83 [396/816 (49%)] loss: 0.0155 L_si: 0.0015 L_grad: 0.0140 
Train Epoch: 83 [432/816 (53%)] loss: 0.0193 L_si: 0.0019 L_grad: 0.0174 
Train Epoch: 83 [468/816 (57%)] loss: 0.0183 L_si: 0.0019 L_grad: 0.0164 
Train Epoch: 83 [504/816 (62%)] loss: 0.0188 L_si: 0.0015 L_grad: 0.0172 
Train Epoch: 83 [540/816 (66%)] loss: 0.0167 L_si: 0.0019 L_grad: 0.0147 
Train Epoch: 83 [576/816 (71%)] loss: 0.0188 L_si: 0.0015 L_grad: 0.0174 
Train Epoch: 83 [612/816 (75%)] loss: 0.0186 L_si: 0.0014 L_grad: 0.0171 
Train Epoch: 83 [648/816 (79%)] loss: 0.0184 L_si: 0.0014 L_grad: 0.0170 
Train Epoch: 83 [684/816 (84%)] loss: 0.0156 L_si: 0.0014 L_grad: 0.0142 
Train Epoch: 83 [720/816 (88%)] loss: 0.0122 L_si: 0.0008 L_grad: 0.0114 
Train Epoch: 83 [756/816 (93%)] loss: 0.0197 L_si: 0.0026 L_grad: 0.0171 
Train Epoch: 83 [792/816 (97%)] loss: 0.0205 L_si: 0.0021 L_grad: 0.0185 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04001577943563461, 0.0389055572450161, 0.044118836522102356, 0.036602526903152466, 0.03954969719052315, 0.03945179283618927, 0.036553315818309784, 0.0409972220659256, 0.043404899537563324, 0.0345807820558548, 0.04010005295276642, 0.03401331603527069, 0.036788735538721085, 0.03822805732488632, 0.03713885322213173, 0.03753802180290222, 0.03469967097043991, 0.04075460135936737, 0.014421998523175716], 'L_si': [0.007308438420295715, 0.0067207589745521545, 0.007719911634922028, 0.006670676171779633, 0.007094733417034149, 0.006482481956481934, 0.006309434771537781, 0.006263352930545807, 0.007172144949436188, 0.004975244402885437, 0.008075043559074402, 0.006176002323627472, 0.006319373846054077, 0.0068219974637031555, 0.0060577839612960815, 0.007116980850696564, 0.005214042961597443, 0.006074406206607819, 0.005835182964801788], 'L_grad': [0.0327073410153389, 0.032184798270463943, 0.03639892488718033, 0.029931852594017982, 0.032454963773489, 0.032969310879707336, 0.030243881046772003, 0.03473386913537979, 0.036232754588127136, 0.02960553579032421, 0.03202500939369202, 0.027837315574288368, 0.030469361692667007, 0.031406059861183167, 0.031081069260835648, 0.03042103908956051, 0.029485628008842468, 0.03468019515275955, 0.008586815558373928]}
Train Epoch: 84 [0/816 (0%)] loss: 0.0184 L_si: 0.0015 L_grad: 0.0169 
Train Epoch: 84 [36/816 (4%)] loss: 0.0168 L_si: 0.0015 L_grad: 0.0153 
Train Epoch: 84 [72/816 (9%)] loss: 0.0165 L_si: 0.0013 L_grad: 0.0152 
Train Epoch: 84 [108/816 (13%)] loss: 0.0128 L_si: 0.0006 L_grad: 0.0122 
Train Epoch: 84 [144/816 (18%)] loss: 0.0186 L_si: 0.0019 L_grad: 0.0167 
Train Epoch: 84 [180/816 (22%)] loss: 0.0181 L_si: 0.0011 L_grad: 0.0171 
Train Epoch: 84 [216/816 (26%)] loss: 0.0179 L_si: 0.0038 L_grad: 0.0142 
Train Epoch: 84 [252/816 (31%)] loss: 0.0162 L_si: 0.0010 L_grad: 0.0152 
Train Epoch: 84 [288/816 (35%)] loss: 0.0169 L_si: 0.0018 L_grad: 0.0152 
Train Epoch: 84 [324/816 (40%)] loss: 0.0202 L_si: 0.0017 L_grad: 0.0185 
Train Epoch: 84 [360/816 (44%)] loss: 0.0166 L_si: 0.0018 L_grad: 0.0148 
Train Epoch: 84 [396/816 (49%)] loss: 0.0168 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 84 [432/816 (53%)] loss: 0.0225 L_si: 0.0022 L_grad: 0.0203 
Train Epoch: 84 [468/816 (57%)] loss: 0.0203 L_si: 0.0025 L_grad: 0.0178 
Train Epoch: 84 [504/816 (62%)] loss: 0.0284 L_si: 0.0058 L_grad: 0.0225 
Train Epoch: 84 [540/816 (66%)] loss: 0.0195 L_si: 0.0026 L_grad: 0.0169 
Train Epoch: 84 [576/816 (71%)] loss: 0.0132 L_si: 0.0006 L_grad: 0.0126 
Train Epoch: 84 [612/816 (75%)] loss: 0.0171 L_si: 0.0016 L_grad: 0.0156 
Train Epoch: 84 [648/816 (79%)] loss: 0.0144 L_si: 0.0008 L_grad: 0.0136 
Train Epoch: 84 [684/816 (84%)] loss: 0.0231 L_si: 0.0022 L_grad: 0.0209 
Train Epoch: 84 [720/816 (88%)] loss: 0.0141 L_si: 0.0007 L_grad: 0.0133 
Train Epoch: 84 [756/816 (93%)] loss: 0.0176 L_si: 0.0012 L_grad: 0.0165 
Train Epoch: 84 [792/816 (97%)] loss: 0.0182 L_si: 0.0012 L_grad: 0.0170 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040105387568473816, 0.04044673591852188, 0.03730636090040207, 0.04107954353094101, 0.04171885550022125, 0.034967318177223206, 0.04193852096796036, 0.0348660945892334, 0.040602169930934906, 0.03076940029859543, 0.04477955028414726, 0.040697477757930756, 0.038816794753074646, 0.03925653547048569, 0.03323352336883545, 0.037917427718639374, 0.038239721208810806, 0.03812698274850845, 0.008018535561859608], 'L_si': [0.007152147591114044, 0.007285617291927338, 0.007435940206050873, 0.007762402296066284, 0.007828690111637115, 0.006095632910728455, 0.007742077112197876, 0.00657305121421814, 0.006805606186389923, 0.00379817932844162, 0.008133545517921448, 0.006546862423419952, 0.007818520069122314, 0.007311910390853882, 0.00533498078584671, 0.0073632970452308655, 0.0069777145981788635, 0.007374808192253113, 0.001416809856891632], 'L_grad': [0.03295323997735977, 0.03316111862659454, 0.029870420694351196, 0.033317141234874725, 0.03389016538858414, 0.02887168526649475, 0.03419644385576248, 0.02829304337501526, 0.03379656374454498, 0.02697122097015381, 0.036646004766225815, 0.0341506153345108, 0.03099827468395233, 0.031944625079631805, 0.02789854072034359, 0.03055412881076336, 0.03126200661063194, 0.03075217641890049, 0.006601725704967976]}
Train Epoch: 85 [0/816 (0%)] loss: 0.0188 L_si: 0.0012 L_grad: 0.0176 
Train Epoch: 85 [36/816 (4%)] loss: 0.0191 L_si: 0.0015 L_grad: 0.0176 
Train Epoch: 85 [72/816 (9%)] loss: 0.0176 L_si: 0.0017 L_grad: 0.0160 
Train Epoch: 85 [108/816 (13%)] loss: 0.0148 L_si: 0.0009 L_grad: 0.0139 
Train Epoch: 85 [144/816 (18%)] loss: 0.0176 L_si: 0.0013 L_grad: 0.0162 
Train Epoch: 85 [180/816 (22%)] loss: 0.0183 L_si: 0.0016 L_grad: 0.0166 
Train Epoch: 85 [216/816 (26%)] loss: 0.0251 L_si: 0.0064 L_grad: 0.0186 
Train Epoch: 85 [252/816 (31%)] loss: 0.0183 L_si: 0.0023 L_grad: 0.0160 
Train Epoch: 85 [288/816 (35%)] loss: 0.0141 L_si: 0.0008 L_grad: 0.0133 
Train Epoch: 85 [324/816 (40%)] loss: 0.0172 L_si: 0.0026 L_grad: 0.0146 
Train Epoch: 85 [360/816 (44%)] loss: 0.0225 L_si: 0.0021 L_grad: 0.0204 
Train Epoch: 85 [396/816 (49%)] loss: 0.0156 L_si: 0.0011 L_grad: 0.0145 
Train Epoch: 85 [432/816 (53%)] loss: 0.0171 L_si: 0.0021 L_grad: 0.0150 
Train Epoch: 85 [468/816 (57%)] loss: 0.0154 L_si: 0.0013 L_grad: 0.0142 
Train Epoch: 85 [504/816 (62%)] loss: 0.0152 L_si: 0.0009 L_grad: 0.0143 
Train Epoch: 85 [540/816 (66%)] loss: 0.0132 L_si: 0.0006 L_grad: 0.0126 
Train Epoch: 85 [576/816 (71%)] loss: 0.0136 L_si: 0.0007 L_grad: 0.0130 
Train Epoch: 85 [612/816 (75%)] loss: 0.0177 L_si: 0.0009 L_grad: 0.0168 
Train Epoch: 85 [648/816 (79%)] loss: 0.0174 L_si: 0.0010 L_grad: 0.0164 
Train Epoch: 85 [684/816 (84%)] loss: 0.0217 L_si: 0.0034 L_grad: 0.0183 
Train Epoch: 85 [720/816 (88%)] loss: 0.0131 L_si: 0.0006 L_grad: 0.0126 
Train Epoch: 85 [756/816 (93%)] loss: 0.0130 L_si: 0.0012 L_grad: 0.0118 
Train Epoch: 85 [792/816 (97%)] loss: 0.0145 L_si: 0.0008 L_grad: 0.0138 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03547453135251999, 0.043615374714136124, 0.04314729943871498, 0.04053609445691109, 0.03901301324367523, 0.039986636489629745, 0.03764571249485016, 0.040251705795526505, 0.03637120872735977, 0.03826070949435234, 0.036248914897441864, 0.0347590409219265, 0.04041362181305885, 0.040391724556684494, 0.03401460498571396, 0.03868113458156586, 0.03701451048254967, 0.04185378551483154, 0.01712608151137829], 'L_si': [0.005499154329299927, 0.007306359708309174, 0.0071780383586883545, 0.007013946771621704, 0.006698399782180786, 0.006093963980674744, 0.006220094859600067, 0.005811795592308044, 0.006976082921028137, 0.0065598562359809875, 0.00649607926607132, 0.006296977400779724, 0.007221609354019165, 0.006019227206707001, 0.0052757710218429565, 0.006722122430801392, 0.006256163120269775, 0.007161431014537811, 0.00813370943069458], 'L_grad': [0.029975377023220062, 0.03630901500582695, 0.03596926108002663, 0.03352214768528938, 0.032314613461494446, 0.033892672508955, 0.03142561763525009, 0.03443991020321846, 0.029395125806331635, 0.03170085325837135, 0.029752837494015694, 0.028462063521146774, 0.03319201245903969, 0.03437249734997749, 0.02873883582651615, 0.031959012150764465, 0.030758347362279892, 0.03469235450029373, 0.008992372080683708]}
Train Epoch: 86 [0/816 (0%)] loss: 0.0156 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 86 [36/816 (4%)] loss: 0.0223 L_si: 0.0019 L_grad: 0.0204 
Train Epoch: 86 [72/816 (9%)] loss: 0.0236 L_si: 0.0034 L_grad: 0.0202 
Train Epoch: 86 [108/816 (13%)] loss: 0.0198 L_si: 0.0057 L_grad: 0.0141 
Train Epoch: 86 [144/816 (18%)] loss: 0.0212 L_si: 0.0028 L_grad: 0.0184 
Train Epoch: 86 [180/816 (22%)] loss: 0.0165 L_si: 0.0013 L_grad: 0.0152 
Train Epoch: 86 [216/816 (26%)] loss: 0.0214 L_si: 0.0016 L_grad: 0.0198 
Train Epoch: 86 [252/816 (31%)] loss: 0.0160 L_si: 0.0012 L_grad: 0.0148 
Train Epoch: 86 [288/816 (35%)] loss: 0.0139 L_si: 0.0007 L_grad: 0.0132 
Train Epoch: 86 [324/816 (40%)] loss: 0.0158 L_si: 0.0010 L_grad: 0.0148 
Train Epoch: 86 [360/816 (44%)] loss: 0.0144 L_si: 0.0009 L_grad: 0.0135 
Train Epoch: 86 [396/816 (49%)] loss: 0.0188 L_si: 0.0014 L_grad: 0.0174 
Train Epoch: 86 [432/816 (53%)] loss: 0.0249 L_si: 0.0037 L_grad: 0.0212 
Train Epoch: 86 [468/816 (57%)] loss: 0.0170 L_si: 0.0019 L_grad: 0.0151 
Train Epoch: 86 [504/816 (62%)] loss: 0.0125 L_si: 0.0008 L_grad: 0.0117 
Train Epoch: 86 [540/816 (66%)] loss: 0.0182 L_si: 0.0012 L_grad: 0.0170 
Train Epoch: 86 [576/816 (71%)] loss: 0.0191 L_si: 0.0023 L_grad: 0.0168 
Train Epoch: 86 [612/816 (75%)] loss: 0.0195 L_si: 0.0013 L_grad: 0.0182 
Train Epoch: 86 [648/816 (79%)] loss: 0.0183 L_si: 0.0017 L_grad: 0.0166 
Train Epoch: 86 [684/816 (84%)] loss: 0.0186 L_si: 0.0016 L_grad: 0.0171 
Train Epoch: 86 [720/816 (88%)] loss: 0.0161 L_si: 0.0011 L_grad: 0.0150 
Train Epoch: 86 [756/816 (93%)] loss: 0.0176 L_si: 0.0012 L_grad: 0.0164 
Train Epoch: 86 [792/816 (97%)] loss: 0.0162 L_si: 0.0011 L_grad: 0.0151 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04140482842922211, 0.039354607462882996, 0.03857715055346489, 0.03733029216527939, 0.04422071576118469, 0.03888854384422302, 0.044177114963531494, 0.037943512201309204, 0.03731437027454376, 0.0372304692864418, 0.03653930500149727, 0.037626802921295166, 0.031136393547058105, 0.044685691595077515, 0.0392303541302681, 0.032833557575941086, 0.03207946568727493, 0.03574257716536522, 0.015547771006822586], 'L_si': [0.00603262335062027, 0.006541430950164795, 0.006918787956237793, 0.006118908524513245, 0.00802011787891388, 0.006585851311683655, 0.007614195346832275, 0.005615264177322388, 0.0060337260365486145, 0.006568007171154022, 0.0064377933740615845, 0.006367042660713196, 0.004889011383056641, 0.0077880024909973145, 0.006702631711959839, 0.004951111972332001, 0.0055159032344818115, 0.006136849522590637, 0.007090084254741669], 'L_grad': [0.03537220507860184, 0.0328131765127182, 0.0316583625972271, 0.031211383640766144, 0.03620059788227081, 0.03230269253253937, 0.03656291961669922, 0.032328248023986816, 0.03128064423799515, 0.03066246211528778, 0.030101511627435684, 0.03125976026058197, 0.026247382164001465, 0.0368976891040802, 0.03252772241830826, 0.027882445603609085, 0.02656356245279312, 0.029605727642774582, 0.008457686752080917]}
Train Epoch: 87 [0/816 (0%)] loss: 0.0197 L_si: 0.0017 L_grad: 0.0180 
Train Epoch: 87 [36/816 (4%)] loss: 0.0157 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 87 [72/816 (9%)] loss: 0.0143 L_si: 0.0008 L_grad: 0.0135 
Train Epoch: 87 [108/816 (13%)] loss: 0.0168 L_si: 0.0013 L_grad: 0.0154 
Train Epoch: 87 [144/816 (18%)] loss: 0.0166 L_si: 0.0017 L_grad: 0.0149 
Train Epoch: 87 [180/816 (22%)] loss: 0.0203 L_si: 0.0030 L_grad: 0.0174 
Train Epoch: 87 [216/816 (26%)] loss: 0.0127 L_si: 0.0007 L_grad: 0.0120 
Train Epoch: 87 [252/816 (31%)] loss: 0.0165 L_si: 0.0013 L_grad: 0.0152 
Train Epoch: 87 [288/816 (35%)] loss: 0.0211 L_si: 0.0017 L_grad: 0.0194 
Train Epoch: 87 [324/816 (40%)] loss: 0.0123 L_si: 0.0008 L_grad: 0.0114 
Train Epoch: 87 [360/816 (44%)] loss: 0.0156 L_si: 0.0020 L_grad: 0.0137 
Train Epoch: 87 [396/816 (49%)] loss: 0.0147 L_si: 0.0011 L_grad: 0.0136 
Train Epoch: 87 [432/816 (53%)] loss: 0.0169 L_si: 0.0020 L_grad: 0.0150 
Train Epoch: 87 [468/816 (57%)] loss: 0.0202 L_si: 0.0032 L_grad: 0.0170 
Train Epoch: 87 [504/816 (62%)] loss: 0.0211 L_si: 0.0021 L_grad: 0.0190 
Train Epoch: 87 [540/816 (66%)] loss: 0.0117 L_si: 0.0005 L_grad: 0.0112 
Train Epoch: 87 [576/816 (71%)] loss: 0.0180 L_si: 0.0010 L_grad: 0.0169 
Train Epoch: 87 [612/816 (75%)] loss: 0.0149 L_si: 0.0011 L_grad: 0.0138 
Train Epoch: 87 [648/816 (79%)] loss: 0.0132 L_si: 0.0008 L_grad: 0.0124 
Train Epoch: 87 [684/816 (84%)] loss: 0.0214 L_si: 0.0025 L_grad: 0.0189 
Train Epoch: 87 [720/816 (88%)] loss: 0.0144 L_si: 0.0010 L_grad: 0.0134 
Train Epoch: 87 [756/816 (93%)] loss: 0.0141 L_si: 0.0011 L_grad: 0.0130 
Train Epoch: 87 [792/816 (97%)] loss: 0.0173 L_si: 0.0012 L_grad: 0.0161 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.040168408304452896, 0.03311018645763397, 0.0377720482647419, 0.03777840733528137, 0.047710027545690536, 0.03787726163864136, 0.034357111901044846, 0.032221462577581406, 0.042067840695381165, 0.03430642560124397, 0.041006702929735184, 0.03994777798652649, 0.03780021145939827, 0.03749755024909973, 0.043017879128456116, 0.043493110686540604, 0.03759206086397171, 0.037755925208330154, 0.01585157960653305], 'L_si': [0.006820023059844971, 0.006626598536968231, 0.0063745081424713135, 0.006712287664413452, 0.007946610450744629, 0.007525183260440826, 0.006326407194137573, 0.005170553922653198, 0.007946118712425232, 0.005955912172794342, 0.005526922643184662, 0.007167786359786987, 0.006139792501926422, 0.006851114332675934, 0.0075333938002586365, 0.007405802607536316, 0.006562530994415283, 0.006189219653606415, 0.00797213613986969], 'L_grad': [0.033348385244607925, 0.026483586058020592, 0.031397540122270584, 0.03106611967086792, 0.03976341709494591, 0.030352076515555382, 0.028030704706907272, 0.027050908654928207, 0.03412172198295593, 0.02835051342844963, 0.03547978028655052, 0.0327799916267395, 0.03166041895747185, 0.030646437779068947, 0.03548448532819748, 0.03608730807900429, 0.031029531732201576, 0.03156670555472374, 0.00787944346666336]}
Train Epoch: 88 [0/816 (0%)] loss: 0.0217 L_si: 0.0033 L_grad: 0.0184 
Train Epoch: 88 [36/816 (4%)] loss: 0.0148 L_si: 0.0010 L_grad: 0.0138 
Train Epoch: 88 [72/816 (9%)] loss: 0.0156 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 88 [108/816 (13%)] loss: 0.0219 L_si: 0.0029 L_grad: 0.0190 
Train Epoch: 88 [144/816 (18%)] loss: 0.0169 L_si: 0.0014 L_grad: 0.0155 
Train Epoch: 88 [180/816 (22%)] loss: 0.0158 L_si: 0.0010 L_grad: 0.0148 
Train Epoch: 88 [216/816 (26%)] loss: 0.0180 L_si: 0.0013 L_grad: 0.0167 
Train Epoch: 88 [252/816 (31%)] loss: 0.0207 L_si: 0.0026 L_grad: 0.0181 
Train Epoch: 88 [288/816 (35%)] loss: 0.0137 L_si: 0.0008 L_grad: 0.0128 
Train Epoch: 88 [324/816 (40%)] loss: 0.0198 L_si: 0.0016 L_grad: 0.0181 
Train Epoch: 88 [360/816 (44%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0142 
Train Epoch: 88 [396/816 (49%)] loss: 0.0145 L_si: 0.0010 L_grad: 0.0135 
Train Epoch: 88 [432/816 (53%)] loss: 0.0137 L_si: 0.0007 L_grad: 0.0130 
Train Epoch: 88 [468/816 (57%)] loss: 0.0176 L_si: 0.0013 L_grad: 0.0162 
Train Epoch: 88 [504/816 (62%)] loss: 0.0227 L_si: 0.0025 L_grad: 0.0202 
Train Epoch: 88 [540/816 (66%)] loss: 0.0161 L_si: 0.0013 L_grad: 0.0148 
Train Epoch: 88 [576/816 (71%)] loss: 0.0273 L_si: 0.0052 L_grad: 0.0221 
Train Epoch: 88 [612/816 (75%)] loss: 0.0146 L_si: 0.0019 L_grad: 0.0128 
Train Epoch: 88 [648/816 (79%)] loss: 0.0173 L_si: 0.0017 L_grad: 0.0157 
Train Epoch: 88 [684/816 (84%)] loss: 0.0166 L_si: 0.0014 L_grad: 0.0153 
Train Epoch: 88 [720/816 (88%)] loss: 0.0186 L_si: 0.0019 L_grad: 0.0167 
Train Epoch: 88 [756/816 (93%)] loss: 0.0184 L_si: 0.0021 L_grad: 0.0163 
Train Epoch: 88 [792/816 (97%)] loss: 0.0123 L_si: 0.0013 L_grad: 0.0110 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.0370255708694458, 0.039954960346221924, 0.04012983292341232, 0.03157280758023262, 0.03404498100280762, 0.035813186317682266, 0.04960326477885246, 0.043201178312301636, 0.03950350731611252, 0.039581138640642166, 0.04127688333392143, 0.03858499974012375, 0.038706548511981964, 0.041216880083084106, 0.03106827475130558, 0.03838973492383957, 0.03863879293203354, 0.039214838296175, 0.011673109605908394], 'L_si': [0.005788028240203857, 0.0063538625836372375, 0.006839588284492493, 0.005072206258773804, 0.0056758299469947815, 0.006034098565578461, 0.008572511374950409, 0.006553761661052704, 0.0056228116154670715, 0.005431875586509705, 0.007120706140995026, 0.006267033517360687, 0.00639970600605011, 0.007751777768135071, 0.004128299653530121, 0.006636887788772583, 0.006612136960029602, 0.006952747702598572, 0.004864312708377838], 'L_grad': [0.031237542629241943, 0.033601097762584686, 0.03329024463891983, 0.026500601321458817, 0.028369149193167686, 0.029779087752103806, 0.041030753403902054, 0.03664741665124893, 0.03388069570064545, 0.03414926305413246, 0.03415617719292641, 0.03231796622276306, 0.032306842505931854, 0.033465102314949036, 0.02693997509777546, 0.031752847135066986, 0.03202665597200394, 0.03226209059357643, 0.006808796431869268]}
Train Epoch: 89 [0/816 (0%)] loss: 0.0127 L_si: 0.0007 L_grad: 0.0119 
Train Epoch: 89 [36/816 (4%)] loss: 0.0152 L_si: 0.0014 L_grad: 0.0138 
Train Epoch: 89 [72/816 (9%)] loss: 0.0194 L_si: 0.0016 L_grad: 0.0178 
Train Epoch: 89 [108/816 (13%)] loss: 0.0153 L_si: 0.0006 L_grad: 0.0147 
Train Epoch: 89 [144/816 (18%)] loss: 0.0163 L_si: 0.0011 L_grad: 0.0152 
Train Epoch: 89 [180/816 (22%)] loss: 0.0177 L_si: 0.0015 L_grad: 0.0163 
Train Epoch: 89 [216/816 (26%)] loss: 0.0171 L_si: 0.0018 L_grad: 0.0154 
Train Epoch: 89 [252/816 (31%)] loss: 0.0207 L_si: 0.0019 L_grad: 0.0188 
Train Epoch: 89 [288/816 (35%)] loss: 0.0154 L_si: 0.0013 L_grad: 0.0141 
Train Epoch: 89 [324/816 (40%)] loss: 0.0161 L_si: 0.0017 L_grad: 0.0143 
Train Epoch: 89 [360/816 (44%)] loss: 0.0159 L_si: 0.0010 L_grad: 0.0148 
Train Epoch: 89 [396/816 (49%)] loss: 0.0173 L_si: 0.0015 L_grad: 0.0158 
Train Epoch: 89 [432/816 (53%)] loss: 0.0200 L_si: 0.0022 L_grad: 0.0177 
Train Epoch: 89 [468/816 (57%)] loss: 0.0101 L_si: 0.0005 L_grad: 0.0096 
Train Epoch: 89 [504/816 (62%)] loss: 0.0188 L_si: 0.0023 L_grad: 0.0166 
Train Epoch: 89 [540/816 (66%)] loss: 0.0193 L_si: 0.0016 L_grad: 0.0177 
Train Epoch: 89 [576/816 (71%)] loss: 0.0129 L_si: 0.0006 L_grad: 0.0123 
Train Epoch: 89 [612/816 (75%)] loss: 0.0224 L_si: 0.0019 L_grad: 0.0205 
Train Epoch: 89 [648/816 (79%)] loss: 0.0132 L_si: 0.0008 L_grad: 0.0125 
Train Epoch: 89 [684/816 (84%)] loss: 0.0152 L_si: 0.0012 L_grad: 0.0140 
Train Epoch: 89 [720/816 (88%)] loss: 0.0198 L_si: 0.0044 L_grad: 0.0154 
Train Epoch: 89 [756/816 (93%)] loss: 0.0142 L_si: 0.0011 L_grad: 0.0131 
Train Epoch: 89 [792/816 (97%)] loss: 0.0206 L_si: 0.0019 L_grad: 0.0186 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04339805990457535, 0.033606503158807755, 0.0411594957113266, 0.03702870383858681, 0.043928638100624084, 0.03948329761624336, 0.03876498341560364, 0.03957345336675644, 0.03970484435558319, 0.04394235089421272, 0.040937960147857666, 0.0404483824968338, 0.03835049271583557, 0.04042259603738785, 0.04199884459376335, 0.031517598778009415, 0.03617232292890549, 0.03715211898088455, 0.013263976201415062], 'L_si': [0.007819876074790955, 0.00607077032327652, 0.007439970970153809, 0.0059574320912361145, 0.006704173982143402, 0.0068335384130477905, 0.0067229196429252625, 0.00695221871137619, 0.006617486476898193, 0.007521979510784149, 0.006929963827133179, 0.0070174261927604675, 0.006894655525684357, 0.007043980062007904, 0.0068921372294425964, 0.004610154777765274, 0.006841026246547699, 0.005891233682632446, 0.006018884479999542], 'L_grad': [0.03557818382978439, 0.027535732835531235, 0.03371952474117279, 0.031071271747350693, 0.03722446411848068, 0.03264975920319557, 0.032042063772678375, 0.03262123465538025, 0.033087357878685, 0.036420371383428574, 0.03400799632072449, 0.033430956304073334, 0.031455837190151215, 0.033378615975379944, 0.035106707364320755, 0.02690744400024414, 0.029331296682357788, 0.031260885298252106, 0.007245092187076807]}
Train Epoch: 90 [0/816 (0%)] loss: 0.0149 L_si: 0.0008 L_grad: 0.0142 
Train Epoch: 90 [36/816 (4%)] loss: 0.0120 L_si: 0.0005 L_grad: 0.0114 
Train Epoch: 90 [72/816 (9%)] loss: 0.0163 L_si: 0.0013 L_grad: 0.0149 
Train Epoch: 90 [108/816 (13%)] loss: 0.0176 L_si: 0.0014 L_grad: 0.0162 
Train Epoch: 90 [144/816 (18%)] loss: 0.0179 L_si: 0.0020 L_grad: 0.0160 
Train Epoch: 90 [180/816 (22%)] loss: 0.0216 L_si: 0.0028 L_grad: 0.0188 
Train Epoch: 90 [216/816 (26%)] loss: 0.0134 L_si: 0.0007 L_grad: 0.0126 
Train Epoch: 90 [252/816 (31%)] loss: 0.0194 L_si: 0.0024 L_grad: 0.0170 
Train Epoch: 90 [288/816 (35%)] loss: 0.0168 L_si: 0.0012 L_grad: 0.0155 
Train Epoch: 90 [324/816 (40%)] loss: 0.0194 L_si: 0.0020 L_grad: 0.0174 
Train Epoch: 90 [360/816 (44%)] loss: 0.0144 L_si: 0.0009 L_grad: 0.0135 
Train Epoch: 90 [396/816 (49%)] loss: 0.0150 L_si: 0.0013 L_grad: 0.0137 
Train Epoch: 90 [432/816 (53%)] loss: 0.0156 L_si: 0.0022 L_grad: 0.0134 
Train Epoch: 90 [468/816 (57%)] loss: 0.0182 L_si: 0.0011 L_grad: 0.0171 
Train Epoch: 90 [504/816 (62%)] loss: 0.0158 L_si: 0.0012 L_grad: 0.0146 
Train Epoch: 90 [540/816 (66%)] loss: 0.0115 L_si: 0.0005 L_grad: 0.0110 
Train Epoch: 90 [576/816 (71%)] loss: 0.0168 L_si: 0.0015 L_grad: 0.0153 
Train Epoch: 90 [612/816 (75%)] loss: 0.0258 L_si: 0.0025 L_grad: 0.0233 
Train Epoch: 90 [648/816 (79%)] loss: 0.0175 L_si: 0.0015 L_grad: 0.0161 
Train Epoch: 90 [684/816 (84%)] loss: 0.0187 L_si: 0.0017 L_grad: 0.0169 
Train Epoch: 90 [720/816 (88%)] loss: 0.0204 L_si: 0.0014 L_grad: 0.0190 
Train Epoch: 90 [756/816 (93%)] loss: 0.0202 L_si: 0.0020 L_grad: 0.0182 
Train Epoch: 90 [792/816 (97%)] loss: 0.0210 L_si: 0.0020 L_grad: 0.0190 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch090-loss-0.0170.pth.tar ...
all losses in batch in validation:  {'loss': [0.03558890521526337, 0.034803517162799835, 0.039372459053993225, 0.04075565189123154, 0.03526303917169571, 0.03533551096916199, 0.033458590507507324, 0.0443931445479393, 0.03955398499965668, 0.04010375589132309, 0.03638880327343941, 0.04677380621433258, 0.03649348393082619, 0.04423973709344864, 0.0339721217751503, 0.03880320489406586, 0.03688577562570572, 0.038454994559288025, 0.015455479733645916], 'L_si': [0.0062097907066345215, 0.005220584571361542, 0.006217733025550842, 0.006544880568981171, 0.005963020026683807, 0.005699969828128815, 0.005103938281536102, 0.006441734731197357, 0.005341134965419769, 0.006984986364841461, 0.006251923739910126, 0.007919460535049438, 0.005645036697387695, 0.007792115211486816, 0.004511423408985138, 0.005572035908699036, 0.005384087562561035, 0.006772823631763458, 0.005443692207336426], 'L_grad': [0.029379112645983696, 0.029582932591438293, 0.03315472602844238, 0.034210771322250366, 0.029300019145011902, 0.029635543003678322, 0.02835465408861637, 0.03795140981674194, 0.03421285003423691, 0.03311876952648163, 0.03013687953352928, 0.03885434567928314, 0.030848447233438492, 0.03644762188196182, 0.02946070022881031, 0.03323116898536682, 0.031501688063144684, 0.03168217092752457, 0.01001178752630949]}
Train Epoch: 91 [0/816 (0%)] loss: 0.0156 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 91 [36/816 (4%)] loss: 0.0146 L_si: 0.0013 L_grad: 0.0133 
Train Epoch: 91 [72/816 (9%)] loss: 0.0176 L_si: 0.0014 L_grad: 0.0162 
Train Epoch: 91 [108/816 (13%)] loss: 0.0202 L_si: 0.0027 L_grad: 0.0175 
Train Epoch: 91 [144/816 (18%)] loss: 0.0187 L_si: 0.0012 L_grad: 0.0175 
Train Epoch: 91 [180/816 (22%)] loss: 0.0173 L_si: 0.0010 L_grad: 0.0163 
Train Epoch: 91 [216/816 (26%)] loss: 0.0163 L_si: 0.0010 L_grad: 0.0153 
Train Epoch: 91 [252/816 (31%)] loss: 0.0217 L_si: 0.0017 L_grad: 0.0201 
Train Epoch: 91 [288/816 (35%)] loss: 0.0251 L_si: 0.0026 L_grad: 0.0226 
Train Epoch: 91 [324/816 (40%)] loss: 0.0180 L_si: 0.0016 L_grad: 0.0164 
Train Epoch: 91 [360/816 (44%)] loss: 0.0155 L_si: 0.0012 L_grad: 0.0143 
Train Epoch: 91 [396/816 (49%)] loss: 0.0144 L_si: 0.0009 L_grad: 0.0134 
Train Epoch: 91 [432/816 (53%)] loss: 0.0194 L_si: 0.0020 L_grad: 0.0174 
Train Epoch: 91 [468/816 (57%)] loss: 0.0170 L_si: 0.0017 L_grad: 0.0153 
Train Epoch: 91 [504/816 (62%)] loss: 0.0164 L_si: 0.0013 L_grad: 0.0151 
Train Epoch: 91 [540/816 (66%)] loss: 0.0165 L_si: 0.0011 L_grad: 0.0154 
Train Epoch: 91 [576/816 (71%)] loss: 0.0153 L_si: 0.0012 L_grad: 0.0141 
Train Epoch: 91 [612/816 (75%)] loss: 0.0186 L_si: 0.0025 L_grad: 0.0161 
Train Epoch: 91 [648/816 (79%)] loss: 0.0164 L_si: 0.0011 L_grad: 0.0153 
Train Epoch: 91 [684/816 (84%)] loss: 0.0157 L_si: 0.0013 L_grad: 0.0144 
Train Epoch: 91 [720/816 (88%)] loss: 0.0162 L_si: 0.0016 L_grad: 0.0146 
Train Epoch: 91 [756/816 (93%)] loss: 0.0141 L_si: 0.0007 L_grad: 0.0134 
Train Epoch: 91 [792/816 (97%)] loss: 0.0170 L_si: 0.0017 L_grad: 0.0153 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.041998736560344696, 0.03906211256980896, 0.035784296691417694, 0.03685808926820755, 0.03833359107375145, 0.0380614772439003, 0.04476439207792282, 0.043143946677446365, 0.03789176791906357, 0.03763231635093689, 0.03602134436368942, 0.038223110139369965, 0.03937000408768654, 0.03389740362763405, 0.042032018303871155, 0.04148487746715546, 0.03819233924150467, 0.04106704145669937, 0.01271803304553032], 'L_si': [0.008234396576881409, 0.007512517273426056, 0.00541137158870697, 0.00739210844039917, 0.0071921274065971375, 0.007141910493373871, 0.00865938514471054, 0.006479203701019287, 0.0058588907122612, 0.0062210336327552795, 0.0062865763902664185, 0.006753697991371155, 0.007216788828372955, 0.0053358376026153564, 0.007035516202449799, 0.0077748894691467285, 0.005957946181297302, 0.0060793086886405945, 0.00683218240737915], 'L_grad': [0.03376433998346329, 0.031549595296382904, 0.030372923240065575, 0.02946598082780838, 0.031141463667154312, 0.030919566750526428, 0.03610500693321228, 0.03666474297642708, 0.03203287720680237, 0.03141128271818161, 0.029734769836068153, 0.03146941214799881, 0.03215321525931358, 0.028561566025018692, 0.034996502101421356, 0.03370998799800873, 0.03223439306020737, 0.03498773276805878, 0.005885850638151169]}
Train Epoch: 92 [0/816 (0%)] loss: 0.0122 L_si: 0.0005 L_grad: 0.0117 
Train Epoch: 92 [36/816 (4%)] loss: 0.0131 L_si: 0.0008 L_grad: 0.0123 
Train Epoch: 92 [72/816 (9%)] loss: 0.0145 L_si: 0.0010 L_grad: 0.0135 
Train Epoch: 92 [108/816 (13%)] loss: 0.0144 L_si: 0.0012 L_grad: 0.0132 
Train Epoch: 92 [144/816 (18%)] loss: 0.0155 L_si: 0.0017 L_grad: 0.0137 
Train Epoch: 92 [180/816 (22%)] loss: 0.0122 L_si: 0.0005 L_grad: 0.0117 
Train Epoch: 92 [216/816 (26%)] loss: 0.0154 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 92 [252/816 (31%)] loss: 0.0152 L_si: 0.0010 L_grad: 0.0141 
Train Epoch: 92 [288/816 (35%)] loss: 0.0146 L_si: 0.0011 L_grad: 0.0135 
Train Epoch: 92 [324/816 (40%)] loss: 0.0154 L_si: 0.0009 L_grad: 0.0144 
Train Epoch: 92 [360/816 (44%)] loss: 0.0130 L_si: 0.0006 L_grad: 0.0124 
Train Epoch: 92 [396/816 (49%)] loss: 0.0155 L_si: 0.0010 L_grad: 0.0145 
Train Epoch: 92 [432/816 (53%)] loss: 0.0144 L_si: 0.0009 L_grad: 0.0135 
Train Epoch: 92 [468/816 (57%)] loss: 0.0173 L_si: 0.0023 L_grad: 0.0150 
Train Epoch: 92 [504/816 (62%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0161 
Train Epoch: 92 [540/816 (66%)] loss: 0.0136 L_si: 0.0010 L_grad: 0.0126 
Train Epoch: 92 [576/816 (71%)] loss: 0.0124 L_si: 0.0005 L_grad: 0.0119 
Train Epoch: 92 [612/816 (75%)] loss: 0.0180 L_si: 0.0026 L_grad: 0.0154 
Train Epoch: 92 [648/816 (79%)] loss: 0.0174 L_si: 0.0014 L_grad: 0.0161 
Train Epoch: 92 [684/816 (84%)] loss: 0.0161 L_si: 0.0015 L_grad: 0.0145 
Train Epoch: 92 [720/816 (88%)] loss: 0.0172 L_si: 0.0014 L_grad: 0.0158 
Train Epoch: 92 [756/816 (93%)] loss: 0.0167 L_si: 0.0014 L_grad: 0.0153 
Train Epoch: 92 [792/816 (97%)] loss: 0.0182 L_si: 0.0017 L_grad: 0.0165 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.039903342723846436, 0.03990369662642479, 0.037074360996484756, 0.038451772183179855, 0.04201627895236015, 0.03540132939815521, 0.03533756732940674, 0.034532591700553894, 0.038730036467313766, 0.04057754948735237, 0.035723693668842316, 0.035125959664583206, 0.035171493887901306, 0.037429407238960266, 0.03606560826301575, 0.036427341401576996, 0.03387460857629776, 0.035380423069000244, 0.012199309654533863], 'L_si': [0.006344757974147797, 0.00554269552230835, 0.005465231835842133, 0.006014317274093628, 0.007112957537174225, 0.0047341883182525635, 0.005842864513397217, 0.005245126783847809, 0.005366191267967224, 0.00714835524559021, 0.0053105950355529785, 0.0051913782954216, 0.0055107176303863525, 0.006045699119567871, 0.006178632378578186, 0.004949189722537994, 0.005394205451011658, 0.0057668909430503845, 0.004956386983394623], 'L_grad': [0.03355858474969864, 0.03436100110411644, 0.031609129160642624, 0.03243745490908623, 0.03490332141518593, 0.03066714107990265, 0.02949470281600952, 0.029287464916706085, 0.03336384519934654, 0.03342919424176216, 0.030413100495934486, 0.029934581369161606, 0.029660774394869804, 0.031383708119392395, 0.02988697588443756, 0.031478151679039, 0.028480403125286102, 0.02961353212594986, 0.00724292267113924]}
Train Epoch: 93 [0/816 (0%)] loss: 0.0145 L_si: 0.0008 L_grad: 0.0137 
Train Epoch: 93 [36/816 (4%)] loss: 0.0251 L_si: 0.0022 L_grad: 0.0229 
Train Epoch: 93 [72/816 (9%)] loss: 0.0160 L_si: 0.0011 L_grad: 0.0149 
Train Epoch: 93 [108/816 (13%)] loss: 0.0203 L_si: 0.0019 L_grad: 0.0184 
Train Epoch: 93 [144/816 (18%)] loss: 0.0203 L_si: 0.0031 L_grad: 0.0172 
Train Epoch: 93 [180/816 (22%)] loss: 0.0212 L_si: 0.0045 L_grad: 0.0167 
Train Epoch: 93 [216/816 (26%)] loss: 0.0173 L_si: 0.0014 L_grad: 0.0159 
Train Epoch: 93 [252/816 (31%)] loss: 0.0175 L_si: 0.0023 L_grad: 0.0152 
Train Epoch: 93 [288/816 (35%)] loss: 0.0220 L_si: 0.0020 L_grad: 0.0200 
Train Epoch: 93 [324/816 (40%)] loss: 0.0139 L_si: 0.0008 L_grad: 0.0131 
Train Epoch: 93 [360/816 (44%)] loss: 0.0183 L_si: 0.0015 L_grad: 0.0168 
Train Epoch: 93 [396/816 (49%)] loss: 0.0158 L_si: 0.0014 L_grad: 0.0144 
Train Epoch: 93 [432/816 (53%)] loss: 0.0167 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 93 [468/816 (57%)] loss: 0.0176 L_si: 0.0015 L_grad: 0.0161 
Train Epoch: 93 [504/816 (62%)] loss: 0.0203 L_si: 0.0027 L_grad: 0.0176 
Train Epoch: 93 [540/816 (66%)] loss: 0.0195 L_si: 0.0018 L_grad: 0.0177 
Train Epoch: 93 [576/816 (71%)] loss: 0.0143 L_si: 0.0008 L_grad: 0.0135 
Train Epoch: 93 [612/816 (75%)] loss: 0.0187 L_si: 0.0018 L_grad: 0.0168 
Train Epoch: 93 [648/816 (79%)] loss: 0.0139 L_si: 0.0012 L_grad: 0.0127 
Train Epoch: 93 [684/816 (84%)] loss: 0.0186 L_si: 0.0013 L_grad: 0.0173 
Train Epoch: 93 [720/816 (88%)] loss: 0.0175 L_si: 0.0012 L_grad: 0.0163 
Train Epoch: 93 [756/816 (93%)] loss: 0.0125 L_si: 0.0007 L_grad: 0.0118 
Train Epoch: 93 [792/816 (97%)] loss: 0.0198 L_si: 0.0016 L_grad: 0.0182 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03615328669548035, 0.036218758672475815, 0.04527541995048523, 0.04588296636939049, 0.03861423209309578, 0.03975067287683487, 0.03144891560077667, 0.03729263320565224, 0.04362688586115837, 0.038347627967596054, 0.035202641040086746, 0.03711427375674248, 0.03222105652093887, 0.04025519639253616, 0.03952503204345703, 0.04148442670702934, 0.038137465715408325, 0.034494299441576004, 0.011398447677493095], 'L_si': [0.005976758897304535, 0.006134264171123505, 0.007337071001529694, 0.007388949394226074, 0.00695684552192688, 0.006689943373203278, 0.005053259432315826, 0.006361678242683411, 0.007343970239162445, 0.006775900721549988, 0.006518810987472534, 0.00659402459859848, 0.004652649164199829, 0.0062930285930633545, 0.007024593651294708, 0.006804108619689941, 0.006005868315696716, 0.005580432713031769, 0.004390306770801544], 'L_grad': [0.030176527798175812, 0.03008449450135231, 0.037938348948955536, 0.03849401697516441, 0.0316573865711689, 0.03306072950363159, 0.026395656168460846, 0.030930954962968826, 0.036282915621995926, 0.031571727246046066, 0.028683830052614212, 0.030520249158143997, 0.027568405494093895, 0.03396216779947281, 0.03250043839216232, 0.0346803180873394, 0.03213159739971161, 0.028913866728544235, 0.007008140906691551]}
Train Epoch: 94 [0/816 (0%)] loss: 0.0147 L_si: 0.0010 L_grad: 0.0137 
Train Epoch: 94 [36/816 (4%)] loss: 0.0216 L_si: 0.0035 L_grad: 0.0181 
Train Epoch: 94 [72/816 (9%)] loss: 0.0140 L_si: 0.0008 L_grad: 0.0133 
Train Epoch: 94 [108/816 (13%)] loss: 0.0183 L_si: 0.0017 L_grad: 0.0165 
Train Epoch: 94 [144/816 (18%)] loss: 0.0149 L_si: 0.0009 L_grad: 0.0140 
Train Epoch: 94 [180/816 (22%)] loss: 0.0227 L_si: 0.0032 L_grad: 0.0195 
Train Epoch: 94 [216/816 (26%)] loss: 0.0174 L_si: 0.0013 L_grad: 0.0161 
Train Epoch: 94 [252/816 (31%)] loss: 0.0208 L_si: 0.0026 L_grad: 0.0181 
Train Epoch: 94 [288/816 (35%)] loss: 0.0147 L_si: 0.0012 L_grad: 0.0135 
Train Epoch: 94 [324/816 (40%)] loss: 0.0158 L_si: 0.0010 L_grad: 0.0148 
Train Epoch: 94 [360/816 (44%)] loss: 0.0183 L_si: 0.0012 L_grad: 0.0170 
Train Epoch: 94 [396/816 (49%)] loss: 0.0215 L_si: 0.0019 L_grad: 0.0196 
Train Epoch: 94 [432/816 (53%)] loss: 0.0135 L_si: 0.0008 L_grad: 0.0127 
Train Epoch: 94 [468/816 (57%)] loss: 0.0182 L_si: 0.0015 L_grad: 0.0167 
Train Epoch: 94 [504/816 (62%)] loss: 0.0188 L_si: 0.0014 L_grad: 0.0174 
Train Epoch: 94 [540/816 (66%)] loss: 0.0151 L_si: 0.0008 L_grad: 0.0143 
Train Epoch: 94 [576/816 (71%)] loss: 0.0166 L_si: 0.0012 L_grad: 0.0154 
Train Epoch: 94 [612/816 (75%)] loss: 0.0127 L_si: 0.0006 L_grad: 0.0121 
Train Epoch: 94 [648/816 (79%)] loss: 0.0115 L_si: 0.0005 L_grad: 0.0110 
Train Epoch: 94 [684/816 (84%)] loss: 0.0192 L_si: 0.0025 L_grad: 0.0168 
Train Epoch: 94 [720/816 (88%)] loss: 0.0164 L_si: 0.0010 L_grad: 0.0154 
Train Epoch: 94 [756/816 (93%)] loss: 0.0146 L_si: 0.0015 L_grad: 0.0131 
Train Epoch: 94 [792/816 (97%)] loss: 0.0124 L_si: 0.0005 L_grad: 0.0119 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03825487196445465, 0.04322931915521622, 0.04063250124454498, 0.03673103451728821, 0.0336688831448555, 0.042526036500930786, 0.03668227791786194, 0.03512109816074371, 0.039926934987306595, 0.03672181814908981, 0.037640154361724854, 0.038210220634937286, 0.04434051737189293, 0.03720492869615555, 0.040009841322898865, 0.036901187151670456, 0.035374924540519714, 0.03995932266116142, 0.0171593576669693], 'L_si': [0.006883285939693451, 0.007066585123538971, 0.006460592150688171, 0.005563296377658844, 0.004010282456874847, 0.006401561200618744, 0.006214559078216553, 0.005248725414276123, 0.005887538194656372, 0.00612398236989975, 0.006675057113170624, 0.006540432572364807, 0.006536431610584259, 0.006607480347156525, 0.006385684013366699, 0.005878567695617676, 0.004789695143699646, 0.007208436727523804, 0.00815117359161377], 'L_grad': [0.0313715860247612, 0.036162734031677246, 0.03417190909385681, 0.031167738139629364, 0.029658600687980652, 0.03612447530031204, 0.030467720702290535, 0.02987237088382244, 0.03403939679265022, 0.030597837641835213, 0.03096509724855423, 0.03166978806257248, 0.03780408576130867, 0.030597448348999023, 0.033624157309532166, 0.03102261945605278, 0.03058522753417492, 0.03275088593363762, 0.00900818407535553]}
Train Epoch: 95 [0/816 (0%)] loss: 0.0172 L_si: 0.0011 L_grad: 0.0161 
Train Epoch: 95 [36/816 (4%)] loss: 0.0148 L_si: 0.0010 L_grad: 0.0138 
Train Epoch: 95 [72/816 (9%)] loss: 0.0124 L_si: 0.0005 L_grad: 0.0119 
Train Epoch: 95 [108/816 (13%)] loss: 0.0229 L_si: 0.0039 L_grad: 0.0190 
Train Epoch: 95 [144/816 (18%)] loss: 0.0152 L_si: 0.0011 L_grad: 0.0141 
Train Epoch: 95 [180/816 (22%)] loss: 0.0159 L_si: 0.0012 L_grad: 0.0147 
Train Epoch: 95 [216/816 (26%)] loss: 0.0158 L_si: 0.0013 L_grad: 0.0145 
Train Epoch: 95 [252/816 (31%)] loss: 0.0123 L_si: 0.0007 L_grad: 0.0116 
Train Epoch: 95 [288/816 (35%)] loss: 0.0131 L_si: 0.0006 L_grad: 0.0125 
Train Epoch: 95 [324/816 (40%)] loss: 0.0208 L_si: 0.0025 L_grad: 0.0182 
Train Epoch: 95 [360/816 (44%)] loss: 0.0178 L_si: 0.0023 L_grad: 0.0155 
Train Epoch: 95 [396/816 (49%)] loss: 0.0121 L_si: 0.0006 L_grad: 0.0115 
Train Epoch: 95 [432/816 (53%)] loss: 0.0186 L_si: 0.0016 L_grad: 0.0170 
Train Epoch: 95 [468/816 (57%)] loss: 0.0202 L_si: 0.0016 L_grad: 0.0186 
Train Epoch: 95 [504/816 (62%)] loss: 0.0122 L_si: 0.0005 L_grad: 0.0117 
Train Epoch: 95 [540/816 (66%)] loss: 0.0223 L_si: 0.0018 L_grad: 0.0206 
Train Epoch: 95 [576/816 (71%)] loss: 0.0157 L_si: 0.0010 L_grad: 0.0147 
Train Epoch: 95 [612/816 (75%)] loss: 0.0155 L_si: 0.0011 L_grad: 0.0144 
Train Epoch: 95 [648/816 (79%)] loss: 0.0143 L_si: 0.0011 L_grad: 0.0132 
Train Epoch: 95 [684/816 (84%)] loss: 0.0169 L_si: 0.0010 L_grad: 0.0159 
Train Epoch: 95 [720/816 (88%)] loss: 0.0151 L_si: 0.0013 L_grad: 0.0138 
Train Epoch: 95 [756/816 (93%)] loss: 0.0151 L_si: 0.0013 L_grad: 0.0138 
Train Epoch: 95 [792/816 (97%)] loss: 0.0181 L_si: 0.0012 L_grad: 0.0169 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.041912827640771866, 0.037587836384773254, 0.03736543282866478, 0.036493923515081406, 0.04265708476305008, 0.036014147102832794, 0.03432381525635719, 0.03730691224336624, 0.0388677716255188, 0.03522147983312607, 0.03845006972551346, 0.04320366680622101, 0.03807872533798218, 0.03475259244441986, 0.038445740938186646, 0.043688029050827026, 0.03541449084877968, 0.037861160933971405, 0.011586494743824005], 'L_si': [0.006468772888183594, 0.006210267543792725, 0.00614243745803833, 0.006246589124202728, 0.0066817328333854675, 0.006140030920505524, 0.005689896643161774, 0.006486468017101288, 0.006195046007633209, 0.005344226956367493, 0.006665259599685669, 0.005935706198215485, 0.005884118378162384, 0.00591731071472168, 0.00561688095331192, 0.005865208804607391, 0.005261875689029694, 0.005914278328418732, 0.004144512116909027], 'L_grad': [0.03544405475258827, 0.03137756884098053, 0.03122299537062645, 0.030247334390878677, 0.03597535192966461, 0.02987411804497242, 0.02863391861319542, 0.030820442363619804, 0.03267272561788559, 0.029877254739403725, 0.03178481012582779, 0.037267960608005524, 0.032194606959819794, 0.02883528172969818, 0.032828859984874725, 0.037822820246219635, 0.030152615159749985, 0.03194688260555267, 0.007441982626914978]}
Train Epoch: 96 [0/816 (0%)] loss: 0.0148 L_si: 0.0009 L_grad: 0.0139 
Train Epoch: 96 [36/816 (4%)] loss: 0.0158 L_si: 0.0009 L_grad: 0.0149 
Train Epoch: 96 [72/816 (9%)] loss: 0.0165 L_si: 0.0011 L_grad: 0.0155 
Train Epoch: 96 [108/816 (13%)] loss: 0.0184 L_si: 0.0017 L_grad: 0.0167 
Train Epoch: 96 [144/816 (18%)] loss: 0.0166 L_si: 0.0011 L_grad: 0.0155 
Train Epoch: 96 [180/816 (22%)] loss: 0.0183 L_si: 0.0015 L_grad: 0.0169 
Train Epoch: 96 [216/816 (26%)] loss: 0.0205 L_si: 0.0024 L_grad: 0.0182 
Train Epoch: 96 [252/816 (31%)] loss: 0.0120 L_si: 0.0007 L_grad: 0.0113 
Train Epoch: 96 [288/816 (35%)] loss: 0.0230 L_si: 0.0019 L_grad: 0.0211 
Train Epoch: 96 [324/816 (40%)] loss: 0.0181 L_si: 0.0020 L_grad: 0.0160 
Train Epoch: 96 [360/816 (44%)] loss: 0.0144 L_si: 0.0007 L_grad: 0.0136 
Train Epoch: 96 [396/816 (49%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0158 
Train Epoch: 96 [432/816 (53%)] loss: 0.0140 L_si: 0.0007 L_grad: 0.0133 
Train Epoch: 96 [468/816 (57%)] loss: 0.0136 L_si: 0.0006 L_grad: 0.0130 
Train Epoch: 96 [504/816 (62%)] loss: 0.0165 L_si: 0.0012 L_grad: 0.0153 
Train Epoch: 96 [540/816 (66%)] loss: 0.0181 L_si: 0.0014 L_grad: 0.0167 
Train Epoch: 96 [576/816 (71%)] loss: 0.0153 L_si: 0.0010 L_grad: 0.0143 
Train Epoch: 96 [612/816 (75%)] loss: 0.0159 L_si: 0.0016 L_grad: 0.0143 
Train Epoch: 96 [648/816 (79%)] loss: 0.0239 L_si: 0.0038 L_grad: 0.0201 
Train Epoch: 96 [684/816 (84%)] loss: 0.0124 L_si: 0.0008 L_grad: 0.0117 
Train Epoch: 96 [720/816 (88%)] loss: 0.0168 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 96 [756/816 (93%)] loss: 0.0154 L_si: 0.0012 L_grad: 0.0142 
Train Epoch: 96 [792/816 (97%)] loss: 0.0222 L_si: 0.0022 L_grad: 0.0199 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.036038465797901154, 0.03919566050171852, 0.04287617653608322, 0.035122718662023544, 0.039890337735414505, 0.04306595399975777, 0.0357961542904377, 0.03843129426240921, 0.035112593322992325, 0.039183273911476135, 0.0418258011341095, 0.036347731947898865, 0.039148278534412384, 0.039134420454502106, 0.04006229713559151, 0.04129880666732788, 0.03612637519836426, 0.041414566338062286, 0.010448929853737354], 'L_si': [0.006341807544231415, 0.006495214998722076, 0.005701310932636261, 0.005141042172908783, 0.00716826319694519, 0.007347866892814636, 0.005632877349853516, 0.00650111585855484, 0.00589270144701004, 0.006054744124412537, 0.006428822875022888, 0.005689755082130432, 0.006274811923503876, 0.006720110774040222, 0.006520755589008331, 0.006286457180976868, 0.006161205470561981, 0.005892954766750336, 0.0035096853971481323], 'L_grad': [0.02969665639102459, 0.032700445502996445, 0.03717486560344696, 0.02998167648911476, 0.032722074538469315, 0.03571808710694313, 0.030163276940584183, 0.03193017840385437, 0.029219891875982285, 0.0331285297870636, 0.03539697825908661, 0.030657975003123283, 0.03287346661090851, 0.032414309680461884, 0.033541541546583176, 0.03501234948635101, 0.029965169727802277, 0.03552161157131195, 0.006939244456589222]}
Train Epoch: 97 [0/816 (0%)] loss: 0.0122 L_si: 0.0006 L_grad: 0.0116 
Train Epoch: 97 [36/816 (4%)] loss: 0.0161 L_si: 0.0010 L_grad: 0.0151 
Train Epoch: 97 [72/816 (9%)] loss: 0.0115 L_si: 0.0006 L_grad: 0.0109 
Train Epoch: 97 [108/816 (13%)] loss: 0.0176 L_si: 0.0012 L_grad: 0.0163 
Train Epoch: 97 [144/816 (18%)] loss: 0.0162 L_si: 0.0011 L_grad: 0.0152 
Train Epoch: 97 [180/816 (22%)] loss: 0.0178 L_si: 0.0018 L_grad: 0.0160 
Train Epoch: 97 [216/816 (26%)] loss: 0.0159 L_si: 0.0011 L_grad: 0.0148 
Train Epoch: 97 [252/816 (31%)] loss: 0.0154 L_si: 0.0014 L_grad: 0.0141 
Train Epoch: 97 [288/816 (35%)] loss: 0.0212 L_si: 0.0023 L_grad: 0.0189 
Train Epoch: 97 [324/816 (40%)] loss: 0.0163 L_si: 0.0013 L_grad: 0.0150 
Train Epoch: 97 [360/816 (44%)] loss: 0.0147 L_si: 0.0012 L_grad: 0.0135 
Train Epoch: 97 [396/816 (49%)] loss: 0.0169 L_si: 0.0012 L_grad: 0.0156 
Train Epoch: 97 [432/816 (53%)] loss: 0.0145 L_si: 0.0010 L_grad: 0.0136 
Train Epoch: 97 [468/816 (57%)] loss: 0.0141 L_si: 0.0007 L_grad: 0.0133 
Train Epoch: 97 [504/816 (62%)] loss: 0.0142 L_si: 0.0008 L_grad: 0.0134 
Train Epoch: 97 [540/816 (66%)] loss: 0.0132 L_si: 0.0007 L_grad: 0.0125 
Train Epoch: 97 [576/816 (71%)] loss: 0.0141 L_si: 0.0009 L_grad: 0.0131 
Train Epoch: 97 [612/816 (75%)] loss: 0.0148 L_si: 0.0016 L_grad: 0.0132 
Train Epoch: 97 [648/816 (79%)] loss: 0.0151 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 97 [684/816 (84%)] loss: 0.0228 L_si: 0.0021 L_grad: 0.0207 
Train Epoch: 97 [720/816 (88%)] loss: 0.0114 L_si: 0.0005 L_grad: 0.0109 
Train Epoch: 97 [756/816 (93%)] loss: 0.0139 L_si: 0.0008 L_grad: 0.0131 
Train Epoch: 97 [792/816 (97%)] loss: 0.0139 L_si: 0.0006 L_grad: 0.0133 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.0448479950428009, 0.0352536104619503, 0.03377359360456467, 0.041192807257175446, 0.03617392107844353, 0.03665304183959961, 0.042767368257045746, 0.03909312188625336, 0.03648483380675316, 0.03529833257198334, 0.03758595138788223, 0.039405547082424164, 0.04227223992347717, 0.04047054797410965, 0.03642386943101883, 0.03940889239311218, 0.0350494422018528, 0.040388550609350204, 0.01459545362740755], 'L_si': [0.007487460970878601, 0.004943348467350006, 0.00479184091091156, 0.005937844514846802, 0.0056276097893714905, 0.0058449506759643555, 0.006171025335788727, 0.006077595055103302, 0.006330810487270355, 0.005528077483177185, 0.005805298686027527, 0.005961455404758453, 0.006966106593608856, 0.005793310701847076, 0.0056518688797950745, 0.006953045725822449, 0.0053893327713012695, 0.007090739905834198, 0.004941090941429138], 'L_grad': [0.0373605340719223, 0.030310261994600296, 0.028981754556298256, 0.035254962742328644, 0.030546311289072037, 0.030808093026280403, 0.03659634292125702, 0.033015526831150055, 0.030154023319482803, 0.029770255088806152, 0.031780652701854706, 0.03344409167766571, 0.03530613332986832, 0.03467723727226257, 0.030772000551223755, 0.032455846667289734, 0.02966010943055153, 0.033297810703516006, 0.009654362685978413]}
Train Epoch: 98 [0/816 (0%)] loss: 0.0140 L_si: 0.0010 L_grad: 0.0131 
Train Epoch: 98 [36/816 (4%)] loss: 0.0127 L_si: 0.0005 L_grad: 0.0122 
Train Epoch: 98 [72/816 (9%)] loss: 0.0159 L_si: 0.0010 L_grad: 0.0150 
Train Epoch: 98 [108/816 (13%)] loss: 0.0149 L_si: 0.0008 L_grad: 0.0141 
Train Epoch: 98 [144/816 (18%)] loss: 0.0177 L_si: 0.0024 L_grad: 0.0153 
Train Epoch: 98 [180/816 (22%)] loss: 0.0145 L_si: 0.0010 L_grad: 0.0135 
Train Epoch: 98 [216/816 (26%)] loss: 0.0176 L_si: 0.0019 L_grad: 0.0157 
Train Epoch: 98 [252/816 (31%)] loss: 0.0146 L_si: 0.0011 L_grad: 0.0135 
Train Epoch: 98 [288/816 (35%)] loss: 0.0201 L_si: 0.0021 L_grad: 0.0181 
Train Epoch: 98 [324/816 (40%)] loss: 0.0154 L_si: 0.0009 L_grad: 0.0145 
Train Epoch: 98 [360/816 (44%)] loss: 0.0236 L_si: 0.0023 L_grad: 0.0213 
Train Epoch: 98 [396/816 (49%)] loss: 0.0173 L_si: 0.0017 L_grad: 0.0155 
Train Epoch: 98 [432/816 (53%)] loss: 0.0147 L_si: 0.0008 L_grad: 0.0140 
Train Epoch: 98 [468/816 (57%)] loss: 0.0156 L_si: 0.0017 L_grad: 0.0139 
Train Epoch: 98 [504/816 (62%)] loss: 0.0228 L_si: 0.0023 L_grad: 0.0205 
Train Epoch: 98 [540/816 (66%)] loss: 0.0210 L_si: 0.0021 L_grad: 0.0188 
Train Epoch: 98 [576/816 (71%)] loss: 0.0202 L_si: 0.0028 L_grad: 0.0174 
Train Epoch: 98 [612/816 (75%)] loss: 0.0160 L_si: 0.0014 L_grad: 0.0146 
Train Epoch: 98 [648/816 (79%)] loss: 0.0194 L_si: 0.0016 L_grad: 0.0178 
Train Epoch: 98 [684/816 (84%)] loss: 0.0107 L_si: 0.0004 L_grad: 0.0103 
Train Epoch: 98 [720/816 (88%)] loss: 0.0140 L_si: 0.0012 L_grad: 0.0128 
Train Epoch: 98 [756/816 (93%)] loss: 0.0200 L_si: 0.0015 L_grad: 0.0185 
Train Epoch: 98 [792/816 (97%)] loss: 0.0200 L_si: 0.0016 L_grad: 0.0183 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.03820418566465378, 0.03404382988810539, 0.03391864150762558, 0.03937403857707977, 0.03576766699552536, 0.038295529782772064, 0.03558158501982689, 0.03778640925884247, 0.03902420401573181, 0.03885508328676224, 0.04176514595746994, 0.039684899151325226, 0.03879101201891899, 0.03722130507230759, 0.04013471305370331, 0.032917723059654236, 0.04013846069574356, 0.03712774068117142, 0.010506060905754566], 'L_si': [0.006549373269081116, 0.005168460309505463, 0.005749918520450592, 0.005495734512805939, 0.006882376968860626, 0.0071806758642196655, 0.006070435047149658, 0.006001807749271393, 0.006432361900806427, 0.006124354898929596, 0.007330961525440216, 0.006521753966808319, 0.006187871098518372, 0.005960643291473389, 0.007585480809211731, 0.00395829975605011, 0.005778133869171143, 0.006549164652824402, 0.0036082789301872253], 'L_grad': [0.03165481239557266, 0.02887536957859993, 0.028168724849820137, 0.033878304064273834, 0.028885290026664734, 0.0311148539185524, 0.02951114997267723, 0.031784601509571075, 0.032591842114925385, 0.03273072838783264, 0.034434184432029724, 0.03316314518451691, 0.03260314092040062, 0.0312606617808342, 0.03254923224449158, 0.028959421440958977, 0.03436032682657242, 0.030578577890992165, 0.006897781975567341]}
Train Epoch: 99 [0/816 (0%)] loss: 0.0166 L_si: 0.0026 L_grad: 0.0140 
Train Epoch: 99 [36/816 (4%)] loss: 0.0194 L_si: 0.0014 L_grad: 0.0180 
Train Epoch: 99 [72/816 (9%)] loss: 0.0140 L_si: 0.0009 L_grad: 0.0131 
Train Epoch: 99 [108/816 (13%)] loss: 0.0208 L_si: 0.0018 L_grad: 0.0190 
Train Epoch: 99 [144/816 (18%)] loss: 0.0111 L_si: 0.0004 L_grad: 0.0107 
Train Epoch: 99 [180/816 (22%)] loss: 0.0155 L_si: 0.0009 L_grad: 0.0146 
Train Epoch: 99 [216/816 (26%)] loss: 0.0136 L_si: 0.0006 L_grad: 0.0129 
Train Epoch: 99 [252/816 (31%)] loss: 0.0182 L_si: 0.0010 L_grad: 0.0172 
Train Epoch: 99 [288/816 (35%)] loss: 0.0147 L_si: 0.0010 L_grad: 0.0137 
Train Epoch: 99 [324/816 (40%)] loss: 0.0189 L_si: 0.0019 L_grad: 0.0170 
Train Epoch: 99 [360/816 (44%)] loss: 0.0149 L_si: 0.0010 L_grad: 0.0139 
Train Epoch: 99 [396/816 (49%)] loss: 0.0142 L_si: 0.0008 L_grad: 0.0134 
Train Epoch: 99 [432/816 (53%)] loss: 0.0167 L_si: 0.0011 L_grad: 0.0157 
Train Epoch: 99 [468/816 (57%)] loss: 0.0164 L_si: 0.0012 L_grad: 0.0152 
Train Epoch: 99 [504/816 (62%)] loss: 0.0146 L_si: 0.0009 L_grad: 0.0137 
Train Epoch: 99 [540/816 (66%)] loss: 0.0137 L_si: 0.0008 L_grad: 0.0129 
Train Epoch: 99 [576/816 (71%)] loss: 0.0138 L_si: 0.0009 L_grad: 0.0129 
Train Epoch: 99 [612/816 (75%)] loss: 0.0195 L_si: 0.0018 L_grad: 0.0177 
Train Epoch: 99 [648/816 (79%)] loss: 0.0159 L_si: 0.0018 L_grad: 0.0141 
Train Epoch: 99 [684/816 (84%)] loss: 0.0175 L_si: 0.0018 L_grad: 0.0157 
Train Epoch: 99 [720/816 (88%)] loss: 0.0178 L_si: 0.0021 L_grad: 0.0157 
Train Epoch: 99 [756/816 (93%)] loss: 0.0162 L_si: 0.0014 L_grad: 0.0148 
Train Epoch: 99 [792/816 (97%)] loss: 0.0145 L_si: 0.0008 L_grad: 0.0137 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
all losses in batch in validation:  {'loss': [0.04283379763364792, 0.03862903639674187, 0.031609684228897095, 0.03775724768638611, 0.03715825825929642, 0.03884483128786087, 0.034377582371234894, 0.03683045506477356, 0.03149677813053131, 0.04031043499708176, 0.04025422781705856, 0.035521648824214935, 0.03840615972876549, 0.039244312793016434, 0.04390208050608635, 0.04237069934606552, 0.03255022317171097, 0.037390969693660736, 0.016029581427574158], 'L_si': [0.006458081305027008, 0.006138160824775696, 0.004914969205856323, 0.006248928606510162, 0.006654776632785797, 0.006279893219470978, 0.005432151257991791, 0.006325572729110718, 0.005484670400619507, 0.006735615432262421, 0.006712146103382111, 0.004971161484718323, 0.007002256810665131, 0.006776362657546997, 0.007169075310230255, 0.0065118372440338135, 0.0050346627831459045, 0.005989357829093933, 0.007305055856704712], 'L_grad': [0.03637571632862091, 0.03249087557196617, 0.026694713160395622, 0.031508319079875946, 0.03050348162651062, 0.03256493806838989, 0.028945431113243103, 0.030504880473017693, 0.026012109592556953, 0.033574819564819336, 0.03354208171367645, 0.030550487339496613, 0.03140390291810036, 0.03246795013546944, 0.036733005195856094, 0.03585886210203171, 0.027515560388565063, 0.0314016118645668, 0.008724524639546871]}
Train Epoch: 100 [0/816 (0%)] loss: 0.0156 L_si: 0.0008 L_grad: 0.0148 
Train Epoch: 100 [36/816 (4%)] loss: 0.0140 L_si: 0.0010 L_grad: 0.0130 
Train Epoch: 100 [72/816 (9%)] loss: 0.0152 L_si: 0.0009 L_grad: 0.0142 
Train Epoch: 100 [108/816 (13%)] loss: 0.0229 L_si: 0.0019 L_grad: 0.0210 
Train Epoch: 100 [144/816 (18%)] loss: 0.0133 L_si: 0.0009 L_grad: 0.0124 
Train Epoch: 100 [180/816 (22%)] loss: 0.0186 L_si: 0.0028 L_grad: 0.0158 
Train Epoch: 100 [216/816 (26%)] loss: 0.0171 L_si: 0.0012 L_grad: 0.0159 
Train Epoch: 100 [252/816 (31%)] loss: 0.0148 L_si: 0.0007 L_grad: 0.0141 
Train Epoch: 100 [288/816 (35%)] loss: 0.0153 L_si: 0.0008 L_grad: 0.0145 
Train Epoch: 100 [324/816 (40%)] loss: 0.0154 L_si: 0.0017 L_grad: 0.0137 
Train Epoch: 100 [360/816 (44%)] loss: 0.0134 L_si: 0.0009 L_grad: 0.0125 
Train Epoch: 100 [396/816 (49%)] loss: 0.0147 L_si: 0.0010 L_grad: 0.0138 
Train Epoch: 100 [432/816 (53%)] loss: 0.0146 L_si: 0.0008 L_grad: 0.0138 
Train Epoch: 100 [468/816 (57%)] loss: 0.0210 L_si: 0.0020 L_grad: 0.0190 
Train Epoch: 100 [504/816 (62%)] loss: 0.0160 L_si: 0.0009 L_grad: 0.0151 
Train Epoch: 100 [540/816 (66%)] loss: 0.0163 L_si: 0.0015 L_grad: 0.0148 
Train Epoch: 100 [576/816 (71%)] loss: 0.0110 L_si: 0.0006 L_grad: 0.0104 
Train Epoch: 100 [612/816 (75%)] loss: 0.0179 L_si: 0.0014 L_grad: 0.0165 
Train Epoch: 100 [648/816 (79%)] loss: 0.0161 L_si: 0.0012 L_grad: 0.0150 
Train Epoch: 100 [684/816 (84%)] loss: 0.0156 L_si: 0.0012 L_grad: 0.0144 
Train Epoch: 100 [720/816 (88%)] loss: 0.0174 L_si: 0.0011 L_grad: 0.0163 
Train Epoch: 100 [756/816 (93%)] loss: 0.0135 L_si: 0.0014 L_grad: 0.0121 
Train Epoch: 100 [792/816 (97%)] loss: 0.0126 L_si: 0.0006 L_grad: 0.0120 
Validation: [0/228 (0%)]
Validation: [36/228 (16%)]
Validation: [72/228 (32%)]
Validation: [108/228 (47%)]
Validation: [144/228 (63%)]
Validation: [180/228 (79%)]
Validation: [216/228 (95%)]
Saving checkpoint: /root/autodl-tmp/train_il_100e/train_s2d_SpikeTransformer/checkpoint-epoch100-loss-0.0161.pth.tar ...
New Learning Rate: 0.000075
all losses in batch in validation:  {'loss': [0.03414009511470795, 0.03584551438689232, 0.03597190976142883, 0.038767796009778976, 0.03638269007205963, 0.037412725389003754, 0.038134023547172546, 0.03239869326353073, 0.03580674156546593, 0.036089181900024414, 0.036281682550907135, 0.03679792582988739, 0.03590631112456322, 0.03932782635092735, 0.04766486585140228, 0.03511916473507881, 0.0429626926779747, 0.03498431295156479, 0.015611658804118633], 'L_si': [0.005066119134426117, 0.00567975640296936, 0.004510939121246338, 0.00674787163734436, 0.00471758097410202, 0.005377590656280518, 0.006256908178329468, 0.004051484167575836, 0.005619540810585022, 0.004851631820201874, 0.004933647811412811, 0.006017319858074188, 0.006233371794223785, 0.006118841469287872, 0.008185155689716339, 0.005197077989578247, 0.0061444565653800964, 0.005072794854640961, 0.006220176815986633], 'L_grad': [0.02907397598028183, 0.03016575798392296, 0.031460970640182495, 0.032019924372434616, 0.03166510909795761, 0.032035134732723236, 0.03187711536884308, 0.028347210958600044, 0.030187200754880905, 0.03123755007982254, 0.031348034739494324, 0.030780604109168053, 0.029672939330339432, 0.03320898488163948, 0.039479710161685944, 0.029922086745500565, 0.036818236112594604, 0.029911519959568977, 0.009391481988132]}
